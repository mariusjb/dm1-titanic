{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7104d2ce",
   "metadata": {},
   "source": [
    "# Training and Evaluation of different Machine Learning Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "202391f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load required packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ce61838",
   "metadata": {},
   "source": [
    "## Train and Test Data\n",
    "We load the train and the test data which we splitted in _preprocessing.ipynb_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "de0a10cb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Age_true</th>\n",
       "      <th>AgeGroup</th>\n",
       "      <th>FareGroup</th>\n",
       "      <th>CabinLvl</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "      <th>Title_Master</th>\n",
       "      <th>Title_Mr</th>\n",
       "      <th>Title_Mrs</th>\n",
       "      <th>Title_Ms</th>\n",
       "      <th>Title_Noble</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pclass  SibSp  Parch  Age_true  AgeGroup  FareGroup  CabinLvl  Embarked_C  \\\n",
       "0       1      0      2         1         0          4         7           0   \n",
       "1       3      0      0         0         3          1         0           0   \n",
       "2       3      1      1         1         0          2         0           0   \n",
       "3       2      1      2         1         4          3         0           0   \n",
       "4       2      1      1         1         4          3         0           0   \n",
       "\n",
       "   Embarked_Q  Embarked_S  Title_Master  Title_Mr  Title_Mrs  Title_Ms  \\\n",
       "0           0           1             1         0          0         0   \n",
       "1           0           1             0         1          0         0   \n",
       "2           0           1             0         0          0         1   \n",
       "3           0           1             0         1          0         0   \n",
       "4           0           1             0         1          0         0   \n",
       "\n",
       "   Title_Noble  Survived  \n",
       "0            0         1  \n",
       "1            0         0  \n",
       "2            0         1  \n",
       "3            0         0  \n",
       "4            0         0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Age_true</th>\n",
       "      <th>AgeGroup</th>\n",
       "      <th>FareGroup</th>\n",
       "      <th>CabinLvl</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "      <th>Title_Master</th>\n",
       "      <th>Title_Mr</th>\n",
       "      <th>Title_Mrs</th>\n",
       "      <th>Title_Ms</th>\n",
       "      <th>Title_Noble</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pclass  SibSp  Parch  Age_true  AgeGroup  FareGroup  CabinLvl  Embarked_C  \\\n",
       "0       3      1      1         0         0          2         0           1   \n",
       "1       2      0      0         1         3          1         0           0   \n",
       "2       3      0      0         1         2          1         0           0   \n",
       "3       2      0      1         1         0          3         0           0   \n",
       "4       3      1      0         1         1          2         0           1   \n",
       "\n",
       "   Embarked_Q  Embarked_S  Title_Master  Title_Mr  Title_Mrs  Title_Ms  \\\n",
       "0           0           0             1         0          0         0   \n",
       "1           0           1             0         1          0         0   \n",
       "2           0           1             0         1          0         0   \n",
       "3           0           1             0         0          0         1   \n",
       "4           0           0             0         0          0         1   \n",
       "\n",
       "   Title_Noble  Survived  \n",
       "0            0         1  \n",
       "1            0         0  \n",
       "2            0         0  \n",
       "3            0         1  \n",
       "4            0         1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# read train and test data\n",
    "\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "# train_data\n",
    "train_data_files = sorted([f for f in os.listdir(\"data\") if (f.endswith(\".csv\") and (f.startswith(\"train_data_\")))], reverse=True)\n",
    "latest_train_data = train_data_files[0]\n",
    "train_data = pd.read_csv(f\"data/{latest_train_data}\")\n",
    "\n",
    "# drop new generated index column\n",
    "train_data.drop(train_data.columns[0], axis=1, inplace=True)\n",
    "display(train_data.head())\n",
    "\n",
    "# split train_data for models\n",
    "y_train = train_data['Survived']\n",
    "X_train = train_data.drop('Survived', axis=1)\n",
    "\n",
    "\n",
    "# test_data\n",
    "test_data_files = sorted([f for f in os.listdir(\"data\") if (f.endswith(\".csv\") and (f.startswith(\"test_data_\")))], reverse=True)\n",
    "latest_test_data = test_data_files[0]\n",
    "test_data = pd.read_csv(f\"data/{latest_test_data}\")\n",
    "\n",
    "#drop new generated index column\n",
    "test_data.drop(test_data.columns[0], axis=1, inplace=True)\n",
    "display(test_data.head())\n",
    "\n",
    "# split test_data for models\n",
    "y_test = test_data['Survived']\n",
    "X_test = test_data.drop('Survived', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72de1a37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "675b47e0",
   "metadata": {},
   "source": [
    "## Model 1: Baseline Model\n",
    "\n",
    "Option A: Our baseline model predicts \"No Survival\" (Class 0) for all passengers since 0 is the most common value of variable 'Survived' in the train data. This results in an accuracy of 58.58% and a f1 score of 0% on the test data.  \n",
    "Option B: Our baseline model predicts \"Survival\" (Class 1) for first-class passengers and \"No Survival\" (Class 0) if a passenger has ticket class 2 or 3. We determined those values by taking the most common value of the variable 'Survived' for each 'Pclass' in the train data. This results in an accuracy of 69.40% and a f1 score of 56.38% on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "149eba15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.585820895522388\n",
      "F1 Score = 0.0\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      1.00      0.74       157\n",
      "           1       0.00      0.00      0.00       111\n",
      "\n",
      "    accuracy                           0.59       268\n",
      "   macro avg       0.29      0.50      0.37       268\n",
      "weighted avg       0.34      0.59      0.43       268\n",
      "\n",
      "Confusion Matrix:\n",
      "[[157   0]\n",
      " [111   0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kikip\\anaconda3\\envs\\dm1_hws22\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\kikip\\anaconda3\\envs\\dm1_hws22\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\kikip\\anaconda3\\envs\\dm1_hws22\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Option A - predict \"No Survival\" for all passengers\n",
    "train_data.groupby('Survived').size()\n",
    "\n",
    "baseline_pred_A = pd.Series(np.zeros(len(y_test)))\n",
    "\n",
    "baseline_acc_A = accuracy_score(y_test, baseline_pred_A)\n",
    "print(\"Accuracy =\", baseline_acc_A) #0.585820895522388\n",
    "\n",
    "baseline_f1_A = f1_score(y_test, baseline_pred_A)\n",
    "print(\"F1 Score =\", baseline_f1_A) #0.0\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, baseline_pred_A))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, baseline_pred_A))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "62b13d8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pclass  Survived\n",
      "1       0            56\n",
      "        1            83\n",
      "2       0            69\n",
      "        1            63\n",
      "3       0           267\n",
      "        1            85\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Option B - predict \"Survival\" or \"No Survival\" based on 'Pclass'\n",
    "\n",
    "# for each 'PClass' find number of passengers that survived and did not survive\n",
    "print(train_data.groupby(['Pclass', 'Survived']).size())\n",
    "# if 'Pclass'==1, we predict 'Survived'=1, else we predict 'Survived'=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3a04d4b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.6940298507462687\n",
      "F1 Score = 0.5638297872340425\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.85      0.76       157\n",
      "           1       0.69      0.48      0.56       111\n",
      "\n",
      "    accuracy                           0.69       268\n",
      "   macro avg       0.69      0.66      0.66       268\n",
      "weighted avg       0.69      0.69      0.68       268\n",
      "\n",
      "Confusion Matrix:\n",
      "[[133  24]\n",
      " [ 58  53]]\n"
     ]
    }
   ],
   "source": [
    "# make prediction\n",
    "X_test['baseline_pred_B'] = 0\n",
    "X_test.loc[X_test['Pclass'] == 1, 'baseline_pred_B'] = 1\n",
    "baseline_pred_B = X_test.baseline_pred_B\n",
    "X_test.drop('baseline_pred_B', axis=1, inplace=True)\n",
    "\n",
    "# print performance measures\n",
    "baseline_acc_B = accuracy_score(y_test, baseline_pred_B)\n",
    "print(\"Accuracy =\", baseline_acc_B) #0.6940298507462687\n",
    "\n",
    "baseline_f1_B = f1_score(y_test, baseline_pred_B)\n",
    "print(\"F1 Score =\", baseline_f1_B) #0.5638297872340425\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, baseline_pred_B))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, baseline_pred_B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b87fee6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "41d03a15",
   "metadata": {},
   "source": [
    "## Model 2: XGBoost\n",
    "We train the _XGBClassifier_ from the _xgboost_-module. First, we train a simple model with the default parameters and then we perform grid search to determine the best hyper parameter combination for our data set.\n",
    "\n",
    "https://www.datacamp.com/tutorial/xgboost-in-python  \n",
    "https://thinkingneuron.com/how-to-create-a-classification-model-using-xgboost-in-python/  \n",
    "https://towardsdatascience.com/a-guide-to-xgboost-hyperparameters-87980c7f44a9 (Hyperparameter Cheatsheet)  \n",
    "https://towardsdatascience.com/beyond-grid-search-hypercharge-hyperparameter-tuning-for-xgboost-7c78f7a2929d (Step by Step Tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "556c7c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "949742ca",
   "metadata": {},
   "source": [
    "### Simple XGB-Classifier with default parameters\n",
    "As a baseline for the xgboost Classifier we train it with the default parameters which results in an accuracy of 79.10% and a f1 score of 73.08%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0a53a8be",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.8097014925373134\n",
      "F1 Score = 0.7536231884057971\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.89      0.84       157\n",
      "           1       0.81      0.70      0.75       111\n",
      "\n",
      "    accuracy                           0.81       268\n",
      "   macro avg       0.81      0.79      0.80       268\n",
      "weighted avg       0.81      0.81      0.81       268\n",
      "\n",
      "Confusion Matrix:\n",
      "[[139  18]\n",
      " [ 33  78]]\n"
     ]
    }
   ],
   "source": [
    "# simple XGB-Classifier with default parameters\n",
    "\n",
    "random.seed(10)\n",
    "\n",
    "xgb_simple = XGBClassifier()\n",
    "xgb_simple.fit(X_train, y_train)\n",
    "xgb_simple_pred = xgb_simple.predict(X_test)\n",
    "\n",
    "xgb_simple_acc = accuracy_score(y_test, xgb_simple_pred)\n",
    "print(\"Accuracy =\", xgb_simple_acc) #0.7910447761194029\n",
    "\n",
    "xgb_simple_f1 = f1_score(y_test, xgb_simple_pred)\n",
    "print(\"F1 Score =\", xgb_simple_f1) #0.7307692307692308\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, xgb_simple_pred))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, xgb_simple_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "079b5fd7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9fb5892c",
   "metadata": {},
   "source": [
    "### Hyper parameter-Tuning for best hyper parameter setting\n",
    "\n",
    "We perform grid search to find the best hyper parameter setting using the following hyper parameters:\n",
    "- _max_depth_\n",
    "- _subsample_\n",
    "- _gamma_\n",
    "- _colsample_bytree_\n",
    "- _colsample_bylevel_\n",
    "- _learning_rate_\n",
    "- _n _estimators_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "387ab105",
   "metadata": {},
   "source": [
    "#### First Attempt\n",
    "We start by tuning on a small grid, i.e., we only use two possible values for each hyper parameter. The best combination of hyper parameters for this grid search is: {'colsample_bylevel': 0.3, 'colsample_bytree': 0.3, 'learning_rate': 0.3, 'max_depth': 3, 'n_estimators': 50, 'subsample': 0.8}. Then, we train the XGBoost Classifier with this hyper parameter setting on the whole train data which results in an accuracy of 82.09% and a f1 score of 77.36%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "48dc982a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_colsample_bylevel</th>\n",
       "      <th>param_colsample_bytree</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_subsample</th>\n",
       "      <th>...</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.038495</td>\n",
       "      <td>0.003062</td>\n",
       "      <td>0.006681</td>\n",
       "      <td>0.000456</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>3</td>\n",
       "      <td>50</td>\n",
       "      <td>0.3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.818433</td>\n",
       "      <td>0.049987</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.036502</td>\n",
       "      <td>0.000662</td>\n",
       "      <td>0.006683</td>\n",
       "      <td>0.000457</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>3</td>\n",
       "      <td>50</td>\n",
       "      <td>0.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.824885</td>\n",
       "      <td>0.055524</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.068317</td>\n",
       "      <td>0.003433</td>\n",
       "      <td>0.006682</td>\n",
       "      <td>0.000639</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>0.3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.834485</td>\n",
       "      <td>0.040747</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.069015</td>\n",
       "      <td>0.006352</td>\n",
       "      <td>0.007181</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>0.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.887097</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.836073</td>\n",
       "      <td>0.052347</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.046675</td>\n",
       "      <td>0.004501</td>\n",
       "      <td>0.007482</td>\n",
       "      <td>0.000807</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "      <td>0.3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.818433</td>\n",
       "      <td>0.052027</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>0.092054</td>\n",
       "      <td>0.012248</td>\n",
       "      <td>0.007182</td>\n",
       "      <td>0.001244</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.7</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>0.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.823067</td>\n",
       "      <td>0.065056</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>0.049867</td>\n",
       "      <td>0.003569</td>\n",
       "      <td>0.006881</td>\n",
       "      <td>0.000699</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.7</td>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "      <td>0.3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.794470</td>\n",
       "      <td>0.050498</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>0.058244</td>\n",
       "      <td>0.007180</td>\n",
       "      <td>0.006883</td>\n",
       "      <td>0.001218</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.7</td>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "      <td>0.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.816846</td>\n",
       "      <td>0.053297</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>0.091609</td>\n",
       "      <td>0.011597</td>\n",
       "      <td>0.007080</td>\n",
       "      <td>0.000829</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.7</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>0.3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.803917</td>\n",
       "      <td>0.053965</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>0.106566</td>\n",
       "      <td>0.015866</td>\n",
       "      <td>0.008079</td>\n",
       "      <td>0.001574</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.7</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>0.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.812033</td>\n",
       "      <td>0.046151</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>64 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0        0.038495      0.003062         0.006681        0.000456   \n",
       "1        0.036502      0.000662         0.006683        0.000457   \n",
       "2        0.068317      0.003433         0.006682        0.000639   \n",
       "3        0.069015      0.006352         0.007181        0.000399   \n",
       "4        0.046675      0.004501         0.007482        0.000807   \n",
       "..            ...           ...              ...             ...   \n",
       "59       0.092054      0.012248         0.007182        0.001244   \n",
       "60       0.049867      0.003569         0.006881        0.000699   \n",
       "61       0.058244      0.007180         0.006883        0.001218   \n",
       "62       0.091609      0.011597         0.007080        0.000829   \n",
       "63       0.106566      0.015866         0.008079        0.001574   \n",
       "\n",
       "   param_colsample_bylevel param_colsample_bytree param_learning_rate  \\\n",
       "0                      0.3                    0.3                 0.3   \n",
       "1                      0.3                    0.3                 0.3   \n",
       "2                      0.3                    0.3                 0.3   \n",
       "3                      0.3                    0.3                 0.3   \n",
       "4                      0.3                    0.3                 0.3   \n",
       "..                     ...                    ...                 ...   \n",
       "59                     0.8                    0.8                 0.7   \n",
       "60                     0.8                    0.8                 0.7   \n",
       "61                     0.8                    0.8                 0.7   \n",
       "62                     0.8                    0.8                 0.7   \n",
       "63                     0.8                    0.8                 0.7   \n",
       "\n",
       "   param_max_depth param_n_estimators param_subsample  ... split3_test_score  \\\n",
       "0                3                 50             0.3  ...          0.854839   \n",
       "1                3                 50             0.8  ...          0.854839   \n",
       "2                3                100             0.3  ...          0.854839   \n",
       "3                3                100             0.8  ...          0.838710   \n",
       "4                5                 50             0.3  ...          0.854839   \n",
       "..             ...                ...             ...  ...               ...   \n",
       "59               3                100             0.8  ...          0.854839   \n",
       "60               5                 50             0.3  ...          0.838710   \n",
       "61               5                 50             0.8  ...          0.854839   \n",
       "62               5                100             0.3  ...          0.806452   \n",
       "63               5                100             0.8  ...          0.854839   \n",
       "\n",
       "    split4_test_score  split5_test_score  split6_test_score  \\\n",
       "0            0.790323           0.806452           0.790323   \n",
       "1            0.806452           0.870968           0.790323   \n",
       "2            0.822581           0.854839           0.790323   \n",
       "3            0.806452           0.887097           0.806452   \n",
       "4            0.774194           0.806452           0.806452   \n",
       "..                ...                ...                ...   \n",
       "59           0.790323           0.806452           0.822581   \n",
       "60           0.741935           0.741935           0.790323   \n",
       "61           0.790323           0.774194           0.822581   \n",
       "62           0.741935           0.741935           0.838710   \n",
       "63           0.790323           0.790323           0.854839   \n",
       "\n",
       "    split7_test_score  split8_test_score  split9_test_score  mean_test_score  \\\n",
       "0            0.822581           0.693548           0.854839         0.818433   \n",
       "1            0.822581           0.677419           0.854839         0.824885   \n",
       "2            0.822581           0.741935           0.838710         0.834485   \n",
       "3            0.822581           0.709677           0.854839         0.836073   \n",
       "4            0.806452           0.693548           0.870968         0.818433   \n",
       "..                ...                ...                ...              ...   \n",
       "59           0.758065           0.693548           0.806452         0.823067   \n",
       "60           0.838710           0.709677           0.854839         0.794470   \n",
       "61           0.822581           0.709677           0.838710         0.816846   \n",
       "62           0.774194           0.725806           0.838710         0.803917   \n",
       "63           0.774194           0.709677           0.806452         0.812033   \n",
       "\n",
       "    std_test_score  rank_test_score  \n",
       "0         0.049987               41  \n",
       "1         0.055524               23  \n",
       "2         0.040747                3  \n",
       "3         0.052347                2  \n",
       "4         0.052027               41  \n",
       "..             ...              ...  \n",
       "59        0.065056               33  \n",
       "60        0.050498               63  \n",
       "61        0.053297               50  \n",
       "62        0.053965               59  \n",
       "63        0.046151               53  \n",
       "\n",
       "[64 rows x 24 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score is 0.8360983102918587 with params {'colsample_bylevel': 0.3, 'colsample_bytree': 0.3, 'learning_rate': 0.7, 'max_depth': 3, 'n_estimators': 50, 'subsample': 0.8}\n"
     ]
    }
   ],
   "source": [
    "# First Attempt\n",
    "\n",
    "random.seed(10)\n",
    "\n",
    "# create an estimator\n",
    "xgb = XGBClassifier()\n",
    "\n",
    "# specify the parameter grid\n",
    "xgb_parameters = {\n",
    "    'max_depth': [3, 5]\n",
    "    , 'subsample': [0.3, 0.8]\n",
    "    , 'colsample_bytree': [0.3, 0.8]\n",
    "    , 'colsample_bylevel': [0.3, 0.8]\n",
    "    , 'learning_rate': [0.3, 0.7]\n",
    "    , 'n_estimators': [50, 100]\n",
    "    #, 'gamma': [0.5, 1, 3]\n",
    "}\n",
    "\n",
    "# specify the cross validation\n",
    "stratified_10_fold_cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "# create grid search instance\n",
    "xgb_grid_search = GridSearchCV(xgb, xgb_parameters, scoring='accuracy', cv=stratified_10_fold_cv)\n",
    "\n",
    "# run the grid search\n",
    "xgb_grid_search.fit(X_train, y_train)\n",
    "\n",
    "# print the results of all hyper parameter combinations\n",
    "xgb_grid_search_results_round1 = pd.DataFrame(xgb_grid_search.cv_results_)\n",
    "display(xgb_grid_search_results_round1)\n",
    "\n",
    "# print the best parameter setting\n",
    "print(\"best score is {} with params {}\".format(xgb_grid_search.best_score_, xgb_grid_search.best_params_))\n",
    "#best score is 0.8409114183307732 with params\n",
    "#{'colsample_bylevel': 0.3, 'colsample_bytree': 0.3, 'learning_rate': 0.3, 'max_depth': 3, 'n_estimators': 50, 'subsample': 0.8}\n",
    "\n",
    "# save dataframe\n",
    "from datetime import datetime\n",
    "date = str(datetime.now().date()).replace(\"-\", \"\")\n",
    "xgb_grid_search_results_round1.to_csv(f\"results/xgb_results_round1_{date}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4abbd5a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_subsample</th>\n",
       "      <th>param_colsample_bylevel</th>\n",
       "      <th>param_colsample_bytree</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>50</td>\n",
       "      <td>0.840911</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>100</td>\n",
       "      <td>0.840911</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.7</td>\n",
       "      <td>100</td>\n",
       "      <td>0.839247</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>5</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.3</td>\n",
       "      <td>50</td>\n",
       "      <td>0.836175</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>3</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.3</td>\n",
       "      <td>50</td>\n",
       "      <td>0.836098</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.7</td>\n",
       "      <td>50</td>\n",
       "      <td>0.797491</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.7</td>\n",
       "      <td>100</td>\n",
       "      <td>0.797491</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.7</td>\n",
       "      <td>100</td>\n",
       "      <td>0.795955</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.7</td>\n",
       "      <td>50</td>\n",
       "      <td>0.792857</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.7</td>\n",
       "      <td>50</td>\n",
       "      <td>0.784869</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>64 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   param_max_depth param_subsample param_colsample_bylevel  \\\n",
       "1                3             0.8                     0.3   \n",
       "3                3             0.8                     0.3   \n",
       "11               3             0.8                     0.3   \n",
       "21               5             0.8                     0.3   \n",
       "17               3             0.8                     0.3   \n",
       "..             ...             ...                     ...   \n",
       "28               5             0.3                     0.3   \n",
       "46               5             0.3                     0.8   \n",
       "30               5             0.3                     0.3   \n",
       "44               5             0.3                     0.8   \n",
       "60               5             0.3                     0.8   \n",
       "\n",
       "   param_colsample_bytree param_learning_rate param_n_estimators  \\\n",
       "1                     0.3                 0.3                 50   \n",
       "3                     0.3                 0.3                100   \n",
       "11                    0.3                 0.7                100   \n",
       "21                    0.8                 0.3                 50   \n",
       "17                    0.8                 0.3                 50   \n",
       "..                    ...                 ...                ...   \n",
       "28                    0.8                 0.7                 50   \n",
       "46                    0.3                 0.7                100   \n",
       "30                    0.8                 0.7                100   \n",
       "44                    0.3                 0.7                 50   \n",
       "60                    0.8                 0.7                 50   \n",
       "\n",
       "    mean_test_score  rank_test_score  \n",
       "1          0.840911                1  \n",
       "3          0.840911                1  \n",
       "11         0.839247                3  \n",
       "21         0.836175                4  \n",
       "17         0.836098                5  \n",
       "..              ...              ...  \n",
       "28         0.797491               60  \n",
       "46         0.797491               61  \n",
       "30         0.795955               62  \n",
       "44         0.792857               63  \n",
       "60         0.784869               64  \n",
       "\n",
       "[64 rows x 8 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# store relevant columns and sort by rank_test_score\n",
    "cols_round1 = ['param_max_depth', 'param_subsample', 'param_colsample_bylevel', 'param_colsample_bytree', 'param_learning_rate', 'param_n_estimators', 'mean_test_score', 'rank_test_score']\n",
    "xgb_results_round1_sorted = xgb_grid_search_results_round1[cols_round1]\n",
    "xgb_results_round1_sorted = xgb_results_round1_sorted.sort_values(by='rank_test_score')\n",
    "display(xgb_results_round1_sorted)\n",
    "\n",
    "# save dataframe\n",
    "from datetime import datetime\n",
    "date = str(datetime.now().date()).replace(\"-\", \"\")\n",
    "xgb_results_round1_sorted.to_csv(f\"results/xgb_results_round1_sorted_{date}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aec0ba87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.8208955223880597\n",
      "F1 Score = 0.7735849056603774\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.88      0.85       157\n",
      "           1       0.81      0.74      0.77       111\n",
      "\n",
      "    accuracy                           0.82       268\n",
      "   macro avg       0.82      0.81      0.81       268\n",
      "weighted avg       0.82      0.82      0.82       268\n",
      "\n",
      "Confusion Matrix:\n",
      "[[138  19]\n",
      " [ 29  82]]\n"
     ]
    }
   ],
   "source": [
    "# Fit and evaluate best model\n",
    "\n",
    "xgb_best = XGBClassifier(max_depth = 3, subsample = 0.8, colsample_bylevel = 0.3, colsample_bytree = 0.3, learning_rate = 0.3, n_estimators = 50)\n",
    "xgb_best.fit(X_train, y_train)\n",
    "xgb_best_pred = xgb_best.predict(X_test)\n",
    "\n",
    "xgb_best_acc = accuracy_score(y_test, xgb_best_pred)\n",
    "print(\"Accuracy =\", xgb_best_acc) #0.8208955223880597\n",
    "\n",
    "xgb_best_f1 = f1_score(y_test, xgb_best_pred)\n",
    "print(\"F1 Score =\", xgb_best_f1) #0.7735849056603774\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, xgb_best_pred))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, xgb_best_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "940748c1",
   "metadata": {},
   "source": [
    "#### Second Attempt\n",
    "We perform a hyper parameter tuning using the following parameters and values:  \n",
    "\n",
    "{'max_depth': [2,3,4,5]  \n",
    ", 'subsample': [0.5, 0.6, 0.7, 0.8, 0.9]  \n",
    ", 'colsample_bytree': [0.3, 0.4, 0.5, 0.6, 0.9]  \n",
    ", 'colsample_bylevel': [0.1, 0.2, 0.3, 0.4, 0.6, 0.7]  \n",
    ", 'learning_rate': [0.1, 0.15, 0.2, 0.25, 0.3, 0.4]  \n",
    ", 'n_estimators': [100, 150, 200, 250, 300]}  \n",
    "\n",
    "The best hyper parameter setting results to be {'colsample_bylevel': 0.4, 'colsample_bytree': 0.5, 'learning_rate': 0.15, 'max_depth': 2, 'n_estimators': 100, 'subsample': 0.7} which leads to an accuracy of 82.84% and a f1 score of 77.88% on the test data (after training the classifier on the whole train data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f96d3ba4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_colsample_bylevel</th>\n",
       "      <th>param_colsample_bytree</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_subsample</th>\n",
       "      <th>...</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.064527</td>\n",
       "      <td>0.004136</td>\n",
       "      <td>0.005885</td>\n",
       "      <td>0.000538</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.820020</td>\n",
       "      <td>0.048275</td>\n",
       "      <td>15186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.064327</td>\n",
       "      <td>0.002493</td>\n",
       "      <td>0.005885</td>\n",
       "      <td>0.000537</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.661290</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.823221</td>\n",
       "      <td>0.059057</td>\n",
       "      <td>12810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.063231</td>\n",
       "      <td>0.001954</td>\n",
       "      <td>0.005785</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.824782</td>\n",
       "      <td>0.057512</td>\n",
       "      <td>12084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.062235</td>\n",
       "      <td>0.001017</td>\n",
       "      <td>0.006082</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.661290</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.824834</td>\n",
       "      <td>0.059251</td>\n",
       "      <td>11402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.062333</td>\n",
       "      <td>0.002285</td>\n",
       "      <td>0.005784</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.828059</td>\n",
       "      <td>0.053977</td>\n",
       "      <td>8256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17995</th>\n",
       "      <td>0.228489</td>\n",
       "      <td>0.002462</td>\n",
       "      <td>0.007480</td>\n",
       "      <td>0.000499</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.802355</td>\n",
       "      <td>0.049888</td>\n",
       "      <td>17998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17996</th>\n",
       "      <td>0.228688</td>\n",
       "      <td>0.002142</td>\n",
       "      <td>0.007281</td>\n",
       "      <td>0.000457</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.800768</td>\n",
       "      <td>0.052893</td>\n",
       "      <td>17999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17997</th>\n",
       "      <td>0.228987</td>\n",
       "      <td>0.001197</td>\n",
       "      <td>0.007580</td>\n",
       "      <td>0.000488</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.810317</td>\n",
       "      <td>0.057193</td>\n",
       "      <td>17871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17998</th>\n",
       "      <td>0.228788</td>\n",
       "      <td>0.001620</td>\n",
       "      <td>0.007181</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.816692</td>\n",
       "      <td>0.055624</td>\n",
       "      <td>17108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17999</th>\n",
       "      <td>0.226893</td>\n",
       "      <td>0.002150</td>\n",
       "      <td>0.007381</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.818382</td>\n",
       "      <td>0.053516</td>\n",
       "      <td>16381</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18000 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0           0.064527      0.004136         0.005885        0.000538   \n",
       "1           0.064327      0.002493         0.005885        0.000537   \n",
       "2           0.063231      0.001954         0.005785        0.000399   \n",
       "3           0.062235      0.001017         0.006082        0.000300   \n",
       "4           0.062333      0.002285         0.005784        0.000399   \n",
       "...              ...           ...              ...             ...   \n",
       "17995       0.228489      0.002462         0.007480        0.000499   \n",
       "17996       0.228688      0.002142         0.007281        0.000457   \n",
       "17997       0.228987      0.001197         0.007580        0.000488   \n",
       "17998       0.228788      0.001620         0.007181        0.000399   \n",
       "17999       0.226893      0.002150         0.007381        0.000489   \n",
       "\n",
       "       param_colsample_bylevel  param_colsample_bytree  param_learning_rate  \\\n",
       "0                          0.1                     0.3                  0.1   \n",
       "1                          0.1                     0.3                  0.1   \n",
       "2                          0.1                     0.3                  0.1   \n",
       "3                          0.1                     0.3                  0.1   \n",
       "4                          0.1                     0.3                  0.1   \n",
       "...                        ...                     ...                  ...   \n",
       "17995                      0.7                     0.9                  0.4   \n",
       "17996                      0.7                     0.9                  0.4   \n",
       "17997                      0.7                     0.9                  0.4   \n",
       "17998                      0.7                     0.9                  0.4   \n",
       "17999                      0.7                     0.9                  0.4   \n",
       "\n",
       "       param_max_depth  param_n_estimators  param_subsample  ...  \\\n",
       "0                    2                 100              0.5  ...   \n",
       "1                    2                 100              0.6  ...   \n",
       "2                    2                 100              0.7  ...   \n",
       "3                    2                 100              0.8  ...   \n",
       "4                    2                 100              0.9  ...   \n",
       "...                ...                 ...              ...  ...   \n",
       "17995                5                 300              0.5  ...   \n",
       "17996                5                 300              0.6  ...   \n",
       "17997                5                 300              0.7  ...   \n",
       "17998                5                 300              0.8  ...   \n",
       "17999                5                 300              0.9  ...   \n",
       "\n",
       "      split3_test_score  split4_test_score  split5_test_score  \\\n",
       "0              0.822581           0.822581           0.806452   \n",
       "1              0.838710           0.822581           0.806452   \n",
       "2              0.838710           0.806452           0.806452   \n",
       "3              0.854839           0.822581           0.806452   \n",
       "4              0.854839           0.822581           0.838710   \n",
       "...                 ...                ...                ...   \n",
       "17995          0.822581           0.774194           0.806452   \n",
       "17996          0.822581           0.774194           0.790323   \n",
       "17997          0.870968           0.774194           0.774194   \n",
       "17998          0.822581           0.790323           0.774194   \n",
       "17999          0.806452           0.790323           0.774194   \n",
       "\n",
       "       split6_test_score  split7_test_score  split8_test_score  \\\n",
       "0               0.822581           0.806452           0.693548   \n",
       "1               0.838710           0.806452           0.661290   \n",
       "2               0.838710           0.806452           0.677419   \n",
       "3               0.854839           0.806452           0.661290   \n",
       "4               0.838710           0.806452           0.677419   \n",
       "...                  ...                ...                ...   \n",
       "17995           0.822581           0.774194           0.709677   \n",
       "17996           0.822581           0.790323           0.693548   \n",
       "17997           0.790323           0.790323           0.709677   \n",
       "17998           0.822581           0.790323           0.709677   \n",
       "17999           0.854839           0.790323           0.709677   \n",
       "\n",
       "       split9_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0               0.838710         0.820020        0.048275            15186  \n",
       "1               0.854839         0.823221        0.059057            12810  \n",
       "2               0.838710         0.824782        0.057512            12084  \n",
       "3               0.838710         0.824834        0.059251            11402  \n",
       "4               0.838710         0.828059        0.053977             8256  \n",
       "...                  ...              ...             ...              ...  \n",
       "17995           0.774194         0.802355        0.049888            17998  \n",
       "17996           0.790323         0.800768        0.052893            17999  \n",
       "17997           0.790323         0.810317        0.057193            17871  \n",
       "17998           0.806452         0.816692        0.055624            17108  \n",
       "17999           0.854839         0.818382        0.053516            16381  \n",
       "\n",
       "[18000 rows x 24 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score is 0.850563 with params {'colsample_bylevel': 0.4, 'colsample_bytree': 0.5, 'learning_rate': 0.15, 'max_depth': 2, 'n_estimators': 100, 'subsample': 0.7}\n"
     ]
    }
   ],
   "source": [
    "# read single parts of round 2, concatenate and update index and rank_test_score\n",
    "\n",
    "df1 = pd.read_csv(\"data\\\\xgb_results_full_1_bylevel=0.1_20221123.csv\")\n",
    "df1.drop(df1.columns[0], axis=1, inplace=True)\n",
    "\n",
    "df2 = pd.read_csv(\"data\\\\xgb_results_full_2_bylevel=0.2_20221123.csv\")\n",
    "df2.drop(df2.columns[0], axis=1, inplace=True)\n",
    "\n",
    "df3 = pd.read_csv(\"data\\\\xgb_results_full_3_bylevel=0.3_20221123.csv\")\n",
    "df3.drop(df3.columns[0], axis=1, inplace=True)\n",
    "\n",
    "df4 = pd.read_csv(\"data\\\\xgb_results_full_4_bylevel=0.4_20221123.csv\")\n",
    "df4.drop(df4.columns[0], axis=1, inplace=True)\n",
    "\n",
    "df5 = pd.read_csv(\"data\\\\xgb_results_full_5_bylevel=0.6_20221123.csv\")\n",
    "df5.drop(df5.columns[0], axis=1, inplace=True)\n",
    "\n",
    "df6 = pd.read_csv(\"data\\\\xgb_results_full_6_bylevel=0.7_20221123.csv\")\n",
    "df6.drop(df6.columns[0], axis=1, inplace=True)\n",
    "\n",
    "df_full = pd.concat([df1,df2,df3,df4,df5,df6])\n",
    "\n",
    "#assign correct rank\n",
    "df_full = df_full.sort_values(by='mean_test_score', ascending=False)\n",
    "df_full['rank_test_score'] = range(1, len(df_full)+1)\n",
    "\n",
    "#get correct order and set new index\n",
    "df_full = df_full.sort_values(by=['param_colsample_bylevel', 'param_colsample_bytree', 'param_learning_rate', 'param_max_depth', 'param_n_estimators', 'param_subsample'])\n",
    "xgb_grid_search_results_round2 = df_full.set_index(np.array(range(len(df_full))))\n",
    "display(xgb_grid_search_results_round2)\n",
    "\n",
    "print(\"best score is 0.850563 with params {'colsample_bylevel': 0.4, 'colsample_bytree': 0.5, 'learning_rate': 0.15, 'max_depth': 2, 'n_estimators': 100, 'subsample': 0.7}\")\n",
    "\n",
    "# save dataframe\n",
    "from datetime import datetime\n",
    "date = str(datetime.now().date()).replace(\"-\", \"\")\n",
    "xgb_grid_search_results_round2.to_csv(f\"results/xgb_results_round2_{date}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "435465f2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_colsample_bylevel</th>\n",
       "      <th>param_colsample_bytree</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_subsample</th>\n",
       "      <th>...</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.064527</td>\n",
       "      <td>0.004136</td>\n",
       "      <td>0.005885</td>\n",
       "      <td>0.000538</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.820020</td>\n",
       "      <td>0.048275</td>\n",
       "      <td>2840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.064327</td>\n",
       "      <td>0.002493</td>\n",
       "      <td>0.005885</td>\n",
       "      <td>0.000537</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.661290</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.823221</td>\n",
       "      <td>0.059057</td>\n",
       "      <td>5179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.063231</td>\n",
       "      <td>0.001954</td>\n",
       "      <td>0.005785</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.824782</td>\n",
       "      <td>0.057512</td>\n",
       "      <td>5860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.062235</td>\n",
       "      <td>0.001017</td>\n",
       "      <td>0.006082</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.661290</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.824834</td>\n",
       "      <td>0.059251</td>\n",
       "      <td>6715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.062333</td>\n",
       "      <td>0.002285</td>\n",
       "      <td>0.005784</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.828059</td>\n",
       "      <td>0.053977</td>\n",
       "      <td>9897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17995</th>\n",
       "      <td>0.228489</td>\n",
       "      <td>0.002462</td>\n",
       "      <td>0.007480</td>\n",
       "      <td>0.000499</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.802355</td>\n",
       "      <td>0.049888</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17996</th>\n",
       "      <td>0.228688</td>\n",
       "      <td>0.002142</td>\n",
       "      <td>0.007281</td>\n",
       "      <td>0.000457</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.800768</td>\n",
       "      <td>0.052893</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17997</th>\n",
       "      <td>0.228987</td>\n",
       "      <td>0.001197</td>\n",
       "      <td>0.007580</td>\n",
       "      <td>0.000488</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.810317</td>\n",
       "      <td>0.057193</td>\n",
       "      <td>139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17998</th>\n",
       "      <td>0.228788</td>\n",
       "      <td>0.001620</td>\n",
       "      <td>0.007181</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.816692</td>\n",
       "      <td>0.055624</td>\n",
       "      <td>893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17999</th>\n",
       "      <td>0.226893</td>\n",
       "      <td>0.002150</td>\n",
       "      <td>0.007381</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.818382</td>\n",
       "      <td>0.053516</td>\n",
       "      <td>1646</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18000 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0           0.064527      0.004136         0.005885        0.000538   \n",
       "1           0.064327      0.002493         0.005885        0.000537   \n",
       "2           0.063231      0.001954         0.005785        0.000399   \n",
       "3           0.062235      0.001017         0.006082        0.000300   \n",
       "4           0.062333      0.002285         0.005784        0.000399   \n",
       "...              ...           ...              ...             ...   \n",
       "17995       0.228489      0.002462         0.007480        0.000499   \n",
       "17996       0.228688      0.002142         0.007281        0.000457   \n",
       "17997       0.228987      0.001197         0.007580        0.000488   \n",
       "17998       0.228788      0.001620         0.007181        0.000399   \n",
       "17999       0.226893      0.002150         0.007381        0.000489   \n",
       "\n",
       "       param_colsample_bylevel  param_colsample_bytree  param_learning_rate  \\\n",
       "0                          0.1                     0.3                  0.1   \n",
       "1                          0.1                     0.3                  0.1   \n",
       "2                          0.1                     0.3                  0.1   \n",
       "3                          0.1                     0.3                  0.1   \n",
       "4                          0.1                     0.3                  0.1   \n",
       "...                        ...                     ...                  ...   \n",
       "17995                      0.7                     0.9                  0.4   \n",
       "17996                      0.7                     0.9                  0.4   \n",
       "17997                      0.7                     0.9                  0.4   \n",
       "17998                      0.7                     0.9                  0.4   \n",
       "17999                      0.7                     0.9                  0.4   \n",
       "\n",
       "       param_max_depth  param_n_estimators  param_subsample  ...  \\\n",
       "0                    2                 100              0.5  ...   \n",
       "1                    2                 100              0.6  ...   \n",
       "2                    2                 100              0.7  ...   \n",
       "3                    2                 100              0.8  ...   \n",
       "4                    2                 100              0.9  ...   \n",
       "...                ...                 ...              ...  ...   \n",
       "17995                5                 300              0.5  ...   \n",
       "17996                5                 300              0.6  ...   \n",
       "17997                5                 300              0.7  ...   \n",
       "17998                5                 300              0.8  ...   \n",
       "17999                5                 300              0.9  ...   \n",
       "\n",
       "      split3_test_score  split4_test_score  split5_test_score  \\\n",
       "0              0.822581           0.822581           0.806452   \n",
       "1              0.838710           0.822581           0.806452   \n",
       "2              0.838710           0.806452           0.806452   \n",
       "3              0.854839           0.822581           0.806452   \n",
       "4              0.854839           0.822581           0.838710   \n",
       "...                 ...                ...                ...   \n",
       "17995          0.822581           0.774194           0.806452   \n",
       "17996          0.822581           0.774194           0.790323   \n",
       "17997          0.870968           0.774194           0.774194   \n",
       "17998          0.822581           0.790323           0.774194   \n",
       "17999          0.806452           0.790323           0.774194   \n",
       "\n",
       "       split6_test_score  split7_test_score  split8_test_score  \\\n",
       "0               0.822581           0.806452           0.693548   \n",
       "1               0.838710           0.806452           0.661290   \n",
       "2               0.838710           0.806452           0.677419   \n",
       "3               0.854839           0.806452           0.661290   \n",
       "4               0.838710           0.806452           0.677419   \n",
       "...                  ...                ...                ...   \n",
       "17995           0.822581           0.774194           0.709677   \n",
       "17996           0.822581           0.790323           0.693548   \n",
       "17997           0.790323           0.790323           0.709677   \n",
       "17998           0.822581           0.790323           0.709677   \n",
       "17999           0.854839           0.790323           0.709677   \n",
       "\n",
       "       split9_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0               0.838710         0.820020        0.048275             2840  \n",
       "1               0.854839         0.823221        0.059057             5179  \n",
       "2               0.838710         0.824782        0.057512             5860  \n",
       "3               0.838710         0.824834        0.059251             6715  \n",
       "4               0.838710         0.828059        0.053977             9897  \n",
       "...                  ...              ...             ...              ...  \n",
       "17995           0.774194         0.802355        0.049888                3  \n",
       "17996           0.790323         0.800768        0.052893                2  \n",
       "17997           0.790323         0.810317        0.057193              139  \n",
       "17998           0.806452         0.816692        0.055624              893  \n",
       "17999           0.854839         0.818382        0.053516             1646  \n",
       "\n",
       "[18000 rows x 24 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Second Attempt\n",
    "\n",
    "random.seed(10)\n",
    "\n",
    "xgb = XGBClassifier()\n",
    "\n",
    "xgb_parameters = {'max_depth': [2,3,4,5]\n",
    "                , 'subsample': [0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "                , 'colsample_bytree': [0.3, 0.4, 0.5, 0.6, 0.9]\n",
    "                , 'colsample_bylevel': [0.1, 0.2, 0.3, 0.4, 0.6, 0.7]\n",
    "                , 'learning_rate': [0.1, 0.15, 0.2, 0.25, 0.3, 0.4]\n",
    "                , 'n_estimators': [100, 150, 200, 250, 300]}\n",
    "\n",
    "stratified_10_fold_cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "xgb_grid_search = GridSearchCV(xgb, xgb_parameters, scoring='accuracy', cv=stratified_10_fold_cv)\n",
    "\n",
    "xgb_grid_search.fit(X_train, y_train)\n",
    "\n",
    "xgb_grid_search_results_round2 = pd.DataFrame(xgb_grid_search.cv_results_)\n",
    "display(xgb_grid_search_results_round2)\n",
    "\n",
    "# print the best parameter setting\n",
    "print(\"best score is {} with params {}\".format(xgb_grid_search.best_score_, xgb_grid_search.best_params_))\n",
    "#best score is 0.850563 with params\n",
    "#{'colsample_bylevel': 0.4, 'colsample_bytree': 0.5, 'learning_rate': 0.15, 'max_depth': 2, 'n_estimators': 100, 'subsample': 0.7}\n",
    "\n",
    "# save dataframe\n",
    "from datetime import datetime\n",
    "date = str(datetime.now().date()).replace(\"-\", \"\")\n",
    "xgb_grid_search_results_round2.to_csv(f\"results/xgb_results_round2_{date}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e682b560",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_subsample</th>\n",
       "      <th>param_colsample_bylevel</th>\n",
       "      <th>param_colsample_bytree</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10302</th>\n",
       "      <td>2</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.15</td>\n",
       "      <td>100</td>\n",
       "      <td>0.850563</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7302</th>\n",
       "      <td>2</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.15</td>\n",
       "      <td>100</td>\n",
       "      <td>0.850563</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4976</th>\n",
       "      <td>5</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.15</td>\n",
       "      <td>100</td>\n",
       "      <td>0.850538</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1976</th>\n",
       "      <td>5</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.15</td>\n",
       "      <td>100</td>\n",
       "      <td>0.850538</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5419</th>\n",
       "      <td>2</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.10</td>\n",
       "      <td>250</td>\n",
       "      <td>0.849002</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7745</th>\n",
       "      <td>3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.40</td>\n",
       "      <td>300</td>\n",
       "      <td>0.803943</td>\n",
       "      <td>17996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13171</th>\n",
       "      <td>4</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.40</td>\n",
       "      <td>300</td>\n",
       "      <td>0.803917</td>\n",
       "      <td>17997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17995</th>\n",
       "      <td>5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.40</td>\n",
       "      <td>300</td>\n",
       "      <td>0.802355</td>\n",
       "      <td>17998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17996</th>\n",
       "      <td>5</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.40</td>\n",
       "      <td>300</td>\n",
       "      <td>0.800768</td>\n",
       "      <td>17999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17940</th>\n",
       "      <td>3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.40</td>\n",
       "      <td>250</td>\n",
       "      <td>0.800742</td>\n",
       "      <td>18000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18000 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       param_max_depth  param_subsample  param_colsample_bylevel  \\\n",
       "10302                2              0.7                      0.4   \n",
       "7302                 2              0.7                      0.3   \n",
       "4976                 5              0.6                      0.2   \n",
       "1976                 5              0.6                      0.1   \n",
       "5419                 2              0.9                      0.2   \n",
       "...                ...              ...                      ...   \n",
       "7745                 3              0.5                      0.3   \n",
       "13171                4              0.6                      0.6   \n",
       "17995                5              0.5                      0.7   \n",
       "17996                5              0.6                      0.7   \n",
       "17940                3              0.5                      0.7   \n",
       "\n",
       "       param_colsample_bytree  param_learning_rate  param_n_estimators  \\\n",
       "10302                     0.5                 0.15                 100   \n",
       "7302                      0.5                 0.15                 100   \n",
       "4976                      0.6                 0.15                 100   \n",
       "1976                      0.6                 0.15                 100   \n",
       "5419                      0.9                 0.10                 250   \n",
       "...                       ...                  ...                 ...   \n",
       "7745                      0.5                 0.40                 300   \n",
       "13171                     0.4                 0.40                 300   \n",
       "17995                     0.9                 0.40                 300   \n",
       "17996                     0.9                 0.40                 300   \n",
       "17940                     0.9                 0.40                 250   \n",
       "\n",
       "       mean_test_score  rank_test_score  \n",
       "10302         0.850563                1  \n",
       "7302          0.850563                2  \n",
       "4976          0.850538                3  \n",
       "1976          0.850538                4  \n",
       "5419          0.849002                5  \n",
       "...                ...              ...  \n",
       "7745          0.803943            17996  \n",
       "13171         0.803917            17997  \n",
       "17995         0.802355            17998  \n",
       "17996         0.800768            17999  \n",
       "17940         0.800742            18000  \n",
       "\n",
       "[18000 rows x 8 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# store relevant columns and sort by rank_test_score\n",
    "cols_round2 = ['param_max_depth', 'param_subsample', 'param_colsample_bylevel', 'param_colsample_bytree', 'param_learning_rate', 'param_n_estimators', 'mean_test_score', 'rank_test_score']\n",
    "xgb_results_round2_sorted = xgb_grid_search_results_round2[cols_round2]\n",
    "xgb_results_round2_sorted = xgb_results_round2_sorted.sort_values(by='rank_test_score')\n",
    "display(xgb_results_round2_sorted)\n",
    "\n",
    "# save dataframe\n",
    "from datetime import datetime\n",
    "date = str(datetime.now().date()).replace(\"-\", \"\")\n",
    "xgb_results_round2_sorted.to_csv(f\"results/xgb_results_round2_sorted_{date}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fc655747",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.8283582089552238\n",
      "F1 Score = 0.7788461538461539\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.90      0.86       157\n",
      "           1       0.84      0.73      0.78       111\n",
      "\n",
      "    accuracy                           0.83       268\n",
      "   macro avg       0.83      0.81      0.82       268\n",
      "weighted avg       0.83      0.83      0.83       268\n",
      "\n",
      "Confusion Matrix:\n",
      "[[141  16]\n",
      " [ 30  81]]\n"
     ]
    }
   ],
   "source": [
    "# Fit and evaluate best model\n",
    "\n",
    "xgb_best = XGBClassifier(max_depth = 2, subsample = 0.7, colsample_bylevel = 0.4, colsample_bytree = 0.5, learning_rate = 0.15, n_estimators = 100)\n",
    "xgb_best.fit(X_train, y_train)\n",
    "xgb_best_pred = xgb_best.predict(X_test)\n",
    "\n",
    "xgb_best_acc = accuracy_score(y_test, xgb_best_pred)\n",
    "print(\"Accuracy =\", xgb_best_acc) #0.8283582089552238\n",
    "\n",
    "xgb_best_f1 = f1_score(y_test, xgb_best_pred)\n",
    "print(\"F1 Score =\", xgb_best_f1) #0.7788461538461539\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, xgb_best_pred))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, xgb_best_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "250c3acb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d82f44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "66e8dc94",
   "metadata": {},
   "source": [
    "#### ausführlich"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1dfcf6bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_colsample_bylevel</th>\n",
       "      <th>param_colsample_bytree</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_subsample</th>\n",
       "      <th>...</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.064527</td>\n",
       "      <td>0.004136</td>\n",
       "      <td>0.005885</td>\n",
       "      <td>5.376236e-04</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.820020</td>\n",
       "      <td>0.048275</td>\n",
       "      <td>2651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.064327</td>\n",
       "      <td>0.002493</td>\n",
       "      <td>0.005885</td>\n",
       "      <td>5.374151e-04</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.661290</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.823221</td>\n",
       "      <td>0.059057</td>\n",
       "      <td>2358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.063231</td>\n",
       "      <td>0.001954</td>\n",
       "      <td>0.005785</td>\n",
       "      <td>3.990535e-04</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.824782</td>\n",
       "      <td>0.057512</td>\n",
       "      <td>2252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.062235</td>\n",
       "      <td>0.001017</td>\n",
       "      <td>0.006082</td>\n",
       "      <td>3.001655e-04</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.661290</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.824834</td>\n",
       "      <td>0.059251</td>\n",
       "      <td>2175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.062333</td>\n",
       "      <td>0.002285</td>\n",
       "      <td>0.005784</td>\n",
       "      <td>3.991850e-04</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.828059</td>\n",
       "      <td>0.053977</td>\n",
       "      <td>1747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2995</th>\n",
       "      <td>0.180018</td>\n",
       "      <td>0.001496</td>\n",
       "      <td>0.007081</td>\n",
       "      <td>2.993507e-04</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.887097</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.828085</td>\n",
       "      <td>0.048801</td>\n",
       "      <td>1701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2996</th>\n",
       "      <td>0.182212</td>\n",
       "      <td>0.003339</td>\n",
       "      <td>0.006982</td>\n",
       "      <td>4.460618e-04</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.826421</td>\n",
       "      <td>0.052840</td>\n",
       "      <td>1992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2997</th>\n",
       "      <td>0.181813</td>\n",
       "      <td>0.001548</td>\n",
       "      <td>0.007082</td>\n",
       "      <td>2.990570e-04</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.824808</td>\n",
       "      <td>0.053239</td>\n",
       "      <td>2204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998</th>\n",
       "      <td>0.181666</td>\n",
       "      <td>0.001723</td>\n",
       "      <td>0.006982</td>\n",
       "      <td>4.529953e-07</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.823272</td>\n",
       "      <td>0.043729</td>\n",
       "      <td>2305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999</th>\n",
       "      <td>0.182113</td>\n",
       "      <td>0.002005</td>\n",
       "      <td>0.007081</td>\n",
       "      <td>2.993824e-04</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.823169</td>\n",
       "      <td>0.050024</td>\n",
       "      <td>2460</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0          0.064527      0.004136         0.005885    5.376236e-04   \n",
       "1          0.064327      0.002493         0.005885    5.374151e-04   \n",
       "2          0.063231      0.001954         0.005785    3.990535e-04   \n",
       "3          0.062235      0.001017         0.006082    3.001655e-04   \n",
       "4          0.062333      0.002285         0.005784    3.991850e-04   \n",
       "...             ...           ...              ...             ...   \n",
       "2995       0.180018      0.001496         0.007081    2.993507e-04   \n",
       "2996       0.182212      0.003339         0.006982    4.460618e-04   \n",
       "2997       0.181813      0.001548         0.007082    2.990570e-04   \n",
       "2998       0.181666      0.001723         0.006982    4.529953e-07   \n",
       "2999       0.182113      0.002005         0.007081    2.993824e-04   \n",
       "\n",
       "      param_colsample_bylevel  param_colsample_bytree  param_learning_rate  \\\n",
       "0                         0.1                     0.3                  0.1   \n",
       "1                         0.1                     0.3                  0.1   \n",
       "2                         0.1                     0.3                  0.1   \n",
       "3                         0.1                     0.3                  0.1   \n",
       "4                         0.1                     0.3                  0.1   \n",
       "...                       ...                     ...                  ...   \n",
       "2995                      0.1                     0.9                  0.4   \n",
       "2996                      0.1                     0.9                  0.4   \n",
       "2997                      0.1                     0.9                  0.4   \n",
       "2998                      0.1                     0.9                  0.4   \n",
       "2999                      0.1                     0.9                  0.4   \n",
       "\n",
       "      param_max_depth  param_n_estimators  param_subsample  ...  \\\n",
       "0                   2                 100              0.5  ...   \n",
       "1                   2                 100              0.6  ...   \n",
       "2                   2                 100              0.7  ...   \n",
       "3                   2                 100              0.8  ...   \n",
       "4                   2                 100              0.9  ...   \n",
       "...               ...                 ...              ...  ...   \n",
       "2995                5                 300              0.5  ...   \n",
       "2996                5                 300              0.6  ...   \n",
       "2997                5                 300              0.7  ...   \n",
       "2998                5                 300              0.8  ...   \n",
       "2999                5                 300              0.9  ...   \n",
       "\n",
       "     split3_test_score  split4_test_score  split5_test_score  \\\n",
       "0             0.822581           0.822581           0.806452   \n",
       "1             0.838710           0.822581           0.806452   \n",
       "2             0.838710           0.806452           0.806452   \n",
       "3             0.854839           0.822581           0.806452   \n",
       "4             0.854839           0.822581           0.838710   \n",
       "...                ...                ...                ...   \n",
       "2995          0.887097           0.806452           0.774194   \n",
       "2996          0.870968           0.774194           0.758065   \n",
       "2997          0.870968           0.790323           0.790323   \n",
       "2998          0.870968           0.790323           0.774194   \n",
       "2999          0.854839           0.806452           0.774194   \n",
       "\n",
       "      split6_test_score  split7_test_score  split8_test_score  \\\n",
       "0              0.822581           0.806452           0.693548   \n",
       "1              0.838710           0.806452           0.661290   \n",
       "2              0.838710           0.806452           0.677419   \n",
       "3              0.854839           0.806452           0.661290   \n",
       "4              0.838710           0.806452           0.677419   \n",
       "...                 ...                ...                ...   \n",
       "2995           0.822581           0.822581           0.725806   \n",
       "2996           0.806452           0.838710           0.741935   \n",
       "2997           0.790323           0.854839           0.709677   \n",
       "2998           0.806452           0.854839           0.741935   \n",
       "2999           0.806452           0.822581           0.725806   \n",
       "\n",
       "      split9_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0              0.838710         0.820020        0.048275             2651  \n",
       "1              0.854839         0.823221        0.059057             2358  \n",
       "2              0.838710         0.824782        0.057512             2252  \n",
       "3              0.838710         0.824834        0.059251             2175  \n",
       "4              0.838710         0.828059        0.053977             1747  \n",
       "...                 ...              ...             ...              ...  \n",
       "2995           0.854839         0.828085        0.048801             1701  \n",
       "2996           0.854839         0.826421        0.052840             1992  \n",
       "2997           0.822581         0.824808        0.053239             2204  \n",
       "2998           0.822581         0.823272        0.043729             2305  \n",
       "2999           0.806452         0.823169        0.050024             2460  \n",
       "\n",
       "[3000 rows x 24 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score is 0.8505376344086022 with params {'colsample_bylevel': 0.1, 'colsample_bytree': 0.6, 'learning_rate': 0.15, 'max_depth': 5, 'n_estimators': 100, 'subsample': 0.6}\n"
     ]
    }
   ],
   "source": [
    "df1 = pd.read_csv(\"data\\\\xgb_results_full_1_bylevel=0.1_20221123.csv\")\n",
    "df1.drop(df1.columns[0], axis=1, inplace=True)\n",
    "display(df1)\n",
    "print(\"best score is 0.8505376344086022 with params {'colsample_bylevel': 0.1, 'colsample_bytree': 0.6, 'learning_rate': 0.15, 'max_depth': 5, 'n_estimators': 100, 'subsample': 0.6}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "714bfa65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_colsample_bylevel</th>\n",
       "      <th>param_colsample_bytree</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_subsample</th>\n",
       "      <th>...</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.064527</td>\n",
       "      <td>0.004136</td>\n",
       "      <td>0.005885</td>\n",
       "      <td>5.376236e-04</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.820020</td>\n",
       "      <td>0.048275</td>\n",
       "      <td>2651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.064327</td>\n",
       "      <td>0.002493</td>\n",
       "      <td>0.005885</td>\n",
       "      <td>5.374151e-04</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.661290</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.823221</td>\n",
       "      <td>0.059057</td>\n",
       "      <td>2358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.063231</td>\n",
       "      <td>0.001954</td>\n",
       "      <td>0.005785</td>\n",
       "      <td>3.990535e-04</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.824782</td>\n",
       "      <td>0.057512</td>\n",
       "      <td>2252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.062235</td>\n",
       "      <td>0.001017</td>\n",
       "      <td>0.006082</td>\n",
       "      <td>3.001655e-04</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.661290</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.824834</td>\n",
       "      <td>0.059251</td>\n",
       "      <td>2175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.062333</td>\n",
       "      <td>0.002285</td>\n",
       "      <td>0.005784</td>\n",
       "      <td>3.991850e-04</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.828059</td>\n",
       "      <td>0.053977</td>\n",
       "      <td>1747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2995</th>\n",
       "      <td>0.180018</td>\n",
       "      <td>0.001496</td>\n",
       "      <td>0.007081</td>\n",
       "      <td>2.993507e-04</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.887097</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.828085</td>\n",
       "      <td>0.048801</td>\n",
       "      <td>1701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2996</th>\n",
       "      <td>0.182212</td>\n",
       "      <td>0.003339</td>\n",
       "      <td>0.006982</td>\n",
       "      <td>4.460618e-04</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.826421</td>\n",
       "      <td>0.052840</td>\n",
       "      <td>1992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2997</th>\n",
       "      <td>0.181813</td>\n",
       "      <td>0.001548</td>\n",
       "      <td>0.007082</td>\n",
       "      <td>2.990570e-04</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.824808</td>\n",
       "      <td>0.053239</td>\n",
       "      <td>2204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998</th>\n",
       "      <td>0.181666</td>\n",
       "      <td>0.001723</td>\n",
       "      <td>0.006982</td>\n",
       "      <td>4.529953e-07</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.823272</td>\n",
       "      <td>0.043729</td>\n",
       "      <td>2305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999</th>\n",
       "      <td>0.182113</td>\n",
       "      <td>0.002005</td>\n",
       "      <td>0.007081</td>\n",
       "      <td>2.993824e-04</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.823169</td>\n",
       "      <td>0.050024</td>\n",
       "      <td>2460</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0          0.064527      0.004136         0.005885    5.376236e-04   \n",
       "1          0.064327      0.002493         0.005885    5.374151e-04   \n",
       "2          0.063231      0.001954         0.005785    3.990535e-04   \n",
       "3          0.062235      0.001017         0.006082    3.001655e-04   \n",
       "4          0.062333      0.002285         0.005784    3.991850e-04   \n",
       "...             ...           ...              ...             ...   \n",
       "2995       0.180018      0.001496         0.007081    2.993507e-04   \n",
       "2996       0.182212      0.003339         0.006982    4.460618e-04   \n",
       "2997       0.181813      0.001548         0.007082    2.990570e-04   \n",
       "2998       0.181666      0.001723         0.006982    4.529953e-07   \n",
       "2999       0.182113      0.002005         0.007081    2.993824e-04   \n",
       "\n",
       "     param_colsample_bylevel param_colsample_bytree param_learning_rate  \\\n",
       "0                        0.1                    0.3                 0.1   \n",
       "1                        0.1                    0.3                 0.1   \n",
       "2                        0.1                    0.3                 0.1   \n",
       "3                        0.1                    0.3                 0.1   \n",
       "4                        0.1                    0.3                 0.1   \n",
       "...                      ...                    ...                 ...   \n",
       "2995                     0.1                    0.9                 0.4   \n",
       "2996                     0.1                    0.9                 0.4   \n",
       "2997                     0.1                    0.9                 0.4   \n",
       "2998                     0.1                    0.9                 0.4   \n",
       "2999                     0.1                    0.9                 0.4   \n",
       "\n",
       "     param_max_depth param_n_estimators param_subsample  ...  \\\n",
       "0                  2                100             0.5  ...   \n",
       "1                  2                100             0.6  ...   \n",
       "2                  2                100             0.7  ...   \n",
       "3                  2                100             0.8  ...   \n",
       "4                  2                100             0.9  ...   \n",
       "...              ...                ...             ...  ...   \n",
       "2995               5                300             0.5  ...   \n",
       "2996               5                300             0.6  ...   \n",
       "2997               5                300             0.7  ...   \n",
       "2998               5                300             0.8  ...   \n",
       "2999               5                300             0.9  ...   \n",
       "\n",
       "     split3_test_score  split4_test_score  split5_test_score  \\\n",
       "0             0.822581           0.822581           0.806452   \n",
       "1             0.838710           0.822581           0.806452   \n",
       "2             0.838710           0.806452           0.806452   \n",
       "3             0.854839           0.822581           0.806452   \n",
       "4             0.854839           0.822581           0.838710   \n",
       "...                ...                ...                ...   \n",
       "2995          0.887097           0.806452           0.774194   \n",
       "2996          0.870968           0.774194           0.758065   \n",
       "2997          0.870968           0.790323           0.790323   \n",
       "2998          0.870968           0.790323           0.774194   \n",
       "2999          0.854839           0.806452           0.774194   \n",
       "\n",
       "      split6_test_score  split7_test_score  split8_test_score  \\\n",
       "0              0.822581           0.806452           0.693548   \n",
       "1              0.838710           0.806452           0.661290   \n",
       "2              0.838710           0.806452           0.677419   \n",
       "3              0.854839           0.806452           0.661290   \n",
       "4              0.838710           0.806452           0.677419   \n",
       "...                 ...                ...                ...   \n",
       "2995           0.822581           0.822581           0.725806   \n",
       "2996           0.806452           0.838710           0.741935   \n",
       "2997           0.790323           0.854839           0.709677   \n",
       "2998           0.806452           0.854839           0.741935   \n",
       "2999           0.806452           0.822581           0.725806   \n",
       "\n",
       "      split9_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0              0.838710         0.820020        0.048275             2651  \n",
       "1              0.854839         0.823221        0.059057             2358  \n",
       "2              0.838710         0.824782        0.057512             2252  \n",
       "3              0.838710         0.824834        0.059251             2175  \n",
       "4              0.838710         0.828059        0.053977             1747  \n",
       "...                 ...              ...             ...              ...  \n",
       "2995           0.854839         0.828085        0.048801             1701  \n",
       "2996           0.854839         0.826421        0.052840             1992  \n",
       "2997           0.822581         0.824808        0.053239             2204  \n",
       "2998           0.822581         0.823272        0.043729             2305  \n",
       "2999           0.806452         0.823169        0.050024             2460  \n",
       "\n",
       "[3000 rows x 24 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score is 0.8505376344086022 with params {'colsample_bylevel': 0.1, 'colsample_bytree': 0.6, 'learning_rate': 0.15, 'max_depth': 5, 'n_estimators': 100, 'subsample': 0.6}\n"
     ]
    }
   ],
   "source": [
    "# Full Tuning - Part 1\n",
    "random.seed(10)\n",
    "\n",
    "xgb = XGBClassifier()\n",
    "\n",
    "xgb_parameters = {'max_depth': [2,3,4,5]\n",
    "                   , 'subsample': [0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "                   , 'colsample_bytree': [0.3, 0.4, 0.5, 0.6, 0.9]\n",
    "                   , 'colsample_bylevel': [0.1]\n",
    "                   , 'learning_rate': [0.1, 0.15, 0.2, 0.25, 0.3, 0.4]\n",
    "                   , 'n_estimators': [100, 150, 200, 250, 300]}\n",
    "\n",
    "stratified_10_fold_cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "xgb_grid_search = GridSearchCV(xgb, xgb_parameters, scoring='accuracy', cv=stratified_10_fold_cv)\n",
    "\n",
    "xgb_grid_search.fit(X_train, y_train)\n",
    "\n",
    "xgb_grid_search_results_full_1 = pd.DataFrame(xgb_grid_search.cv_results_)\n",
    "display(xgb_grid_search_results_full_1)\n",
    "\n",
    "print(\"best score is {} with params {}\".format(xgb_grid_search.best_score_, xgb_grid_search.best_params_))\n",
    "\n",
    "# best values for\n",
    "\n",
    "# save dataframe\n",
    "from datetime import datetime\n",
    "date = str(datetime.now().date()).replace(\"-\", \"\")\n",
    "xgb_grid_search_results_full_1.to_csv(f\"results/xgb_results_full_round2_1_bylevel=0.1_{date}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a821b1df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_colsample_bylevel</th>\n",
       "      <th>param_colsample_bytree</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_subsample</th>\n",
       "      <th>...</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.062133</td>\n",
       "      <td>0.002485</td>\n",
       "      <td>0.006284</td>\n",
       "      <td>0.000639</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.820020</td>\n",
       "      <td>0.048275</td>\n",
       "      <td>2663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.063131</td>\n",
       "      <td>0.003027</td>\n",
       "      <td>0.006683</td>\n",
       "      <td>0.000457</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.661290</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.823221</td>\n",
       "      <td>0.059057</td>\n",
       "      <td>2338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.060438</td>\n",
       "      <td>0.000798</td>\n",
       "      <td>0.006782</td>\n",
       "      <td>0.000398</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.824782</td>\n",
       "      <td>0.057512</td>\n",
       "      <td>2222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.059541</td>\n",
       "      <td>0.000779</td>\n",
       "      <td>0.006682</td>\n",
       "      <td>0.000457</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.661290</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.824834</td>\n",
       "      <td>0.059251</td>\n",
       "      <td>2132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.059840</td>\n",
       "      <td>0.001092</td>\n",
       "      <td>0.006782</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.828059</td>\n",
       "      <td>0.053977</td>\n",
       "      <td>1661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2995</th>\n",
       "      <td>0.195577</td>\n",
       "      <td>0.001636</td>\n",
       "      <td>0.017653</td>\n",
       "      <td>0.031683</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.819918</td>\n",
       "      <td>0.052433</td>\n",
       "      <td>2744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2996</th>\n",
       "      <td>0.221308</td>\n",
       "      <td>0.011234</td>\n",
       "      <td>0.006782</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.819995</td>\n",
       "      <td>0.058351</td>\n",
       "      <td>2693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2997</th>\n",
       "      <td>0.226194</td>\n",
       "      <td>0.002309</td>\n",
       "      <td>0.007082</td>\n",
       "      <td>0.000299</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.821582</td>\n",
       "      <td>0.054587</td>\n",
       "      <td>2581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998</th>\n",
       "      <td>0.199167</td>\n",
       "      <td>0.006213</td>\n",
       "      <td>0.007381</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.823195</td>\n",
       "      <td>0.052389</td>\n",
       "      <td>2389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999</th>\n",
       "      <td>0.196574</td>\n",
       "      <td>0.001133</td>\n",
       "      <td>0.007480</td>\n",
       "      <td>0.000499</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.826395</td>\n",
       "      <td>0.049816</td>\n",
       "      <td>2002</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0          0.062133      0.002485         0.006284        0.000639   \n",
       "1          0.063131      0.003027         0.006683        0.000457   \n",
       "2          0.060438      0.000798         0.006782        0.000398   \n",
       "3          0.059541      0.000779         0.006682        0.000457   \n",
       "4          0.059840      0.001092         0.006782        0.000399   \n",
       "...             ...           ...              ...             ...   \n",
       "2995       0.195577      0.001636         0.017653        0.031683   \n",
       "2996       0.221308      0.011234         0.006782        0.000399   \n",
       "2997       0.226194      0.002309         0.007082        0.000299   \n",
       "2998       0.199167      0.006213         0.007381        0.000489   \n",
       "2999       0.196574      0.001133         0.007480        0.000499   \n",
       "\n",
       "      param_colsample_bylevel  param_colsample_bytree  param_learning_rate  \\\n",
       "0                         0.2                     0.3                  0.1   \n",
       "1                         0.2                     0.3                  0.1   \n",
       "2                         0.2                     0.3                  0.1   \n",
       "3                         0.2                     0.3                  0.1   \n",
       "4                         0.2                     0.3                  0.1   \n",
       "...                       ...                     ...                  ...   \n",
       "2995                      0.2                     0.9                  0.4   \n",
       "2996                      0.2                     0.9                  0.4   \n",
       "2997                      0.2                     0.9                  0.4   \n",
       "2998                      0.2                     0.9                  0.4   \n",
       "2999                      0.2                     0.9                  0.4   \n",
       "\n",
       "      param_max_depth  param_n_estimators  param_subsample  ...  \\\n",
       "0                   2                 100              0.5  ...   \n",
       "1                   2                 100              0.6  ...   \n",
       "2                   2                 100              0.7  ...   \n",
       "3                   2                 100              0.8  ...   \n",
       "4                   2                 100              0.9  ...   \n",
       "...               ...                 ...              ...  ...   \n",
       "2995                5                 300              0.5  ...   \n",
       "2996                5                 300              0.6  ...   \n",
       "2997                5                 300              0.7  ...   \n",
       "2998                5                 300              0.8  ...   \n",
       "2999                5                 300              0.9  ...   \n",
       "\n",
       "     split3_test_score  split4_test_score  split5_test_score  \\\n",
       "0             0.822581           0.822581           0.806452   \n",
       "1             0.838710           0.822581           0.806452   \n",
       "2             0.838710           0.806452           0.806452   \n",
       "3             0.854839           0.822581           0.806452   \n",
       "4             0.854839           0.822581           0.838710   \n",
       "...                ...                ...                ...   \n",
       "2995          0.822581           0.806452           0.774194   \n",
       "2996          0.838710           0.806452           0.774194   \n",
       "2997          0.838710           0.790323           0.758065   \n",
       "2998          0.838710           0.822581           0.774194   \n",
       "2999          0.838710           0.806452           0.790323   \n",
       "\n",
       "      split6_test_score  split7_test_score  split8_test_score  \\\n",
       "0              0.822581           0.806452           0.693548   \n",
       "1              0.838710           0.806452           0.661290   \n",
       "2              0.838710           0.806452           0.677419   \n",
       "3              0.854839           0.806452           0.661290   \n",
       "4              0.838710           0.806452           0.677419   \n",
       "...                 ...                ...                ...   \n",
       "2995           0.790323           0.790323           0.741935   \n",
       "2996           0.822581           0.838710           0.693548   \n",
       "2997           0.806452           0.854839           0.725806   \n",
       "2998           0.838710           0.822581           0.725806   \n",
       "2999           0.838710           0.822581           0.725806   \n",
       "\n",
       "      split9_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0              0.838710         0.820020        0.048275             2663  \n",
       "1              0.854839         0.823221        0.059057             2338  \n",
       "2              0.838710         0.824782        0.057512             2222  \n",
       "3              0.838710         0.824834        0.059251             2132  \n",
       "4              0.838710         0.828059        0.053977             1661  \n",
       "...                 ...              ...             ...              ...  \n",
       "2995           0.822581         0.819918        0.052433             2744  \n",
       "2996           0.822581         0.819995        0.058351             2693  \n",
       "2997           0.822581         0.821582        0.054587             2581  \n",
       "2998           0.790323         0.823195        0.052389             2389  \n",
       "2999           0.806452         0.826395        0.049816             2002  \n",
       "\n",
       "[3000 rows x 24 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score is 0.8505376344086022 with params {'colsample_bylevel': 0.2, 'colsample_bytree': 0.6, 'learning_rate': 0.15, 'max_depth': 5, 'n_estimators': 100, 'subsample': 0.6}\n"
     ]
    }
   ],
   "source": [
    "df2 = pd.read_csv(\"data\\\\xgb_results_full_2_bylevel=0.2_20221123.csv\")\n",
    "df2.drop(df2.columns[0], axis=1, inplace=True)\n",
    "display(df2)\n",
    "print(\"best score is 0.8505376344086022 with params {'colsample_bylevel': 0.2, 'colsample_bytree': 0.6, 'learning_rate': 0.15, 'max_depth': 5, 'n_estimators': 100, 'subsample': 0.6}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cf6243bd",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_colsample_bylevel</th>\n",
       "      <th>param_colsample_bytree</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_subsample</th>\n",
       "      <th>...</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.062133</td>\n",
       "      <td>0.002485</td>\n",
       "      <td>0.006284</td>\n",
       "      <td>0.000639</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.820020</td>\n",
       "      <td>0.048275</td>\n",
       "      <td>2663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.063131</td>\n",
       "      <td>0.003027</td>\n",
       "      <td>0.006683</td>\n",
       "      <td>0.000457</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.661290</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.823221</td>\n",
       "      <td>0.059057</td>\n",
       "      <td>2338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.060438</td>\n",
       "      <td>0.000798</td>\n",
       "      <td>0.006782</td>\n",
       "      <td>0.000398</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.824782</td>\n",
       "      <td>0.057512</td>\n",
       "      <td>2222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.059541</td>\n",
       "      <td>0.000779</td>\n",
       "      <td>0.006682</td>\n",
       "      <td>0.000457</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.661290</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.824834</td>\n",
       "      <td>0.059251</td>\n",
       "      <td>2132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.059840</td>\n",
       "      <td>0.001092</td>\n",
       "      <td>0.006782</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.828059</td>\n",
       "      <td>0.053977</td>\n",
       "      <td>1661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2995</th>\n",
       "      <td>0.195577</td>\n",
       "      <td>0.001636</td>\n",
       "      <td>0.017653</td>\n",
       "      <td>0.031683</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.819918</td>\n",
       "      <td>0.052433</td>\n",
       "      <td>2744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2996</th>\n",
       "      <td>0.221308</td>\n",
       "      <td>0.011234</td>\n",
       "      <td>0.006782</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.819995</td>\n",
       "      <td>0.058351</td>\n",
       "      <td>2693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2997</th>\n",
       "      <td>0.226194</td>\n",
       "      <td>0.002309</td>\n",
       "      <td>0.007082</td>\n",
       "      <td>0.000299</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.821582</td>\n",
       "      <td>0.054587</td>\n",
       "      <td>2581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998</th>\n",
       "      <td>0.199167</td>\n",
       "      <td>0.006213</td>\n",
       "      <td>0.007381</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.823195</td>\n",
       "      <td>0.052389</td>\n",
       "      <td>2389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999</th>\n",
       "      <td>0.196574</td>\n",
       "      <td>0.001133</td>\n",
       "      <td>0.007480</td>\n",
       "      <td>0.000499</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.826395</td>\n",
       "      <td>0.049816</td>\n",
       "      <td>2002</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0          0.062133      0.002485         0.006284        0.000639   \n",
       "1          0.063131      0.003027         0.006683        0.000457   \n",
       "2          0.060438      0.000798         0.006782        0.000398   \n",
       "3          0.059541      0.000779         0.006682        0.000457   \n",
       "4          0.059840      0.001092         0.006782        0.000399   \n",
       "...             ...           ...              ...             ...   \n",
       "2995       0.195577      0.001636         0.017653        0.031683   \n",
       "2996       0.221308      0.011234         0.006782        0.000399   \n",
       "2997       0.226194      0.002309         0.007082        0.000299   \n",
       "2998       0.199167      0.006213         0.007381        0.000489   \n",
       "2999       0.196574      0.001133         0.007480        0.000499   \n",
       "\n",
       "     param_colsample_bylevel param_colsample_bytree param_learning_rate  \\\n",
       "0                        0.2                    0.3                 0.1   \n",
       "1                        0.2                    0.3                 0.1   \n",
       "2                        0.2                    0.3                 0.1   \n",
       "3                        0.2                    0.3                 0.1   \n",
       "4                        0.2                    0.3                 0.1   \n",
       "...                      ...                    ...                 ...   \n",
       "2995                     0.2                    0.9                 0.4   \n",
       "2996                     0.2                    0.9                 0.4   \n",
       "2997                     0.2                    0.9                 0.4   \n",
       "2998                     0.2                    0.9                 0.4   \n",
       "2999                     0.2                    0.9                 0.4   \n",
       "\n",
       "     param_max_depth param_n_estimators param_subsample  ...  \\\n",
       "0                  2                100             0.5  ...   \n",
       "1                  2                100             0.6  ...   \n",
       "2                  2                100             0.7  ...   \n",
       "3                  2                100             0.8  ...   \n",
       "4                  2                100             0.9  ...   \n",
       "...              ...                ...             ...  ...   \n",
       "2995               5                300             0.5  ...   \n",
       "2996               5                300             0.6  ...   \n",
       "2997               5                300             0.7  ...   \n",
       "2998               5                300             0.8  ...   \n",
       "2999               5                300             0.9  ...   \n",
       "\n",
       "     split3_test_score  split4_test_score  split5_test_score  \\\n",
       "0             0.822581           0.822581           0.806452   \n",
       "1             0.838710           0.822581           0.806452   \n",
       "2             0.838710           0.806452           0.806452   \n",
       "3             0.854839           0.822581           0.806452   \n",
       "4             0.854839           0.822581           0.838710   \n",
       "...                ...                ...                ...   \n",
       "2995          0.822581           0.806452           0.774194   \n",
       "2996          0.838710           0.806452           0.774194   \n",
       "2997          0.838710           0.790323           0.758065   \n",
       "2998          0.838710           0.822581           0.774194   \n",
       "2999          0.838710           0.806452           0.790323   \n",
       "\n",
       "      split6_test_score  split7_test_score  split8_test_score  \\\n",
       "0              0.822581           0.806452           0.693548   \n",
       "1              0.838710           0.806452           0.661290   \n",
       "2              0.838710           0.806452           0.677419   \n",
       "3              0.854839           0.806452           0.661290   \n",
       "4              0.838710           0.806452           0.677419   \n",
       "...                 ...                ...                ...   \n",
       "2995           0.790323           0.790323           0.741935   \n",
       "2996           0.822581           0.838710           0.693548   \n",
       "2997           0.806452           0.854839           0.725806   \n",
       "2998           0.838710           0.822581           0.725806   \n",
       "2999           0.838710           0.822581           0.725806   \n",
       "\n",
       "      split9_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0              0.838710         0.820020        0.048275             2663  \n",
       "1              0.854839         0.823221        0.059057             2338  \n",
       "2              0.838710         0.824782        0.057512             2222  \n",
       "3              0.838710         0.824834        0.059251             2132  \n",
       "4              0.838710         0.828059        0.053977             1661  \n",
       "...                 ...              ...             ...              ...  \n",
       "2995           0.822581         0.819918        0.052433             2744  \n",
       "2996           0.822581         0.819995        0.058351             2693  \n",
       "2997           0.822581         0.821582        0.054587             2581  \n",
       "2998           0.790323         0.823195        0.052389             2389  \n",
       "2999           0.806452         0.826395        0.049816             2002  \n",
       "\n",
       "[3000 rows x 24 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score is 0.8505376344086022 with params {'colsample_bylevel': 0.2, 'colsample_bytree': 0.6, 'learning_rate': 0.15, 'max_depth': 5, 'n_estimators': 100, 'subsample': 0.6}\n"
     ]
    }
   ],
   "source": [
    "# Full Tuning - Part 2\n",
    "random.seed(10)\n",
    "\n",
    "xgb = XGBClassifier()\n",
    "\n",
    "xgb_parameters = {'max_depth': [2,3,4,5]\n",
    "                   , 'subsample': [0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "                   , 'colsample_bytree': [0.3, 0.4, 0.5, 0.6, 0.9]\n",
    "                   , 'colsample_bylevel': [0.2]\n",
    "                   , 'learning_rate': [0.1, 0.15, 0.2, 0.25, 0.3, 0.4]\n",
    "                   , 'n_estimators': [100, 150, 200, 250, 300]}\n",
    "\n",
    "stratified_10_fold_cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "xgb_grid_search = GridSearchCV(xgb, xgb_parameters, scoring='accuracy', cv=stratified_10_fold_cv)\n",
    "\n",
    "xgb_grid_search.fit(X_train, y_train)\n",
    "\n",
    "xgb_grid_search_results_full_2 = pd.DataFrame(xgb_grid_search.cv_results_)\n",
    "display(xgb_grid_search_results_full_2)\n",
    "\n",
    "print(\"best score is {} with params {}\".format(xgb_grid_search.best_score_, xgb_grid_search.best_params_))\n",
    "#best score is 0.8505376344086022 with params\n",
    "#{'colsample_bylevel': 0.2, 'colsample_bytree': 0.6, 'learning_rate': 0.15, 'max_depth': 5, 'n_estimators': 100, 'subsample': 0.6}\n",
    "\n",
    "# save dataframe\n",
    "from datetime import datetime\n",
    "date = str(datetime.now().date()).replace(\"-\", \"\")\n",
    "xgb_grid_search_results_full_2.to_csv(f\"results/xgb_results_full_round2_2_bylevel=0.2_{date}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9c3c4e54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_colsample_bylevel</th>\n",
       "      <th>param_colsample_bytree</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_subsample</th>\n",
       "      <th>...</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.062034</td>\n",
       "      <td>0.001596</td>\n",
       "      <td>0.006882</td>\n",
       "      <td>0.000537</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.820020</td>\n",
       "      <td>0.048275</td>\n",
       "      <td>2509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.068327</td>\n",
       "      <td>0.005910</td>\n",
       "      <td>0.006573</td>\n",
       "      <td>0.000502</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.661290</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.823221</td>\n",
       "      <td>0.059057</td>\n",
       "      <td>2140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.065225</td>\n",
       "      <td>0.003191</td>\n",
       "      <td>0.006683</td>\n",
       "      <td>0.000457</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.824782</td>\n",
       "      <td>0.057512</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.063630</td>\n",
       "      <td>0.001596</td>\n",
       "      <td>0.006483</td>\n",
       "      <td>0.000499</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.661290</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.824834</td>\n",
       "      <td>0.059251</td>\n",
       "      <td>1898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.061435</td>\n",
       "      <td>0.001493</td>\n",
       "      <td>0.006483</td>\n",
       "      <td>0.000498</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.828059</td>\n",
       "      <td>0.053977</td>\n",
       "      <td>1394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2995</th>\n",
       "      <td>0.206226</td>\n",
       "      <td>0.002782</td>\n",
       "      <td>0.007182</td>\n",
       "      <td>0.000598</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.813646</td>\n",
       "      <td>0.044452</td>\n",
       "      <td>2900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2996</th>\n",
       "      <td>0.207998</td>\n",
       "      <td>0.002457</td>\n",
       "      <td>0.007280</td>\n",
       "      <td>0.000457</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.818459</td>\n",
       "      <td>0.053856</td>\n",
       "      <td>2648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2997</th>\n",
       "      <td>0.207744</td>\n",
       "      <td>0.000898</td>\n",
       "      <td>0.007480</td>\n",
       "      <td>0.000499</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.813594</td>\n",
       "      <td>0.056215</td>\n",
       "      <td>2908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998</th>\n",
       "      <td>0.208343</td>\n",
       "      <td>0.001863</td>\n",
       "      <td>0.007280</td>\n",
       "      <td>0.000457</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.815207</td>\n",
       "      <td>0.053961</td>\n",
       "      <td>2850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999</th>\n",
       "      <td>0.207644</td>\n",
       "      <td>0.001882</td>\n",
       "      <td>0.007381</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.820020</td>\n",
       "      <td>0.055129</td>\n",
       "      <td>2509</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0          0.062034      0.001596         0.006882        0.000537   \n",
       "1          0.068327      0.005910         0.006573        0.000502   \n",
       "2          0.065225      0.003191         0.006683        0.000457   \n",
       "3          0.063630      0.001596         0.006483        0.000499   \n",
       "4          0.061435      0.001493         0.006483        0.000498   \n",
       "...             ...           ...              ...             ...   \n",
       "2995       0.206226      0.002782         0.007182        0.000598   \n",
       "2996       0.207998      0.002457         0.007280        0.000457   \n",
       "2997       0.207744      0.000898         0.007480        0.000499   \n",
       "2998       0.208343      0.001863         0.007280        0.000457   \n",
       "2999       0.207644      0.001882         0.007381        0.000489   \n",
       "\n",
       "      param_colsample_bylevel  param_colsample_bytree  param_learning_rate  \\\n",
       "0                         0.3                     0.3                  0.1   \n",
       "1                         0.3                     0.3                  0.1   \n",
       "2                         0.3                     0.3                  0.1   \n",
       "3                         0.3                     0.3                  0.1   \n",
       "4                         0.3                     0.3                  0.1   \n",
       "...                       ...                     ...                  ...   \n",
       "2995                      0.3                     0.9                  0.4   \n",
       "2996                      0.3                     0.9                  0.4   \n",
       "2997                      0.3                     0.9                  0.4   \n",
       "2998                      0.3                     0.9                  0.4   \n",
       "2999                      0.3                     0.9                  0.4   \n",
       "\n",
       "      param_max_depth  param_n_estimators  param_subsample  ...  \\\n",
       "0                   2                 100              0.5  ...   \n",
       "1                   2                 100              0.6  ...   \n",
       "2                   2                 100              0.7  ...   \n",
       "3                   2                 100              0.8  ...   \n",
       "4                   2                 100              0.9  ...   \n",
       "...               ...                 ...              ...  ...   \n",
       "2995                5                 300              0.5  ...   \n",
       "2996                5                 300              0.6  ...   \n",
       "2997                5                 300              0.7  ...   \n",
       "2998                5                 300              0.8  ...   \n",
       "2999                5                 300              0.9  ...   \n",
       "\n",
       "     split3_test_score  split4_test_score  split5_test_score  \\\n",
       "0             0.822581           0.822581           0.806452   \n",
       "1             0.838710           0.822581           0.806452   \n",
       "2             0.838710           0.806452           0.806452   \n",
       "3             0.854839           0.822581           0.806452   \n",
       "4             0.854839           0.822581           0.838710   \n",
       "...                ...                ...                ...   \n",
       "2995          0.838710           0.790323           0.774194   \n",
       "2996          0.854839           0.774194           0.790323   \n",
       "2997          0.854839           0.790323           0.758065   \n",
       "2998          0.854839           0.790323           0.790323   \n",
       "2999          0.822581           0.790323           0.774194   \n",
       "\n",
       "      split6_test_score  split7_test_score  split8_test_score  \\\n",
       "0              0.822581           0.806452           0.693548   \n",
       "1              0.838710           0.806452           0.661290   \n",
       "2              0.838710           0.806452           0.677419   \n",
       "3              0.854839           0.806452           0.661290   \n",
       "4              0.838710           0.806452           0.677419   \n",
       "...                 ...                ...                ...   \n",
       "2995           0.838710           0.822581           0.709677   \n",
       "2996           0.854839           0.806452           0.693548   \n",
       "2997           0.822581           0.806452           0.709677   \n",
       "2998           0.822581           0.806452           0.693548   \n",
       "2999           0.854839           0.806452           0.709677   \n",
       "\n",
       "      split9_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0              0.838710         0.820020        0.048275             2509  \n",
       "1              0.854839         0.823221        0.059057             2140  \n",
       "2              0.838710         0.824782        0.057512             2021  \n",
       "3              0.838710         0.824834        0.059251             1898  \n",
       "4              0.838710         0.828059        0.053977             1394  \n",
       "...                 ...              ...             ...              ...  \n",
       "2995           0.822581         0.813646        0.044452             2900  \n",
       "2996           0.854839         0.818459        0.053856             2648  \n",
       "2997           0.822581         0.813594        0.056215             2908  \n",
       "2998           0.822581         0.815207        0.053961             2850  \n",
       "2999           0.854839         0.820020        0.055129             2509  \n",
       "\n",
       "[3000 rows x 24 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score is 0.850563236047107 with params {'colsample_bylevel': 0.3, 'colsample_bytree': 0.5, 'learning_rate': 0.15, 'max_depth': 2, 'n_estimators': 100, 'subsample': 0.7}\n"
     ]
    }
   ],
   "source": [
    "df3 = pd.read_csv(\"data\\\\xgb_results_full_3_bylevel=0.3_20221123.csv\")\n",
    "df3.drop(df3.columns[0], axis=1, inplace=True)\n",
    "display(df3)\n",
    "print(\"best score is 0.850563236047107 with params {'colsample_bylevel': 0.3, 'colsample_bytree': 0.5, 'learning_rate': 0.15, 'max_depth': 2, 'n_estimators': 100, 'subsample': 0.7}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "96404602",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_colsample_bylevel</th>\n",
       "      <th>param_colsample_bytree</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_subsample</th>\n",
       "      <th>...</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.062034</td>\n",
       "      <td>0.001596</td>\n",
       "      <td>0.006882</td>\n",
       "      <td>0.000537</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.820020</td>\n",
       "      <td>0.048275</td>\n",
       "      <td>2509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.068327</td>\n",
       "      <td>0.005910</td>\n",
       "      <td>0.006573</td>\n",
       "      <td>0.000502</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.661290</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.823221</td>\n",
       "      <td>0.059057</td>\n",
       "      <td>2140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.065225</td>\n",
       "      <td>0.003191</td>\n",
       "      <td>0.006683</td>\n",
       "      <td>0.000457</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.824782</td>\n",
       "      <td>0.057512</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.063630</td>\n",
       "      <td>0.001596</td>\n",
       "      <td>0.006483</td>\n",
       "      <td>0.000499</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.661290</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.824834</td>\n",
       "      <td>0.059251</td>\n",
       "      <td>1898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.061435</td>\n",
       "      <td>0.001493</td>\n",
       "      <td>0.006483</td>\n",
       "      <td>0.000498</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.828059</td>\n",
       "      <td>0.053977</td>\n",
       "      <td>1394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2995</th>\n",
       "      <td>0.206226</td>\n",
       "      <td>0.002782</td>\n",
       "      <td>0.007182</td>\n",
       "      <td>0.000598</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.813646</td>\n",
       "      <td>0.044452</td>\n",
       "      <td>2900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2996</th>\n",
       "      <td>0.207998</td>\n",
       "      <td>0.002457</td>\n",
       "      <td>0.007280</td>\n",
       "      <td>0.000457</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.818459</td>\n",
       "      <td>0.053856</td>\n",
       "      <td>2648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2997</th>\n",
       "      <td>0.207744</td>\n",
       "      <td>0.000898</td>\n",
       "      <td>0.007480</td>\n",
       "      <td>0.000499</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.813594</td>\n",
       "      <td>0.056215</td>\n",
       "      <td>2908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998</th>\n",
       "      <td>0.208343</td>\n",
       "      <td>0.001863</td>\n",
       "      <td>0.007280</td>\n",
       "      <td>0.000457</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.815207</td>\n",
       "      <td>0.053961</td>\n",
       "      <td>2850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999</th>\n",
       "      <td>0.207644</td>\n",
       "      <td>0.001882</td>\n",
       "      <td>0.007381</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.820020</td>\n",
       "      <td>0.055129</td>\n",
       "      <td>2509</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0          0.062034      0.001596         0.006882        0.000537   \n",
       "1          0.068327      0.005910         0.006573        0.000502   \n",
       "2          0.065225      0.003191         0.006683        0.000457   \n",
       "3          0.063630      0.001596         0.006483        0.000499   \n",
       "4          0.061435      0.001493         0.006483        0.000498   \n",
       "...             ...           ...              ...             ...   \n",
       "2995       0.206226      0.002782         0.007182        0.000598   \n",
       "2996       0.207998      0.002457         0.007280        0.000457   \n",
       "2997       0.207744      0.000898         0.007480        0.000499   \n",
       "2998       0.208343      0.001863         0.007280        0.000457   \n",
       "2999       0.207644      0.001882         0.007381        0.000489   \n",
       "\n",
       "     param_colsample_bylevel param_colsample_bytree param_learning_rate  \\\n",
       "0                        0.3                    0.3                 0.1   \n",
       "1                        0.3                    0.3                 0.1   \n",
       "2                        0.3                    0.3                 0.1   \n",
       "3                        0.3                    0.3                 0.1   \n",
       "4                        0.3                    0.3                 0.1   \n",
       "...                      ...                    ...                 ...   \n",
       "2995                     0.3                    0.9                 0.4   \n",
       "2996                     0.3                    0.9                 0.4   \n",
       "2997                     0.3                    0.9                 0.4   \n",
       "2998                     0.3                    0.9                 0.4   \n",
       "2999                     0.3                    0.9                 0.4   \n",
       "\n",
       "     param_max_depth param_n_estimators param_subsample  ...  \\\n",
       "0                  2                100             0.5  ...   \n",
       "1                  2                100             0.6  ...   \n",
       "2                  2                100             0.7  ...   \n",
       "3                  2                100             0.8  ...   \n",
       "4                  2                100             0.9  ...   \n",
       "...              ...                ...             ...  ...   \n",
       "2995               5                300             0.5  ...   \n",
       "2996               5                300             0.6  ...   \n",
       "2997               5                300             0.7  ...   \n",
       "2998               5                300             0.8  ...   \n",
       "2999               5                300             0.9  ...   \n",
       "\n",
       "     split3_test_score  split4_test_score  split5_test_score  \\\n",
       "0             0.822581           0.822581           0.806452   \n",
       "1             0.838710           0.822581           0.806452   \n",
       "2             0.838710           0.806452           0.806452   \n",
       "3             0.854839           0.822581           0.806452   \n",
       "4             0.854839           0.822581           0.838710   \n",
       "...                ...                ...                ...   \n",
       "2995          0.838710           0.790323           0.774194   \n",
       "2996          0.854839           0.774194           0.790323   \n",
       "2997          0.854839           0.790323           0.758065   \n",
       "2998          0.854839           0.790323           0.790323   \n",
       "2999          0.822581           0.790323           0.774194   \n",
       "\n",
       "      split6_test_score  split7_test_score  split8_test_score  \\\n",
       "0              0.822581           0.806452           0.693548   \n",
       "1              0.838710           0.806452           0.661290   \n",
       "2              0.838710           0.806452           0.677419   \n",
       "3              0.854839           0.806452           0.661290   \n",
       "4              0.838710           0.806452           0.677419   \n",
       "...                 ...                ...                ...   \n",
       "2995           0.838710           0.822581           0.709677   \n",
       "2996           0.854839           0.806452           0.693548   \n",
       "2997           0.822581           0.806452           0.709677   \n",
       "2998           0.822581           0.806452           0.693548   \n",
       "2999           0.854839           0.806452           0.709677   \n",
       "\n",
       "      split9_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0              0.838710         0.820020        0.048275             2509  \n",
       "1              0.854839         0.823221        0.059057             2140  \n",
       "2              0.838710         0.824782        0.057512             2021  \n",
       "3              0.838710         0.824834        0.059251             1898  \n",
       "4              0.838710         0.828059        0.053977             1394  \n",
       "...                 ...              ...             ...              ...  \n",
       "2995           0.822581         0.813646        0.044452             2900  \n",
       "2996           0.854839         0.818459        0.053856             2648  \n",
       "2997           0.822581         0.813594        0.056215             2908  \n",
       "2998           0.822581         0.815207        0.053961             2850  \n",
       "2999           0.854839         0.820020        0.055129             2509  \n",
       "\n",
       "[3000 rows x 24 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score is 0.850563236047107 with params {'colsample_bylevel': 0.3, 'colsample_bytree': 0.5, 'learning_rate': 0.15, 'max_depth': 2, 'n_estimators': 100, 'subsample': 0.7}\n"
     ]
    }
   ],
   "source": [
    "# Full Tuning - Part 3\n",
    "random.seed(10)\n",
    "\n",
    "xgb = XGBClassifier()\n",
    "\n",
    "xgb_parameters = {'max_depth': [2,3,4,5]\n",
    "                   , 'subsample': [0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "                   , 'colsample_bytree': [0.3, 0.4, 0.5, 0.6, 0.9]\n",
    "                   , 'colsample_bylevel': [0.3]\n",
    "                   , 'learning_rate': [0.1, 0.15, 0.2, 0.25, 0.3, 0.4]\n",
    "                   , 'n_estimators': [100, 150, 200, 250, 300]}\n",
    "\n",
    "stratified_10_fold_cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "xgb_grid_search = GridSearchCV(xgb, xgb_parameters, scoring='accuracy', cv=stratified_10_fold_cv)\n",
    "\n",
    "xgb_grid_search.fit(X_train, y_train)\n",
    "\n",
    "xgb_grid_search_results_full_3 = pd.DataFrame(xgb_grid_search.cv_results_)\n",
    "display(xgb_grid_search_results_full_3)\n",
    "\n",
    "print(\"best score is {} with params {}\".format(xgb_grid_search.best_score_, xgb_grid_search.best_params_))\n",
    "#best score is 0.850563236047107 with params\n",
    "#{'colsample_bylevel': 0.3, 'colsample_bytree': 0.5, 'learning_rate': 0.15, 'max_depth': 2, 'n_estimators': 100, 'subsample': 0.7}\n",
    "\n",
    "# save dataframe\n",
    "from datetime import datetime\n",
    "date = str(datetime.now().date()).replace(\"-\", \"\")\n",
    "xgb_grid_search_results_full_3.to_csv(f\"results/xgb_results_full_round2_3_bylevel=0.3_{date}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1205514d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_colsample_bylevel</th>\n",
       "      <th>param_colsample_bytree</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_subsample</th>\n",
       "      <th>...</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.061735</td>\n",
       "      <td>0.001296</td>\n",
       "      <td>0.006482</td>\n",
       "      <td>0.000669</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.820020</td>\n",
       "      <td>0.048275</td>\n",
       "      <td>2502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.063031</td>\n",
       "      <td>0.002778</td>\n",
       "      <td>0.006483</td>\n",
       "      <td>0.000669</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.661290</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.823221</td>\n",
       "      <td>0.059057</td>\n",
       "      <td>2077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.060638</td>\n",
       "      <td>0.000746</td>\n",
       "      <td>0.006782</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.824782</td>\n",
       "      <td>0.057512</td>\n",
       "      <td>1941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.060339</td>\n",
       "      <td>0.000919</td>\n",
       "      <td>0.006483</td>\n",
       "      <td>0.000499</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.661290</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.824834</td>\n",
       "      <td>0.059251</td>\n",
       "      <td>1818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.059840</td>\n",
       "      <td>0.001180</td>\n",
       "      <td>0.006682</td>\n",
       "      <td>0.000457</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.828059</td>\n",
       "      <td>0.053977</td>\n",
       "      <td>1289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2995</th>\n",
       "      <td>0.218216</td>\n",
       "      <td>0.004179</td>\n",
       "      <td>0.007181</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.808807</td>\n",
       "      <td>0.046180</td>\n",
       "      <td>2975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2996</th>\n",
       "      <td>0.221009</td>\n",
       "      <td>0.003402</td>\n",
       "      <td>0.007480</td>\n",
       "      <td>0.000499</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.812007</td>\n",
       "      <td>0.049754</td>\n",
       "      <td>2922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2997</th>\n",
       "      <td>0.221308</td>\n",
       "      <td>0.004515</td>\n",
       "      <td>0.007380</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.816795</td>\n",
       "      <td>0.050406</td>\n",
       "      <td>2770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998</th>\n",
       "      <td>0.219213</td>\n",
       "      <td>0.003908</td>\n",
       "      <td>0.007194</td>\n",
       "      <td>0.000425</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.816820</td>\n",
       "      <td>0.047212</td>\n",
       "      <td>2763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999</th>\n",
       "      <td>0.216122</td>\n",
       "      <td>0.003092</td>\n",
       "      <td>0.007381</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.818382</td>\n",
       "      <td>0.050014</td>\n",
       "      <td>2693</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0          0.061735      0.001296         0.006482        0.000669   \n",
       "1          0.063031      0.002778         0.006483        0.000669   \n",
       "2          0.060638      0.000746         0.006782        0.000399   \n",
       "3          0.060339      0.000919         0.006483        0.000499   \n",
       "4          0.059840      0.001180         0.006682        0.000457   \n",
       "...             ...           ...              ...             ...   \n",
       "2995       0.218216      0.004179         0.007181        0.000399   \n",
       "2996       0.221009      0.003402         0.007480        0.000499   \n",
       "2997       0.221308      0.004515         0.007380        0.000489   \n",
       "2998       0.219213      0.003908         0.007194        0.000425   \n",
       "2999       0.216122      0.003092         0.007381        0.000489   \n",
       "\n",
       "      param_colsample_bylevel  param_colsample_bytree  param_learning_rate  \\\n",
       "0                         0.4                     0.3                  0.1   \n",
       "1                         0.4                     0.3                  0.1   \n",
       "2                         0.4                     0.3                  0.1   \n",
       "3                         0.4                     0.3                  0.1   \n",
       "4                         0.4                     0.3                  0.1   \n",
       "...                       ...                     ...                  ...   \n",
       "2995                      0.4                     0.9                  0.4   \n",
       "2996                      0.4                     0.9                  0.4   \n",
       "2997                      0.4                     0.9                  0.4   \n",
       "2998                      0.4                     0.9                  0.4   \n",
       "2999                      0.4                     0.9                  0.4   \n",
       "\n",
       "      param_max_depth  param_n_estimators  param_subsample  ...  \\\n",
       "0                   2                 100              0.5  ...   \n",
       "1                   2                 100              0.6  ...   \n",
       "2                   2                 100              0.7  ...   \n",
       "3                   2                 100              0.8  ...   \n",
       "4                   2                 100              0.9  ...   \n",
       "...               ...                 ...              ...  ...   \n",
       "2995                5                 300              0.5  ...   \n",
       "2996                5                 300              0.6  ...   \n",
       "2997                5                 300              0.7  ...   \n",
       "2998                5                 300              0.8  ...   \n",
       "2999                5                 300              0.9  ...   \n",
       "\n",
       "     split3_test_score  split4_test_score  split5_test_score  \\\n",
       "0             0.822581           0.822581           0.806452   \n",
       "1             0.838710           0.822581           0.806452   \n",
       "2             0.838710           0.806452           0.806452   \n",
       "3             0.854839           0.822581           0.806452   \n",
       "4             0.854839           0.822581           0.838710   \n",
       "...                ...                ...                ...   \n",
       "2995          0.838710           0.758065           0.790323   \n",
       "2996          0.838710           0.790323           0.806452   \n",
       "2997          0.838710           0.790323           0.790323   \n",
       "2998          0.838710           0.790323           0.806452   \n",
       "2999          0.822581           0.774194           0.774194   \n",
       "\n",
       "      split6_test_score  split7_test_score  split8_test_score  \\\n",
       "0              0.822581           0.806452           0.693548   \n",
       "1              0.838710           0.806452           0.661290   \n",
       "2              0.838710           0.806452           0.677419   \n",
       "3              0.854839           0.806452           0.661290   \n",
       "4              0.838710           0.806452           0.677419   \n",
       "...                 ...                ...                ...   \n",
       "2995           0.806452           0.790323           0.741935   \n",
       "2996           0.838710           0.774194           0.725806   \n",
       "2997           0.790323           0.822581           0.725806   \n",
       "2998           0.838710           0.790323           0.725806   \n",
       "2999           0.854839           0.790323           0.725806   \n",
       "\n",
       "      split9_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0              0.838710         0.820020        0.048275             2502  \n",
       "1              0.854839         0.823221        0.059057             2077  \n",
       "2              0.838710         0.824782        0.057512             1941  \n",
       "3              0.838710         0.824834        0.059251             1818  \n",
       "4              0.838710         0.828059        0.053977             1289  \n",
       "...                 ...              ...             ...              ...  \n",
       "2995           0.822581         0.808807        0.046180             2975  \n",
       "2996           0.790323         0.812007        0.049754             2922  \n",
       "2997           0.822581         0.816795        0.050406             2770  \n",
       "2998           0.806452         0.816820        0.047212             2763  \n",
       "2999           0.838710         0.818382        0.050014             2693  \n",
       "\n",
       "[3000 rows x 24 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score is 0.850563236047107 with params {'colsample_bylevel': 0.4, 'colsample_bytree': 0.5, 'learning_rate': 0.15, 'max_depth': 2, 'n_estimators': 100, 'subsample': 0.7}\n"
     ]
    }
   ],
   "source": [
    "df4 = pd.read_csv(\"data\\\\xgb_results_full_4_bylevel=0.4_20221123.csv\")\n",
    "df4.drop(df4.columns[0], axis=1, inplace=True)\n",
    "display(df4)\n",
    "print(\"best score is 0.850563236047107 with params {'colsample_bylevel': 0.4, 'colsample_bytree': 0.5, 'learning_rate': 0.15, 'max_depth': 2, 'n_estimators': 100, 'subsample': 0.7}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b8606396",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_colsample_bylevel</th>\n",
       "      <th>param_colsample_bytree</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_subsample</th>\n",
       "      <th>...</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.061735</td>\n",
       "      <td>0.001296</td>\n",
       "      <td>0.006482</td>\n",
       "      <td>0.000669</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.820020</td>\n",
       "      <td>0.048275</td>\n",
       "      <td>2502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.063031</td>\n",
       "      <td>0.002778</td>\n",
       "      <td>0.006483</td>\n",
       "      <td>0.000669</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.661290</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.823221</td>\n",
       "      <td>0.059057</td>\n",
       "      <td>2077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.060638</td>\n",
       "      <td>0.000746</td>\n",
       "      <td>0.006782</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.824782</td>\n",
       "      <td>0.057512</td>\n",
       "      <td>1941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.060339</td>\n",
       "      <td>0.000919</td>\n",
       "      <td>0.006483</td>\n",
       "      <td>0.000499</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.661290</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.824834</td>\n",
       "      <td>0.059251</td>\n",
       "      <td>1818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.059840</td>\n",
       "      <td>0.001180</td>\n",
       "      <td>0.006682</td>\n",
       "      <td>0.000457</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.828059</td>\n",
       "      <td>0.053977</td>\n",
       "      <td>1289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2995</th>\n",
       "      <td>0.218216</td>\n",
       "      <td>0.004179</td>\n",
       "      <td>0.007181</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.808807</td>\n",
       "      <td>0.046180</td>\n",
       "      <td>2975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2996</th>\n",
       "      <td>0.221009</td>\n",
       "      <td>0.003402</td>\n",
       "      <td>0.007480</td>\n",
       "      <td>0.000499</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.812007</td>\n",
       "      <td>0.049754</td>\n",
       "      <td>2922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2997</th>\n",
       "      <td>0.221308</td>\n",
       "      <td>0.004515</td>\n",
       "      <td>0.007380</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.816795</td>\n",
       "      <td>0.050406</td>\n",
       "      <td>2770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998</th>\n",
       "      <td>0.219213</td>\n",
       "      <td>0.003908</td>\n",
       "      <td>0.007194</td>\n",
       "      <td>0.000425</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.816820</td>\n",
       "      <td>0.047212</td>\n",
       "      <td>2763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999</th>\n",
       "      <td>0.216122</td>\n",
       "      <td>0.003092</td>\n",
       "      <td>0.007381</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.818382</td>\n",
       "      <td>0.050014</td>\n",
       "      <td>2693</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0          0.061735      0.001296         0.006482        0.000669   \n",
       "1          0.063031      0.002778         0.006483        0.000669   \n",
       "2          0.060638      0.000746         0.006782        0.000399   \n",
       "3          0.060339      0.000919         0.006483        0.000499   \n",
       "4          0.059840      0.001180         0.006682        0.000457   \n",
       "...             ...           ...              ...             ...   \n",
       "2995       0.218216      0.004179         0.007181        0.000399   \n",
       "2996       0.221009      0.003402         0.007480        0.000499   \n",
       "2997       0.221308      0.004515         0.007380        0.000489   \n",
       "2998       0.219213      0.003908         0.007194        0.000425   \n",
       "2999       0.216122      0.003092         0.007381        0.000489   \n",
       "\n",
       "     param_colsample_bylevel param_colsample_bytree param_learning_rate  \\\n",
       "0                        0.4                    0.3                 0.1   \n",
       "1                        0.4                    0.3                 0.1   \n",
       "2                        0.4                    0.3                 0.1   \n",
       "3                        0.4                    0.3                 0.1   \n",
       "4                        0.4                    0.3                 0.1   \n",
       "...                      ...                    ...                 ...   \n",
       "2995                     0.4                    0.9                 0.4   \n",
       "2996                     0.4                    0.9                 0.4   \n",
       "2997                     0.4                    0.9                 0.4   \n",
       "2998                     0.4                    0.9                 0.4   \n",
       "2999                     0.4                    0.9                 0.4   \n",
       "\n",
       "     param_max_depth param_n_estimators param_subsample  ...  \\\n",
       "0                  2                100             0.5  ...   \n",
       "1                  2                100             0.6  ...   \n",
       "2                  2                100             0.7  ...   \n",
       "3                  2                100             0.8  ...   \n",
       "4                  2                100             0.9  ...   \n",
       "...              ...                ...             ...  ...   \n",
       "2995               5                300             0.5  ...   \n",
       "2996               5                300             0.6  ...   \n",
       "2997               5                300             0.7  ...   \n",
       "2998               5                300             0.8  ...   \n",
       "2999               5                300             0.9  ...   \n",
       "\n",
       "     split3_test_score  split4_test_score  split5_test_score  \\\n",
       "0             0.822581           0.822581           0.806452   \n",
       "1             0.838710           0.822581           0.806452   \n",
       "2             0.838710           0.806452           0.806452   \n",
       "3             0.854839           0.822581           0.806452   \n",
       "4             0.854839           0.822581           0.838710   \n",
       "...                ...                ...                ...   \n",
       "2995          0.838710           0.758065           0.790323   \n",
       "2996          0.838710           0.790323           0.806452   \n",
       "2997          0.838710           0.790323           0.790323   \n",
       "2998          0.838710           0.790323           0.806452   \n",
       "2999          0.822581           0.774194           0.774194   \n",
       "\n",
       "      split6_test_score  split7_test_score  split8_test_score  \\\n",
       "0              0.822581           0.806452           0.693548   \n",
       "1              0.838710           0.806452           0.661290   \n",
       "2              0.838710           0.806452           0.677419   \n",
       "3              0.854839           0.806452           0.661290   \n",
       "4              0.838710           0.806452           0.677419   \n",
       "...                 ...                ...                ...   \n",
       "2995           0.806452           0.790323           0.741935   \n",
       "2996           0.838710           0.774194           0.725806   \n",
       "2997           0.790323           0.822581           0.725806   \n",
       "2998           0.838710           0.790323           0.725806   \n",
       "2999           0.854839           0.790323           0.725806   \n",
       "\n",
       "      split9_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0              0.838710         0.820020        0.048275             2502  \n",
       "1              0.854839         0.823221        0.059057             2077  \n",
       "2              0.838710         0.824782        0.057512             1941  \n",
       "3              0.838710         0.824834        0.059251             1818  \n",
       "4              0.838710         0.828059        0.053977             1289  \n",
       "...                 ...              ...             ...              ...  \n",
       "2995           0.822581         0.808807        0.046180             2975  \n",
       "2996           0.790323         0.812007        0.049754             2922  \n",
       "2997           0.822581         0.816795        0.050406             2770  \n",
       "2998           0.806452         0.816820        0.047212             2763  \n",
       "2999           0.838710         0.818382        0.050014             2693  \n",
       "\n",
       "[3000 rows x 24 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score is 0.850563236047107 with params {'colsample_bylevel': 0.4, 'colsample_bytree': 0.5, 'learning_rate': 0.15, 'max_depth': 2, 'n_estimators': 100, 'subsample': 0.7}\n"
     ]
    }
   ],
   "source": [
    "# Full Tuning - Part 4\n",
    "random.seed(10)\n",
    "\n",
    "xgb = XGBClassifier()\n",
    "\n",
    "xgb_parameters = {'max_depth': [2,3,4,5]\n",
    "                   , 'subsample': [0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "                   , 'colsample_bytree': [0.3, 0.4, 0.5, 0.6, 0.9]\n",
    "                   , 'colsample_bylevel': [0.4]\n",
    "                   , 'learning_rate': [0.1, 0.15, 0.2, 0.25, 0.3, 0.4]\n",
    "                   , 'n_estimators': [100, 150, 200, 250, 300]}\n",
    "\n",
    "stratified_10_fold_cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "xgb_grid_search = GridSearchCV(xgb, xgb_parameters, scoring='accuracy', cv=stratified_10_fold_cv)\n",
    "\n",
    "xgb_grid_search.fit(X_train, y_train)\n",
    "\n",
    "xgb_grid_search_results_full_4 = pd.DataFrame(xgb_grid_search.cv_results_)\n",
    "display(xgb_grid_search_results_full_4)\n",
    "\n",
    "print(\"best score is {} with params {}\".format(xgb_grid_search.best_score_, xgb_grid_search.best_params_))\n",
    "#best score is 0.850563236047107 with params\n",
    "#{'colsample_bylevel': 0.4, 'colsample_bytree': 0.5, 'learning_rate': 0.15, 'max_depth': 2, 'n_estimators': 100, 'subsample': 0.7}\n",
    "\n",
    "# save dataframe\n",
    "from datetime import datetime\n",
    "date = str(datetime.now().date()).replace(\"-\", \"\")\n",
    "xgb_grid_search_results_full_4.to_csv(f\"results/xgb_results_full_round2_4_bylevel=0.4_{date}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9153372b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_colsample_bylevel</th>\n",
       "      <th>param_colsample_bytree</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_subsample</th>\n",
       "      <th>...</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.063530</td>\n",
       "      <td>0.002446</td>\n",
       "      <td>0.006383</td>\n",
       "      <td>0.000662</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.834537</td>\n",
       "      <td>0.044892</td>\n",
       "      <td>215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.065725</td>\n",
       "      <td>0.003351</td>\n",
       "      <td>0.006882</td>\n",
       "      <td>0.000299</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.832949</td>\n",
       "      <td>0.048291</td>\n",
       "      <td>320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.062236</td>\n",
       "      <td>0.001196</td>\n",
       "      <td>0.006780</td>\n",
       "      <td>0.000398</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.887097</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.842601</td>\n",
       "      <td>0.046342</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.061335</td>\n",
       "      <td>0.001798</td>\n",
       "      <td>0.006583</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.834562</td>\n",
       "      <td>0.050284</td>\n",
       "      <td>208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.060937</td>\n",
       "      <td>0.000698</td>\n",
       "      <td>0.006483</td>\n",
       "      <td>0.000669</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.887097</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.832924</td>\n",
       "      <td>0.057218</td>\n",
       "      <td>327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2995</th>\n",
       "      <td>0.219613</td>\n",
       "      <td>0.001532</td>\n",
       "      <td>0.007380</td>\n",
       "      <td>0.000488</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.805504</td>\n",
       "      <td>0.051226</td>\n",
       "      <td>2997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2996</th>\n",
       "      <td>0.222105</td>\n",
       "      <td>0.001787</td>\n",
       "      <td>0.006882</td>\n",
       "      <td>0.000698</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.810317</td>\n",
       "      <td>0.059764</td>\n",
       "      <td>2968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2997</th>\n",
       "      <td>0.221906</td>\n",
       "      <td>0.002534</td>\n",
       "      <td>0.007281</td>\n",
       "      <td>0.000457</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.818331</td>\n",
       "      <td>0.051641</td>\n",
       "      <td>2706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998</th>\n",
       "      <td>0.224599</td>\n",
       "      <td>0.011023</td>\n",
       "      <td>0.007380</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.816718</td>\n",
       "      <td>0.054669</td>\n",
       "      <td>2825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999</th>\n",
       "      <td>0.219812</td>\n",
       "      <td>0.002609</td>\n",
       "      <td>0.007381</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.807220</td>\n",
       "      <td>0.045482</td>\n",
       "      <td>2983</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0          0.063530      0.002446         0.006383        0.000662   \n",
       "1          0.065725      0.003351         0.006882        0.000299   \n",
       "2          0.062236      0.001196         0.006780        0.000398   \n",
       "3          0.061335      0.001798         0.006583        0.000489   \n",
       "4          0.060937      0.000698         0.006483        0.000669   \n",
       "...             ...           ...              ...             ...   \n",
       "2995       0.219613      0.001532         0.007380        0.000488   \n",
       "2996       0.222105      0.001787         0.006882        0.000698   \n",
       "2997       0.221906      0.002534         0.007281        0.000457   \n",
       "2998       0.224599      0.011023         0.007380        0.000489   \n",
       "2999       0.219812      0.002609         0.007381        0.000489   \n",
       "\n",
       "      param_colsample_bylevel  param_colsample_bytree  param_learning_rate  \\\n",
       "0                         0.6                     0.3                  0.1   \n",
       "1                         0.6                     0.3                  0.1   \n",
       "2                         0.6                     0.3                  0.1   \n",
       "3                         0.6                     0.3                  0.1   \n",
       "4                         0.6                     0.3                  0.1   \n",
       "...                       ...                     ...                  ...   \n",
       "2995                      0.6                     0.9                  0.4   \n",
       "2996                      0.6                     0.9                  0.4   \n",
       "2997                      0.6                     0.9                  0.4   \n",
       "2998                      0.6                     0.9                  0.4   \n",
       "2999                      0.6                     0.9                  0.4   \n",
       "\n",
       "      param_max_depth  param_n_estimators  param_subsample  ...  \\\n",
       "0                   2                 100              0.5  ...   \n",
       "1                   2                 100              0.6  ...   \n",
       "2                   2                 100              0.7  ...   \n",
       "3                   2                 100              0.8  ...   \n",
       "4                   2                 100              0.9  ...   \n",
       "...               ...                 ...              ...  ...   \n",
       "2995                5                 300              0.5  ...   \n",
       "2996                5                 300              0.6  ...   \n",
       "2997                5                 300              0.7  ...   \n",
       "2998                5                 300              0.8  ...   \n",
       "2999                5                 300              0.9  ...   \n",
       "\n",
       "     split3_test_score  split4_test_score  split5_test_score  \\\n",
       "0             0.870968           0.822581           0.838710   \n",
       "1             0.854839           0.822581           0.854839   \n",
       "2             0.887097           0.838710           0.854839   \n",
       "3             0.870968           0.822581           0.870968   \n",
       "4             0.870968           0.822581           0.887097   \n",
       "...                ...                ...                ...   \n",
       "2995          0.806452           0.741935           0.774194   \n",
       "2996          0.854839           0.790323           0.758065   \n",
       "2997          0.838710           0.774194           0.790323   \n",
       "2998          0.838710           0.790323           0.758065   \n",
       "2999          0.822581           0.790323           0.758065   \n",
       "\n",
       "      split6_test_score  split7_test_score  split8_test_score  \\\n",
       "0              0.854839           0.822581           0.709677   \n",
       "1              0.854839           0.822581           0.693548   \n",
       "2              0.854839           0.838710           0.709677   \n",
       "3              0.838710           0.822581           0.693548   \n",
       "4              0.822581           0.806452           0.677419   \n",
       "...                 ...                ...                ...   \n",
       "2995           0.806452           0.790323           0.741935   \n",
       "2996           0.822581           0.741935           0.725806   \n",
       "2997           0.822581           0.774194           0.725806   \n",
       "2998           0.822581           0.806452           0.709677   \n",
       "2999           0.838710           0.806452           0.709677   \n",
       "\n",
       "      split9_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0              0.838710         0.834537        0.044892              215  \n",
       "1              0.854839         0.832949        0.048291              320  \n",
       "2              0.854839         0.842601        0.046342               17  \n",
       "3              0.854839         0.834562        0.050284              208  \n",
       "4              0.854839         0.832924        0.057218              327  \n",
       "...                 ...              ...             ...              ...  \n",
       "2995           0.806452         0.805504        0.051226             2997  \n",
       "2996           0.806452         0.810317        0.059764             2968  \n",
       "2997           0.822581         0.818331        0.051641             2706  \n",
       "2998           0.806452         0.816718        0.054669             2825  \n",
       "2999           0.822581         0.807220        0.045482             2983  \n",
       "\n",
       "[3000 rows x 24 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score is 0.8458269329237071 with params {'colsample_bylevel': 0.6, 'colsample_bytree': 0.4, 'learning_rate': 0.1, 'max_depth': 2, 'n_estimators': 100, 'subsample': 0.8}\n"
     ]
    }
   ],
   "source": [
    "df5 = pd.read_csv(\"data\\\\xgb_results_full_5_bylevel=0.6_20221123.csv\")\n",
    "df5.drop(df5.columns[0], axis=1, inplace=True)\n",
    "display(df5)\n",
    "print(\"best score is 0.8458269329237071 with params {'colsample_bylevel': 0.6, 'colsample_bytree': 0.4, 'learning_rate': 0.1, 'max_depth': 2, 'n_estimators': 100, 'subsample': 0.8}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "04f9734e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_colsample_bylevel</th>\n",
       "      <th>param_colsample_bytree</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_subsample</th>\n",
       "      <th>...</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.063530</td>\n",
       "      <td>0.002446</td>\n",
       "      <td>0.006383</td>\n",
       "      <td>0.000662</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.834537</td>\n",
       "      <td>0.044892</td>\n",
       "      <td>215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.065725</td>\n",
       "      <td>0.003351</td>\n",
       "      <td>0.006882</td>\n",
       "      <td>0.000299</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.832949</td>\n",
       "      <td>0.048291</td>\n",
       "      <td>320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.062236</td>\n",
       "      <td>0.001196</td>\n",
       "      <td>0.006780</td>\n",
       "      <td>0.000398</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.887097</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.842601</td>\n",
       "      <td>0.046342</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.061335</td>\n",
       "      <td>0.001798</td>\n",
       "      <td>0.006583</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.834562</td>\n",
       "      <td>0.050284</td>\n",
       "      <td>208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.060937</td>\n",
       "      <td>0.000698</td>\n",
       "      <td>0.006483</td>\n",
       "      <td>0.000669</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.887097</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.832924</td>\n",
       "      <td>0.057218</td>\n",
       "      <td>327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2995</th>\n",
       "      <td>0.219613</td>\n",
       "      <td>0.001532</td>\n",
       "      <td>0.007380</td>\n",
       "      <td>0.000488</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.805504</td>\n",
       "      <td>0.051226</td>\n",
       "      <td>2997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2996</th>\n",
       "      <td>0.222105</td>\n",
       "      <td>0.001787</td>\n",
       "      <td>0.006882</td>\n",
       "      <td>0.000698</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.810317</td>\n",
       "      <td>0.059764</td>\n",
       "      <td>2968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2997</th>\n",
       "      <td>0.221906</td>\n",
       "      <td>0.002534</td>\n",
       "      <td>0.007281</td>\n",
       "      <td>0.000457</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.818331</td>\n",
       "      <td>0.051641</td>\n",
       "      <td>2706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998</th>\n",
       "      <td>0.224599</td>\n",
       "      <td>0.011023</td>\n",
       "      <td>0.007380</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.816718</td>\n",
       "      <td>0.054669</td>\n",
       "      <td>2825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999</th>\n",
       "      <td>0.219812</td>\n",
       "      <td>0.002609</td>\n",
       "      <td>0.007381</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.807220</td>\n",
       "      <td>0.045482</td>\n",
       "      <td>2983</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0          0.063530      0.002446         0.006383        0.000662   \n",
       "1          0.065725      0.003351         0.006882        0.000299   \n",
       "2          0.062236      0.001196         0.006780        0.000398   \n",
       "3          0.061335      0.001798         0.006583        0.000489   \n",
       "4          0.060937      0.000698         0.006483        0.000669   \n",
       "...             ...           ...              ...             ...   \n",
       "2995       0.219613      0.001532         0.007380        0.000488   \n",
       "2996       0.222105      0.001787         0.006882        0.000698   \n",
       "2997       0.221906      0.002534         0.007281        0.000457   \n",
       "2998       0.224599      0.011023         0.007380        0.000489   \n",
       "2999       0.219812      0.002609         0.007381        0.000489   \n",
       "\n",
       "     param_colsample_bylevel param_colsample_bytree param_learning_rate  \\\n",
       "0                        0.6                    0.3                 0.1   \n",
       "1                        0.6                    0.3                 0.1   \n",
       "2                        0.6                    0.3                 0.1   \n",
       "3                        0.6                    0.3                 0.1   \n",
       "4                        0.6                    0.3                 0.1   \n",
       "...                      ...                    ...                 ...   \n",
       "2995                     0.6                    0.9                 0.4   \n",
       "2996                     0.6                    0.9                 0.4   \n",
       "2997                     0.6                    0.9                 0.4   \n",
       "2998                     0.6                    0.9                 0.4   \n",
       "2999                     0.6                    0.9                 0.4   \n",
       "\n",
       "     param_max_depth param_n_estimators param_subsample  ...  \\\n",
       "0                  2                100             0.5  ...   \n",
       "1                  2                100             0.6  ...   \n",
       "2                  2                100             0.7  ...   \n",
       "3                  2                100             0.8  ...   \n",
       "4                  2                100             0.9  ...   \n",
       "...              ...                ...             ...  ...   \n",
       "2995               5                300             0.5  ...   \n",
       "2996               5                300             0.6  ...   \n",
       "2997               5                300             0.7  ...   \n",
       "2998               5                300             0.8  ...   \n",
       "2999               5                300             0.9  ...   \n",
       "\n",
       "     split3_test_score  split4_test_score  split5_test_score  \\\n",
       "0             0.870968           0.822581           0.838710   \n",
       "1             0.854839           0.822581           0.854839   \n",
       "2             0.887097           0.838710           0.854839   \n",
       "3             0.870968           0.822581           0.870968   \n",
       "4             0.870968           0.822581           0.887097   \n",
       "...                ...                ...                ...   \n",
       "2995          0.806452           0.741935           0.774194   \n",
       "2996          0.854839           0.790323           0.758065   \n",
       "2997          0.838710           0.774194           0.790323   \n",
       "2998          0.838710           0.790323           0.758065   \n",
       "2999          0.822581           0.790323           0.758065   \n",
       "\n",
       "      split6_test_score  split7_test_score  split8_test_score  \\\n",
       "0              0.854839           0.822581           0.709677   \n",
       "1              0.854839           0.822581           0.693548   \n",
       "2              0.854839           0.838710           0.709677   \n",
       "3              0.838710           0.822581           0.693548   \n",
       "4              0.822581           0.806452           0.677419   \n",
       "...                 ...                ...                ...   \n",
       "2995           0.806452           0.790323           0.741935   \n",
       "2996           0.822581           0.741935           0.725806   \n",
       "2997           0.822581           0.774194           0.725806   \n",
       "2998           0.822581           0.806452           0.709677   \n",
       "2999           0.838710           0.806452           0.709677   \n",
       "\n",
       "      split9_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0              0.838710         0.834537        0.044892              215  \n",
       "1              0.854839         0.832949        0.048291              320  \n",
       "2              0.854839         0.842601        0.046342               17  \n",
       "3              0.854839         0.834562        0.050284              208  \n",
       "4              0.854839         0.832924        0.057218              327  \n",
       "...                 ...              ...             ...              ...  \n",
       "2995           0.806452         0.805504        0.051226             2997  \n",
       "2996           0.806452         0.810317        0.059764             2968  \n",
       "2997           0.822581         0.818331        0.051641             2706  \n",
       "2998           0.806452         0.816718        0.054669             2825  \n",
       "2999           0.822581         0.807220        0.045482             2983  \n",
       "\n",
       "[3000 rows x 24 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score is 0.8458269329237071 with params {'colsample_bylevel': 0.6, 'colsample_bytree': 0.4, 'learning_rate': 0.1, 'max_depth': 2, 'n_estimators': 100, 'subsample': 0.8}\n"
     ]
    }
   ],
   "source": [
    "# Full Tuning - Part 5\n",
    "random.seed(10)\n",
    "\n",
    "xgb = XGBClassifier()\n",
    "\n",
    "xgb_parameters = {'max_depth': [2,3,4,5]\n",
    "                   , 'subsample': [0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "                   , 'colsample_bytree': [0.3, 0.4, 0.5, 0.6, 0.9]\n",
    "                   , 'colsample_bylevel': [0.6]\n",
    "                   , 'learning_rate': [0.1, 0.15, 0.2, 0.25, 0.3, 0.4]\n",
    "                   , 'n_estimators': [100, 150, 200, 250, 300]}\n",
    "\n",
    "stratified_10_fold_cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "xgb_grid_search = GridSearchCV(xgb, xgb_parameters, scoring='accuracy', cv=stratified_10_fold_cv)\n",
    "\n",
    "xgb_grid_search.fit(X_train, y_train)\n",
    "\n",
    "xgb_grid_search_results_full_5 = pd.DataFrame(xgb_grid_search.cv_results_)\n",
    "display(xgb_grid_search_results_full_5)\n",
    "\n",
    "print(\"best score is {} with params {}\".format(xgb_grid_search.best_score_, xgb_grid_search.best_params_))\n",
    "#best score is 0.8458269329237071 with params\n",
    "#{'colsample_bylevel': 0.6, 'colsample_bytree': 0.4, 'learning_rate': 0.1, 'max_depth': 2, 'n_estimators': 100, 'subsample': 0.8}\n",
    "\n",
    "# save dataframe\n",
    "from datetime import datetime\n",
    "date = str(datetime.now().date()).replace(\"-\", \"\")\n",
    "xgb_grid_search_results_full_5.to_csv(f\"results/xgb_results_full_round2_5_bylevel=0.6_{date}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b6962257",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_colsample_bylevel</th>\n",
       "      <th>param_colsample_bytree</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_subsample</th>\n",
       "      <th>...</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.063128</td>\n",
       "      <td>0.002527</td>\n",
       "      <td>0.006483</td>\n",
       "      <td>0.000669</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.834537</td>\n",
       "      <td>0.044892</td>\n",
       "      <td>218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.065325</td>\n",
       "      <td>0.003097</td>\n",
       "      <td>0.006882</td>\n",
       "      <td>0.000537</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.832949</td>\n",
       "      <td>0.048291</td>\n",
       "      <td>327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.061886</td>\n",
       "      <td>0.000566</td>\n",
       "      <td>0.006583</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.887097</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.842601</td>\n",
       "      <td>0.046342</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.061137</td>\n",
       "      <td>0.000638</td>\n",
       "      <td>0.006882</td>\n",
       "      <td>0.000299</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.834562</td>\n",
       "      <td>0.050284</td>\n",
       "      <td>210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.060537</td>\n",
       "      <td>0.000638</td>\n",
       "      <td>0.006682</td>\n",
       "      <td>0.000457</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.887097</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.832924</td>\n",
       "      <td>0.057218</td>\n",
       "      <td>333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2995</th>\n",
       "      <td>0.228489</td>\n",
       "      <td>0.002462</td>\n",
       "      <td>0.007480</td>\n",
       "      <td>0.000499</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.802355</td>\n",
       "      <td>0.049888</td>\n",
       "      <td>2998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2996</th>\n",
       "      <td>0.228688</td>\n",
       "      <td>0.002142</td>\n",
       "      <td>0.007281</td>\n",
       "      <td>0.000457</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.800768</td>\n",
       "      <td>0.052893</td>\n",
       "      <td>2999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2997</th>\n",
       "      <td>0.228987</td>\n",
       "      <td>0.001197</td>\n",
       "      <td>0.007580</td>\n",
       "      <td>0.000488</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.810317</td>\n",
       "      <td>0.057193</td>\n",
       "      <td>2964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998</th>\n",
       "      <td>0.228788</td>\n",
       "      <td>0.001620</td>\n",
       "      <td>0.007181</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.816692</td>\n",
       "      <td>0.055624</td>\n",
       "      <td>2812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999</th>\n",
       "      <td>0.226893</td>\n",
       "      <td>0.002150</td>\n",
       "      <td>0.007381</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.818382</td>\n",
       "      <td>0.053516</td>\n",
       "      <td>2629</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0          0.063128      0.002527         0.006483        0.000669   \n",
       "1          0.065325      0.003097         0.006882        0.000537   \n",
       "2          0.061886      0.000566         0.006583        0.000489   \n",
       "3          0.061137      0.000638         0.006882        0.000299   \n",
       "4          0.060537      0.000638         0.006682        0.000457   \n",
       "...             ...           ...              ...             ...   \n",
       "2995       0.228489      0.002462         0.007480        0.000499   \n",
       "2996       0.228688      0.002142         0.007281        0.000457   \n",
       "2997       0.228987      0.001197         0.007580        0.000488   \n",
       "2998       0.228788      0.001620         0.007181        0.000399   \n",
       "2999       0.226893      0.002150         0.007381        0.000489   \n",
       "\n",
       "      param_colsample_bylevel  param_colsample_bytree  param_learning_rate  \\\n",
       "0                         0.7                     0.3                  0.1   \n",
       "1                         0.7                     0.3                  0.1   \n",
       "2                         0.7                     0.3                  0.1   \n",
       "3                         0.7                     0.3                  0.1   \n",
       "4                         0.7                     0.3                  0.1   \n",
       "...                       ...                     ...                  ...   \n",
       "2995                      0.7                     0.9                  0.4   \n",
       "2996                      0.7                     0.9                  0.4   \n",
       "2997                      0.7                     0.9                  0.4   \n",
       "2998                      0.7                     0.9                  0.4   \n",
       "2999                      0.7                     0.9                  0.4   \n",
       "\n",
       "      param_max_depth  param_n_estimators  param_subsample  ...  \\\n",
       "0                   2                 100              0.5  ...   \n",
       "1                   2                 100              0.6  ...   \n",
       "2                   2                 100              0.7  ...   \n",
       "3                   2                 100              0.8  ...   \n",
       "4                   2                 100              0.9  ...   \n",
       "...               ...                 ...              ...  ...   \n",
       "2995                5                 300              0.5  ...   \n",
       "2996                5                 300              0.6  ...   \n",
       "2997                5                 300              0.7  ...   \n",
       "2998                5                 300              0.8  ...   \n",
       "2999                5                 300              0.9  ...   \n",
       "\n",
       "     split3_test_score  split4_test_score  split5_test_score  \\\n",
       "0             0.870968           0.822581           0.838710   \n",
       "1             0.854839           0.822581           0.854839   \n",
       "2             0.887097           0.838710           0.854839   \n",
       "3             0.870968           0.822581           0.870968   \n",
       "4             0.870968           0.822581           0.887097   \n",
       "...                ...                ...                ...   \n",
       "2995          0.822581           0.774194           0.806452   \n",
       "2996          0.822581           0.774194           0.790323   \n",
       "2997          0.870968           0.774194           0.774194   \n",
       "2998          0.822581           0.790323           0.774194   \n",
       "2999          0.806452           0.790323           0.774194   \n",
       "\n",
       "      split6_test_score  split7_test_score  split8_test_score  \\\n",
       "0              0.854839           0.822581           0.709677   \n",
       "1              0.854839           0.822581           0.693548   \n",
       "2              0.854839           0.838710           0.709677   \n",
       "3              0.838710           0.822581           0.693548   \n",
       "4              0.822581           0.806452           0.677419   \n",
       "...                 ...                ...                ...   \n",
       "2995           0.822581           0.774194           0.709677   \n",
       "2996           0.822581           0.790323           0.693548   \n",
       "2997           0.790323           0.790323           0.709677   \n",
       "2998           0.822581           0.790323           0.709677   \n",
       "2999           0.854839           0.790323           0.709677   \n",
       "\n",
       "      split9_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0              0.838710         0.834537        0.044892              218  \n",
       "1              0.854839         0.832949        0.048291              327  \n",
       "2              0.854839         0.842601        0.046342               16  \n",
       "3              0.854839         0.834562        0.050284              210  \n",
       "4              0.854839         0.832924        0.057218              333  \n",
       "...                 ...              ...             ...              ...  \n",
       "2995           0.774194         0.802355        0.049888             2998  \n",
       "2996           0.790323         0.800768        0.052893             2999  \n",
       "2997           0.790323         0.810317        0.057193             2964  \n",
       "2998           0.806452         0.816692        0.055624             2812  \n",
       "2999           0.854839         0.818382        0.053516             2629  \n",
       "\n",
       "[3000 rows x 24 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score is 0.8490015360983103 with params {'colsample_bylevel': 0.7, 'colsample_bytree': 0.4, 'learning_rate': 0.1, 'max_depth': 2, 'n_estimators': 150, 'subsample': 0.9}\n"
     ]
    }
   ],
   "source": [
    "df6 = pd.read_csv(\"data\\\\xgb_results_full_6_bylevel=0.7_20221123.csv\")\n",
    "df6.drop(df6.columns[0], axis=1, inplace=True)\n",
    "display(df6)\n",
    "print(\"best score is 0.8490015360983103 with params {'colsample_bylevel': 0.7, 'colsample_bytree': 0.4, 'learning_rate': 0.1, 'max_depth': 2, 'n_estimators': 150, 'subsample': 0.9}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dc96b622",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_colsample_bylevel</th>\n",
       "      <th>param_colsample_bytree</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_subsample</th>\n",
       "      <th>...</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.063128</td>\n",
       "      <td>0.002527</td>\n",
       "      <td>0.006483</td>\n",
       "      <td>0.000669</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.834537</td>\n",
       "      <td>0.044892</td>\n",
       "      <td>218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.065325</td>\n",
       "      <td>0.003097</td>\n",
       "      <td>0.006882</td>\n",
       "      <td>0.000537</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.832949</td>\n",
       "      <td>0.048291</td>\n",
       "      <td>327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.061886</td>\n",
       "      <td>0.000566</td>\n",
       "      <td>0.006583</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.887097</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.842601</td>\n",
       "      <td>0.046342</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.061137</td>\n",
       "      <td>0.000638</td>\n",
       "      <td>0.006882</td>\n",
       "      <td>0.000299</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.834562</td>\n",
       "      <td>0.050284</td>\n",
       "      <td>210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.060537</td>\n",
       "      <td>0.000638</td>\n",
       "      <td>0.006682</td>\n",
       "      <td>0.000457</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.887097</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.832924</td>\n",
       "      <td>0.057218</td>\n",
       "      <td>333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2995</th>\n",
       "      <td>0.228489</td>\n",
       "      <td>0.002462</td>\n",
       "      <td>0.007480</td>\n",
       "      <td>0.000499</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.802355</td>\n",
       "      <td>0.049888</td>\n",
       "      <td>2998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2996</th>\n",
       "      <td>0.228688</td>\n",
       "      <td>0.002142</td>\n",
       "      <td>0.007281</td>\n",
       "      <td>0.000457</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.800768</td>\n",
       "      <td>0.052893</td>\n",
       "      <td>2999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2997</th>\n",
       "      <td>0.228987</td>\n",
       "      <td>0.001197</td>\n",
       "      <td>0.007580</td>\n",
       "      <td>0.000488</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.810317</td>\n",
       "      <td>0.057193</td>\n",
       "      <td>2964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998</th>\n",
       "      <td>0.228788</td>\n",
       "      <td>0.001620</td>\n",
       "      <td>0.007181</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.816692</td>\n",
       "      <td>0.055624</td>\n",
       "      <td>2812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999</th>\n",
       "      <td>0.226893</td>\n",
       "      <td>0.002150</td>\n",
       "      <td>0.007381</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.818382</td>\n",
       "      <td>0.053516</td>\n",
       "      <td>2629</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0          0.063128      0.002527         0.006483        0.000669   \n",
       "1          0.065325      0.003097         0.006882        0.000537   \n",
       "2          0.061886      0.000566         0.006583        0.000489   \n",
       "3          0.061137      0.000638         0.006882        0.000299   \n",
       "4          0.060537      0.000638         0.006682        0.000457   \n",
       "...             ...           ...              ...             ...   \n",
       "2995       0.228489      0.002462         0.007480        0.000499   \n",
       "2996       0.228688      0.002142         0.007281        0.000457   \n",
       "2997       0.228987      0.001197         0.007580        0.000488   \n",
       "2998       0.228788      0.001620         0.007181        0.000399   \n",
       "2999       0.226893      0.002150         0.007381        0.000489   \n",
       "\n",
       "     param_colsample_bylevel param_colsample_bytree param_learning_rate  \\\n",
       "0                        0.7                    0.3                 0.1   \n",
       "1                        0.7                    0.3                 0.1   \n",
       "2                        0.7                    0.3                 0.1   \n",
       "3                        0.7                    0.3                 0.1   \n",
       "4                        0.7                    0.3                 0.1   \n",
       "...                      ...                    ...                 ...   \n",
       "2995                     0.7                    0.9                 0.4   \n",
       "2996                     0.7                    0.9                 0.4   \n",
       "2997                     0.7                    0.9                 0.4   \n",
       "2998                     0.7                    0.9                 0.4   \n",
       "2999                     0.7                    0.9                 0.4   \n",
       "\n",
       "     param_max_depth param_n_estimators param_subsample  ...  \\\n",
       "0                  2                100             0.5  ...   \n",
       "1                  2                100             0.6  ...   \n",
       "2                  2                100             0.7  ...   \n",
       "3                  2                100             0.8  ...   \n",
       "4                  2                100             0.9  ...   \n",
       "...              ...                ...             ...  ...   \n",
       "2995               5                300             0.5  ...   \n",
       "2996               5                300             0.6  ...   \n",
       "2997               5                300             0.7  ...   \n",
       "2998               5                300             0.8  ...   \n",
       "2999               5                300             0.9  ...   \n",
       "\n",
       "     split3_test_score  split4_test_score  split5_test_score  \\\n",
       "0             0.870968           0.822581           0.838710   \n",
       "1             0.854839           0.822581           0.854839   \n",
       "2             0.887097           0.838710           0.854839   \n",
       "3             0.870968           0.822581           0.870968   \n",
       "4             0.870968           0.822581           0.887097   \n",
       "...                ...                ...                ...   \n",
       "2995          0.822581           0.774194           0.806452   \n",
       "2996          0.822581           0.774194           0.790323   \n",
       "2997          0.870968           0.774194           0.774194   \n",
       "2998          0.822581           0.790323           0.774194   \n",
       "2999          0.806452           0.790323           0.774194   \n",
       "\n",
       "      split6_test_score  split7_test_score  split8_test_score  \\\n",
       "0              0.854839           0.822581           0.709677   \n",
       "1              0.854839           0.822581           0.693548   \n",
       "2              0.854839           0.838710           0.709677   \n",
       "3              0.838710           0.822581           0.693548   \n",
       "4              0.822581           0.806452           0.677419   \n",
       "...                 ...                ...                ...   \n",
       "2995           0.822581           0.774194           0.709677   \n",
       "2996           0.822581           0.790323           0.693548   \n",
       "2997           0.790323           0.790323           0.709677   \n",
       "2998           0.822581           0.790323           0.709677   \n",
       "2999           0.854839           0.790323           0.709677   \n",
       "\n",
       "      split9_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0              0.838710         0.834537        0.044892              218  \n",
       "1              0.854839         0.832949        0.048291              327  \n",
       "2              0.854839         0.842601        0.046342               16  \n",
       "3              0.854839         0.834562        0.050284              210  \n",
       "4              0.854839         0.832924        0.057218              333  \n",
       "...                 ...              ...             ...              ...  \n",
       "2995           0.774194         0.802355        0.049888             2998  \n",
       "2996           0.790323         0.800768        0.052893             2999  \n",
       "2997           0.790323         0.810317        0.057193             2964  \n",
       "2998           0.806452         0.816692        0.055624             2812  \n",
       "2999           0.854839         0.818382        0.053516             2629  \n",
       "\n",
       "[3000 rows x 24 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score is 0.8490015360983103 with params {'colsample_bylevel': 0.7, 'colsample_bytree': 0.4, 'learning_rate': 0.1, 'max_depth': 2, 'n_estimators': 150, 'subsample': 0.9}\n"
     ]
    }
   ],
   "source": [
    "# Full Tuning - Part 6\n",
    "random.seed(10)\n",
    "\n",
    "xgb = XGBClassifier()\n",
    "\n",
    "xgb_parameters = {'max_depth': [2,3,4,5]\n",
    "                   , 'subsample': [0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "                   , 'colsample_bytree': [0.3, 0.4, 0.5, 0.6, 0.9]\n",
    "                   , 'colsample_bylevel': [0.7]\n",
    "                   , 'learning_rate': [0.1, 0.15, 0.2, 0.25, 0.3, 0.4]\n",
    "                   , 'n_estimators': [100, 150, 200, 250, 300]}\n",
    "\n",
    "stratified_10_fold_cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "xgb_grid_search = GridSearchCV(xgb, xgb_parameters, scoring='accuracy', cv=stratified_10_fold_cv)\n",
    "\n",
    "xgb_grid_search.fit(X_train, y_train)\n",
    "\n",
    "xgb_grid_search_results_full_6 = pd.DataFrame(xgb_grid_search.cv_results_)\n",
    "display(xgb_grid_search_results_full_6)\n",
    "\n",
    "print(\"best score is {} with params {}\".format(xgb_grid_search.best_score_, xgb_grid_search.best_params_))\n",
    "#best score is 0.8490015360983103 with params\n",
    "#{'colsample_bylevel': 0.7, 'colsample_bytree': 0.4, 'learning_rate': 0.1, 'max_depth': 2, 'n_estimators': 150, 'subsample': 0.9}\n",
    "\n",
    "# save dataframe\n",
    "from datetime import datetime\n",
    "date = str(datetime.now().date()).replace(\"-\", \"\")\n",
    "xgb_grid_search_results_full_6.to_csv(f\"results/xgb_results_full_round2_6_bylevel=0.7_{date}.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd55526d",
   "metadata": {},
   "source": [
    "Combine single hyper parameter tuning to find best values for hyper parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9b22556b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_colsample_bylevel</th>\n",
       "      <th>param_colsample_bytree</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_subsample</th>\n",
       "      <th>...</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.064527</td>\n",
       "      <td>0.004136</td>\n",
       "      <td>0.005885</td>\n",
       "      <td>0.000538</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.820020</td>\n",
       "      <td>0.048275</td>\n",
       "      <td>15186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.064327</td>\n",
       "      <td>0.002493</td>\n",
       "      <td>0.005885</td>\n",
       "      <td>0.000537</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.661290</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.823221</td>\n",
       "      <td>0.059057</td>\n",
       "      <td>12810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.063231</td>\n",
       "      <td>0.001954</td>\n",
       "      <td>0.005785</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.824782</td>\n",
       "      <td>0.057512</td>\n",
       "      <td>12084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.062235</td>\n",
       "      <td>0.001017</td>\n",
       "      <td>0.006082</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.661290</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.824834</td>\n",
       "      <td>0.059251</td>\n",
       "      <td>11402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.062333</td>\n",
       "      <td>0.002285</td>\n",
       "      <td>0.005784</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.828059</td>\n",
       "      <td>0.053977</td>\n",
       "      <td>8256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17995</th>\n",
       "      <td>0.228489</td>\n",
       "      <td>0.002462</td>\n",
       "      <td>0.007480</td>\n",
       "      <td>0.000499</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.802355</td>\n",
       "      <td>0.049888</td>\n",
       "      <td>17998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17996</th>\n",
       "      <td>0.228688</td>\n",
       "      <td>0.002142</td>\n",
       "      <td>0.007281</td>\n",
       "      <td>0.000457</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.800768</td>\n",
       "      <td>0.052893</td>\n",
       "      <td>17999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17997</th>\n",
       "      <td>0.228987</td>\n",
       "      <td>0.001197</td>\n",
       "      <td>0.007580</td>\n",
       "      <td>0.000488</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.810317</td>\n",
       "      <td>0.057193</td>\n",
       "      <td>17871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17998</th>\n",
       "      <td>0.228788</td>\n",
       "      <td>0.001620</td>\n",
       "      <td>0.007181</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.816692</td>\n",
       "      <td>0.055624</td>\n",
       "      <td>17108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17999</th>\n",
       "      <td>0.226893</td>\n",
       "      <td>0.002150</td>\n",
       "      <td>0.007381</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.818382</td>\n",
       "      <td>0.053516</td>\n",
       "      <td>16381</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18000 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0           0.064527      0.004136         0.005885        0.000538   \n",
       "1           0.064327      0.002493         0.005885        0.000537   \n",
       "2           0.063231      0.001954         0.005785        0.000399   \n",
       "3           0.062235      0.001017         0.006082        0.000300   \n",
       "4           0.062333      0.002285         0.005784        0.000399   \n",
       "...              ...           ...              ...             ...   \n",
       "17995       0.228489      0.002462         0.007480        0.000499   \n",
       "17996       0.228688      0.002142         0.007281        0.000457   \n",
       "17997       0.228987      0.001197         0.007580        0.000488   \n",
       "17998       0.228788      0.001620         0.007181        0.000399   \n",
       "17999       0.226893      0.002150         0.007381        0.000489   \n",
       "\n",
       "       param_colsample_bylevel  param_colsample_bytree  param_learning_rate  \\\n",
       "0                          0.1                     0.3                  0.1   \n",
       "1                          0.1                     0.3                  0.1   \n",
       "2                          0.1                     0.3                  0.1   \n",
       "3                          0.1                     0.3                  0.1   \n",
       "4                          0.1                     0.3                  0.1   \n",
       "...                        ...                     ...                  ...   \n",
       "17995                      0.7                     0.9                  0.4   \n",
       "17996                      0.7                     0.9                  0.4   \n",
       "17997                      0.7                     0.9                  0.4   \n",
       "17998                      0.7                     0.9                  0.4   \n",
       "17999                      0.7                     0.9                  0.4   \n",
       "\n",
       "       param_max_depth  param_n_estimators  param_subsample  ...  \\\n",
       "0                    2                 100              0.5  ...   \n",
       "1                    2                 100              0.6  ...   \n",
       "2                    2                 100              0.7  ...   \n",
       "3                    2                 100              0.8  ...   \n",
       "4                    2                 100              0.9  ...   \n",
       "...                ...                 ...              ...  ...   \n",
       "17995                5                 300              0.5  ...   \n",
       "17996                5                 300              0.6  ...   \n",
       "17997                5                 300              0.7  ...   \n",
       "17998                5                 300              0.8  ...   \n",
       "17999                5                 300              0.9  ...   \n",
       "\n",
       "      split3_test_score  split4_test_score  split5_test_score  \\\n",
       "0              0.822581           0.822581           0.806452   \n",
       "1              0.838710           0.822581           0.806452   \n",
       "2              0.838710           0.806452           0.806452   \n",
       "3              0.854839           0.822581           0.806452   \n",
       "4              0.854839           0.822581           0.838710   \n",
       "...                 ...                ...                ...   \n",
       "17995          0.822581           0.774194           0.806452   \n",
       "17996          0.822581           0.774194           0.790323   \n",
       "17997          0.870968           0.774194           0.774194   \n",
       "17998          0.822581           0.790323           0.774194   \n",
       "17999          0.806452           0.790323           0.774194   \n",
       "\n",
       "       split6_test_score  split7_test_score  split8_test_score  \\\n",
       "0               0.822581           0.806452           0.693548   \n",
       "1               0.838710           0.806452           0.661290   \n",
       "2               0.838710           0.806452           0.677419   \n",
       "3               0.854839           0.806452           0.661290   \n",
       "4               0.838710           0.806452           0.677419   \n",
       "...                  ...                ...                ...   \n",
       "17995           0.822581           0.774194           0.709677   \n",
       "17996           0.822581           0.790323           0.693548   \n",
       "17997           0.790323           0.790323           0.709677   \n",
       "17998           0.822581           0.790323           0.709677   \n",
       "17999           0.854839           0.790323           0.709677   \n",
       "\n",
       "       split9_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0               0.838710         0.820020        0.048275            15186  \n",
       "1               0.854839         0.823221        0.059057            12810  \n",
       "2               0.838710         0.824782        0.057512            12084  \n",
       "3               0.838710         0.824834        0.059251            11402  \n",
       "4               0.838710         0.828059        0.053977             8256  \n",
       "...                  ...              ...             ...              ...  \n",
       "17995           0.774194         0.802355        0.049888            17998  \n",
       "17996           0.790323         0.800768        0.052893            17999  \n",
       "17997           0.790323         0.810317        0.057193            17871  \n",
       "17998           0.806452         0.816692        0.055624            17108  \n",
       "17999           0.854839         0.818382        0.053516            16381  \n",
       "\n",
       "[18000 rows x 24 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score is 0.850563 with params {'colsample_bylevel': 0.4, 'colsample_bytree': 0.5, 'learning_rate': 0.15, 'max_depth': 2, 'n_estimators': 100, 'subsample': 0.7}\n"
     ]
    }
   ],
   "source": [
    "# read single parts of round 2, concatenate and update index and rank_test_score\n",
    "\n",
    "df1 = pd.read_csv(\"data\\\\xgb_results_full_1_bylevel=0.1_20221123.csv\")\n",
    "df1.drop(df1.columns[0], axis=1, inplace=True)\n",
    "\n",
    "df2 = pd.read_csv(\"data\\\\xgb_results_full_2_bylevel=0.2_20221123.csv\")\n",
    "df2.drop(df2.columns[0], axis=1, inplace=True)\n",
    "\n",
    "df3 = pd.read_csv(\"data\\\\xgb_results_full_3_bylevel=0.3_20221123.csv\")\n",
    "df3.drop(df3.columns[0], axis=1, inplace=True)\n",
    "\n",
    "df4 = pd.read_csv(\"data\\\\xgb_results_full_4_bylevel=0.4_20221123.csv\")\n",
    "df4.drop(df4.columns[0], axis=1, inplace=True)\n",
    "\n",
    "df5 = pd.read_csv(\"data\\\\xgb_results_full_5_bylevel=0.6_20221123.csv\")\n",
    "df5.drop(df5.columns[0], axis=1, inplace=True)\n",
    "\n",
    "df6 = pd.read_csv(\"data\\\\xgb_results_full_6_bylevel=0.7_20221123.csv\")\n",
    "df6.drop(df6.columns[0], axis=1, inplace=True)\n",
    "\n",
    "df_full = pd.concat([df1,df2,df3,df4,df5,df6])\n",
    "\n",
    "#assign correct rank\n",
    "df_full = df_full.sort_values(by='mean_test_score', ascending=False)\n",
    "df_full['rank_test_score'] = range(1, len(df_full)+1)\n",
    "\n",
    "#get correct order and set new index\n",
    "df_full = df_full.sort_values(by=['param_colsample_bylevel', 'param_colsample_bytree', 'param_learning_rate', 'param_max_depth', 'param_n_estimators', 'param_subsample'])\n",
    "xgb_grid_search_results_round2 = df_full.set_index(np.array(range(len(df_full))))\n",
    "display(xgb_grid_search_results_round2)\n",
    "\n",
    "print(\"best score is 0.850563 with params {'colsample_bylevel': 0.4, 'colsample_bytree': 0.5, 'learning_rate': 0.15, 'max_depth': 2, 'n_estimators': 100, 'subsample': 0.7}\")\n",
    "\n",
    "# save dataframe\n",
    "from datetime import datetime\n",
    "date = str(datetime.now().date()).replace(\"-\", \"\")\n",
    "xgb_grid_search_results_round2.to_csv(f\"results/xgb_results_round2_{date}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "22eaf083",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_subsample</th>\n",
       "      <th>param_colsample_bylevel</th>\n",
       "      <th>param_colsample_bytree</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10302</th>\n",
       "      <td>2</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.15</td>\n",
       "      <td>100</td>\n",
       "      <td>0.850563</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7302</th>\n",
       "      <td>2</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.15</td>\n",
       "      <td>100</td>\n",
       "      <td>0.850563</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4976</th>\n",
       "      <td>5</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.15</td>\n",
       "      <td>100</td>\n",
       "      <td>0.850538</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1976</th>\n",
       "      <td>5</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.15</td>\n",
       "      <td>100</td>\n",
       "      <td>0.850538</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5419</th>\n",
       "      <td>2</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.10</td>\n",
       "      <td>250</td>\n",
       "      <td>0.849002</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7745</th>\n",
       "      <td>3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.40</td>\n",
       "      <td>300</td>\n",
       "      <td>0.803943</td>\n",
       "      <td>17996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13171</th>\n",
       "      <td>4</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.40</td>\n",
       "      <td>300</td>\n",
       "      <td>0.803917</td>\n",
       "      <td>17997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17995</th>\n",
       "      <td>5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.40</td>\n",
       "      <td>300</td>\n",
       "      <td>0.802355</td>\n",
       "      <td>17998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17996</th>\n",
       "      <td>5</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.40</td>\n",
       "      <td>300</td>\n",
       "      <td>0.800768</td>\n",
       "      <td>17999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17940</th>\n",
       "      <td>3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.40</td>\n",
       "      <td>250</td>\n",
       "      <td>0.800742</td>\n",
       "      <td>18000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18000 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       param_max_depth  param_subsample  param_colsample_bylevel  \\\n",
       "10302                2              0.7                      0.4   \n",
       "7302                 2              0.7                      0.3   \n",
       "4976                 5              0.6                      0.2   \n",
       "1976                 5              0.6                      0.1   \n",
       "5419                 2              0.9                      0.2   \n",
       "...                ...              ...                      ...   \n",
       "7745                 3              0.5                      0.3   \n",
       "13171                4              0.6                      0.6   \n",
       "17995                5              0.5                      0.7   \n",
       "17996                5              0.6                      0.7   \n",
       "17940                3              0.5                      0.7   \n",
       "\n",
       "       param_colsample_bytree  param_learning_rate  param_n_estimators  \\\n",
       "10302                     0.5                 0.15                 100   \n",
       "7302                      0.5                 0.15                 100   \n",
       "4976                      0.6                 0.15                 100   \n",
       "1976                      0.6                 0.15                 100   \n",
       "5419                      0.9                 0.10                 250   \n",
       "...                       ...                  ...                 ...   \n",
       "7745                      0.5                 0.40                 300   \n",
       "13171                     0.4                 0.40                 300   \n",
       "17995                     0.9                 0.40                 300   \n",
       "17996                     0.9                 0.40                 300   \n",
       "17940                     0.9                 0.40                 250   \n",
       "\n",
       "       mean_test_score  rank_test_score  \n",
       "10302         0.850563                1  \n",
       "7302          0.850563                2  \n",
       "4976          0.850538                3  \n",
       "1976          0.850538                4  \n",
       "5419          0.849002                5  \n",
       "...                ...              ...  \n",
       "7745          0.803943            17996  \n",
       "13171         0.803917            17997  \n",
       "17995         0.802355            17998  \n",
       "17996         0.800768            17999  \n",
       "17940         0.800742            18000  \n",
       "\n",
       "[18000 rows x 8 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# store relevant columns and sort by rank_test_score\n",
    "cols_full = ['param_max_depth', 'param_subsample', 'param_colsample_bylevel', 'param_colsample_bytree', 'param_learning_rate', 'param_n_estimators', 'mean_test_score', 'rank_test_score']\n",
    "xgb_results_round2_sorted = xgb_grid_search_results_round2[cols_full]\n",
    "xgb_results_round2_sorted = xgb_results_round2_sorted.sort_values(by='rank_test_score')\n",
    "display(xgb_results_round2_sorted)\n",
    "\n",
    "# save dataframe\n",
    "from datetime import datetime\n",
    "date = str(datetime.now().date()).replace(\"-\", \"\")\n",
    "xgb_results_round2_sorted.to_csv(f\"results/xgb_results_round2_sorted_{date}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "31aeddd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.8283582089552238\n",
      "F1 Score = 0.7788461538461539\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.90      0.86       157\n",
      "           1       0.84      0.73      0.78       111\n",
      "\n",
      "    accuracy                           0.83       268\n",
      "   macro avg       0.83      0.81      0.82       268\n",
      "weighted avg       0.83      0.83      0.83       268\n",
      "\n",
      "Confusion Matrix:\n",
      "[[141  16]\n",
      " [ 30  81]]\n"
     ]
    }
   ],
   "source": [
    "# Fit and evaluate best model\n",
    "\n",
    "xgb_best = XGBClassifier(max_depth = 2, subsample = 0.7, colsample_bylevel = 0.4, colsample_bytree = 0.5, learning_rate = 0.15, n_estimators = 100)\n",
    "xgb_best.fit(X_train, y_train)\n",
    "xgb_best_pred = xgb_best.predict(X_test)\n",
    "\n",
    "xgb_best_acc = accuracy_score(y_test, xgb_best_pred)\n",
    "print(\"Accuracy =\", xgb_best_acc) #0.8283582089552238\n",
    "\n",
    "xgb_best_f1 = f1_score(y_test, xgb_best_pred)\n",
    "print(\"F1 Score =\", xgb_best_f1) #0.7788461538461539\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, xgb_best_pred))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, xgb_best_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56268403",
   "metadata": {},
   "source": [
    "beim nächsten Tuning:  \n",
    "- param_subsample ungleich 0.5\n",
    "- param_colsample_bytree ungleich 0.3\n",
    "- param_colsample_bylevel ungleich 0.6\n",
    "- param_learning_rate kleiner gleich 0.2\n",
    "- param_n_estimators ungleich 200 und ungleich 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f05c0475",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc874cb6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af95c214",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2f3a4dda",
   "metadata": {},
   "source": [
    "#### Third Attempt\n",
    "We perform a second hyper parameter tuning, adjusting the parameter grid according to the results of round 2. We use the following parameters and values:  \n",
    "\n",
    "{'max_depth': [2,3,4,5]  \n",
    ", 'subsample': [0.6, 0.7, 0.8, 0.9]  \n",
    ", 'gamma': [0, 1, 10]  \n",
    ", 'colsample_bytree': [0.4, 0.5, 0.6, 0.9]  \n",
    ", 'colsample_bylevel': [0.1, 0.2, 0.3, 0.4]  \n",
    ", 'learning_rate': [0.01, 0.05, 0.08, 0.1, 0.15, 0.2]  \n",
    ", 'n_estimators': [30, 50, 80, 100, 150, 200]}  \n",
    "\n",
    "The best hyper parameter setting results to be xxx which leads to an accuracy of xxx% and a f1 score of xxx% on the test data (after training the classifier on the whole train data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dfb85f37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_colsample_bylevel</th>\n",
       "      <th>param_colsample_bytree</th>\n",
       "      <th>param_gamma</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>...</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.028623</td>\n",
       "      <td>0.002525</td>\n",
       "      <td>0.007181</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.741295</td>\n",
       "      <td>0.048078</td>\n",
       "      <td>27618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.027127</td>\n",
       "      <td>0.000598</td>\n",
       "      <td>0.007082</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.742908</td>\n",
       "      <td>0.049390</td>\n",
       "      <td>27616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.027028</td>\n",
       "      <td>0.000698</td>\n",
       "      <td>0.007580</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.752586</td>\n",
       "      <td>0.048690</td>\n",
       "      <td>27568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.027427</td>\n",
       "      <td>0.000920</td>\n",
       "      <td>0.007381</td>\n",
       "      <td>0.000662</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.742960</td>\n",
       "      <td>0.043040</td>\n",
       "      <td>27614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.040093</td>\n",
       "      <td>0.001465</td>\n",
       "      <td>0.007082</td>\n",
       "      <td>0.000536</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>...</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.765463</td>\n",
       "      <td>0.037846</td>\n",
       "      <td>27462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27643</th>\n",
       "      <td>0.129354</td>\n",
       "      <td>0.001184</td>\n",
       "      <td>0.007281</td>\n",
       "      <td>0.000457</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.20</td>\n",
       "      <td>5</td>\n",
       "      <td>150</td>\n",
       "      <td>...</td>\n",
       "      <td>0.887097</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.919355</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.826600</td>\n",
       "      <td>0.059814</td>\n",
       "      <td>14497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27644</th>\n",
       "      <td>0.168948</td>\n",
       "      <td>0.001739</td>\n",
       "      <td>0.007581</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.20</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.919355</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.828187</td>\n",
       "      <td>0.060472</td>\n",
       "      <td>13496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27645</th>\n",
       "      <td>0.170344</td>\n",
       "      <td>0.002515</td>\n",
       "      <td>0.007481</td>\n",
       "      <td>0.000498</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.20</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.887097</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.824936</td>\n",
       "      <td>0.057195</td>\n",
       "      <td>15641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27646</th>\n",
       "      <td>0.169896</td>\n",
       "      <td>0.002405</td>\n",
       "      <td>0.007281</td>\n",
       "      <td>0.000457</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.20</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.824910</td>\n",
       "      <td>0.045101</td>\n",
       "      <td>15655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27647</th>\n",
       "      <td>0.169047</td>\n",
       "      <td>0.001201</td>\n",
       "      <td>0.007281</td>\n",
       "      <td>0.000457</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.20</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.887097</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.919355</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.826600</td>\n",
       "      <td>0.059814</td>\n",
       "      <td>14482</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27648 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0           0.028623      0.002525         0.007181        0.000399   \n",
       "1           0.027127      0.000598         0.007082        0.000300   \n",
       "2           0.027028      0.000698         0.007580        0.000489   \n",
       "3           0.027427      0.000920         0.007381        0.000662   \n",
       "4           0.040093      0.001465         0.007082        0.000536   \n",
       "...              ...           ...              ...             ...   \n",
       "27643       0.129354      0.001184         0.007281        0.000457   \n",
       "27644       0.168948      0.001739         0.007581        0.000489   \n",
       "27645       0.170344      0.002515         0.007481        0.000498   \n",
       "27646       0.169896      0.002405         0.007281        0.000457   \n",
       "27647       0.169047      0.001201         0.007281        0.000457   \n",
       "\n",
       "       param_colsample_bylevel  param_colsample_bytree  param_gamma  \\\n",
       "0                          0.1                     0.4            0   \n",
       "1                          0.1                     0.4            0   \n",
       "2                          0.1                     0.4            0   \n",
       "3                          0.1                     0.4            0   \n",
       "4                          0.1                     0.4            0   \n",
       "...                        ...                     ...          ...   \n",
       "27643                      0.4                     0.9           10   \n",
       "27644                      0.4                     0.9           10   \n",
       "27645                      0.4                     0.9           10   \n",
       "27646                      0.4                     0.9           10   \n",
       "27647                      0.4                     0.9           10   \n",
       "\n",
       "       param_learning_rate  param_max_depth  param_n_estimators  ...  \\\n",
       "0                     0.01                2                  30  ...   \n",
       "1                     0.01                2                  30  ...   \n",
       "2                     0.01                2                  30  ...   \n",
       "3                     0.01                2                  30  ...   \n",
       "4                     0.01                2                  50  ...   \n",
       "...                    ...              ...                 ...  ...   \n",
       "27643                 0.20                5                 150  ...   \n",
       "27644                 0.20                5                 200  ...   \n",
       "27645                 0.20                5                 200  ...   \n",
       "27646                 0.20                5                 200  ...   \n",
       "27647                 0.20                5                 200  ...   \n",
       "\n",
       "       split3_test_score split4_test_score  split5_test_score  \\\n",
       "0               0.758065          0.741935           0.741935   \n",
       "1               0.774194          0.741935           0.741935   \n",
       "2               0.774194          0.758065           0.774194   \n",
       "3               0.790323          0.725806           0.709677   \n",
       "4               0.790323          0.774194           0.774194   \n",
       "...                  ...               ...                ...   \n",
       "27643           0.887097          0.806452           0.919355   \n",
       "27644           0.919355          0.838710           0.870968   \n",
       "27645           0.870968          0.806452           0.887097   \n",
       "27646           0.870968          0.806452           0.854839   \n",
       "27647           0.887097          0.806452           0.919355   \n",
       "\n",
       "       split6_test_score  split7_test_score  split8_test_score  \\\n",
       "0               0.725806           0.677419           0.693548   \n",
       "1               0.725806           0.677419           0.677419   \n",
       "2               0.741935           0.693548           0.677419   \n",
       "3               0.741935           0.709677           0.709677   \n",
       "4               0.725806           0.693548           0.725806   \n",
       "...                  ...                ...                ...   \n",
       "27643           0.822581           0.806452           0.693548   \n",
       "27644           0.806452           0.806452           0.677419   \n",
       "27645           0.806452           0.822581           0.677419   \n",
       "27646           0.822581           0.806452           0.709677   \n",
       "27647           0.822581           0.806452           0.693548   \n",
       "\n",
       "       split9_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0               0.677419         0.741295        0.048078            27618  \n",
       "1               0.693548         0.742908        0.049390            27616  \n",
       "2               0.709677         0.752586        0.048690            27568  \n",
       "3               0.677419         0.742960        0.043040            27614  \n",
       "4               0.758065         0.765463        0.037846            27462  \n",
       "...                  ...              ...             ...              ...  \n",
       "27643           0.822581         0.826600        0.059814            14497  \n",
       "27644           0.838710         0.828187        0.060472            13496  \n",
       "27645           0.838710         0.824936        0.057195            15641  \n",
       "27646           0.822581         0.824910        0.045101            15655  \n",
       "27647           0.822581         0.826600        0.059814            14482  \n",
       "\n",
       "[27648 rows x 25 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score is 0.850563 with params {'colsample_bylevel': 0.4, 'colsample_bytree': 0.4, 'gamma': 1, 'learning_rate': 0.15, 'max_depth': 4, 'n_estimators': 30, 'subsample': 0.9}\n"
     ]
    }
   ],
   "source": [
    "# read single parts of round 3, concatenate and update index and rank_test_score\n",
    "\n",
    "df1 = pd.read_csv(\"data\\\\xgb_results_full_1_learning=0.01_20221124.csv\")\n",
    "df1.drop(df1.columns[0], axis=1, inplace=True)\n",
    "\n",
    "df2 = pd.read_csv(\"data\\\\xgb_results_full_2_learning=0.05_20221124.csv\")\n",
    "df2.drop(df2.columns[0], axis=1, inplace=True)\n",
    "\n",
    "df3 = pd.read_csv(\"data\\\\xgb_results_full_3_learning=0.08_20221124.csv\")\n",
    "df3.drop(df3.columns[0], axis=1, inplace=True)\n",
    "\n",
    "df4 = pd.read_csv(\"data\\\\xgb_results_full_4_learning=0.1_20221124.csv\")\n",
    "df4.drop(df4.columns[0], axis=1, inplace=True)\n",
    "\n",
    "df5 = pd.read_csv(\"data\\\\xgb_results_full_5_learning=0.15_20221124.csv\")\n",
    "df5.drop(df5.columns[0], axis=1, inplace=True)\n",
    "\n",
    "df6 = pd.read_csv(\"data\\\\xgb_results_full_6_learning=0.2_20221124.csv\")\n",
    "df6.drop(df6.columns[0], axis=1, inplace=True)\n",
    "\n",
    "df_full = pd.concat([df1,df2,df3,df4,df5,df6])\n",
    "\n",
    "#assign correct rank\n",
    "df_full = df_full.sort_values(by='mean_test_score', ascending=False)\n",
    "df_full['rank_test_score'] = range(1, len(df_full)+1)\n",
    "\n",
    "#get correct order and set new index\n",
    "df_full = df_full.sort_values(by=['param_colsample_bylevel', 'param_colsample_bytree', 'param_gamma', 'param_learning_rate', 'param_max_depth', 'param_n_estimators', 'param_subsample'])\n",
    "xgb_grid_search_results_round3 = df_full.set_index(np.array(range(len(df_full))))\n",
    "display(xgb_grid_search_results_round3)\n",
    "\n",
    "print(\"best score is 0.850563 with params {'colsample_bylevel': 0.4, 'colsample_bytree': 0.4, 'gamma': 1, 'learning_rate': 0.15, 'max_depth': 4, 'n_estimators': 30, 'subsample': 0.9}\")\n",
    "\n",
    "# save dataframe\n",
    "from datetime import datetime\n",
    "date = str(datetime.now().date()).replace(\"-\", \"\")\n",
    "xgb_grid_search_results_round3.to_csv(f\"results/xgb_results_round3_{date}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ef1cdad4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_colsample_bylevel</th>\n",
       "      <th>param_colsample_bytree</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_subsample</th>\n",
       "      <th>...</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.064527</td>\n",
       "      <td>0.004136</td>\n",
       "      <td>0.005885</td>\n",
       "      <td>0.000538</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.820020</td>\n",
       "      <td>0.048275</td>\n",
       "      <td>2840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.064327</td>\n",
       "      <td>0.002493</td>\n",
       "      <td>0.005885</td>\n",
       "      <td>0.000537</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.661290</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.823221</td>\n",
       "      <td>0.059057</td>\n",
       "      <td>5179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.063231</td>\n",
       "      <td>0.001954</td>\n",
       "      <td>0.005785</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.824782</td>\n",
       "      <td>0.057512</td>\n",
       "      <td>5860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.062235</td>\n",
       "      <td>0.001017</td>\n",
       "      <td>0.006082</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.661290</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.824834</td>\n",
       "      <td>0.059251</td>\n",
       "      <td>6715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.062333</td>\n",
       "      <td>0.002285</td>\n",
       "      <td>0.005784</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.828059</td>\n",
       "      <td>0.053977</td>\n",
       "      <td>9897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17995</th>\n",
       "      <td>0.228489</td>\n",
       "      <td>0.002462</td>\n",
       "      <td>0.007480</td>\n",
       "      <td>0.000499</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.802355</td>\n",
       "      <td>0.049888</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17996</th>\n",
       "      <td>0.228688</td>\n",
       "      <td>0.002142</td>\n",
       "      <td>0.007281</td>\n",
       "      <td>0.000457</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.800768</td>\n",
       "      <td>0.052893</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17997</th>\n",
       "      <td>0.228987</td>\n",
       "      <td>0.001197</td>\n",
       "      <td>0.007580</td>\n",
       "      <td>0.000488</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.810317</td>\n",
       "      <td>0.057193</td>\n",
       "      <td>139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17998</th>\n",
       "      <td>0.228788</td>\n",
       "      <td>0.001620</td>\n",
       "      <td>0.007181</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.816692</td>\n",
       "      <td>0.055624</td>\n",
       "      <td>893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17999</th>\n",
       "      <td>0.226893</td>\n",
       "      <td>0.002150</td>\n",
       "      <td>0.007381</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.818382</td>\n",
       "      <td>0.053516</td>\n",
       "      <td>1646</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18000 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0           0.064527      0.004136         0.005885        0.000538   \n",
       "1           0.064327      0.002493         0.005885        0.000537   \n",
       "2           0.063231      0.001954         0.005785        0.000399   \n",
       "3           0.062235      0.001017         0.006082        0.000300   \n",
       "4           0.062333      0.002285         0.005784        0.000399   \n",
       "...              ...           ...              ...             ...   \n",
       "17995       0.228489      0.002462         0.007480        0.000499   \n",
       "17996       0.228688      0.002142         0.007281        0.000457   \n",
       "17997       0.228987      0.001197         0.007580        0.000488   \n",
       "17998       0.228788      0.001620         0.007181        0.000399   \n",
       "17999       0.226893      0.002150         0.007381        0.000489   \n",
       "\n",
       "       param_colsample_bylevel  param_colsample_bytree  param_learning_rate  \\\n",
       "0                          0.1                     0.3                  0.1   \n",
       "1                          0.1                     0.3                  0.1   \n",
       "2                          0.1                     0.3                  0.1   \n",
       "3                          0.1                     0.3                  0.1   \n",
       "4                          0.1                     0.3                  0.1   \n",
       "...                        ...                     ...                  ...   \n",
       "17995                      0.7                     0.9                  0.4   \n",
       "17996                      0.7                     0.9                  0.4   \n",
       "17997                      0.7                     0.9                  0.4   \n",
       "17998                      0.7                     0.9                  0.4   \n",
       "17999                      0.7                     0.9                  0.4   \n",
       "\n",
       "       param_max_depth  param_n_estimators  param_subsample  ...  \\\n",
       "0                    2                 100              0.5  ...   \n",
       "1                    2                 100              0.6  ...   \n",
       "2                    2                 100              0.7  ...   \n",
       "3                    2                 100              0.8  ...   \n",
       "4                    2                 100              0.9  ...   \n",
       "...                ...                 ...              ...  ...   \n",
       "17995                5                 300              0.5  ...   \n",
       "17996                5                 300              0.6  ...   \n",
       "17997                5                 300              0.7  ...   \n",
       "17998                5                 300              0.8  ...   \n",
       "17999                5                 300              0.9  ...   \n",
       "\n",
       "      split3_test_score  split4_test_score  split5_test_score  \\\n",
       "0              0.822581           0.822581           0.806452   \n",
       "1              0.838710           0.822581           0.806452   \n",
       "2              0.838710           0.806452           0.806452   \n",
       "3              0.854839           0.822581           0.806452   \n",
       "4              0.854839           0.822581           0.838710   \n",
       "...                 ...                ...                ...   \n",
       "17995          0.822581           0.774194           0.806452   \n",
       "17996          0.822581           0.774194           0.790323   \n",
       "17997          0.870968           0.774194           0.774194   \n",
       "17998          0.822581           0.790323           0.774194   \n",
       "17999          0.806452           0.790323           0.774194   \n",
       "\n",
       "       split6_test_score  split7_test_score  split8_test_score  \\\n",
       "0               0.822581           0.806452           0.693548   \n",
       "1               0.838710           0.806452           0.661290   \n",
       "2               0.838710           0.806452           0.677419   \n",
       "3               0.854839           0.806452           0.661290   \n",
       "4               0.838710           0.806452           0.677419   \n",
       "...                  ...                ...                ...   \n",
       "17995           0.822581           0.774194           0.709677   \n",
       "17996           0.822581           0.790323           0.693548   \n",
       "17997           0.790323           0.790323           0.709677   \n",
       "17998           0.822581           0.790323           0.709677   \n",
       "17999           0.854839           0.790323           0.709677   \n",
       "\n",
       "       split9_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0               0.838710         0.820020        0.048275             2840  \n",
       "1               0.854839         0.823221        0.059057             5179  \n",
       "2               0.838710         0.824782        0.057512             5860  \n",
       "3               0.838710         0.824834        0.059251             6715  \n",
       "4               0.838710         0.828059        0.053977             9897  \n",
       "...                  ...              ...             ...              ...  \n",
       "17995           0.774194         0.802355        0.049888                3  \n",
       "17996           0.790323         0.800768        0.052893                2  \n",
       "17997           0.790323         0.810317        0.057193              139  \n",
       "17998           0.806452         0.816692        0.055624              893  \n",
       "17999           0.854839         0.818382        0.053516             1646  \n",
       "\n",
       "[18000 rows x 24 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Third Attempt\n",
    "\n",
    "random.seed(10)\n",
    "\n",
    "xgb = XGBClassifier()\n",
    "\n",
    "xgb_parameters = {'max_depth': [2,3,4,5]\n",
    "                   , 'subsample': [0.6, 0.7, 0.8, 0.9]\n",
    "                   , 'gamma': [0, 1, 10]\n",
    "                   , 'colsample_bytree': [0.4, 0.5, 0.6, 0.9]\n",
    "                   , 'colsample_bylevel': [0.1, 0.2, 0.3, 0.4]\n",
    "                   , 'learning_rate': [0.01, 0.05, 0.08, 0.1, 0.15, 0.2]\n",
    "                   , 'n_estimators': [30, 50, 80, 100, 150, 200]}\n",
    "\n",
    "stratified_10_fold_cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "xgb_grid_search = GridSearchCV(xgb, xgb_parameters, scoring='accuracy', cv=stratified_10_fold_cv)\n",
    "\n",
    "xgb_grid_search.fit(X_train, y_train)\n",
    "\n",
    "xgb_grid_search_results_round3 = pd.DataFrame(xgb_grid_search.cv_results_)\n",
    "display(xgb_grid_search_results_round3)\n",
    "\n",
    "# print the best parameter setting\n",
    "print(\"best score is {} with params {}\".format(xgb_grid_search.best_score_, xgb_grid_search.best_params_))\n",
    "#best score is 0.850563 with params {'colsample_bylevel': 0.4, 'colsample_bytree': 0.4, 'gamma': 1, 'learning_rate': 0.15, 'max_depth': 4, 'n_estimators': 30, 'subsample': 0.9}\n",
    "\n",
    "# save dataframe\n",
    "from datetime import datetime\n",
    "date = str(datetime.now().date()).replace(\"-\", \"\")\n",
    "xgb_grid_search_results_round3.to_csv(f\"results/xgb_results_round3_{date}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0acf7bf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_subsample</th>\n",
       "      <th>param_colsample_bylevel</th>\n",
       "      <th>param_colsample_bytree</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_gamma</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21747</th>\n",
       "      <td>4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.15</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>0.856989</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13080</th>\n",
       "      <td>3</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.15</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>0.852227</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13176</th>\n",
       "      <td>3</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.20</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>0.852202</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21720</th>\n",
       "      <td>3</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.15</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>0.852202</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23470</th>\n",
       "      <td>3</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.15</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>0.852151</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6340</th>\n",
       "      <td>2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.01</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>0.718920</td>\n",
       "      <td>27644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6339</th>\n",
       "      <td>2</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.01</td>\n",
       "      <td>30</td>\n",
       "      <td>10</td>\n",
       "      <td>0.709217</td>\n",
       "      <td>27645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6338</th>\n",
       "      <td>2</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.01</td>\n",
       "      <td>30</td>\n",
       "      <td>10</td>\n",
       "      <td>0.705991</td>\n",
       "      <td>27646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6336</th>\n",
       "      <td>2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.01</td>\n",
       "      <td>30</td>\n",
       "      <td>10</td>\n",
       "      <td>0.704403</td>\n",
       "      <td>27647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6337</th>\n",
       "      <td>2</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.01</td>\n",
       "      <td>30</td>\n",
       "      <td>10</td>\n",
       "      <td>0.702765</td>\n",
       "      <td>27648</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27648 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       param_max_depth  param_subsample  param_colsample_bylevel  \\\n",
       "21747                4              0.9                      0.4   \n",
       "13080                3              0.6                      0.2   \n",
       "13176                3              0.6                      0.2   \n",
       "21720                3              0.6                      0.4   \n",
       "23470                3              0.8                      0.4   \n",
       "...                ...              ...                      ...   \n",
       "6340                 2              0.6                      0.1   \n",
       "6339                 2              0.9                      0.1   \n",
       "6338                 2              0.8                      0.1   \n",
       "6336                 2              0.6                      0.1   \n",
       "6337                 2              0.7                      0.1   \n",
       "\n",
       "       param_colsample_bytree  param_learning_rate  param_n_estimators  \\\n",
       "21747                     0.4                 0.15                  30   \n",
       "13080                     0.9                 0.15                  30   \n",
       "13176                     0.9                 0.20                  30   \n",
       "21720                     0.4                 0.15                  30   \n",
       "23470                     0.5                 0.15                 200   \n",
       "...                       ...                  ...                 ...   \n",
       "6340                      0.9                 0.01                  50   \n",
       "6339                      0.9                 0.01                  30   \n",
       "6338                      0.9                 0.01                  30   \n",
       "6336                      0.9                 0.01                  30   \n",
       "6337                      0.9                 0.01                  30   \n",
       "\n",
       "       param_gamma  mean_test_score  rank_test_score  \n",
       "21747            1         0.856989                1  \n",
       "13080            1         0.852227                2  \n",
       "13176            1         0.852202                3  \n",
       "21720            1         0.852202                4  \n",
       "23470            1         0.852151                5  \n",
       "...            ...              ...              ...  \n",
       "6340            10         0.718920            27644  \n",
       "6339            10         0.709217            27645  \n",
       "6338            10         0.705991            27646  \n",
       "6336            10         0.704403            27647  \n",
       "6337            10         0.702765            27648  \n",
       "\n",
       "[27648 rows x 9 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# store relevant columns and sort by rank_test_score\n",
    "cols_round3 = ['param_max_depth', 'param_subsample', 'param_colsample_bylevel', 'param_colsample_bytree', 'param_learning_rate', 'param_n_estimators', 'param_gamma', 'mean_test_score', 'rank_test_score']\n",
    "xgb_results_round3_sorted = xgb_grid_search_results_round3[cols_round3]\n",
    "xgb_results_round3_sorted = xgb_results_round3_sorted.sort_values(by='rank_test_score')\n",
    "display(xgb_results_round3_sorted)\n",
    "\n",
    "# save dataframe\n",
    "from datetime import datetime\n",
    "date = str(datetime.now().date()).replace(\"-\", \"\")\n",
    "xgb_results_round3_sorted.to_csv(f\"results/xgb_results_round3_sorted_{date}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "11f0488a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.8283582089552238\n",
      "F1 Score = 0.7788461538461539\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.90      0.86       157\n",
      "           1       0.84      0.73      0.78       111\n",
      "\n",
      "    accuracy                           0.83       268\n",
      "   macro avg       0.83      0.81      0.82       268\n",
      "weighted avg       0.83      0.83      0.83       268\n",
      "\n",
      "Confusion Matrix:\n",
      "[[141  16]\n",
      " [ 30  81]]\n"
     ]
    }
   ],
   "source": [
    "# Fit and evaluate best model\n",
    "\n",
    "xgb_best = XGBClassifier(max_depth = 4, subsample = 0.9, colsample_bylevel = 0.4, colsample_bytree = 0.4, learning_rate = 0.15, n_estimators = 30, gamma = 1)\n",
    "xgb_best.fit(X_train, y_train)\n",
    "xgb_best_pred = xgb_best.predict(X_test)\n",
    "\n",
    "xgb_best_acc = accuracy_score(y_test, xgb_best_pred)\n",
    "print(\"Accuracy =\", xgb_best_acc) #0.8283582089552238\n",
    "\n",
    "xgb_best_f1 = f1_score(y_test, xgb_best_pred)\n",
    "print(\"F1 Score =\", xgb_best_f1) #0.7788461538461539\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, xgb_best_pred))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, xgb_best_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "871fce0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ec32490",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b5d3a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "486b0ff9",
   "metadata": {},
   "source": [
    "#### ausführlich"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ea249e06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_colsample_bylevel</th>\n",
       "      <th>param_colsample_bytree</th>\n",
       "      <th>param_gamma</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>...</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.028623</td>\n",
       "      <td>0.002525</td>\n",
       "      <td>0.007181</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.741295</td>\n",
       "      <td>0.048078</td>\n",
       "      <td>4578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.027127</td>\n",
       "      <td>0.000598</td>\n",
       "      <td>0.007082</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.742908</td>\n",
       "      <td>0.049390</td>\n",
       "      <td>4575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.027028</td>\n",
       "      <td>0.000698</td>\n",
       "      <td>0.007580</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.752586</td>\n",
       "      <td>0.048690</td>\n",
       "      <td>4530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.027427</td>\n",
       "      <td>0.000920</td>\n",
       "      <td>0.007381</td>\n",
       "      <td>0.000662</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.742960</td>\n",
       "      <td>0.043040</td>\n",
       "      <td>4573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.040093</td>\n",
       "      <td>0.001465</td>\n",
       "      <td>0.007082</td>\n",
       "      <td>0.000536</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>...</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.765463</td>\n",
       "      <td>0.037846</td>\n",
       "      <td>4434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4603</th>\n",
       "      <td>0.129553</td>\n",
       "      <td>0.002379</td>\n",
       "      <td>0.007381</td>\n",
       "      <td>0.000488</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.01</td>\n",
       "      <td>5</td>\n",
       "      <td>150</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.813774</td>\n",
       "      <td>0.047909</td>\n",
       "      <td>2050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4604</th>\n",
       "      <td>0.169746</td>\n",
       "      <td>0.002475</td>\n",
       "      <td>0.007680</td>\n",
       "      <td>0.000457</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.01</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.816948</td>\n",
       "      <td>0.046448</td>\n",
       "      <td>1787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4605</th>\n",
       "      <td>0.169550</td>\n",
       "      <td>0.002185</td>\n",
       "      <td>0.007381</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.01</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.815335</td>\n",
       "      <td>0.050783</td>\n",
       "      <td>1939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4606</th>\n",
       "      <td>0.170743</td>\n",
       "      <td>0.003753</td>\n",
       "      <td>0.007481</td>\n",
       "      <td>0.000499</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.01</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.812186</td>\n",
       "      <td>0.050956</td>\n",
       "      <td>2153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4607</th>\n",
       "      <td>0.168649</td>\n",
       "      <td>0.001371</td>\n",
       "      <td>0.007380</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.01</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.813774</td>\n",
       "      <td>0.047909</td>\n",
       "      <td>2050</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4608 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0          0.028623      0.002525         0.007181        0.000399   \n",
       "1          0.027127      0.000598         0.007082        0.000300   \n",
       "2          0.027028      0.000698         0.007580        0.000489   \n",
       "3          0.027427      0.000920         0.007381        0.000662   \n",
       "4          0.040093      0.001465         0.007082        0.000536   \n",
       "...             ...           ...              ...             ...   \n",
       "4603       0.129553      0.002379         0.007381        0.000488   \n",
       "4604       0.169746      0.002475         0.007680        0.000457   \n",
       "4605       0.169550      0.002185         0.007381        0.000489   \n",
       "4606       0.170743      0.003753         0.007481        0.000499   \n",
       "4607       0.168649      0.001371         0.007380        0.000489   \n",
       "\n",
       "      param_colsample_bylevel  param_colsample_bytree  param_gamma  \\\n",
       "0                         0.1                     0.4            0   \n",
       "1                         0.1                     0.4            0   \n",
       "2                         0.1                     0.4            0   \n",
       "3                         0.1                     0.4            0   \n",
       "4                         0.1                     0.4            0   \n",
       "...                       ...                     ...          ...   \n",
       "4603                      0.4                     0.9           10   \n",
       "4604                      0.4                     0.9           10   \n",
       "4605                      0.4                     0.9           10   \n",
       "4606                      0.4                     0.9           10   \n",
       "4607                      0.4                     0.9           10   \n",
       "\n",
       "      param_learning_rate  param_max_depth  param_n_estimators  ...  \\\n",
       "0                    0.01                2                  30  ...   \n",
       "1                    0.01                2                  30  ...   \n",
       "2                    0.01                2                  30  ...   \n",
       "3                    0.01                2                  30  ...   \n",
       "4                    0.01                2                  50  ...   \n",
       "...                   ...              ...                 ...  ...   \n",
       "4603                 0.01                5                 150  ...   \n",
       "4604                 0.01                5                 200  ...   \n",
       "4605                 0.01                5                 200  ...   \n",
       "4606                 0.01                5                 200  ...   \n",
       "4607                 0.01                5                 200  ...   \n",
       "\n",
       "      split3_test_score split4_test_score  split5_test_score  \\\n",
       "0              0.758065          0.741935           0.741935   \n",
       "1              0.774194          0.741935           0.741935   \n",
       "2              0.774194          0.758065           0.774194   \n",
       "3              0.790323          0.725806           0.709677   \n",
       "4              0.790323          0.774194           0.774194   \n",
       "...                 ...               ...                ...   \n",
       "4603           0.838710          0.822581           0.870968   \n",
       "4604           0.838710          0.822581           0.870968   \n",
       "4605           0.838710          0.822581           0.870968   \n",
       "4606           0.838710          0.822581           0.870968   \n",
       "4607           0.838710          0.822581           0.870968   \n",
       "\n",
       "      split6_test_score  split7_test_score  split8_test_score  \\\n",
       "0              0.725806           0.677419           0.693548   \n",
       "1              0.725806           0.677419           0.677419   \n",
       "2              0.741935           0.693548           0.677419   \n",
       "3              0.741935           0.709677           0.709677   \n",
       "4              0.725806           0.693548           0.725806   \n",
       "...                 ...                ...                ...   \n",
       "4603           0.822581           0.806452           0.693548   \n",
       "4604           0.822581           0.806452           0.693548   \n",
       "4605           0.822581           0.806452           0.677419   \n",
       "4606           0.822581           0.822581           0.677419   \n",
       "4607           0.822581           0.806452           0.693548   \n",
       "\n",
       "      split9_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0              0.677419         0.741295        0.048078             4578  \n",
       "1              0.693548         0.742908        0.049390             4575  \n",
       "2              0.709677         0.752586        0.048690             4530  \n",
       "3              0.677419         0.742960        0.043040             4573  \n",
       "4              0.758065         0.765463        0.037846             4434  \n",
       "...                 ...              ...             ...              ...  \n",
       "4603           0.822581         0.813774        0.047909             2050  \n",
       "4604           0.822581         0.816948        0.046448             1787  \n",
       "4605           0.822581         0.815335        0.050783             1939  \n",
       "4606           0.822581         0.812186        0.050956             2153  \n",
       "4607           0.822581         0.813774        0.047909             2050  \n",
       "\n",
       "[4608 rows x 25 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score is 0.8505376344086022 with params {'colsample_bylevel': 0.1, 'colsample_bytree': 0.6, 'learning_rate': 0.15, 'max_depth': 5, 'n_estimators': 100, 'subsample': 0.6}\n"
     ]
    }
   ],
   "source": [
    "df1 = pd.read_csv(\"data\\\\xgb_results_full_1_learning=0.01_20221124.csv\")\n",
    "df1.drop(df1.columns[0], axis=1, inplace=True)\n",
    "display(df1)\n",
    "print(\"best score is 0.8505376344086022 with params {'colsample_bylevel': 0.1, 'colsample_bytree': 0.6, 'learning_rate': 0.15, 'max_depth': 5, 'n_estimators': 100, 'subsample': 0.6}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "042c4de6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_colsample_bylevel</th>\n",
       "      <th>param_colsample_bytree</th>\n",
       "      <th>param_gamma</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>...</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.028623</td>\n",
       "      <td>0.002525</td>\n",
       "      <td>0.007181</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.741295</td>\n",
       "      <td>0.048078</td>\n",
       "      <td>4578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.027127</td>\n",
       "      <td>0.000598</td>\n",
       "      <td>0.007082</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.742908</td>\n",
       "      <td>0.049390</td>\n",
       "      <td>4575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.027028</td>\n",
       "      <td>0.000698</td>\n",
       "      <td>0.007580</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.752586</td>\n",
       "      <td>0.048690</td>\n",
       "      <td>4530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.027427</td>\n",
       "      <td>0.000920</td>\n",
       "      <td>0.007381</td>\n",
       "      <td>0.000662</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.742960</td>\n",
       "      <td>0.043040</td>\n",
       "      <td>4573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.040093</td>\n",
       "      <td>0.001465</td>\n",
       "      <td>0.007082</td>\n",
       "      <td>0.000536</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>...</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.765463</td>\n",
       "      <td>0.037846</td>\n",
       "      <td>4434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4603</th>\n",
       "      <td>0.129553</td>\n",
       "      <td>0.002379</td>\n",
       "      <td>0.007381</td>\n",
       "      <td>0.000488</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.01</td>\n",
       "      <td>5</td>\n",
       "      <td>150</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.813774</td>\n",
       "      <td>0.047909</td>\n",
       "      <td>2050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4604</th>\n",
       "      <td>0.169746</td>\n",
       "      <td>0.002475</td>\n",
       "      <td>0.007680</td>\n",
       "      <td>0.000457</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.01</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.816948</td>\n",
       "      <td>0.046448</td>\n",
       "      <td>1787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4605</th>\n",
       "      <td>0.169550</td>\n",
       "      <td>0.002185</td>\n",
       "      <td>0.007381</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.01</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.815335</td>\n",
       "      <td>0.050783</td>\n",
       "      <td>1939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4606</th>\n",
       "      <td>0.170743</td>\n",
       "      <td>0.003753</td>\n",
       "      <td>0.007481</td>\n",
       "      <td>0.000499</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.01</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.812186</td>\n",
       "      <td>0.050956</td>\n",
       "      <td>2153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4607</th>\n",
       "      <td>0.168649</td>\n",
       "      <td>0.001371</td>\n",
       "      <td>0.007380</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.01</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.813774</td>\n",
       "      <td>0.047909</td>\n",
       "      <td>2050</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4608 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0          0.028623      0.002525         0.007181        0.000399   \n",
       "1          0.027127      0.000598         0.007082        0.000300   \n",
       "2          0.027028      0.000698         0.007580        0.000489   \n",
       "3          0.027427      0.000920         0.007381        0.000662   \n",
       "4          0.040093      0.001465         0.007082        0.000536   \n",
       "...             ...           ...              ...             ...   \n",
       "4603       0.129553      0.002379         0.007381        0.000488   \n",
       "4604       0.169746      0.002475         0.007680        0.000457   \n",
       "4605       0.169550      0.002185         0.007381        0.000489   \n",
       "4606       0.170743      0.003753         0.007481        0.000499   \n",
       "4607       0.168649      0.001371         0.007380        0.000489   \n",
       "\n",
       "     param_colsample_bylevel param_colsample_bytree param_gamma  \\\n",
       "0                        0.1                    0.4           0   \n",
       "1                        0.1                    0.4           0   \n",
       "2                        0.1                    0.4           0   \n",
       "3                        0.1                    0.4           0   \n",
       "4                        0.1                    0.4           0   \n",
       "...                      ...                    ...         ...   \n",
       "4603                     0.4                    0.9          10   \n",
       "4604                     0.4                    0.9          10   \n",
       "4605                     0.4                    0.9          10   \n",
       "4606                     0.4                    0.9          10   \n",
       "4607                     0.4                    0.9          10   \n",
       "\n",
       "     param_learning_rate param_max_depth param_n_estimators  ...  \\\n",
       "0                   0.01               2                 30  ...   \n",
       "1                   0.01               2                 30  ...   \n",
       "2                   0.01               2                 30  ...   \n",
       "3                   0.01               2                 30  ...   \n",
       "4                   0.01               2                 50  ...   \n",
       "...                  ...             ...                ...  ...   \n",
       "4603                0.01               5                150  ...   \n",
       "4604                0.01               5                200  ...   \n",
       "4605                0.01               5                200  ...   \n",
       "4606                0.01               5                200  ...   \n",
       "4607                0.01               5                200  ...   \n",
       "\n",
       "     split3_test_score split4_test_score  split5_test_score  \\\n",
       "0             0.758065          0.741935           0.741935   \n",
       "1             0.774194          0.741935           0.741935   \n",
       "2             0.774194          0.758065           0.774194   \n",
       "3             0.790323          0.725806           0.709677   \n",
       "4             0.790323          0.774194           0.774194   \n",
       "...                ...               ...                ...   \n",
       "4603          0.838710          0.822581           0.870968   \n",
       "4604          0.838710          0.822581           0.870968   \n",
       "4605          0.838710          0.822581           0.870968   \n",
       "4606          0.838710          0.822581           0.870968   \n",
       "4607          0.838710          0.822581           0.870968   \n",
       "\n",
       "      split6_test_score  split7_test_score  split8_test_score  \\\n",
       "0              0.725806           0.677419           0.693548   \n",
       "1              0.725806           0.677419           0.677419   \n",
       "2              0.741935           0.693548           0.677419   \n",
       "3              0.741935           0.709677           0.709677   \n",
       "4              0.725806           0.693548           0.725806   \n",
       "...                 ...                ...                ...   \n",
       "4603           0.822581           0.806452           0.693548   \n",
       "4604           0.822581           0.806452           0.693548   \n",
       "4605           0.822581           0.806452           0.677419   \n",
       "4606           0.822581           0.822581           0.677419   \n",
       "4607           0.822581           0.806452           0.693548   \n",
       "\n",
       "      split9_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0              0.677419         0.741295        0.048078             4578  \n",
       "1              0.693548         0.742908        0.049390             4575  \n",
       "2              0.709677         0.752586        0.048690             4530  \n",
       "3              0.677419         0.742960        0.043040             4573  \n",
       "4              0.758065         0.765463        0.037846             4434  \n",
       "...                 ...              ...             ...              ...  \n",
       "4603           0.822581         0.813774        0.047909             2050  \n",
       "4604           0.822581         0.816948        0.046448             1787  \n",
       "4605           0.822581         0.815335        0.050783             1939  \n",
       "4606           0.822581         0.812186        0.050956             2153  \n",
       "4607           0.822581         0.813774        0.047909             2050  \n",
       "\n",
       "[4608 rows x 25 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score is 0.844162826420891 with params {'colsample_bylevel': 0.3, 'colsample_bytree': 0.9, 'gamma': 1, 'learning_rate': 0.01, 'max_depth': 5, 'n_estimators': 200, 'subsample': 0.7}\n"
     ]
    }
   ],
   "source": [
    "# Full Tuning - Part 1\n",
    "random.seed(10)\n",
    "\n",
    "xgb = XGBClassifier()\n",
    "\n",
    "xgb_parameters = {'max_depth': [2,3,4,5]\n",
    "                   , 'subsample': [0.6, 0.7, 0.8, 0.9]\n",
    "                   , 'gamma': [0, 1, 10]\n",
    "                   , 'colsample_bytree': [0.4, 0.5, 0.6, 0.9]\n",
    "                   , 'colsample_bylevel': [0.1, 0.2, 0.3, 0.4]\n",
    "                   , 'learning_rate': [0.01]\n",
    "                   , 'n_estimators': [30, 50, 80, 100, 150, 200]}\n",
    "\n",
    "stratified_10_fold_cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "xgb_grid_search = GridSearchCV(xgb, xgb_parameters, scoring='accuracy', cv=stratified_10_fold_cv)\n",
    "\n",
    "xgb_grid_search.fit(X_train, y_train)\n",
    "\n",
    "xgb_grid_search_results_full_1 = pd.DataFrame(xgb_grid_search.cv_results_)\n",
    "display(xgb_grid_search_results_full_1)\n",
    "\n",
    "print(\"best score is {} with params {}\".format(xgb_grid_search.best_score_, xgb_grid_search.best_params_))\n",
    "#best score is 0.844162826420891 with params\n",
    "{'colsample_bylevel': 0.3, 'colsample_bytree': 0.9, 'gamma': 1, 'learning_rate': 0.01, 'max_depth': 5, 'n_estimators': 200, 'subsample': 0.7}\n",
    "\n",
    "# save dataframe\n",
    "from datetime import datetime\n",
    "date = str(datetime.now().date()).replace(\"-\", \"\")\n",
    "xgb_grid_search_results_full_1.to_csv(f\"results/xgb_results_full_round3_1_learning=0.01_{date}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c6d50dac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_colsample_bylevel</th>\n",
       "      <th>param_colsample_bytree</th>\n",
       "      <th>param_gamma</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>...</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.028523</td>\n",
       "      <td>0.001197</td>\n",
       "      <td>0.007181</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.775090</td>\n",
       "      <td>0.045213</td>\n",
       "      <td>4574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.027227</td>\n",
       "      <td>0.000779</td>\n",
       "      <td>0.006981</td>\n",
       "      <td>0.000772</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.765463</td>\n",
       "      <td>0.044700</td>\n",
       "      <td>4590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.030020</td>\n",
       "      <td>0.003261</td>\n",
       "      <td>0.007580</td>\n",
       "      <td>0.000662</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.775090</td>\n",
       "      <td>0.048492</td>\n",
       "      <td>4576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.027626</td>\n",
       "      <td>0.001097</td>\n",
       "      <td>0.007480</td>\n",
       "      <td>0.000499</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.776677</td>\n",
       "      <td>0.047735</td>\n",
       "      <td>4572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.039397</td>\n",
       "      <td>0.000667</td>\n",
       "      <td>0.007378</td>\n",
       "      <td>0.000491</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>...</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.799155</td>\n",
       "      <td>0.059192</td>\n",
       "      <td>4360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4603</th>\n",
       "      <td>0.130850</td>\n",
       "      <td>0.001882</td>\n",
       "      <td>0.007381</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.05</td>\n",
       "      <td>5</td>\n",
       "      <td>150</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.919355</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.816999</td>\n",
       "      <td>0.059810</td>\n",
       "      <td>3203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4604</th>\n",
       "      <td>0.171740</td>\n",
       "      <td>0.001773</td>\n",
       "      <td>0.007580</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.05</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.919355</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.818612</td>\n",
       "      <td>0.053929</td>\n",
       "      <td>2994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4605</th>\n",
       "      <td>0.171541</td>\n",
       "      <td>0.002318</td>\n",
       "      <td>0.007381</td>\n",
       "      <td>0.000488</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.05</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.919355</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.823400</td>\n",
       "      <td>0.053525</td>\n",
       "      <td>2604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4606</th>\n",
       "      <td>0.171951</td>\n",
       "      <td>0.002359</td>\n",
       "      <td>0.007469</td>\n",
       "      <td>0.000504</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.05</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.887097</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.816999</td>\n",
       "      <td>0.046733</td>\n",
       "      <td>3198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4607</th>\n",
       "      <td>0.170743</td>\n",
       "      <td>0.001773</td>\n",
       "      <td>0.007580</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.05</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.903226</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.815387</td>\n",
       "      <td>0.057189</td>\n",
       "      <td>3367</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4608 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0          0.028523      0.001197         0.007181        0.000399   \n",
       "1          0.027227      0.000779         0.006981        0.000772   \n",
       "2          0.030020      0.003261         0.007580        0.000662   \n",
       "3          0.027626      0.001097         0.007480        0.000499   \n",
       "4          0.039397      0.000667         0.007378        0.000491   \n",
       "...             ...           ...              ...             ...   \n",
       "4603       0.130850      0.001882         0.007381        0.000489   \n",
       "4604       0.171740      0.001773         0.007580        0.000489   \n",
       "4605       0.171541      0.002318         0.007381        0.000488   \n",
       "4606       0.171951      0.002359         0.007469        0.000504   \n",
       "4607       0.170743      0.001773         0.007580        0.000489   \n",
       "\n",
       "      param_colsample_bylevel  param_colsample_bytree  param_gamma  \\\n",
       "0                         0.1                     0.4            0   \n",
       "1                         0.1                     0.4            0   \n",
       "2                         0.1                     0.4            0   \n",
       "3                         0.1                     0.4            0   \n",
       "4                         0.1                     0.4            0   \n",
       "...                       ...                     ...          ...   \n",
       "4603                      0.4                     0.9           10   \n",
       "4604                      0.4                     0.9           10   \n",
       "4605                      0.4                     0.9           10   \n",
       "4606                      0.4                     0.9           10   \n",
       "4607                      0.4                     0.9           10   \n",
       "\n",
       "      param_learning_rate  param_max_depth  param_n_estimators  ...  \\\n",
       "0                    0.05                2                  30  ...   \n",
       "1                    0.05                2                  30  ...   \n",
       "2                    0.05                2                  30  ...   \n",
       "3                    0.05                2                  30  ...   \n",
       "4                    0.05                2                  50  ...   \n",
       "...                   ...              ...                 ...  ...   \n",
       "4603                 0.05                5                 150  ...   \n",
       "4604                 0.05                5                 200  ...   \n",
       "4605                 0.05                5                 200  ...   \n",
       "4606                 0.05                5                 200  ...   \n",
       "4607                 0.05                5                 200  ...   \n",
       "\n",
       "      split3_test_score split4_test_score  split5_test_score  \\\n",
       "0              0.774194          0.741935           0.806452   \n",
       "1              0.774194          0.741935           0.790323   \n",
       "2              0.806452          0.758065           0.806452   \n",
       "3              0.806452          0.741935           0.790323   \n",
       "4              0.806452          0.806452           0.870968   \n",
       "...                 ...               ...                ...   \n",
       "4603           0.838710          0.806452           0.919355   \n",
       "4604           0.838710          0.822581           0.919355   \n",
       "4605           0.838710          0.822581           0.919355   \n",
       "4606           0.838710          0.822581           0.887097   \n",
       "4607           0.838710          0.806452           0.903226   \n",
       "\n",
       "      split6_test_score  split7_test_score  split8_test_score  \\\n",
       "0              0.806452           0.677419           0.725806   \n",
       "1              0.790323           0.677419           0.709677   \n",
       "2              0.790323           0.677419           0.709677   \n",
       "3              0.806452           0.677419           0.725806   \n",
       "4              0.806452           0.693548           0.693548   \n",
       "...                 ...                ...                ...   \n",
       "4603           0.822581           0.790323           0.693548   \n",
       "4604           0.822581           0.806452           0.693548   \n",
       "4605           0.822581           0.822581           0.693548   \n",
       "4606           0.822581           0.806452           0.709677   \n",
       "4607           0.822581           0.790323           0.693548   \n",
       "\n",
       "      split9_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0              0.774194         0.775090        0.045213             4574  \n",
       "1              0.758065         0.765463        0.044700             4590  \n",
       "2              0.758065         0.775090        0.048492             4576  \n",
       "3              0.758065         0.776677        0.047735             4572  \n",
       "4              0.790323         0.799155        0.059192             4360  \n",
       "...                 ...              ...             ...              ...  \n",
       "4603           0.838710         0.816999        0.059810             3203  \n",
       "4604           0.822581         0.818612        0.053929             2994  \n",
       "4605           0.822581         0.823400        0.053525             2604  \n",
       "4606           0.822581         0.816999        0.046733             3198  \n",
       "4607           0.838710         0.815387        0.057189             3367  \n",
       "\n",
       "[4608 rows x 25 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score is 0.8506144393241168 with params {'colsample_bylevel': 0.2, 'colsample_bytree': 0.9, 'gamma': 1, 'learning_rate': 0.05, 'max_depth': 4, 'n_estimators': 100, 'subsample': 0.7}\n"
     ]
    }
   ],
   "source": [
    "df2 = pd.read_csv(\"data\\\\xgb_results_full_2_learning=0.05_20221124.csv\")\n",
    "df2.drop(df2.columns[0], axis=1, inplace=True)\n",
    "display(df2)\n",
    "print(\"best score is 0.8506144393241168 with params {'colsample_bylevel': 0.2, 'colsample_bytree': 0.9, 'gamma': 1, 'learning_rate': 0.05, 'max_depth': 4, 'n_estimators': 100, 'subsample': 0.7}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cecd42a5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_colsample_bylevel</th>\n",
       "      <th>param_colsample_bytree</th>\n",
       "      <th>param_gamma</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>...</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.028523</td>\n",
       "      <td>0.001197</td>\n",
       "      <td>0.007181</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.775090</td>\n",
       "      <td>0.045213</td>\n",
       "      <td>4574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.027227</td>\n",
       "      <td>0.000779</td>\n",
       "      <td>0.006981</td>\n",
       "      <td>0.000772</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.765463</td>\n",
       "      <td>0.044700</td>\n",
       "      <td>4590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.030020</td>\n",
       "      <td>0.003261</td>\n",
       "      <td>0.007580</td>\n",
       "      <td>0.000662</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.775090</td>\n",
       "      <td>0.048492</td>\n",
       "      <td>4576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.027626</td>\n",
       "      <td>0.001097</td>\n",
       "      <td>0.007480</td>\n",
       "      <td>0.000499</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.776677</td>\n",
       "      <td>0.047735</td>\n",
       "      <td>4572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.039397</td>\n",
       "      <td>0.000667</td>\n",
       "      <td>0.007378</td>\n",
       "      <td>0.000491</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>...</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.799155</td>\n",
       "      <td>0.059192</td>\n",
       "      <td>4360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4603</th>\n",
       "      <td>0.130850</td>\n",
       "      <td>0.001882</td>\n",
       "      <td>0.007381</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.05</td>\n",
       "      <td>5</td>\n",
       "      <td>150</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.919355</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.816999</td>\n",
       "      <td>0.059810</td>\n",
       "      <td>3203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4604</th>\n",
       "      <td>0.171740</td>\n",
       "      <td>0.001773</td>\n",
       "      <td>0.007580</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.05</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.919355</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.818612</td>\n",
       "      <td>0.053929</td>\n",
       "      <td>2994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4605</th>\n",
       "      <td>0.171541</td>\n",
       "      <td>0.002318</td>\n",
       "      <td>0.007381</td>\n",
       "      <td>0.000488</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.05</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.919355</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.823400</td>\n",
       "      <td>0.053525</td>\n",
       "      <td>2604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4606</th>\n",
       "      <td>0.171951</td>\n",
       "      <td>0.002359</td>\n",
       "      <td>0.007469</td>\n",
       "      <td>0.000504</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.05</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.887097</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.816999</td>\n",
       "      <td>0.046733</td>\n",
       "      <td>3198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4607</th>\n",
       "      <td>0.170743</td>\n",
       "      <td>0.001773</td>\n",
       "      <td>0.007580</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.05</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.903226</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.815387</td>\n",
       "      <td>0.057189</td>\n",
       "      <td>3367</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4608 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0          0.028523      0.001197         0.007181        0.000399   \n",
       "1          0.027227      0.000779         0.006981        0.000772   \n",
       "2          0.030020      0.003261         0.007580        0.000662   \n",
       "3          0.027626      0.001097         0.007480        0.000499   \n",
       "4          0.039397      0.000667         0.007378        0.000491   \n",
       "...             ...           ...              ...             ...   \n",
       "4603       0.130850      0.001882         0.007381        0.000489   \n",
       "4604       0.171740      0.001773         0.007580        0.000489   \n",
       "4605       0.171541      0.002318         0.007381        0.000488   \n",
       "4606       0.171951      0.002359         0.007469        0.000504   \n",
       "4607       0.170743      0.001773         0.007580        0.000489   \n",
       "\n",
       "     param_colsample_bylevel param_colsample_bytree param_gamma  \\\n",
       "0                        0.1                    0.4           0   \n",
       "1                        0.1                    0.4           0   \n",
       "2                        0.1                    0.4           0   \n",
       "3                        0.1                    0.4           0   \n",
       "4                        0.1                    0.4           0   \n",
       "...                      ...                    ...         ...   \n",
       "4603                     0.4                    0.9          10   \n",
       "4604                     0.4                    0.9          10   \n",
       "4605                     0.4                    0.9          10   \n",
       "4606                     0.4                    0.9          10   \n",
       "4607                     0.4                    0.9          10   \n",
       "\n",
       "     param_learning_rate param_max_depth param_n_estimators  ...  \\\n",
       "0                   0.05               2                 30  ...   \n",
       "1                   0.05               2                 30  ...   \n",
       "2                   0.05               2                 30  ...   \n",
       "3                   0.05               2                 30  ...   \n",
       "4                   0.05               2                 50  ...   \n",
       "...                  ...             ...                ...  ...   \n",
       "4603                0.05               5                150  ...   \n",
       "4604                0.05               5                200  ...   \n",
       "4605                0.05               5                200  ...   \n",
       "4606                0.05               5                200  ...   \n",
       "4607                0.05               5                200  ...   \n",
       "\n",
       "     split3_test_score split4_test_score  split5_test_score  \\\n",
       "0             0.774194          0.741935           0.806452   \n",
       "1             0.774194          0.741935           0.790323   \n",
       "2             0.806452          0.758065           0.806452   \n",
       "3             0.806452          0.741935           0.790323   \n",
       "4             0.806452          0.806452           0.870968   \n",
       "...                ...               ...                ...   \n",
       "4603          0.838710          0.806452           0.919355   \n",
       "4604          0.838710          0.822581           0.919355   \n",
       "4605          0.838710          0.822581           0.919355   \n",
       "4606          0.838710          0.822581           0.887097   \n",
       "4607          0.838710          0.806452           0.903226   \n",
       "\n",
       "      split6_test_score  split7_test_score  split8_test_score  \\\n",
       "0              0.806452           0.677419           0.725806   \n",
       "1              0.790323           0.677419           0.709677   \n",
       "2              0.790323           0.677419           0.709677   \n",
       "3              0.806452           0.677419           0.725806   \n",
       "4              0.806452           0.693548           0.693548   \n",
       "...                 ...                ...                ...   \n",
       "4603           0.822581           0.790323           0.693548   \n",
       "4604           0.822581           0.806452           0.693548   \n",
       "4605           0.822581           0.822581           0.693548   \n",
       "4606           0.822581           0.806452           0.709677   \n",
       "4607           0.822581           0.790323           0.693548   \n",
       "\n",
       "      split9_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0              0.774194         0.775090        0.045213             4574  \n",
       "1              0.758065         0.765463        0.044700             4590  \n",
       "2              0.758065         0.775090        0.048492             4576  \n",
       "3              0.758065         0.776677        0.047735             4572  \n",
       "4              0.790323         0.799155        0.059192             4360  \n",
       "...                 ...              ...             ...              ...  \n",
       "4603           0.838710         0.816999        0.059810             3203  \n",
       "4604           0.822581         0.818612        0.053929             2994  \n",
       "4605           0.822581         0.823400        0.053525             2604  \n",
       "4606           0.822581         0.816999        0.046733             3198  \n",
       "4607           0.838710         0.815387        0.057189             3367  \n",
       "\n",
       "[4608 rows x 25 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score is 0.8506144393241168 with params {'colsample_bylevel': 0.2, 'colsample_bytree': 0.9, 'gamma': 1, 'learning_rate': 0.05, 'max_depth': 4, 'n_estimators': 100, 'subsample': 0.7}\n"
     ]
    }
   ],
   "source": [
    "# Full Tuning - Part 2\n",
    "random.seed(10)\n",
    "\n",
    "xgb = XGBClassifier()\n",
    "\n",
    "xgb_parameters = {'max_depth': [2,3,4,5]\n",
    "                   , 'subsample': [0.6, 0.7, 0.8, 0.9]\n",
    "                   , 'gamma': [0, 1, 10]\n",
    "                   , 'colsample_bytree': [0.4, 0.5, 0.6, 0.9]\n",
    "                   , 'colsample_bylevel': [0.1, 0.2, 0.3, 0.4]\n",
    "                   , 'learning_rate': [0.05]\n",
    "                   , 'n_estimators': [30, 50, 80, 100, 150, 200]}\n",
    "\n",
    "stratified_10_fold_cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "xgb_grid_search = GridSearchCV(xgb, xgb_parameters, scoring='accuracy', cv=stratified_10_fold_cv)\n",
    "\n",
    "xgb_grid_search.fit(X_train, y_train)\n",
    "\n",
    "xgb_grid_search_results_full_2 = pd.DataFrame(xgb_grid_search.cv_results_)\n",
    "display(xgb_grid_search_results_full_2)\n",
    "\n",
    "print(\"best score is {} with params {}\".format(xgb_grid_search.best_score_, xgb_grid_search.best_params_))\n",
    "#best score is 0.8506144393241168 with params\n",
    "#{'colsample_bylevel': 0.2, 'colsample_bytree': 0.9, 'gamma': 1, 'learning_rate': 0.05, 'max_depth': 4, 'n_estimators': 100, 'subsample': 0.7}\n",
    "\n",
    "# save dataframe\n",
    "from datetime import datetime\n",
    "date = str(datetime.now().date()).replace(\"-\", \"\")\n",
    "xgb_grid_search_results_full_2.to_csv(f\"results/xgb_results_full_round3_2_learning=0.05_{date}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "de35f20c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_colsample_bylevel</th>\n",
       "      <th>param_colsample_bytree</th>\n",
       "      <th>param_gamma</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>...</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.028224</td>\n",
       "      <td>0.001548</td>\n",
       "      <td>0.007181</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.08</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.791193</td>\n",
       "      <td>0.044965</td>\n",
       "      <td>4563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.026928</td>\n",
       "      <td>0.000772</td>\n",
       "      <td>0.007181</td>\n",
       "      <td>0.000599</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.08</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.789555</td>\n",
       "      <td>0.044749</td>\n",
       "      <td>4576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.029339</td>\n",
       "      <td>0.001735</td>\n",
       "      <td>0.007479</td>\n",
       "      <td>0.000498</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.08</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.789580</td>\n",
       "      <td>0.046896</td>\n",
       "      <td>4572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.028622</td>\n",
       "      <td>0.001947</td>\n",
       "      <td>0.007481</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.08</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.792780</td>\n",
       "      <td>0.044102</td>\n",
       "      <td>4551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.039893</td>\n",
       "      <td>0.001261</td>\n",
       "      <td>0.007380</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.08</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.812007</td>\n",
       "      <td>0.056776</td>\n",
       "      <td>4032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4603</th>\n",
       "      <td>0.129553</td>\n",
       "      <td>0.001133</td>\n",
       "      <td>0.007580</td>\n",
       "      <td>0.000488</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.08</td>\n",
       "      <td>5</td>\n",
       "      <td>150</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.919355</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.824962</td>\n",
       "      <td>0.052356</td>\n",
       "      <td>2818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4604</th>\n",
       "      <td>0.170643</td>\n",
       "      <td>0.001863</td>\n",
       "      <td>0.007581</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.08</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.903226</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.820225</td>\n",
       "      <td>0.053767</td>\n",
       "      <td>3155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4605</th>\n",
       "      <td>0.170045</td>\n",
       "      <td>0.001561</td>\n",
       "      <td>0.007281</td>\n",
       "      <td>0.000457</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.08</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.887097</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.816974</td>\n",
       "      <td>0.048018</td>\n",
       "      <td>3490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4606</th>\n",
       "      <td>0.169746</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>0.007480</td>\n",
       "      <td>0.000499</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.08</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.903226</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.816999</td>\n",
       "      <td>0.050944</td>\n",
       "      <td>3455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4607</th>\n",
       "      <td>0.170444</td>\n",
       "      <td>0.002693</td>\n",
       "      <td>0.007181</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.08</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.919355</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.823374</td>\n",
       "      <td>0.053036</td>\n",
       "      <td>2921</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4608 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0          0.028224      0.001548         0.007181        0.000399   \n",
       "1          0.026928      0.000772         0.007181        0.000599   \n",
       "2          0.029339      0.001735         0.007479        0.000498   \n",
       "3          0.028622      0.001947         0.007481        0.000500   \n",
       "4          0.039893      0.001261         0.007380        0.000489   \n",
       "...             ...           ...              ...             ...   \n",
       "4603       0.129553      0.001133         0.007580        0.000488   \n",
       "4604       0.170643      0.001863         0.007581        0.000489   \n",
       "4605       0.170045      0.001561         0.007281        0.000457   \n",
       "4606       0.169746      0.000977         0.007480        0.000499   \n",
       "4607       0.170444      0.002693         0.007181        0.000399   \n",
       "\n",
       "      param_colsample_bylevel  param_colsample_bytree  param_gamma  \\\n",
       "0                         0.1                     0.4            0   \n",
       "1                         0.1                     0.4            0   \n",
       "2                         0.1                     0.4            0   \n",
       "3                         0.1                     0.4            0   \n",
       "4                         0.1                     0.4            0   \n",
       "...                       ...                     ...          ...   \n",
       "4603                      0.4                     0.9           10   \n",
       "4604                      0.4                     0.9           10   \n",
       "4605                      0.4                     0.9           10   \n",
       "4606                      0.4                     0.9           10   \n",
       "4607                      0.4                     0.9           10   \n",
       "\n",
       "      param_learning_rate  param_max_depth  param_n_estimators  ...  \\\n",
       "0                    0.08                2                  30  ...   \n",
       "1                    0.08                2                  30  ...   \n",
       "2                    0.08                2                  30  ...   \n",
       "3                    0.08                2                  30  ...   \n",
       "4                    0.08                2                  50  ...   \n",
       "...                   ...              ...                 ...  ...   \n",
       "4603                 0.08                5                 150  ...   \n",
       "4604                 0.08                5                 200  ...   \n",
       "4605                 0.08                5                 200  ...   \n",
       "4606                 0.08                5                 200  ...   \n",
       "4607                 0.08                5                 200  ...   \n",
       "\n",
       "      split3_test_score split4_test_score  split5_test_score  \\\n",
       "0              0.806452          0.774194           0.822581   \n",
       "1              0.806452          0.774194           0.822581   \n",
       "2              0.838710          0.774194           0.822581   \n",
       "3              0.838710          0.774194           0.822581   \n",
       "4              0.854839          0.790323           0.870968   \n",
       "...                 ...               ...                ...   \n",
       "4603           0.838710          0.806452           0.919355   \n",
       "4604           0.870968          0.806452           0.903226   \n",
       "4605           0.838710          0.822581           0.887097   \n",
       "4606           0.838710          0.806452           0.903226   \n",
       "4607           0.838710          0.806452           0.919355   \n",
       "\n",
       "      split6_test_score  split7_test_score  split8_test_score  \\\n",
       "0              0.822581           0.693548           0.725806   \n",
       "1              0.790323           0.709677           0.709677   \n",
       "2              0.790323           0.709677           0.709677   \n",
       "3              0.790323           0.725806           0.709677   \n",
       "4              0.806452           0.741935           0.693548   \n",
       "...                 ...                ...                ...   \n",
       "4603           0.822581           0.806452           0.709677   \n",
       "4604           0.822581           0.822581           0.693548   \n",
       "4605           0.822581           0.806452           0.693548   \n",
       "4606           0.822581           0.806452           0.709677   \n",
       "4607           0.822581           0.806452           0.709677   \n",
       "\n",
       "      split9_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0              0.806452         0.791193        0.044965             4563  \n",
       "1              0.806452         0.789555        0.044749             4576  \n",
       "2              0.790323         0.789580        0.046896             4572  \n",
       "3              0.790323         0.792780        0.044102             4551  \n",
       "4              0.806452         0.812007        0.056776             4032  \n",
       "...                 ...              ...             ...              ...  \n",
       "4603           0.822581         0.824962        0.052356             2818  \n",
       "4604           0.822581         0.820225        0.053767             3155  \n",
       "4605           0.822581         0.816974        0.048018             3490  \n",
       "4606           0.822581         0.816999        0.050944             3455  \n",
       "4607           0.822581         0.823374        0.053036             2921  \n",
       "\n",
       "[4608 rows x 25 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score is 0.8506400409626217 with params {'colsample_bylevel': 0.2, 'colsample_bytree': 0.5, 'gamma': 1, 'learning_rate': 0.08, 'max_depth': 2, 'n_estimators': 150, 'subsample': 0.8}\n"
     ]
    }
   ],
   "source": [
    "df3 = pd.read_csv(\"data\\\\xgb_results_full_3_learning=0.08_20221124.csv\")\n",
    "df3.drop(df3.columns[0], axis=1, inplace=True)\n",
    "display(df3)\n",
    "print(\"best score is 0.8506400409626217 with params {'colsample_bylevel': 0.2, 'colsample_bytree': 0.5, 'gamma': 1, 'learning_rate': 0.08, 'max_depth': 2, 'n_estimators': 150, 'subsample': 0.8}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3ae2939c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_colsample_bylevel</th>\n",
       "      <th>param_colsample_bytree</th>\n",
       "      <th>param_gamma</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>...</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.028224</td>\n",
       "      <td>0.001548</td>\n",
       "      <td>0.007181</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.08</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.791193</td>\n",
       "      <td>0.044965</td>\n",
       "      <td>4563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.026928</td>\n",
       "      <td>0.000772</td>\n",
       "      <td>0.007181</td>\n",
       "      <td>0.000599</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.08</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.789555</td>\n",
       "      <td>0.044749</td>\n",
       "      <td>4576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.029339</td>\n",
       "      <td>0.001735</td>\n",
       "      <td>0.007479</td>\n",
       "      <td>0.000498</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.08</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.789580</td>\n",
       "      <td>0.046896</td>\n",
       "      <td>4572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.028622</td>\n",
       "      <td>0.001947</td>\n",
       "      <td>0.007481</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.08</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.792780</td>\n",
       "      <td>0.044102</td>\n",
       "      <td>4551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.039893</td>\n",
       "      <td>0.001261</td>\n",
       "      <td>0.007380</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.08</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.812007</td>\n",
       "      <td>0.056776</td>\n",
       "      <td>4032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4603</th>\n",
       "      <td>0.129553</td>\n",
       "      <td>0.001133</td>\n",
       "      <td>0.007580</td>\n",
       "      <td>0.000488</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.08</td>\n",
       "      <td>5</td>\n",
       "      <td>150</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.919355</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.824962</td>\n",
       "      <td>0.052356</td>\n",
       "      <td>2818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4604</th>\n",
       "      <td>0.170643</td>\n",
       "      <td>0.001863</td>\n",
       "      <td>0.007581</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.08</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.903226</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.820225</td>\n",
       "      <td>0.053767</td>\n",
       "      <td>3155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4605</th>\n",
       "      <td>0.170045</td>\n",
       "      <td>0.001561</td>\n",
       "      <td>0.007281</td>\n",
       "      <td>0.000457</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.08</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.887097</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.816974</td>\n",
       "      <td>0.048018</td>\n",
       "      <td>3490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4606</th>\n",
       "      <td>0.169746</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>0.007480</td>\n",
       "      <td>0.000499</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.08</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.903226</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.816999</td>\n",
       "      <td>0.050944</td>\n",
       "      <td>3455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4607</th>\n",
       "      <td>0.170444</td>\n",
       "      <td>0.002693</td>\n",
       "      <td>0.007181</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.08</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.919355</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.823374</td>\n",
       "      <td>0.053036</td>\n",
       "      <td>2921</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4608 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0          0.028224      0.001548         0.007181        0.000399   \n",
       "1          0.026928      0.000772         0.007181        0.000599   \n",
       "2          0.029339      0.001735         0.007479        0.000498   \n",
       "3          0.028622      0.001947         0.007481        0.000500   \n",
       "4          0.039893      0.001261         0.007380        0.000489   \n",
       "...             ...           ...              ...             ...   \n",
       "4603       0.129553      0.001133         0.007580        0.000488   \n",
       "4604       0.170643      0.001863         0.007581        0.000489   \n",
       "4605       0.170045      0.001561         0.007281        0.000457   \n",
       "4606       0.169746      0.000977         0.007480        0.000499   \n",
       "4607       0.170444      0.002693         0.007181        0.000399   \n",
       "\n",
       "     param_colsample_bylevel param_colsample_bytree param_gamma  \\\n",
       "0                        0.1                    0.4           0   \n",
       "1                        0.1                    0.4           0   \n",
       "2                        0.1                    0.4           0   \n",
       "3                        0.1                    0.4           0   \n",
       "4                        0.1                    0.4           0   \n",
       "...                      ...                    ...         ...   \n",
       "4603                     0.4                    0.9          10   \n",
       "4604                     0.4                    0.9          10   \n",
       "4605                     0.4                    0.9          10   \n",
       "4606                     0.4                    0.9          10   \n",
       "4607                     0.4                    0.9          10   \n",
       "\n",
       "     param_learning_rate param_max_depth param_n_estimators  ...  \\\n",
       "0                   0.08               2                 30  ...   \n",
       "1                   0.08               2                 30  ...   \n",
       "2                   0.08               2                 30  ...   \n",
       "3                   0.08               2                 30  ...   \n",
       "4                   0.08               2                 50  ...   \n",
       "...                  ...             ...                ...  ...   \n",
       "4603                0.08               5                150  ...   \n",
       "4604                0.08               5                200  ...   \n",
       "4605                0.08               5                200  ...   \n",
       "4606                0.08               5                200  ...   \n",
       "4607                0.08               5                200  ...   \n",
       "\n",
       "     split3_test_score split4_test_score  split5_test_score  \\\n",
       "0             0.806452          0.774194           0.822581   \n",
       "1             0.806452          0.774194           0.822581   \n",
       "2             0.838710          0.774194           0.822581   \n",
       "3             0.838710          0.774194           0.822581   \n",
       "4             0.854839          0.790323           0.870968   \n",
       "...                ...               ...                ...   \n",
       "4603          0.838710          0.806452           0.919355   \n",
       "4604          0.870968          0.806452           0.903226   \n",
       "4605          0.838710          0.822581           0.887097   \n",
       "4606          0.838710          0.806452           0.903226   \n",
       "4607          0.838710          0.806452           0.919355   \n",
       "\n",
       "      split6_test_score  split7_test_score  split8_test_score  \\\n",
       "0              0.822581           0.693548           0.725806   \n",
       "1              0.790323           0.709677           0.709677   \n",
       "2              0.790323           0.709677           0.709677   \n",
       "3              0.790323           0.725806           0.709677   \n",
       "4              0.806452           0.741935           0.693548   \n",
       "...                 ...                ...                ...   \n",
       "4603           0.822581           0.806452           0.709677   \n",
       "4604           0.822581           0.822581           0.693548   \n",
       "4605           0.822581           0.806452           0.693548   \n",
       "4606           0.822581           0.806452           0.709677   \n",
       "4607           0.822581           0.806452           0.709677   \n",
       "\n",
       "      split9_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0              0.806452         0.791193        0.044965             4563  \n",
       "1              0.806452         0.789555        0.044749             4576  \n",
       "2              0.790323         0.789580        0.046896             4572  \n",
       "3              0.790323         0.792780        0.044102             4551  \n",
       "4              0.806452         0.812007        0.056776             4032  \n",
       "...                 ...              ...             ...              ...  \n",
       "4603           0.822581         0.824962        0.052356             2818  \n",
       "4604           0.822581         0.820225        0.053767             3155  \n",
       "4605           0.822581         0.816974        0.048018             3490  \n",
       "4606           0.822581         0.816999        0.050944             3455  \n",
       "4607           0.822581         0.823374        0.053036             2921  \n",
       "\n",
       "[4608 rows x 25 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score is 0.8506400409626217 with params {'colsample_bylevel': 0.2, 'colsample_bytree': 0.5, 'gamma': 1, 'learning_rate': 0.08, 'max_depth': 2, 'n_estimators': 150, 'subsample': 0.8}\n"
     ]
    }
   ],
   "source": [
    "# Full Tuning - Part 3\n",
    "random.seed(10)\n",
    "\n",
    "xgb = XGBClassifier()\n",
    "\n",
    "xgb_parameters = {'max_depth': [2,3,4,5]\n",
    "                   , 'subsample': [0.6, 0.7, 0.8, 0.9]\n",
    "                   , 'gamma': [0, 1, 10]\n",
    "                   , 'colsample_bytree': [0.4, 0.5, 0.6, 0.9]\n",
    "                   , 'colsample_bylevel': [0.1, 0.2, 0.3, 0.4]\n",
    "                   , 'learning_rate': [0.08]\n",
    "                   , 'n_estimators': [30, 50, 80, 100, 150, 200]}\n",
    "\n",
    "stratified_10_fold_cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "xgb_grid_search = GridSearchCV(xgb, xgb_parameters, scoring='accuracy', cv=stratified_10_fold_cv)\n",
    "\n",
    "xgb_grid_search.fit(X_train, y_train)\n",
    "\n",
    "xgb_grid_search_results_full_3 = pd.DataFrame(xgb_grid_search.cv_results_)\n",
    "display(xgb_grid_search_results_full_3)\n",
    "\n",
    "print(\"best score is {} with params {}\".format(xgb_grid_search.best_score_, xgb_grid_search.best_params_))\n",
    "#best score is 0.8506400409626217 with params\n",
    "#{'colsample_bylevel': 0.2, 'colsample_bytree': 0.5, 'gamma': 1, 'learning_rate': 0.08, 'max_depth': 2, 'n_estimators': 150, 'subsample': 0.8}\n",
    "\n",
    "# save dataframe\n",
    "from datetime import datetime\n",
    "date = str(datetime.now().date()).replace(\"-\", \"\")\n",
    "xgb_grid_search_results_full_3.to_csv(f\"results/xgb_results_full_round3_3_learning=0.08_{date}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9eef9359",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_colsample_bylevel</th>\n",
       "      <th>param_colsample_bytree</th>\n",
       "      <th>param_gamma</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>...</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.027726</td>\n",
       "      <td>0.001246</td>\n",
       "      <td>0.007381</td>\n",
       "      <td>0.000662</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.791219</td>\n",
       "      <td>0.043138</td>\n",
       "      <td>4572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.027127</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>0.007081</td>\n",
       "      <td>0.000698</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.797619</td>\n",
       "      <td>0.056310</td>\n",
       "      <td>4538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.027725</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>0.007582</td>\n",
       "      <td>0.000486</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.800819</td>\n",
       "      <td>0.053966</td>\n",
       "      <td>4506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.028225</td>\n",
       "      <td>0.001002</td>\n",
       "      <td>0.007579</td>\n",
       "      <td>0.000661</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.799232</td>\n",
       "      <td>0.049960</td>\n",
       "      <td>4523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.041589</td>\n",
       "      <td>0.000779</td>\n",
       "      <td>0.007481</td>\n",
       "      <td>0.000499</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.812007</td>\n",
       "      <td>0.054003</td>\n",
       "      <td>4127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4603</th>\n",
       "      <td>0.128755</td>\n",
       "      <td>0.000698</td>\n",
       "      <td>0.007581</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.1</td>\n",
       "      <td>5</td>\n",
       "      <td>150</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.919355</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.818587</td>\n",
       "      <td>0.059897</td>\n",
       "      <td>3439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4604</th>\n",
       "      <td>0.181969</td>\n",
       "      <td>0.018973</td>\n",
       "      <td>0.007281</td>\n",
       "      <td>0.000457</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.1</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.903226</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.818612</td>\n",
       "      <td>0.058941</td>\n",
       "      <td>3420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4605</th>\n",
       "      <td>0.176428</td>\n",
       "      <td>0.003770</td>\n",
       "      <td>0.007381</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.1</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.887097</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.815463</td>\n",
       "      <td>0.055569</td>\n",
       "      <td>3709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4606</th>\n",
       "      <td>0.171740</td>\n",
       "      <td>0.003450</td>\n",
       "      <td>0.007381</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.1</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.903226</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.812238</td>\n",
       "      <td>0.052148</td>\n",
       "      <td>4000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4607</th>\n",
       "      <td>0.170743</td>\n",
       "      <td>0.002706</td>\n",
       "      <td>0.007680</td>\n",
       "      <td>0.000457</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.1</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.919355</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.821761</td>\n",
       "      <td>0.060591</td>\n",
       "      <td>3170</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4608 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0          0.027726      0.001246         0.007381        0.000662   \n",
       "1          0.027127      0.000977         0.007081        0.000698   \n",
       "2          0.027725      0.000977         0.007582        0.000486   \n",
       "3          0.028225      0.001002         0.007579        0.000661   \n",
       "4          0.041589      0.000779         0.007481        0.000499   \n",
       "...             ...           ...              ...             ...   \n",
       "4603       0.128755      0.000698         0.007581        0.000489   \n",
       "4604       0.181969      0.018973         0.007281        0.000457   \n",
       "4605       0.176428      0.003770         0.007381        0.000489   \n",
       "4606       0.171740      0.003450         0.007381        0.000489   \n",
       "4607       0.170743      0.002706         0.007680        0.000457   \n",
       "\n",
       "      param_colsample_bylevel  param_colsample_bytree  param_gamma  \\\n",
       "0                         0.1                     0.4            0   \n",
       "1                         0.1                     0.4            0   \n",
       "2                         0.1                     0.4            0   \n",
       "3                         0.1                     0.4            0   \n",
       "4                         0.1                     0.4            0   \n",
       "...                       ...                     ...          ...   \n",
       "4603                      0.4                     0.9           10   \n",
       "4604                      0.4                     0.9           10   \n",
       "4605                      0.4                     0.9           10   \n",
       "4606                      0.4                     0.9           10   \n",
       "4607                      0.4                     0.9           10   \n",
       "\n",
       "      param_learning_rate  param_max_depth  param_n_estimators  ...  \\\n",
       "0                     0.1                2                  30  ...   \n",
       "1                     0.1                2                  30  ...   \n",
       "2                     0.1                2                  30  ...   \n",
       "3                     0.1                2                  30  ...   \n",
       "4                     0.1                2                  50  ...   \n",
       "...                   ...              ...                 ...  ...   \n",
       "4603                  0.1                5                 150  ...   \n",
       "4604                  0.1                5                 200  ...   \n",
       "4605                  0.1                5                 200  ...   \n",
       "4606                  0.1                5                 200  ...   \n",
       "4607                  0.1                5                 200  ...   \n",
       "\n",
       "      split3_test_score split4_test_score  split5_test_score  \\\n",
       "0              0.838710          0.790323           0.822581   \n",
       "1              0.838710          0.774194           0.870968   \n",
       "2              0.838710          0.774194           0.870968   \n",
       "3              0.838710          0.790323           0.854839   \n",
       "4              0.870968          0.790323           0.854839   \n",
       "...                 ...               ...                ...   \n",
       "4603           0.838710          0.806452           0.919355   \n",
       "4604           0.870968          0.806452           0.903226   \n",
       "4605           0.870968          0.822581           0.887097   \n",
       "4606           0.838710          0.806452           0.903226   \n",
       "4607           0.838710          0.806452           0.919355   \n",
       "\n",
       "      split6_test_score  split7_test_score  split8_test_score  \\\n",
       "0              0.790323           0.709677           0.709677   \n",
       "1              0.806452           0.725806           0.677419   \n",
       "2              0.806452           0.725806           0.693548   \n",
       "3              0.806452           0.725806           0.693548   \n",
       "4              0.806452           0.758065           0.693548   \n",
       "...                 ...                ...                ...   \n",
       "4603           0.822581           0.806452           0.677419   \n",
       "4604           0.822581           0.822581           0.677419   \n",
       "4605           0.822581           0.822581           0.693548   \n",
       "4606           0.822581           0.806452           0.709677   \n",
       "4607           0.822581           0.806452           0.677419   \n",
       "\n",
       "      split9_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0              0.806452         0.791219        0.043138             4572  \n",
       "1              0.806452         0.797619        0.056310             4538  \n",
       "2              0.806452         0.800819        0.053966             4506  \n",
       "3              0.806452         0.799232        0.049960             4523  \n",
       "4              0.790323         0.812007        0.054003             4127  \n",
       "...                 ...              ...             ...              ...  \n",
       "4603           0.838710         0.818587        0.059897             3439  \n",
       "4604           0.822581         0.818612        0.058941             3420  \n",
       "4605           0.822581         0.815463        0.055569             3709  \n",
       "4606           0.822581         0.812238        0.052148             4000  \n",
       "4607           0.838710         0.821761        0.060591             3170  \n",
       "\n",
       "[4608 rows x 25 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score is 0.8506400409626217 with params {'colsample_bylevel': 0.3, 'colsample_bytree': 0.5, 'gamma': 1, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 100, 'subsample': 0.8}\n"
     ]
    }
   ],
   "source": [
    "df4 = pd.read_csv(\"data\\\\xgb_results_full_4_learning=0.1_20221124.csv\")\n",
    "df4.drop(df4.columns[0], axis=1, inplace=True)\n",
    "display(df4)\n",
    "print(\"best score is 0.8506400409626217 with params {'colsample_bylevel': 0.3, 'colsample_bytree': 0.5, 'gamma': 1, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 100, 'subsample': 0.8}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "81c3993c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_colsample_bylevel</th>\n",
       "      <th>param_colsample_bytree</th>\n",
       "      <th>param_gamma</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>...</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.027726</td>\n",
       "      <td>0.001246</td>\n",
       "      <td>0.007381</td>\n",
       "      <td>0.000662</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.791219</td>\n",
       "      <td>0.043138</td>\n",
       "      <td>4572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.027127</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>0.007081</td>\n",
       "      <td>0.000698</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.797619</td>\n",
       "      <td>0.056310</td>\n",
       "      <td>4538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.027725</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>0.007582</td>\n",
       "      <td>0.000486</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.800819</td>\n",
       "      <td>0.053966</td>\n",
       "      <td>4506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.028225</td>\n",
       "      <td>0.001002</td>\n",
       "      <td>0.007579</td>\n",
       "      <td>0.000661</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.799232</td>\n",
       "      <td>0.049960</td>\n",
       "      <td>4523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.041589</td>\n",
       "      <td>0.000779</td>\n",
       "      <td>0.007481</td>\n",
       "      <td>0.000499</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.812007</td>\n",
       "      <td>0.054003</td>\n",
       "      <td>4127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4603</th>\n",
       "      <td>0.128755</td>\n",
       "      <td>0.000698</td>\n",
       "      <td>0.007581</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.1</td>\n",
       "      <td>5</td>\n",
       "      <td>150</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.919355</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.818587</td>\n",
       "      <td>0.059897</td>\n",
       "      <td>3439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4604</th>\n",
       "      <td>0.181969</td>\n",
       "      <td>0.018973</td>\n",
       "      <td>0.007281</td>\n",
       "      <td>0.000457</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.1</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.903226</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.818612</td>\n",
       "      <td>0.058941</td>\n",
       "      <td>3420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4605</th>\n",
       "      <td>0.176428</td>\n",
       "      <td>0.003770</td>\n",
       "      <td>0.007381</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.1</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.887097</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.815463</td>\n",
       "      <td>0.055569</td>\n",
       "      <td>3709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4606</th>\n",
       "      <td>0.171740</td>\n",
       "      <td>0.003450</td>\n",
       "      <td>0.007381</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.1</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.903226</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.812238</td>\n",
       "      <td>0.052148</td>\n",
       "      <td>4000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4607</th>\n",
       "      <td>0.170743</td>\n",
       "      <td>0.002706</td>\n",
       "      <td>0.007680</td>\n",
       "      <td>0.000457</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.1</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.919355</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.821761</td>\n",
       "      <td>0.060591</td>\n",
       "      <td>3170</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4608 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0          0.027726      0.001246         0.007381        0.000662   \n",
       "1          0.027127      0.000977         0.007081        0.000698   \n",
       "2          0.027725      0.000977         0.007582        0.000486   \n",
       "3          0.028225      0.001002         0.007579        0.000661   \n",
       "4          0.041589      0.000779         0.007481        0.000499   \n",
       "...             ...           ...              ...             ...   \n",
       "4603       0.128755      0.000698         0.007581        0.000489   \n",
       "4604       0.181969      0.018973         0.007281        0.000457   \n",
       "4605       0.176428      0.003770         0.007381        0.000489   \n",
       "4606       0.171740      0.003450         0.007381        0.000489   \n",
       "4607       0.170743      0.002706         0.007680        0.000457   \n",
       "\n",
       "     param_colsample_bylevel param_colsample_bytree param_gamma  \\\n",
       "0                        0.1                    0.4           0   \n",
       "1                        0.1                    0.4           0   \n",
       "2                        0.1                    0.4           0   \n",
       "3                        0.1                    0.4           0   \n",
       "4                        0.1                    0.4           0   \n",
       "...                      ...                    ...         ...   \n",
       "4603                     0.4                    0.9          10   \n",
       "4604                     0.4                    0.9          10   \n",
       "4605                     0.4                    0.9          10   \n",
       "4606                     0.4                    0.9          10   \n",
       "4607                     0.4                    0.9          10   \n",
       "\n",
       "     param_learning_rate param_max_depth param_n_estimators  ...  \\\n",
       "0                    0.1               2                 30  ...   \n",
       "1                    0.1               2                 30  ...   \n",
       "2                    0.1               2                 30  ...   \n",
       "3                    0.1               2                 30  ...   \n",
       "4                    0.1               2                 50  ...   \n",
       "...                  ...             ...                ...  ...   \n",
       "4603                 0.1               5                150  ...   \n",
       "4604                 0.1               5                200  ...   \n",
       "4605                 0.1               5                200  ...   \n",
       "4606                 0.1               5                200  ...   \n",
       "4607                 0.1               5                200  ...   \n",
       "\n",
       "     split3_test_score split4_test_score  split5_test_score  \\\n",
       "0             0.838710          0.790323           0.822581   \n",
       "1             0.838710          0.774194           0.870968   \n",
       "2             0.838710          0.774194           0.870968   \n",
       "3             0.838710          0.790323           0.854839   \n",
       "4             0.870968          0.790323           0.854839   \n",
       "...                ...               ...                ...   \n",
       "4603          0.838710          0.806452           0.919355   \n",
       "4604          0.870968          0.806452           0.903226   \n",
       "4605          0.870968          0.822581           0.887097   \n",
       "4606          0.838710          0.806452           0.903226   \n",
       "4607          0.838710          0.806452           0.919355   \n",
       "\n",
       "      split6_test_score  split7_test_score  split8_test_score  \\\n",
       "0              0.790323           0.709677           0.709677   \n",
       "1              0.806452           0.725806           0.677419   \n",
       "2              0.806452           0.725806           0.693548   \n",
       "3              0.806452           0.725806           0.693548   \n",
       "4              0.806452           0.758065           0.693548   \n",
       "...                 ...                ...                ...   \n",
       "4603           0.822581           0.806452           0.677419   \n",
       "4604           0.822581           0.822581           0.677419   \n",
       "4605           0.822581           0.822581           0.693548   \n",
       "4606           0.822581           0.806452           0.709677   \n",
       "4607           0.822581           0.806452           0.677419   \n",
       "\n",
       "      split9_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0              0.806452         0.791219        0.043138             4572  \n",
       "1              0.806452         0.797619        0.056310             4538  \n",
       "2              0.806452         0.800819        0.053966             4506  \n",
       "3              0.806452         0.799232        0.049960             4523  \n",
       "4              0.790323         0.812007        0.054003             4127  \n",
       "...                 ...              ...             ...              ...  \n",
       "4603           0.838710         0.818587        0.059897             3439  \n",
       "4604           0.822581         0.818612        0.058941             3420  \n",
       "4605           0.822581         0.815463        0.055569             3709  \n",
       "4606           0.822581         0.812238        0.052148             4000  \n",
       "4607           0.838710         0.821761        0.060591             3170  \n",
       "\n",
       "[4608 rows x 25 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score is 0.8506400409626217 with params {'colsample_bylevel': 0.3, 'colsample_bytree': 0.5, 'gamma': 1, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 100, 'subsample': 0.8}\n"
     ]
    }
   ],
   "source": [
    "# Full Tuning - Part 4\n",
    "random.seed(10)\n",
    "\n",
    "xgb = XGBClassifier()\n",
    "\n",
    "xgb_parameters = {'max_depth': [2,3,4,5]\n",
    "                   , 'subsample': [0.6, 0.7, 0.8, 0.9]\n",
    "                   , 'gamma': [0, 1, 10]\n",
    "                   , 'colsample_bytree': [0.4, 0.5, 0.6, 0.9]\n",
    "                   , 'colsample_bylevel': [0.1, 0.2, 0.3, 0.4]\n",
    "                   , 'learning_rate': [0.1]\n",
    "                   , 'n_estimators': [30, 50, 80, 100, 150, 200]}\n",
    "\n",
    "stratified_10_fold_cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "xgb_grid_search = GridSearchCV(xgb, xgb_parameters, scoring='accuracy', cv=stratified_10_fold_cv)\n",
    "\n",
    "xgb_grid_search.fit(X_train, y_train)\n",
    "\n",
    "xgb_grid_search_results_full_4 = pd.DataFrame(xgb_grid_search.cv_results_)\n",
    "display(xgb_grid_search_results_full_4)\n",
    "\n",
    "print(\"best score is {} with params {}\".format(xgb_grid_search.best_score_, xgb_grid_search.best_params_))\n",
    "#best score is 0.8506400409626217 with params\n",
    "#{'colsample_bylevel': 0.3, 'colsample_bytree': 0.5, 'gamma': 1, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 100, 'subsample': 0.8}\n",
    "\n",
    "# save dataframe\n",
    "from datetime import datetime\n",
    "date = str(datetime.now().date()).replace(\"-\", \"\")\n",
    "xgb_grid_search_results_full_4.to_csv(f\"results/xgb_results_full_round3_4_learning=0.1_{date}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "83e43f97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_colsample_bylevel</th>\n",
       "      <th>param_colsample_bytree</th>\n",
       "      <th>param_gamma</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>...</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.028225</td>\n",
       "      <td>0.001002</td>\n",
       "      <td>0.007380</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.15</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.807220</td>\n",
       "      <td>0.059458</td>\n",
       "      <td>4384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.027726</td>\n",
       "      <td>0.000870</td>\n",
       "      <td>0.006783</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.15</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.887097</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.805658</td>\n",
       "      <td>0.060796</td>\n",
       "      <td>4446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.028425</td>\n",
       "      <td>0.001357</td>\n",
       "      <td>0.007184</td>\n",
       "      <td>0.000398</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.15</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.804019</td>\n",
       "      <td>0.053790</td>\n",
       "      <td>4484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.029920</td>\n",
       "      <td>0.001262</td>\n",
       "      <td>0.007680</td>\n",
       "      <td>0.001184</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.15</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.818484</td>\n",
       "      <td>0.052359</td>\n",
       "      <td>3585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.039893</td>\n",
       "      <td>0.001180</td>\n",
       "      <td>0.007580</td>\n",
       "      <td>0.000662</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.15</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.820097</td>\n",
       "      <td>0.044768</td>\n",
       "      <td>3445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4603</th>\n",
       "      <td>0.129254</td>\n",
       "      <td>0.001017</td>\n",
       "      <td>0.007382</td>\n",
       "      <td>0.000488</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.15</td>\n",
       "      <td>5</td>\n",
       "      <td>150</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.903226</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.812212</td>\n",
       "      <td>0.054700</td>\n",
       "      <td>4012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4604</th>\n",
       "      <td>0.171740</td>\n",
       "      <td>0.001657</td>\n",
       "      <td>0.007480</td>\n",
       "      <td>0.000499</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.15</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.813722</td>\n",
       "      <td>0.052700</td>\n",
       "      <td>3948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4605</th>\n",
       "      <td>0.170244</td>\n",
       "      <td>0.001342</td>\n",
       "      <td>0.007780</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.15</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.820123</td>\n",
       "      <td>0.057714</td>\n",
       "      <td>3430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4606</th>\n",
       "      <td>0.170145</td>\n",
       "      <td>0.001795</td>\n",
       "      <td>0.007281</td>\n",
       "      <td>0.000457</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.15</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.903226</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.817025</td>\n",
       "      <td>0.051360</td>\n",
       "      <td>3604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4607</th>\n",
       "      <td>0.170145</td>\n",
       "      <td>0.002410</td>\n",
       "      <td>0.007580</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.15</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.903226</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.812212</td>\n",
       "      <td>0.054700</td>\n",
       "      <td>4012</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4608 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0          0.028225      0.001002         0.007380        0.000489   \n",
       "1          0.027726      0.000870         0.006783        0.000977   \n",
       "2          0.028425      0.001357         0.007184        0.000398   \n",
       "3          0.029920      0.001262         0.007680        0.001184   \n",
       "4          0.039893      0.001180         0.007580        0.000662   \n",
       "...             ...           ...              ...             ...   \n",
       "4603       0.129254      0.001017         0.007382        0.000488   \n",
       "4604       0.171740      0.001657         0.007480        0.000499   \n",
       "4605       0.170244      0.001342         0.007780        0.000399   \n",
       "4606       0.170145      0.001795         0.007281        0.000457   \n",
       "4607       0.170145      0.002410         0.007580        0.000489   \n",
       "\n",
       "      param_colsample_bylevel  param_colsample_bytree  param_gamma  \\\n",
       "0                         0.1                     0.4            0   \n",
       "1                         0.1                     0.4            0   \n",
       "2                         0.1                     0.4            0   \n",
       "3                         0.1                     0.4            0   \n",
       "4                         0.1                     0.4            0   \n",
       "...                       ...                     ...          ...   \n",
       "4603                      0.4                     0.9           10   \n",
       "4604                      0.4                     0.9           10   \n",
       "4605                      0.4                     0.9           10   \n",
       "4606                      0.4                     0.9           10   \n",
       "4607                      0.4                     0.9           10   \n",
       "\n",
       "      param_learning_rate  param_max_depth  param_n_estimators  ...  \\\n",
       "0                    0.15                2                  30  ...   \n",
       "1                    0.15                2                  30  ...   \n",
       "2                    0.15                2                  30  ...   \n",
       "3                    0.15                2                  30  ...   \n",
       "4                    0.15                2                  50  ...   \n",
       "...                   ...              ...                 ...  ...   \n",
       "4603                 0.15                5                 150  ...   \n",
       "4604                 0.15                5                 200  ...   \n",
       "4605                 0.15                5                 200  ...   \n",
       "4606                 0.15                5                 200  ...   \n",
       "4607                 0.15                5                 200  ...   \n",
       "\n",
       "      split3_test_score split4_test_score  split5_test_score  \\\n",
       "0              0.870968          0.790323           0.870968   \n",
       "1              0.854839          0.806452           0.887097   \n",
       "2              0.838710          0.790323           0.854839   \n",
       "3              0.870968          0.806452           0.870968   \n",
       "4              0.870968          0.790323           0.854839   \n",
       "...                 ...               ...                ...   \n",
       "4603           0.838710          0.806452           0.903226   \n",
       "4604           0.838710          0.822581           0.854839   \n",
       "4605           0.870968          0.806452           0.870968   \n",
       "4606           0.838710          0.806452           0.903226   \n",
       "4607           0.838710          0.806452           0.903226   \n",
       "\n",
       "      split6_test_score  split7_test_score  split8_test_score  \\\n",
       "0              0.822581           0.709677           0.693548   \n",
       "1              0.822581           0.725806           0.677419   \n",
       "2              0.838710           0.725806           0.693548   \n",
       "3              0.822581           0.725806           0.725806   \n",
       "4              0.838710           0.758065           0.725806   \n",
       "...                 ...                ...                ...   \n",
       "4603           0.822581           0.806452           0.693548   \n",
       "4604           0.806452           0.806452           0.677419   \n",
       "4605           0.822581           0.806452           0.677419   \n",
       "4606           0.822581           0.806452           0.709677   \n",
       "4607           0.822581           0.806452           0.693548   \n",
       "\n",
       "      split9_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0              0.790323         0.807220        0.059458             4384  \n",
       "1              0.790323         0.805658        0.060796             4446  \n",
       "2              0.790323         0.804019        0.053790             4484  \n",
       "3              0.822581         0.818484        0.052359             3585  \n",
       "4              0.822581         0.820097        0.044768             3445  \n",
       "...                 ...              ...             ...              ...  \n",
       "4603           0.822581         0.812212        0.054700             4012  \n",
       "4604           0.838710         0.813722        0.052700             3948  \n",
       "4605           0.822581         0.820123        0.057714             3430  \n",
       "4606           0.838710         0.817025        0.051360             3604  \n",
       "4607           0.822581         0.812212        0.054700             4012  \n",
       "\n",
       "[4608 rows x 25 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score is 0.856989247311828 with params {'colsample_bylevel': 0.4, 'colsample_bytree': 0.4, 'gamma': 1, 'learning_rate': 0.15, 'max_depth': 4, 'n_estimators': 30, 'subsample': 0.9}\n"
     ]
    }
   ],
   "source": [
    "df5 = pd.read_csv(\"data\\\\xgb_results_full_5_learning=0.15_20221124.csv\")\n",
    "df5.drop(df5.columns[0], axis=1, inplace=True)\n",
    "display(df5)\n",
    "print(\"best score is 0.856989247311828 with params {'colsample_bylevel': 0.4, 'colsample_bytree': 0.4, 'gamma': 1, 'learning_rate': 0.15, 'max_depth': 4, 'n_estimators': 30, 'subsample': 0.9}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8e53020f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_colsample_bylevel</th>\n",
       "      <th>param_colsample_bytree</th>\n",
       "      <th>param_gamma</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>...</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.028225</td>\n",
       "      <td>0.001002</td>\n",
       "      <td>0.007380</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.15</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.807220</td>\n",
       "      <td>0.059458</td>\n",
       "      <td>4384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.027726</td>\n",
       "      <td>0.000870</td>\n",
       "      <td>0.006783</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.15</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.887097</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.805658</td>\n",
       "      <td>0.060796</td>\n",
       "      <td>4446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.028425</td>\n",
       "      <td>0.001357</td>\n",
       "      <td>0.007184</td>\n",
       "      <td>0.000398</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.15</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.804019</td>\n",
       "      <td>0.053790</td>\n",
       "      <td>4484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.029920</td>\n",
       "      <td>0.001262</td>\n",
       "      <td>0.007680</td>\n",
       "      <td>0.001184</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.15</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.818484</td>\n",
       "      <td>0.052359</td>\n",
       "      <td>3585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.039893</td>\n",
       "      <td>0.001180</td>\n",
       "      <td>0.007580</td>\n",
       "      <td>0.000662</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.15</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.820097</td>\n",
       "      <td>0.044768</td>\n",
       "      <td>3445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4603</th>\n",
       "      <td>0.129254</td>\n",
       "      <td>0.001017</td>\n",
       "      <td>0.007382</td>\n",
       "      <td>0.000488</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.15</td>\n",
       "      <td>5</td>\n",
       "      <td>150</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.903226</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.812212</td>\n",
       "      <td>0.054700</td>\n",
       "      <td>4012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4604</th>\n",
       "      <td>0.171740</td>\n",
       "      <td>0.001657</td>\n",
       "      <td>0.007480</td>\n",
       "      <td>0.000499</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.15</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.813722</td>\n",
       "      <td>0.052700</td>\n",
       "      <td>3948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4605</th>\n",
       "      <td>0.170244</td>\n",
       "      <td>0.001342</td>\n",
       "      <td>0.007780</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.15</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.820123</td>\n",
       "      <td>0.057714</td>\n",
       "      <td>3430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4606</th>\n",
       "      <td>0.170145</td>\n",
       "      <td>0.001795</td>\n",
       "      <td>0.007281</td>\n",
       "      <td>0.000457</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.15</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.903226</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.817025</td>\n",
       "      <td>0.051360</td>\n",
       "      <td>3604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4607</th>\n",
       "      <td>0.170145</td>\n",
       "      <td>0.002410</td>\n",
       "      <td>0.007580</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.15</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.903226</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.812212</td>\n",
       "      <td>0.054700</td>\n",
       "      <td>4012</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4608 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0          0.028225      0.001002         0.007380        0.000489   \n",
       "1          0.027726      0.000870         0.006783        0.000977   \n",
       "2          0.028425      0.001357         0.007184        0.000398   \n",
       "3          0.029920      0.001262         0.007680        0.001184   \n",
       "4          0.039893      0.001180         0.007580        0.000662   \n",
       "...             ...           ...              ...             ...   \n",
       "4603       0.129254      0.001017         0.007382        0.000488   \n",
       "4604       0.171740      0.001657         0.007480        0.000499   \n",
       "4605       0.170244      0.001342         0.007780        0.000399   \n",
       "4606       0.170145      0.001795         0.007281        0.000457   \n",
       "4607       0.170145      0.002410         0.007580        0.000489   \n",
       "\n",
       "     param_colsample_bylevel param_colsample_bytree param_gamma  \\\n",
       "0                        0.1                    0.4           0   \n",
       "1                        0.1                    0.4           0   \n",
       "2                        0.1                    0.4           0   \n",
       "3                        0.1                    0.4           0   \n",
       "4                        0.1                    0.4           0   \n",
       "...                      ...                    ...         ...   \n",
       "4603                     0.4                    0.9          10   \n",
       "4604                     0.4                    0.9          10   \n",
       "4605                     0.4                    0.9          10   \n",
       "4606                     0.4                    0.9          10   \n",
       "4607                     0.4                    0.9          10   \n",
       "\n",
       "     param_learning_rate param_max_depth param_n_estimators  ...  \\\n",
       "0                   0.15               2                 30  ...   \n",
       "1                   0.15               2                 30  ...   \n",
       "2                   0.15               2                 30  ...   \n",
       "3                   0.15               2                 30  ...   \n",
       "4                   0.15               2                 50  ...   \n",
       "...                  ...             ...                ...  ...   \n",
       "4603                0.15               5                150  ...   \n",
       "4604                0.15               5                200  ...   \n",
       "4605                0.15               5                200  ...   \n",
       "4606                0.15               5                200  ...   \n",
       "4607                0.15               5                200  ...   \n",
       "\n",
       "     split3_test_score split4_test_score  split5_test_score  \\\n",
       "0             0.870968          0.790323           0.870968   \n",
       "1             0.854839          0.806452           0.887097   \n",
       "2             0.838710          0.790323           0.854839   \n",
       "3             0.870968          0.806452           0.870968   \n",
       "4             0.870968          0.790323           0.854839   \n",
       "...                ...               ...                ...   \n",
       "4603          0.838710          0.806452           0.903226   \n",
       "4604          0.838710          0.822581           0.854839   \n",
       "4605          0.870968          0.806452           0.870968   \n",
       "4606          0.838710          0.806452           0.903226   \n",
       "4607          0.838710          0.806452           0.903226   \n",
       "\n",
       "      split6_test_score  split7_test_score  split8_test_score  \\\n",
       "0              0.822581           0.709677           0.693548   \n",
       "1              0.822581           0.725806           0.677419   \n",
       "2              0.838710           0.725806           0.693548   \n",
       "3              0.822581           0.725806           0.725806   \n",
       "4              0.838710           0.758065           0.725806   \n",
       "...                 ...                ...                ...   \n",
       "4603           0.822581           0.806452           0.693548   \n",
       "4604           0.806452           0.806452           0.677419   \n",
       "4605           0.822581           0.806452           0.677419   \n",
       "4606           0.822581           0.806452           0.709677   \n",
       "4607           0.822581           0.806452           0.693548   \n",
       "\n",
       "      split9_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0              0.790323         0.807220        0.059458             4384  \n",
       "1              0.790323         0.805658        0.060796             4446  \n",
       "2              0.790323         0.804019        0.053790             4484  \n",
       "3              0.822581         0.818484        0.052359             3585  \n",
       "4              0.822581         0.820097        0.044768             3445  \n",
       "...                 ...              ...             ...              ...  \n",
       "4603           0.822581         0.812212        0.054700             4012  \n",
       "4604           0.838710         0.813722        0.052700             3948  \n",
       "4605           0.822581         0.820123        0.057714             3430  \n",
       "4606           0.838710         0.817025        0.051360             3604  \n",
       "4607           0.822581         0.812212        0.054700             4012  \n",
       "\n",
       "[4608 rows x 25 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score is 0.856989247311828 with params {'colsample_bylevel': 0.4, 'colsample_bytree': 0.4, 'gamma': 1, 'learning_rate': 0.15, 'max_depth': 4, 'n_estimators': 30, 'subsample': 0.9}\n"
     ]
    }
   ],
   "source": [
    "# Full Tuning - Part 5\n",
    "random.seed(10)\n",
    "\n",
    "xgb = XGBClassifier()\n",
    "\n",
    "xgb_parameters = {'max_depth': [2,3,4,5]\n",
    "                   , 'subsample': [0.6, 0.7, 0.8, 0.9]\n",
    "                   , 'gamma': [0, 1, 10]\n",
    "                   , 'colsample_bytree': [0.4, 0.5, 0.6, 0.9]\n",
    "                   , 'colsample_bylevel': [0.1, 0.2, 0.3, 0.4]\n",
    "                   , 'learning_rate': [0.15]\n",
    "                   , 'n_estimators': [30, 50, 80, 100, 150, 200]}\n",
    "\n",
    "stratified_10_fold_cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "xgb_grid_search = GridSearchCV(xgb, xgb_parameters, scoring='accuracy', cv=stratified_10_fold_cv)\n",
    "\n",
    "xgb_grid_search.fit(X_train, y_train)\n",
    "\n",
    "xgb_grid_search_results_full_5 = pd.DataFrame(xgb_grid_search.cv_results_)\n",
    "display(xgb_grid_search_results_full_5)\n",
    "\n",
    "print(\"best score is {} with params {}\".format(xgb_grid_search.best_score_, xgb_grid_search.best_params_))\n",
    "#best score is 0.856989247311828 with params\n",
    "#{'colsample_bylevel': 0.4, 'colsample_bytree': 0.4, 'gamma': 1, 'learning_rate': 0.15, 'max_depth': 4, 'n_estimators': 30, 'subsample': 0.9}\n",
    "\n",
    "# save dataframe\n",
    "from datetime import datetime\n",
    "date = str(datetime.now().date()).replace(\"-\", \"\")\n",
    "xgb_grid_search_results_full_5.to_csv(f\"results/xgb_results_full_round3_5_learning=0.15_{date}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "addcfcca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_colsample_bylevel</th>\n",
       "      <th>param_colsample_bytree</th>\n",
       "      <th>param_gamma</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>...</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.028224</td>\n",
       "      <td>0.000897</td>\n",
       "      <td>0.007381</td>\n",
       "      <td>0.000488</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.821582</td>\n",
       "      <td>0.063111</td>\n",
       "      <td>3320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.027226</td>\n",
       "      <td>0.000639</td>\n",
       "      <td>0.006683</td>\n",
       "      <td>0.000897</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>0.887097</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.887097</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.829647</td>\n",
       "      <td>0.062955</td>\n",
       "      <td>2389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.029321</td>\n",
       "      <td>0.001353</td>\n",
       "      <td>0.007580</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.887097</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.816846</td>\n",
       "      <td>0.062937</td>\n",
       "      <td>3729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.028125</td>\n",
       "      <td>0.001657</td>\n",
       "      <td>0.007281</td>\n",
       "      <td>0.000457</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>0.887097</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.829647</td>\n",
       "      <td>0.060854</td>\n",
       "      <td>2389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.039993</td>\n",
       "      <td>0.001133</td>\n",
       "      <td>0.007181</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.887097</td>\n",
       "      <td>0.821710</td>\n",
       "      <td>0.053554</td>\n",
       "      <td>3262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4603</th>\n",
       "      <td>0.129354</td>\n",
       "      <td>0.001184</td>\n",
       "      <td>0.007281</td>\n",
       "      <td>0.000457</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5</td>\n",
       "      <td>150</td>\n",
       "      <td>...</td>\n",
       "      <td>0.887097</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.919355</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.826600</td>\n",
       "      <td>0.059814</td>\n",
       "      <td>2710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4604</th>\n",
       "      <td>0.168948</td>\n",
       "      <td>0.001739</td>\n",
       "      <td>0.007581</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.919355</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.828187</td>\n",
       "      <td>0.060472</td>\n",
       "      <td>2464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4605</th>\n",
       "      <td>0.170344</td>\n",
       "      <td>0.002515</td>\n",
       "      <td>0.007481</td>\n",
       "      <td>0.000498</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.887097</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.824936</td>\n",
       "      <td>0.057195</td>\n",
       "      <td>2943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4606</th>\n",
       "      <td>0.169896</td>\n",
       "      <td>0.002405</td>\n",
       "      <td>0.007281</td>\n",
       "      <td>0.000457</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.824910</td>\n",
       "      <td>0.045101</td>\n",
       "      <td>2951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4607</th>\n",
       "      <td>0.169047</td>\n",
       "      <td>0.001201</td>\n",
       "      <td>0.007281</td>\n",
       "      <td>0.000457</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.887097</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.919355</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.826600</td>\n",
       "      <td>0.059814</td>\n",
       "      <td>2710</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4608 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0          0.028224      0.000897         0.007381        0.000488   \n",
       "1          0.027226      0.000639         0.006683        0.000897   \n",
       "2          0.029321      0.001353         0.007580        0.000489   \n",
       "3          0.028125      0.001657         0.007281        0.000457   \n",
       "4          0.039993      0.001133         0.007181        0.000399   \n",
       "...             ...           ...              ...             ...   \n",
       "4603       0.129354      0.001184         0.007281        0.000457   \n",
       "4604       0.168948      0.001739         0.007581        0.000489   \n",
       "4605       0.170344      0.002515         0.007481        0.000498   \n",
       "4606       0.169896      0.002405         0.007281        0.000457   \n",
       "4607       0.169047      0.001201         0.007281        0.000457   \n",
       "\n",
       "      param_colsample_bylevel  param_colsample_bytree  param_gamma  \\\n",
       "0                         0.1                     0.4            0   \n",
       "1                         0.1                     0.4            0   \n",
       "2                         0.1                     0.4            0   \n",
       "3                         0.1                     0.4            0   \n",
       "4                         0.1                     0.4            0   \n",
       "...                       ...                     ...          ...   \n",
       "4603                      0.4                     0.9           10   \n",
       "4604                      0.4                     0.9           10   \n",
       "4605                      0.4                     0.9           10   \n",
       "4606                      0.4                     0.9           10   \n",
       "4607                      0.4                     0.9           10   \n",
       "\n",
       "      param_learning_rate  param_max_depth  param_n_estimators  ...  \\\n",
       "0                     0.2                2                  30  ...   \n",
       "1                     0.2                2                  30  ...   \n",
       "2                     0.2                2                  30  ...   \n",
       "3                     0.2                2                  30  ...   \n",
       "4                     0.2                2                  50  ...   \n",
       "...                   ...              ...                 ...  ...   \n",
       "4603                  0.2                5                 150  ...   \n",
       "4604                  0.2                5                 200  ...   \n",
       "4605                  0.2                5                 200  ...   \n",
       "4606                  0.2                5                 200  ...   \n",
       "4607                  0.2                5                 200  ...   \n",
       "\n",
       "      split3_test_score split4_test_score  split5_test_score  \\\n",
       "0              0.870968          0.790323           0.854839   \n",
       "1              0.887097          0.806452           0.887097   \n",
       "2              0.870968          0.806452           0.887097   \n",
       "3              0.887097          0.790323           0.870968   \n",
       "4              0.854839          0.790323           0.854839   \n",
       "...                 ...               ...                ...   \n",
       "4603           0.887097          0.806452           0.919355   \n",
       "4604           0.919355          0.838710           0.870968   \n",
       "4605           0.870968          0.806452           0.887097   \n",
       "4606           0.870968          0.806452           0.854839   \n",
       "4607           0.887097          0.806452           0.919355   \n",
       "\n",
       "      split6_test_score  split7_test_score  split8_test_score  \\\n",
       "0              0.838710           0.725806           0.693548   \n",
       "1              0.822581           0.741935           0.693548   \n",
       "2              0.822581           0.725806           0.677419   \n",
       "3              0.822581           0.758065           0.693548   \n",
       "4              0.838710           0.741935           0.709677   \n",
       "...                 ...                ...                ...   \n",
       "4603           0.822581           0.806452           0.693548   \n",
       "4604           0.806452           0.806452           0.677419   \n",
       "4605           0.806452           0.822581           0.677419   \n",
       "4606           0.822581           0.806452           0.709677   \n",
       "4607           0.822581           0.806452           0.693548   \n",
       "\n",
       "      split9_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0              0.822581         0.821582        0.063111             3320  \n",
       "1              0.838710         0.829647        0.062955             2389  \n",
       "2              0.822581         0.816846        0.062937             3729  \n",
       "3              0.854839         0.829647        0.060854             2389  \n",
       "4              0.887097         0.821710        0.053554             3262  \n",
       "...                 ...              ...             ...              ...  \n",
       "4603           0.822581         0.826600        0.059814             2710  \n",
       "4604           0.838710         0.828187        0.060472             2464  \n",
       "4605           0.838710         0.824936        0.057195             2943  \n",
       "4606           0.822581         0.824910        0.045101             2951  \n",
       "4607           0.822581         0.826600        0.059814             2710  \n",
       "\n",
       "[4608 rows x 25 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score is 0.8522017409114184 with params {'colsample_bylevel': 0.2, 'colsample_bytree': 0.9, 'gamma': 1, 'learning_rate': 0.2, 'max_depth': 3, 'n_estimators': 30, 'subsample': 0.6}\n"
     ]
    }
   ],
   "source": [
    "df6 = pd.read_csv(\"data\\\\xgb_results_full_6_learning=0.2_20221124.csv\")\n",
    "df6.drop(df6.columns[0], axis=1, inplace=True)\n",
    "display(df6)\n",
    "print(\"best score is 0.8522017409114184 with params {'colsample_bylevel': 0.2, 'colsample_bytree': 0.9, 'gamma': 1, 'learning_rate': 0.2, 'max_depth': 3, 'n_estimators': 30, 'subsample': 0.6}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "de9ada4d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_colsample_bylevel</th>\n",
       "      <th>param_colsample_bytree</th>\n",
       "      <th>param_gamma</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>...</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.028224</td>\n",
       "      <td>0.000897</td>\n",
       "      <td>0.007381</td>\n",
       "      <td>0.000488</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.821582</td>\n",
       "      <td>0.063111</td>\n",
       "      <td>3320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.027226</td>\n",
       "      <td>0.000639</td>\n",
       "      <td>0.006683</td>\n",
       "      <td>0.000897</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>0.887097</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.887097</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.829647</td>\n",
       "      <td>0.062955</td>\n",
       "      <td>2389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.029321</td>\n",
       "      <td>0.001353</td>\n",
       "      <td>0.007580</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.887097</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.816846</td>\n",
       "      <td>0.062937</td>\n",
       "      <td>3729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.028125</td>\n",
       "      <td>0.001657</td>\n",
       "      <td>0.007281</td>\n",
       "      <td>0.000457</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>0.887097</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.829647</td>\n",
       "      <td>0.060854</td>\n",
       "      <td>2389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.039993</td>\n",
       "      <td>0.001133</td>\n",
       "      <td>0.007181</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.887097</td>\n",
       "      <td>0.821710</td>\n",
       "      <td>0.053554</td>\n",
       "      <td>3262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4603</th>\n",
       "      <td>0.129354</td>\n",
       "      <td>0.001184</td>\n",
       "      <td>0.007281</td>\n",
       "      <td>0.000457</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5</td>\n",
       "      <td>150</td>\n",
       "      <td>...</td>\n",
       "      <td>0.887097</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.919355</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.826600</td>\n",
       "      <td>0.059814</td>\n",
       "      <td>2710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4604</th>\n",
       "      <td>0.168948</td>\n",
       "      <td>0.001739</td>\n",
       "      <td>0.007581</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.919355</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.828187</td>\n",
       "      <td>0.060472</td>\n",
       "      <td>2464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4605</th>\n",
       "      <td>0.170344</td>\n",
       "      <td>0.002515</td>\n",
       "      <td>0.007481</td>\n",
       "      <td>0.000498</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.887097</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.824936</td>\n",
       "      <td>0.057195</td>\n",
       "      <td>2943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4606</th>\n",
       "      <td>0.169896</td>\n",
       "      <td>0.002405</td>\n",
       "      <td>0.007281</td>\n",
       "      <td>0.000457</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.824910</td>\n",
       "      <td>0.045101</td>\n",
       "      <td>2951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4607</th>\n",
       "      <td>0.169047</td>\n",
       "      <td>0.001201</td>\n",
       "      <td>0.007281</td>\n",
       "      <td>0.000457</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.887097</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.919355</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.826600</td>\n",
       "      <td>0.059814</td>\n",
       "      <td>2710</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4608 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0          0.028224      0.000897         0.007381        0.000488   \n",
       "1          0.027226      0.000639         0.006683        0.000897   \n",
       "2          0.029321      0.001353         0.007580        0.000489   \n",
       "3          0.028125      0.001657         0.007281        0.000457   \n",
       "4          0.039993      0.001133         0.007181        0.000399   \n",
       "...             ...           ...              ...             ...   \n",
       "4603       0.129354      0.001184         0.007281        0.000457   \n",
       "4604       0.168948      0.001739         0.007581        0.000489   \n",
       "4605       0.170344      0.002515         0.007481        0.000498   \n",
       "4606       0.169896      0.002405         0.007281        0.000457   \n",
       "4607       0.169047      0.001201         0.007281        0.000457   \n",
       "\n",
       "     param_colsample_bylevel param_colsample_bytree param_gamma  \\\n",
       "0                        0.1                    0.4           0   \n",
       "1                        0.1                    0.4           0   \n",
       "2                        0.1                    0.4           0   \n",
       "3                        0.1                    0.4           0   \n",
       "4                        0.1                    0.4           0   \n",
       "...                      ...                    ...         ...   \n",
       "4603                     0.4                    0.9          10   \n",
       "4604                     0.4                    0.9          10   \n",
       "4605                     0.4                    0.9          10   \n",
       "4606                     0.4                    0.9          10   \n",
       "4607                     0.4                    0.9          10   \n",
       "\n",
       "     param_learning_rate param_max_depth param_n_estimators  ...  \\\n",
       "0                    0.2               2                 30  ...   \n",
       "1                    0.2               2                 30  ...   \n",
       "2                    0.2               2                 30  ...   \n",
       "3                    0.2               2                 30  ...   \n",
       "4                    0.2               2                 50  ...   \n",
       "...                  ...             ...                ...  ...   \n",
       "4603                 0.2               5                150  ...   \n",
       "4604                 0.2               5                200  ...   \n",
       "4605                 0.2               5                200  ...   \n",
       "4606                 0.2               5                200  ...   \n",
       "4607                 0.2               5                200  ...   \n",
       "\n",
       "     split3_test_score split4_test_score  split5_test_score  \\\n",
       "0             0.870968          0.790323           0.854839   \n",
       "1             0.887097          0.806452           0.887097   \n",
       "2             0.870968          0.806452           0.887097   \n",
       "3             0.887097          0.790323           0.870968   \n",
       "4             0.854839          0.790323           0.854839   \n",
       "...                ...               ...                ...   \n",
       "4603          0.887097          0.806452           0.919355   \n",
       "4604          0.919355          0.838710           0.870968   \n",
       "4605          0.870968          0.806452           0.887097   \n",
       "4606          0.870968          0.806452           0.854839   \n",
       "4607          0.887097          0.806452           0.919355   \n",
       "\n",
       "      split6_test_score  split7_test_score  split8_test_score  \\\n",
       "0              0.838710           0.725806           0.693548   \n",
       "1              0.822581           0.741935           0.693548   \n",
       "2              0.822581           0.725806           0.677419   \n",
       "3              0.822581           0.758065           0.693548   \n",
       "4              0.838710           0.741935           0.709677   \n",
       "...                 ...                ...                ...   \n",
       "4603           0.822581           0.806452           0.693548   \n",
       "4604           0.806452           0.806452           0.677419   \n",
       "4605           0.806452           0.822581           0.677419   \n",
       "4606           0.822581           0.806452           0.709677   \n",
       "4607           0.822581           0.806452           0.693548   \n",
       "\n",
       "      split9_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0              0.822581         0.821582        0.063111             3320  \n",
       "1              0.838710         0.829647        0.062955             2389  \n",
       "2              0.822581         0.816846        0.062937             3729  \n",
       "3              0.854839         0.829647        0.060854             2389  \n",
       "4              0.887097         0.821710        0.053554             3262  \n",
       "...                 ...              ...             ...              ...  \n",
       "4603           0.822581         0.826600        0.059814             2710  \n",
       "4604           0.838710         0.828187        0.060472             2464  \n",
       "4605           0.838710         0.824936        0.057195             2943  \n",
       "4606           0.822581         0.824910        0.045101             2951  \n",
       "4607           0.822581         0.826600        0.059814             2710  \n",
       "\n",
       "[4608 rows x 25 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score is 0.8522017409114184 with params {'colsample_bylevel': 0.2, 'colsample_bytree': 0.9, 'gamma': 1, 'learning_rate': 0.2, 'max_depth': 3, 'n_estimators': 30, 'subsample': 0.6}\n"
     ]
    }
   ],
   "source": [
    "# Full Tuning - Part 6\n",
    "random.seed(10)\n",
    "\n",
    "xgb = XGBClassifier()\n",
    "\n",
    "xgb_parameters = {'max_depth': [2,3,4,5]\n",
    "                   , 'subsample': [0.6, 0.7, 0.8, 0.9]\n",
    "                   , 'gamma': [0, 1, 10]\n",
    "                   , 'colsample_bytree': [0.4, 0.5, 0.6, 0.9]\n",
    "                   , 'colsample_bylevel': [0.1, 0.2, 0.3, 0.4]\n",
    "                   , 'learning_rate': [0.2]\n",
    "                   , 'n_estimators': [30, 50, 80, 100, 150, 200]}\n",
    "\n",
    "stratified_10_fold_cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "xgb_grid_search = GridSearchCV(xgb, xgb_parameters, scoring='accuracy', cv=stratified_10_fold_cv)\n",
    "\n",
    "xgb_grid_search.fit(X_train, y_train)\n",
    "\n",
    "xgb_grid_search_results_full_6 = pd.DataFrame(xgb_grid_search.cv_results_)\n",
    "display(xgb_grid_search_results_full_6)\n",
    "\n",
    "print(\"best score is {} with params {}\".format(xgb_grid_search.best_score_, xgb_grid_search.best_params_))\n",
    "#best score is 0.8522017409114184 with params\n",
    "#{'colsample_bylevel': 0.2, 'colsample_bytree': 0.9, 'gamma': 1, 'learning_rate': 0.2, 'max_depth': 3, 'n_estimators': 30, 'subsample': 0.6}\n",
    "\n",
    "# save dataframe\n",
    "from datetime import datetime\n",
    "date = str(datetime.now().date()).replace(\"-\", \"\")\n",
    "xgb_grid_search_results_full_6.to_csv(f\"results/xgb_results_full_round3_6_learning=0.2_{date}.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b07bc15",
   "metadata": {},
   "source": [
    "Combine single hyper parameter tuning to find best values for hyper parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "aab3352c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_colsample_bylevel</th>\n",
       "      <th>param_colsample_bytree</th>\n",
       "      <th>param_gamma</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>...</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.028623</td>\n",
       "      <td>0.002525</td>\n",
       "      <td>0.007181</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.741295</td>\n",
       "      <td>0.048078</td>\n",
       "      <td>27618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.027127</td>\n",
       "      <td>0.000598</td>\n",
       "      <td>0.007082</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.742908</td>\n",
       "      <td>0.049390</td>\n",
       "      <td>27616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.027028</td>\n",
       "      <td>0.000698</td>\n",
       "      <td>0.007580</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.752586</td>\n",
       "      <td>0.048690</td>\n",
       "      <td>27568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.027427</td>\n",
       "      <td>0.000920</td>\n",
       "      <td>0.007381</td>\n",
       "      <td>0.000662</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.742960</td>\n",
       "      <td>0.043040</td>\n",
       "      <td>27614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.040093</td>\n",
       "      <td>0.001465</td>\n",
       "      <td>0.007082</td>\n",
       "      <td>0.000536</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>...</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.765463</td>\n",
       "      <td>0.037846</td>\n",
       "      <td>27462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27643</th>\n",
       "      <td>0.129354</td>\n",
       "      <td>0.001184</td>\n",
       "      <td>0.007281</td>\n",
       "      <td>0.000457</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.20</td>\n",
       "      <td>5</td>\n",
       "      <td>150</td>\n",
       "      <td>...</td>\n",
       "      <td>0.887097</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.919355</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.826600</td>\n",
       "      <td>0.059814</td>\n",
       "      <td>14497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27644</th>\n",
       "      <td>0.168948</td>\n",
       "      <td>0.001739</td>\n",
       "      <td>0.007581</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.20</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.919355</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.828187</td>\n",
       "      <td>0.060472</td>\n",
       "      <td>13496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27645</th>\n",
       "      <td>0.170344</td>\n",
       "      <td>0.002515</td>\n",
       "      <td>0.007481</td>\n",
       "      <td>0.000498</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.20</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.887097</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.824936</td>\n",
       "      <td>0.057195</td>\n",
       "      <td>15641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27646</th>\n",
       "      <td>0.169896</td>\n",
       "      <td>0.002405</td>\n",
       "      <td>0.007281</td>\n",
       "      <td>0.000457</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.20</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.824910</td>\n",
       "      <td>0.045101</td>\n",
       "      <td>15655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27647</th>\n",
       "      <td>0.169047</td>\n",
       "      <td>0.001201</td>\n",
       "      <td>0.007281</td>\n",
       "      <td>0.000457</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.20</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.887097</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.919355</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.826600</td>\n",
       "      <td>0.059814</td>\n",
       "      <td>14482</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27648 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0           0.028623      0.002525         0.007181        0.000399   \n",
       "1           0.027127      0.000598         0.007082        0.000300   \n",
       "2           0.027028      0.000698         0.007580        0.000489   \n",
       "3           0.027427      0.000920         0.007381        0.000662   \n",
       "4           0.040093      0.001465         0.007082        0.000536   \n",
       "...              ...           ...              ...             ...   \n",
       "27643       0.129354      0.001184         0.007281        0.000457   \n",
       "27644       0.168948      0.001739         0.007581        0.000489   \n",
       "27645       0.170344      0.002515         0.007481        0.000498   \n",
       "27646       0.169896      0.002405         0.007281        0.000457   \n",
       "27647       0.169047      0.001201         0.007281        0.000457   \n",
       "\n",
       "       param_colsample_bylevel  param_colsample_bytree  param_gamma  \\\n",
       "0                          0.1                     0.4            0   \n",
       "1                          0.1                     0.4            0   \n",
       "2                          0.1                     0.4            0   \n",
       "3                          0.1                     0.4            0   \n",
       "4                          0.1                     0.4            0   \n",
       "...                        ...                     ...          ...   \n",
       "27643                      0.4                     0.9           10   \n",
       "27644                      0.4                     0.9           10   \n",
       "27645                      0.4                     0.9           10   \n",
       "27646                      0.4                     0.9           10   \n",
       "27647                      0.4                     0.9           10   \n",
       "\n",
       "       param_learning_rate  param_max_depth  param_n_estimators  ...  \\\n",
       "0                     0.01                2                  30  ...   \n",
       "1                     0.01                2                  30  ...   \n",
       "2                     0.01                2                  30  ...   \n",
       "3                     0.01                2                  30  ...   \n",
       "4                     0.01                2                  50  ...   \n",
       "...                    ...              ...                 ...  ...   \n",
       "27643                 0.20                5                 150  ...   \n",
       "27644                 0.20                5                 200  ...   \n",
       "27645                 0.20                5                 200  ...   \n",
       "27646                 0.20                5                 200  ...   \n",
       "27647                 0.20                5                 200  ...   \n",
       "\n",
       "       split3_test_score split4_test_score  split5_test_score  \\\n",
       "0               0.758065          0.741935           0.741935   \n",
       "1               0.774194          0.741935           0.741935   \n",
       "2               0.774194          0.758065           0.774194   \n",
       "3               0.790323          0.725806           0.709677   \n",
       "4               0.790323          0.774194           0.774194   \n",
       "...                  ...               ...                ...   \n",
       "27643           0.887097          0.806452           0.919355   \n",
       "27644           0.919355          0.838710           0.870968   \n",
       "27645           0.870968          0.806452           0.887097   \n",
       "27646           0.870968          0.806452           0.854839   \n",
       "27647           0.887097          0.806452           0.919355   \n",
       "\n",
       "       split6_test_score  split7_test_score  split8_test_score  \\\n",
       "0               0.725806           0.677419           0.693548   \n",
       "1               0.725806           0.677419           0.677419   \n",
       "2               0.741935           0.693548           0.677419   \n",
       "3               0.741935           0.709677           0.709677   \n",
       "4               0.725806           0.693548           0.725806   \n",
       "...                  ...                ...                ...   \n",
       "27643           0.822581           0.806452           0.693548   \n",
       "27644           0.806452           0.806452           0.677419   \n",
       "27645           0.806452           0.822581           0.677419   \n",
       "27646           0.822581           0.806452           0.709677   \n",
       "27647           0.822581           0.806452           0.693548   \n",
       "\n",
       "       split9_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0               0.677419         0.741295        0.048078            27618  \n",
       "1               0.693548         0.742908        0.049390            27616  \n",
       "2               0.709677         0.752586        0.048690            27568  \n",
       "3               0.677419         0.742960        0.043040            27614  \n",
       "4               0.758065         0.765463        0.037846            27462  \n",
       "...                  ...              ...             ...              ...  \n",
       "27643           0.822581         0.826600        0.059814            14497  \n",
       "27644           0.838710         0.828187        0.060472            13496  \n",
       "27645           0.838710         0.824936        0.057195            15641  \n",
       "27646           0.822581         0.824910        0.045101            15655  \n",
       "27647           0.822581         0.826600        0.059814            14482  \n",
       "\n",
       "[27648 rows x 25 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score is 0.850563 with params {'colsample_bylevel': 0.4, 'colsample_bytree': 0.4, 'gamma': 1, 'learning_rate': 0.15, 'max_depth': 4, 'n_estimators': 30, 'subsample': 0.9}\n"
     ]
    }
   ],
   "source": [
    "# read single parts of round 3, concatenate and update index and rank_test_score\n",
    "\n",
    "df1 = pd.read_csv(\"data\\\\xgb_results_full_1_learning=0.01_20221124.csv\")\n",
    "df1.drop(df1.columns[0], axis=1, inplace=True)\n",
    "\n",
    "df2 = pd.read_csv(\"data\\\\xgb_results_full_2_learning=0.05_20221124.csv\")\n",
    "df2.drop(df2.columns[0], axis=1, inplace=True)\n",
    "\n",
    "df3 = pd.read_csv(\"data\\\\xgb_results_full_3_learning=0.08_20221124.csv\")\n",
    "df3.drop(df3.columns[0], axis=1, inplace=True)\n",
    "\n",
    "df4 = pd.read_csv(\"data\\\\xgb_results_full_4_learning=0.1_20221124.csv\")\n",
    "df4.drop(df4.columns[0], axis=1, inplace=True)\n",
    "\n",
    "df5 = pd.read_csv(\"data\\\\xgb_results_full_5_learning=0.15_20221124.csv\")\n",
    "df5.drop(df5.columns[0], axis=1, inplace=True)\n",
    "\n",
    "df6 = pd.read_csv(\"data\\\\xgb_results_full_6_learning=0.2_20221124.csv\")\n",
    "df6.drop(df6.columns[0], axis=1, inplace=True)\n",
    "\n",
    "df_full = pd.concat([df1,df2,df3,df4,df5,df6])\n",
    "\n",
    "#assign correct rank\n",
    "df_full = df_full.sort_values(by='mean_test_score', ascending=False)\n",
    "df_full['rank_test_score'] = range(1, len(df_full)+1)\n",
    "\n",
    "#get correct order and set new index\n",
    "df_full = df_full.sort_values(by=['param_colsample_bylevel', 'param_colsample_bytree', 'param_gamma', 'param_learning_rate', 'param_max_depth', 'param_n_estimators', 'param_subsample'])\n",
    "xgb_grid_search_results_round3 = df_full.set_index(np.array(range(len(df_full))))\n",
    "display(xgb_grid_search_results_round3)\n",
    "\n",
    "print(\"best score is 0.850563 with params {'colsample_bylevel': 0.4, 'colsample_bytree': 0.4, 'gamma': 1, 'learning_rate': 0.15, 'max_depth': 4, 'n_estimators': 30, 'subsample': 0.9}\")\n",
    "\n",
    "# save dataframe\n",
    "from datetime import datetime\n",
    "date = str(datetime.now().date()).replace(\"-\", \"\")\n",
    "xgb_grid_search_results_round3.to_csv(f\"results/xgb_results_round3_{date}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ffd07def",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_subsample</th>\n",
       "      <th>param_colsample_bylevel</th>\n",
       "      <th>param_colsample_bytree</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_gamma</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21747</th>\n",
       "      <td>4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.15</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>0.856989</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13080</th>\n",
       "      <td>3</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.15</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>0.852227</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13176</th>\n",
       "      <td>3</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.20</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>0.852202</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21720</th>\n",
       "      <td>3</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.15</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>0.852202</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23470</th>\n",
       "      <td>3</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.15</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>0.852151</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6340</th>\n",
       "      <td>2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.01</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>0.718920</td>\n",
       "      <td>27644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6339</th>\n",
       "      <td>2</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.01</td>\n",
       "      <td>30</td>\n",
       "      <td>10</td>\n",
       "      <td>0.709217</td>\n",
       "      <td>27645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6338</th>\n",
       "      <td>2</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.01</td>\n",
       "      <td>30</td>\n",
       "      <td>10</td>\n",
       "      <td>0.705991</td>\n",
       "      <td>27646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6336</th>\n",
       "      <td>2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.01</td>\n",
       "      <td>30</td>\n",
       "      <td>10</td>\n",
       "      <td>0.704403</td>\n",
       "      <td>27647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6337</th>\n",
       "      <td>2</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.01</td>\n",
       "      <td>30</td>\n",
       "      <td>10</td>\n",
       "      <td>0.702765</td>\n",
       "      <td>27648</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27648 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       param_max_depth  param_subsample  param_colsample_bylevel  \\\n",
       "21747                4              0.9                      0.4   \n",
       "13080                3              0.6                      0.2   \n",
       "13176                3              0.6                      0.2   \n",
       "21720                3              0.6                      0.4   \n",
       "23470                3              0.8                      0.4   \n",
       "...                ...              ...                      ...   \n",
       "6340                 2              0.6                      0.1   \n",
       "6339                 2              0.9                      0.1   \n",
       "6338                 2              0.8                      0.1   \n",
       "6336                 2              0.6                      0.1   \n",
       "6337                 2              0.7                      0.1   \n",
       "\n",
       "       param_colsample_bytree  param_learning_rate  param_n_estimators  \\\n",
       "21747                     0.4                 0.15                  30   \n",
       "13080                     0.9                 0.15                  30   \n",
       "13176                     0.9                 0.20                  30   \n",
       "21720                     0.4                 0.15                  30   \n",
       "23470                     0.5                 0.15                 200   \n",
       "...                       ...                  ...                 ...   \n",
       "6340                      0.9                 0.01                  50   \n",
       "6339                      0.9                 0.01                  30   \n",
       "6338                      0.9                 0.01                  30   \n",
       "6336                      0.9                 0.01                  30   \n",
       "6337                      0.9                 0.01                  30   \n",
       "\n",
       "       param_gamma  mean_test_score  rank_test_score  \n",
       "21747            1         0.856989                1  \n",
       "13080            1         0.852227                2  \n",
       "13176            1         0.852202                3  \n",
       "21720            1         0.852202                4  \n",
       "23470            1         0.852151                5  \n",
       "...            ...              ...              ...  \n",
       "6340            10         0.718920            27644  \n",
       "6339            10         0.709217            27645  \n",
       "6338            10         0.705991            27646  \n",
       "6336            10         0.704403            27647  \n",
       "6337            10         0.702765            27648  \n",
       "\n",
       "[27648 rows x 9 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# store relevant columns and sort by rank_test_score\n",
    "cols_round3 = ['param_max_depth', 'param_subsample', 'param_colsample_bylevel', 'param_colsample_bytree', 'param_learning_rate', 'param_n_estimators', 'param_gamma', 'mean_test_score', 'rank_test_score']\n",
    "xgb_results_round3_sorted = xgb_grid_search_results_round3[cols_round3]\n",
    "xgb_results_round3_sorted = xgb_results_round3_sorted.sort_values(by='rank_test_score')\n",
    "display(xgb_results_round3_sorted)\n",
    "\n",
    "# save dataframe\n",
    "from datetime import datetime\n",
    "date = str(datetime.now().date()).replace(\"-\", \"\")\n",
    "xgb_results_round3_sorted.to_csv(f\"results/xgb_results_round3_sorted_{date}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ff9a854a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.8283582089552238\n",
      "F1 Score = 0.7788461538461539\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.90      0.86       157\n",
      "           1       0.84      0.73      0.78       111\n",
      "\n",
      "    accuracy                           0.83       268\n",
      "   macro avg       0.83      0.81      0.82       268\n",
      "weighted avg       0.83      0.83      0.83       268\n",
      "\n",
      "Confusion Matrix:\n",
      "[[141  16]\n",
      " [ 30  81]]\n"
     ]
    }
   ],
   "source": [
    "# Fit and evaluate best model\n",
    "\n",
    "xgb_best = XGBClassifier(max_depth = 4, subsample = 0.9, colsample_bylevel = 0.4, colsample_bytree = 0.4, learning_rate = 0.15, n_estimators = 30, gamma = 1)\n",
    "xgb_best.fit(X_train, y_train)\n",
    "xgb_best_pred = xgb_best.predict(X_test)\n",
    "\n",
    "xgb_best_acc = accuracy_score(y_test, xgb_best_pred)\n",
    "print(\"Accuracy =\", xgb_best_acc) #0.8283582089552238\n",
    "\n",
    "xgb_best_f1 = f1_score(y_test, xgb_best_pred)\n",
    "print(\"F1 Score =\", xgb_best_f1) #0.7788461538461539\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, xgb_best_pred))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, xgb_best_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "077c8219",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.8395522388059702\n",
      "F1 Score = 0.7922705314009663\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.91      0.87       157\n",
      "           1       0.85      0.74      0.79       111\n",
      "\n",
      "    accuracy                           0.84       268\n",
      "   macro avg       0.84      0.82      0.83       268\n",
      "weighted avg       0.84      0.84      0.84       268\n",
      "\n",
      "Confusion Matrix:\n",
      "[[143  14]\n",
      " [ 29  82]]\n"
     ]
    }
   ],
   "source": [
    "# Fit and evaluate second best model with n_estimators=20\n",
    "\n",
    "xgb_best = XGBClassifier(max_depth = 3, subsample = 0.6, colsample_bylevel = 0.2, colsample_bytree = 0.9, learning_rate = 0.15, n_estimators = 20, gamma = 1)\n",
    "xgb_best.fit(X_train, y_train)\n",
    "xgb_best_pred = xgb_best.predict(X_test)\n",
    "\n",
    "xgb_best_acc = accuracy_score(y_test, xgb_best_pred)\n",
    "print(\"Accuracy =\", xgb_best_acc) #0.8395522388059702\n",
    "\n",
    "xgb_best_f1 = f1_score(y_test, xgb_best_pred)\n",
    "print(\"F1 Score =\", xgb_best_f1) #0.7922705314009663\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, xgb_best_pred))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, xgb_best_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4514dfe0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d157f690",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ccfb2ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b4d25208",
   "metadata": {},
   "source": [
    "#### Fourth Attempt\n",
    "We perform a third hyper parameter tuning, adjusting the parameter grid according to the results of round 3. We use the following parameters and values:  \n",
    "\n",
    "{'max_depth': [2,3,4]  \n",
    ", 'subsample': [0.6, 0.8, 0.9]  \n",
    ", 'gamma': [0, 0.5, 1]  \n",
    ", 'colsample_bytree': [0.4, 0.5, 0.9]  \n",
    ", 'colsample_bylevel': [0.2, 0.3, 0.4]  \n",
    ", 'learning_rate': [0.05 0.1, 0.15, 0.2]  \n",
    ", 'n_estimators': [10, 20, 30, 40, 50]}\n",
    "\n",
    "The best hyper parameter setting results to be xxx which leads to an accuracy of xxx% and a f1 score of xxx% on the test data (after training the classifier on the whole train data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "46b05a84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_colsample_bylevel</th>\n",
       "      <th>param_colsample_bytree</th>\n",
       "      <th>param_gamma</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>...</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.021696</td>\n",
       "      <td>0.004852</td>\n",
       "      <td>0.009495</td>\n",
       "      <td>0.002555</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.661290</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.661290</td>\n",
       "      <td>0.661290</td>\n",
       "      <td>0.661290</td>\n",
       "      <td>0.720430</td>\n",
       "      <td>0.052226</td>\n",
       "      <td>4858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.023734</td>\n",
       "      <td>0.003344</td>\n",
       "      <td>0.010269</td>\n",
       "      <td>0.002012</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.661290</td>\n",
       "      <td>0.629032</td>\n",
       "      <td>0.661290</td>\n",
       "      <td>0.720405</td>\n",
       "      <td>0.060569</td>\n",
       "      <td>4860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.021329</td>\n",
       "      <td>0.002649</td>\n",
       "      <td>0.009234</td>\n",
       "      <td>0.001687</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.645161</td>\n",
       "      <td>0.645161</td>\n",
       "      <td>0.661290</td>\n",
       "      <td>0.723630</td>\n",
       "      <td>0.057244</td>\n",
       "      <td>4855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.031445</td>\n",
       "      <td>0.001912</td>\n",
       "      <td>0.009800</td>\n",
       "      <td>0.001109</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>...</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.760599</td>\n",
       "      <td>0.045057</td>\n",
       "      <td>4835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.034447</td>\n",
       "      <td>0.002939</td>\n",
       "      <td>0.010506</td>\n",
       "      <td>0.001006</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>...</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.760625</td>\n",
       "      <td>0.047805</td>\n",
       "      <td>4834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4855</th>\n",
       "      <td>0.039993</td>\n",
       "      <td>0.000829</td>\n",
       "      <td>0.007979</td>\n",
       "      <td>0.000446</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.20</td>\n",
       "      <td>4</td>\n",
       "      <td>40</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.887097</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.850589</td>\n",
       "      <td>0.041824</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4856</th>\n",
       "      <td>0.057798</td>\n",
       "      <td>0.044078</td>\n",
       "      <td>0.008179</td>\n",
       "      <td>0.002352</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.20</td>\n",
       "      <td>4</td>\n",
       "      <td>40</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.823349</td>\n",
       "      <td>0.036404</td>\n",
       "      <td>3249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4857</th>\n",
       "      <td>0.065325</td>\n",
       "      <td>0.017959</td>\n",
       "      <td>0.008279</td>\n",
       "      <td>0.000779</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.20</td>\n",
       "      <td>4</td>\n",
       "      <td>50</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.834434</td>\n",
       "      <td>0.055885</td>\n",
       "      <td>1740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4858</th>\n",
       "      <td>0.067819</td>\n",
       "      <td>0.006180</td>\n",
       "      <td>0.008378</td>\n",
       "      <td>0.001196</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.20</td>\n",
       "      <td>4</td>\n",
       "      <td>50</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.837737</td>\n",
       "      <td>0.042732</td>\n",
       "      <td>1033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4859</th>\n",
       "      <td>0.055651</td>\n",
       "      <td>0.002176</td>\n",
       "      <td>0.007880</td>\n",
       "      <td>0.001042</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.20</td>\n",
       "      <td>4</td>\n",
       "      <td>50</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.828111</td>\n",
       "      <td>0.042532</td>\n",
       "      <td>2692</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4860 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0          0.021696      0.004852         0.009495        0.002555   \n",
       "1          0.023734      0.003344         0.010269        0.002012   \n",
       "2          0.021329      0.002649         0.009234        0.001687   \n",
       "3          0.031445      0.001912         0.009800        0.001109   \n",
       "4          0.034447      0.002939         0.010506        0.001006   \n",
       "...             ...           ...              ...             ...   \n",
       "4855       0.039993      0.000829         0.007979        0.000446   \n",
       "4856       0.057798      0.044078         0.008179        0.002352   \n",
       "4857       0.065325      0.017959         0.008279        0.000779   \n",
       "4858       0.067819      0.006180         0.008378        0.001196   \n",
       "4859       0.055651      0.002176         0.007880        0.001042   \n",
       "\n",
       "      param_colsample_bylevel  param_colsample_bytree  param_gamma  \\\n",
       "0                         0.2                     0.4          0.0   \n",
       "1                         0.2                     0.4          0.0   \n",
       "2                         0.2                     0.4          0.0   \n",
       "3                         0.2                     0.4          0.0   \n",
       "4                         0.2                     0.4          0.0   \n",
       "...                       ...                     ...          ...   \n",
       "4855                      0.4                     0.9          1.0   \n",
       "4856                      0.4                     0.9          1.0   \n",
       "4857                      0.4                     0.9          1.0   \n",
       "4858                      0.4                     0.9          1.0   \n",
       "4859                      0.4                     0.9          1.0   \n",
       "\n",
       "      param_learning_rate  param_max_depth  param_n_estimators  ...  \\\n",
       "0                    0.05                2                  10  ...   \n",
       "1                    0.05                2                  10  ...   \n",
       "2                    0.05                2                  10  ...   \n",
       "3                    0.05                2                  20  ...   \n",
       "4                    0.05                2                  20  ...   \n",
       "...                   ...              ...                 ...  ...   \n",
       "4855                 0.20                4                  40  ...   \n",
       "4856                 0.20                4                  40  ...   \n",
       "4857                 0.20                4                  50  ...   \n",
       "4858                 0.20                4                  50  ...   \n",
       "4859                 0.20                4                  50  ...   \n",
       "\n",
       "      split3_test_score split4_test_score  split5_test_score  \\\n",
       "0              0.741935          0.661290           0.758065   \n",
       "1              0.774194          0.677419           0.758065   \n",
       "2              0.741935          0.709677           0.774194   \n",
       "3              0.774194          0.741935           0.790323   \n",
       "4              0.806452          0.725806           0.790323   \n",
       "...                 ...               ...                ...   \n",
       "4855           0.870968          0.822581           0.854839   \n",
       "4856           0.854839          0.822581           0.806452   \n",
       "4857           0.838710          0.822581           0.790323   \n",
       "4858           0.838710          0.822581           0.822581   \n",
       "4859           0.870968          0.822581           0.790323   \n",
       "\n",
       "      split6_test_score  split7_test_score  split8_test_score  \\\n",
       "0              0.725806           0.661290           0.661290   \n",
       "1              0.693548           0.661290           0.629032   \n",
       "2              0.709677           0.645161           0.645161   \n",
       "3              0.758065           0.693548           0.709677   \n",
       "4              0.774194           0.693548           0.693548   \n",
       "...                 ...                ...                ...   \n",
       "4855           0.887097           0.838710           0.741935   \n",
       "4856           0.854839           0.822581           0.725806   \n",
       "4857           0.854839           0.838710           0.693548   \n",
       "4858           0.870968           0.838710           0.725806   \n",
       "4859           0.854839           0.806452           0.725806   \n",
       "\n",
       "      split9_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0              0.661290         0.720430        0.052226             4858  \n",
       "1              0.661290         0.720405        0.060569             4860  \n",
       "2              0.661290         0.723630        0.057244             4855  \n",
       "3              0.709677         0.760599        0.045057             4835  \n",
       "4              0.709677         0.760625        0.047805             4834  \n",
       "...                 ...              ...             ...              ...  \n",
       "4855           0.854839         0.850589        0.041824               18  \n",
       "4856           0.822581         0.823349        0.036404             3249  \n",
       "4857           0.854839         0.834434        0.055885             1740  \n",
       "4858           0.854839         0.837737        0.042732             1033  \n",
       "4859           0.838710         0.828111        0.042532             2692  \n",
       "\n",
       "[4860 rows x 25 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score is 0.856989 with params {'colsample_bylevel': 0.4, 'colsample_bytree': 0.4, 'gamma': 1, 'learning_rate': 0.15, 'max_depth': 4, 'n_estimators': 30, 'subsample': 0.9}\n"
     ]
    }
   ],
   "source": [
    "# read single parts of round 3, concatenate and update index and rank_test_score\n",
    "\n",
    "df2 = pd.read_csv(\"data\\\\xgb_results_full_2_learning=0.05_r3_20221124.csv\")\n",
    "df2.drop(df2.columns[0], axis=1, inplace=True)\n",
    "\n",
    "df4 = pd.read_csv(\"data\\\\xgb_results_full_4_learning=0.1_r3_20221124.csv\")\n",
    "df4.drop(df4.columns[0], axis=1, inplace=True)\n",
    "\n",
    "df5 = pd.read_csv(\"data\\\\xgb_results_full_5_learning=0.15_r3_20221124.csv\")\n",
    "df5.drop(df5.columns[0], axis=1, inplace=True)\n",
    "\n",
    "df6 = pd.read_csv(\"data\\\\xgb_results_full_6_learning=0.2_r3_20221124.csv\")\n",
    "df6.drop(df6.columns[0], axis=1, inplace=True)\n",
    "\n",
    "df_full = pd.concat([df2,df4,df5,df6])\n",
    "\n",
    "#assign correct rank\n",
    "df_full = df_full.sort_values(by='mean_test_score', ascending=False)\n",
    "df_full['rank_test_score'] = range(1, len(df_full)+1)\n",
    "\n",
    "#get correct order and set new index\n",
    "df_full = df_full.sort_values(by=['param_colsample_bylevel', 'param_colsample_bytree', 'param_gamma', 'param_learning_rate', 'param_max_depth', 'param_n_estimators', 'param_subsample'])\n",
    "xgb_grid_search_results_round4 = df_full.set_index(np.array(range(len(df_full))))\n",
    "display(xgb_grid_search_results_round4)\n",
    "\n",
    "print(\"best score is 0.856989 with params {'colsample_bylevel': 0.4, 'colsample_bytree': 0.4, 'gamma': 1, 'learning_rate': 0.15, 'max_depth': 4, 'n_estimators': 30, 'subsample': 0.9}\")\n",
    "\n",
    "# save dataframe\n",
    "from datetime import datetime\n",
    "date = str(datetime.now().date()).replace(\"-\", \"\")\n",
    "xgb_grid_search_results_round4.to_csv(f\"results/xgb_results_round4_{date}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "db0eebb7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "expression expected after dictionary key and ':' (2098851133.py, line 12)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn [54], line 12\u001b[1;36m\u001b[0m\n\u001b[1;33m    , 'learning_rate': [0.05 0.1, 0.15, 0.2]\u001b[0m\n\u001b[1;37m                     ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m expression expected after dictionary key and ':'\n"
     ]
    }
   ],
   "source": [
    "# Third Attempt\n",
    "\n",
    "random.seed(10)\n",
    "\n",
    "xgb = XGBClassifier()\n",
    "\n",
    "xgb_parameters = {'max_depth': [2,3,4]\n",
    "                   , 'subsample': [0.6, 0.8, 0.9]\n",
    "                   , 'gamma': [0, 0.5, 1]\n",
    "                   , 'colsample_bytree': [0.4, 0.5, 0.9]\n",
    "                   , 'colsample_bylevel': [0.2, 0.3, 0.4]\n",
    "                   , 'learning_rate': [0.05, 0.1, 0.15, 0.2]\n",
    "                   , 'n_estimators': [10, 20, 30, 40, 50]}\n",
    "\n",
    "stratified_10_fold_cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "xgb_grid_search = GridSearchCV(xgb, xgb_parameters, scoring='accuracy', cv=stratified_10_fold_cv)\n",
    "\n",
    "xgb_grid_search.fit(X_train, y_train)\n",
    "\n",
    "xgb_grid_search_results_round4 = pd.DataFrame(xgb_grid_search.cv_results_)\n",
    "display(xgb_grid_search_results_round4)\n",
    "\n",
    "# print the best parameter setting\n",
    "print(\"best score is {} with params {}\".format(xgb_grid_search.best_score_, xgb_grid_search.best_params_))\n",
    "#best score is 0.856989 with params {'colsample_bylevel': 0.4, 'colsample_bytree': 0.4, 'gamma': 1, 'learning_rate': 0.15, 'max_depth': 4, 'n_estimators': 30, 'subsample': 0.9}\n",
    "\n",
    "# save dataframe\n",
    "from datetime import datetime\n",
    "date = str(datetime.now().date()).replace(\"-\", \"\")\n",
    "xgb_grid_search_results_round4.to_csv(f\"results/xgb_results_round4_{date}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ecd39336",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_subsample</th>\n",
       "      <th>param_colsample_bylevel</th>\n",
       "      <th>param_colsample_bytree</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_gamma</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3728</th>\n",
       "      <td>4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.15</td>\n",
       "      <td>30</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.856989</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3714</th>\n",
       "      <td>3</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.15</td>\n",
       "      <td>40</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.853840</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1401</th>\n",
       "      <td>2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.20</td>\n",
       "      <td>30</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.852253</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1551</th>\n",
       "      <td>3</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.15</td>\n",
       "      <td>30</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.852227</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1596</th>\n",
       "      <td>3</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.20</td>\n",
       "      <td>30</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.852202</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.05</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.722043</td>\n",
       "      <td>4856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.05</td>\n",
       "      <td>10</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.720430</td>\n",
       "      <td>4857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.05</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.720430</td>\n",
       "      <td>4858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>2</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.05</td>\n",
       "      <td>10</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.720405</td>\n",
       "      <td>4859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.05</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.720405</td>\n",
       "      <td>4860</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4860 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      param_max_depth  param_subsample  param_colsample_bylevel  \\\n",
       "3728                4              0.9                      0.4   \n",
       "3714                3              0.6                      0.4   \n",
       "1401                2              0.6                      0.2   \n",
       "1551                3              0.6                      0.2   \n",
       "1596                3              0.6                      0.2   \n",
       "...               ...              ...                      ...   \n",
       "360                 2              0.6                      0.2   \n",
       "180                 2              0.6                      0.2   \n",
       "0                   2              0.6                      0.2   \n",
       "181                 2              0.8                      0.2   \n",
       "1                   2              0.8                      0.2   \n",
       "\n",
       "      param_colsample_bytree  param_learning_rate  param_n_estimators  \\\n",
       "3728                     0.4                 0.15                  30   \n",
       "3714                     0.4                 0.15                  40   \n",
       "1401                     0.9                 0.20                  30   \n",
       "1551                     0.9                 0.15                  30   \n",
       "1596                     0.9                 0.20                  30   \n",
       "...                      ...                  ...                 ...   \n",
       "360                      0.4                 0.05                  10   \n",
       "180                      0.4                 0.05                  10   \n",
       "0                        0.4                 0.05                  10   \n",
       "181                      0.4                 0.05                  10   \n",
       "1                        0.4                 0.05                  10   \n",
       "\n",
       "      param_gamma  mean_test_score  rank_test_score  \n",
       "3728          1.0         0.856989                1  \n",
       "3714          1.0         0.853840                2  \n",
       "1401          0.5         0.852253                3  \n",
       "1551          1.0         0.852227                4  \n",
       "1596          1.0         0.852202                5  \n",
       "...           ...              ...              ...  \n",
       "360           1.0         0.722043             4856  \n",
       "180           0.5         0.720430             4857  \n",
       "0             0.0         0.720430             4858  \n",
       "181           0.5         0.720405             4859  \n",
       "1             0.0         0.720405             4860  \n",
       "\n",
       "[4860 rows x 9 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# store relevant columns and sort by rank_test_score\n",
    "cols_round4 = ['param_max_depth', 'param_subsample', 'param_colsample_bylevel', 'param_colsample_bytree', 'param_learning_rate', 'param_n_estimators', 'param_gamma', 'mean_test_score', 'rank_test_score']\n",
    "xgb_results_round4_sorted = xgb_grid_search_results_round4[cols_round4]\n",
    "xgb_results_round4_sorted = xgb_results_round4_sorted.sort_values(by='rank_test_score')\n",
    "display(xgb_results_round4_sorted)\n",
    "\n",
    "# save dataframe\n",
    "from datetime import datetime\n",
    "date = str(datetime.now().date()).replace(\"-\", \"\")\n",
    "xgb_results_round4_sorted.to_csv(f\"results/xgb_results_round4_sorted_{date}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4deb5e3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.8283582089552238\n",
      "F1 Score = 0.7788461538461539\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.90      0.86       157\n",
      "           1       0.84      0.73      0.78       111\n",
      "\n",
      "    accuracy                           0.83       268\n",
      "   macro avg       0.83      0.81      0.82       268\n",
      "weighted avg       0.83      0.83      0.83       268\n",
      "\n",
      "Confusion Matrix:\n",
      "[[141  16]\n",
      " [ 30  81]]\n"
     ]
    }
   ],
   "source": [
    "# Fit and evaluate best model\n",
    "\n",
    "xgb_best = XGBClassifier(max_depth = 4, subsample = 0.9, colsample_bylevel = 0.4, colsample_bytree = 0.4, learning_rate = 0.15, n_estimators = 30, gamma = 1)\n",
    "xgb_best.fit(X_train, y_train)\n",
    "xgb_best_pred = xgb_best.predict(X_test)\n",
    "\n",
    "xgb_best_acc = accuracy_score(y_test, xgb_best_pred)\n",
    "print(\"Accuracy =\", xgb_best_acc) #0.8283582089552238\n",
    "\n",
    "xgb_best_f1 = f1_score(y_test, xgb_best_pred)\n",
    "print(\"F1 Score =\", xgb_best_f1) #0.7788461538461539\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, xgb_best_pred))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, xgb_best_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a1510f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc5a5c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "41362cd1",
   "metadata": {},
   "source": [
    "#### ausführlich"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "74ca2db4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_colsample_bylevel</th>\n",
       "      <th>param_colsample_bytree</th>\n",
       "      <th>param_gamma</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>...</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.021696</td>\n",
       "      <td>0.004852</td>\n",
       "      <td>0.009495</td>\n",
       "      <td>0.002555</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.661290</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.661290</td>\n",
       "      <td>0.661290</td>\n",
       "      <td>0.661290</td>\n",
       "      <td>0.720430</td>\n",
       "      <td>0.052226</td>\n",
       "      <td>1212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.023734</td>\n",
       "      <td>0.003344</td>\n",
       "      <td>0.010269</td>\n",
       "      <td>0.002012</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.661290</td>\n",
       "      <td>0.629032</td>\n",
       "      <td>0.661290</td>\n",
       "      <td>0.720405</td>\n",
       "      <td>0.060569</td>\n",
       "      <td>1214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.021329</td>\n",
       "      <td>0.002649</td>\n",
       "      <td>0.009234</td>\n",
       "      <td>0.001687</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.645161</td>\n",
       "      <td>0.645161</td>\n",
       "      <td>0.661290</td>\n",
       "      <td>0.723630</td>\n",
       "      <td>0.057244</td>\n",
       "      <td>1208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.031445</td>\n",
       "      <td>0.001912</td>\n",
       "      <td>0.009800</td>\n",
       "      <td>0.001109</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>...</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.760599</td>\n",
       "      <td>0.045057</td>\n",
       "      <td>1204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.034447</td>\n",
       "      <td>0.002939</td>\n",
       "      <td>0.010506</td>\n",
       "      <td>0.001006</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>...</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.760625</td>\n",
       "      <td>0.047805</td>\n",
       "      <td>1203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1210</th>\n",
       "      <td>0.064949</td>\n",
       "      <td>0.005643</td>\n",
       "      <td>0.010790</td>\n",
       "      <td>0.002114</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>4</td>\n",
       "      <td>40</td>\n",
       "      <td>...</td>\n",
       "      <td>0.903226</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.829647</td>\n",
       "      <td>0.056432</td>\n",
       "      <td>337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1211</th>\n",
       "      <td>0.059376</td>\n",
       "      <td>0.006451</td>\n",
       "      <td>0.009179</td>\n",
       "      <td>0.002418</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>4</td>\n",
       "      <td>40</td>\n",
       "      <td>...</td>\n",
       "      <td>0.887097</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.824936</td>\n",
       "      <td>0.053006</td>\n",
       "      <td>496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1212</th>\n",
       "      <td>0.072250</td>\n",
       "      <td>0.006942</td>\n",
       "      <td>0.010528</td>\n",
       "      <td>0.001857</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>4</td>\n",
       "      <td>50</td>\n",
       "      <td>...</td>\n",
       "      <td>0.887097</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.834511</td>\n",
       "      <td>0.054857</td>\n",
       "      <td>156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1213</th>\n",
       "      <td>0.075180</td>\n",
       "      <td>0.004525</td>\n",
       "      <td>0.011624</td>\n",
       "      <td>0.001827</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>4</td>\n",
       "      <td>50</td>\n",
       "      <td>...</td>\n",
       "      <td>0.903226</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.837686</td>\n",
       "      <td>0.053661</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1214</th>\n",
       "      <td>0.071844</td>\n",
       "      <td>0.005366</td>\n",
       "      <td>0.010349</td>\n",
       "      <td>0.001572</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>4</td>\n",
       "      <td>50</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.821633</td>\n",
       "      <td>0.045313</td>\n",
       "      <td>643</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1215 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0          0.021696      0.004852         0.009495        0.002555   \n",
       "1          0.023734      0.003344         0.010269        0.002012   \n",
       "2          0.021329      0.002649         0.009234        0.001687   \n",
       "3          0.031445      0.001912         0.009800        0.001109   \n",
       "4          0.034447      0.002939         0.010506        0.001006   \n",
       "...             ...           ...              ...             ...   \n",
       "1210       0.064949      0.005643         0.010790        0.002114   \n",
       "1211       0.059376      0.006451         0.009179        0.002418   \n",
       "1212       0.072250      0.006942         0.010528        0.001857   \n",
       "1213       0.075180      0.004525         0.011624        0.001827   \n",
       "1214       0.071844      0.005366         0.010349        0.001572   \n",
       "\n",
       "      param_colsample_bylevel  param_colsample_bytree  param_gamma  \\\n",
       "0                         0.2                     0.4          0.0   \n",
       "1                         0.2                     0.4          0.0   \n",
       "2                         0.2                     0.4          0.0   \n",
       "3                         0.2                     0.4          0.0   \n",
       "4                         0.2                     0.4          0.0   \n",
       "...                       ...                     ...          ...   \n",
       "1210                      0.4                     0.9          1.0   \n",
       "1211                      0.4                     0.9          1.0   \n",
       "1212                      0.4                     0.9          1.0   \n",
       "1213                      0.4                     0.9          1.0   \n",
       "1214                      0.4                     0.9          1.0   \n",
       "\n",
       "      param_learning_rate  param_max_depth  param_n_estimators  ...  \\\n",
       "0                    0.05                2                  10  ...   \n",
       "1                    0.05                2                  10  ...   \n",
       "2                    0.05                2                  10  ...   \n",
       "3                    0.05                2                  20  ...   \n",
       "4                    0.05                2                  20  ...   \n",
       "...                   ...              ...                 ...  ...   \n",
       "1210                 0.05                4                  40  ...   \n",
       "1211                 0.05                4                  40  ...   \n",
       "1212                 0.05                4                  50  ...   \n",
       "1213                 0.05                4                  50  ...   \n",
       "1214                 0.05                4                  50  ...   \n",
       "\n",
       "      split3_test_score split4_test_score  split5_test_score  \\\n",
       "0              0.741935          0.661290           0.758065   \n",
       "1              0.774194          0.677419           0.758065   \n",
       "2              0.741935          0.709677           0.774194   \n",
       "3              0.774194          0.741935           0.790323   \n",
       "4              0.806452          0.725806           0.790323   \n",
       "...                 ...               ...                ...   \n",
       "1210           0.903226          0.806452           0.822581   \n",
       "1211           0.887097          0.822581           0.870968   \n",
       "1212           0.887097          0.822581           0.870968   \n",
       "1213           0.903226          0.822581           0.838710   \n",
       "1214           0.838710          0.822581           0.822581   \n",
       "\n",
       "      split6_test_score  split7_test_score  split8_test_score  \\\n",
       "0              0.725806           0.661290           0.661290   \n",
       "1              0.693548           0.661290           0.629032   \n",
       "2              0.709677           0.645161           0.645161   \n",
       "3              0.758065           0.693548           0.709677   \n",
       "4              0.774194           0.693548           0.693548   \n",
       "...                 ...                ...                ...   \n",
       "1210           0.822581           0.790323           0.693548   \n",
       "1211           0.822581           0.774194           0.693548   \n",
       "1212           0.822581           0.790323           0.693548   \n",
       "1213           0.822581           0.790323           0.709677   \n",
       "1214           0.822581           0.774194           0.709677   \n",
       "\n",
       "      split9_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0              0.661290         0.720430        0.052226             1212  \n",
       "1              0.661290         0.720405        0.060569             1214  \n",
       "2              0.661290         0.723630        0.057244             1208  \n",
       "3              0.709677         0.760599        0.045057             1204  \n",
       "4              0.709677         0.760625        0.047805             1203  \n",
       "...                 ...              ...             ...              ...  \n",
       "1210           0.838710         0.829647        0.056432              337  \n",
       "1211           0.838710         0.824936        0.053006              496  \n",
       "1212           0.854839         0.834511        0.054857              156  \n",
       "1213           0.854839         0.837686        0.053661               90  \n",
       "1214           0.838710         0.821633        0.045313              643  \n",
       "\n",
       "[1215 rows x 25 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score is 0.8457501280081926 with params {'colsample_bylevel': 0.3, 'colsample_bytree': 0.9, 'gamma': 0.5, 'learning_rate': 0.05, 'max_depth': 4, 'n_estimators': 40, 'subsample': 0.6}\n"
     ]
    }
   ],
   "source": [
    "df2 = pd.read_csv(\"data\\\\xgb_results_full_2_learning=0.05_r3_20221124.csv\")\n",
    "df2.drop(df2.columns[0], axis=1, inplace=True)\n",
    "display(df2)\n",
    "print(\"best score is 0.8457501280081926 with params {'colsample_bylevel': 0.3, 'colsample_bytree': 0.9, 'gamma': 0.5, 'learning_rate': 0.05, 'max_depth': 4, 'n_estimators': 40, 'subsample': 0.6}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "55456590",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_colsample_bylevel</th>\n",
       "      <th>param_colsample_bytree</th>\n",
       "      <th>param_gamma</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>...</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.021696</td>\n",
       "      <td>0.004852</td>\n",
       "      <td>0.009495</td>\n",
       "      <td>0.002555</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.661290</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.661290</td>\n",
       "      <td>0.661290</td>\n",
       "      <td>0.661290</td>\n",
       "      <td>0.720430</td>\n",
       "      <td>0.052226</td>\n",
       "      <td>1212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.023734</td>\n",
       "      <td>0.003344</td>\n",
       "      <td>0.010269</td>\n",
       "      <td>0.002012</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.661290</td>\n",
       "      <td>0.629032</td>\n",
       "      <td>0.661290</td>\n",
       "      <td>0.720405</td>\n",
       "      <td>0.060569</td>\n",
       "      <td>1214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.021329</td>\n",
       "      <td>0.002649</td>\n",
       "      <td>0.009234</td>\n",
       "      <td>0.001687</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.645161</td>\n",
       "      <td>0.645161</td>\n",
       "      <td>0.661290</td>\n",
       "      <td>0.723630</td>\n",
       "      <td>0.057244</td>\n",
       "      <td>1208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.031445</td>\n",
       "      <td>0.001912</td>\n",
       "      <td>0.009800</td>\n",
       "      <td>0.001109</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>...</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.760599</td>\n",
       "      <td>0.045057</td>\n",
       "      <td>1204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.034447</td>\n",
       "      <td>0.002939</td>\n",
       "      <td>0.010506</td>\n",
       "      <td>0.001006</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>...</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.760625</td>\n",
       "      <td>0.047805</td>\n",
       "      <td>1203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1210</th>\n",
       "      <td>0.064949</td>\n",
       "      <td>0.005643</td>\n",
       "      <td>0.010790</td>\n",
       "      <td>0.002114</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.05</td>\n",
       "      <td>4</td>\n",
       "      <td>40</td>\n",
       "      <td>...</td>\n",
       "      <td>0.903226</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.829647</td>\n",
       "      <td>0.056432</td>\n",
       "      <td>337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1211</th>\n",
       "      <td>0.059376</td>\n",
       "      <td>0.006451</td>\n",
       "      <td>0.009179</td>\n",
       "      <td>0.002418</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.05</td>\n",
       "      <td>4</td>\n",
       "      <td>40</td>\n",
       "      <td>...</td>\n",
       "      <td>0.887097</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.824936</td>\n",
       "      <td>0.053006</td>\n",
       "      <td>496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1212</th>\n",
       "      <td>0.072250</td>\n",
       "      <td>0.006942</td>\n",
       "      <td>0.010528</td>\n",
       "      <td>0.001857</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.05</td>\n",
       "      <td>4</td>\n",
       "      <td>50</td>\n",
       "      <td>...</td>\n",
       "      <td>0.887097</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.834511</td>\n",
       "      <td>0.054857</td>\n",
       "      <td>156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1213</th>\n",
       "      <td>0.075180</td>\n",
       "      <td>0.004525</td>\n",
       "      <td>0.011624</td>\n",
       "      <td>0.001827</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.05</td>\n",
       "      <td>4</td>\n",
       "      <td>50</td>\n",
       "      <td>...</td>\n",
       "      <td>0.903226</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.837686</td>\n",
       "      <td>0.053661</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1214</th>\n",
       "      <td>0.071844</td>\n",
       "      <td>0.005366</td>\n",
       "      <td>0.010349</td>\n",
       "      <td>0.001572</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.05</td>\n",
       "      <td>4</td>\n",
       "      <td>50</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.821633</td>\n",
       "      <td>0.045313</td>\n",
       "      <td>643</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1215 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0          0.021696      0.004852         0.009495        0.002555   \n",
       "1          0.023734      0.003344         0.010269        0.002012   \n",
       "2          0.021329      0.002649         0.009234        0.001687   \n",
       "3          0.031445      0.001912         0.009800        0.001109   \n",
       "4          0.034447      0.002939         0.010506        0.001006   \n",
       "...             ...           ...              ...             ...   \n",
       "1210       0.064949      0.005643         0.010790        0.002114   \n",
       "1211       0.059376      0.006451         0.009179        0.002418   \n",
       "1212       0.072250      0.006942         0.010528        0.001857   \n",
       "1213       0.075180      0.004525         0.011624        0.001827   \n",
       "1214       0.071844      0.005366         0.010349        0.001572   \n",
       "\n",
       "     param_colsample_bylevel param_colsample_bytree param_gamma  \\\n",
       "0                        0.2                    0.4           0   \n",
       "1                        0.2                    0.4           0   \n",
       "2                        0.2                    0.4           0   \n",
       "3                        0.2                    0.4           0   \n",
       "4                        0.2                    0.4           0   \n",
       "...                      ...                    ...         ...   \n",
       "1210                     0.4                    0.9           1   \n",
       "1211                     0.4                    0.9           1   \n",
       "1212                     0.4                    0.9           1   \n",
       "1213                     0.4                    0.9           1   \n",
       "1214                     0.4                    0.9           1   \n",
       "\n",
       "     param_learning_rate param_max_depth param_n_estimators  ...  \\\n",
       "0                   0.05               2                 10  ...   \n",
       "1                   0.05               2                 10  ...   \n",
       "2                   0.05               2                 10  ...   \n",
       "3                   0.05               2                 20  ...   \n",
       "4                   0.05               2                 20  ...   \n",
       "...                  ...             ...                ...  ...   \n",
       "1210                0.05               4                 40  ...   \n",
       "1211                0.05               4                 40  ...   \n",
       "1212                0.05               4                 50  ...   \n",
       "1213                0.05               4                 50  ...   \n",
       "1214                0.05               4                 50  ...   \n",
       "\n",
       "     split3_test_score split4_test_score  split5_test_score  \\\n",
       "0             0.741935          0.661290           0.758065   \n",
       "1             0.774194          0.677419           0.758065   \n",
       "2             0.741935          0.709677           0.774194   \n",
       "3             0.774194          0.741935           0.790323   \n",
       "4             0.806452          0.725806           0.790323   \n",
       "...                ...               ...                ...   \n",
       "1210          0.903226          0.806452           0.822581   \n",
       "1211          0.887097          0.822581           0.870968   \n",
       "1212          0.887097          0.822581           0.870968   \n",
       "1213          0.903226          0.822581           0.838710   \n",
       "1214          0.838710          0.822581           0.822581   \n",
       "\n",
       "      split6_test_score  split7_test_score  split8_test_score  \\\n",
       "0              0.725806           0.661290           0.661290   \n",
       "1              0.693548           0.661290           0.629032   \n",
       "2              0.709677           0.645161           0.645161   \n",
       "3              0.758065           0.693548           0.709677   \n",
       "4              0.774194           0.693548           0.693548   \n",
       "...                 ...                ...                ...   \n",
       "1210           0.822581           0.790323           0.693548   \n",
       "1211           0.822581           0.774194           0.693548   \n",
       "1212           0.822581           0.790323           0.693548   \n",
       "1213           0.822581           0.790323           0.709677   \n",
       "1214           0.822581           0.774194           0.709677   \n",
       "\n",
       "      split9_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0              0.661290         0.720430        0.052226             1212  \n",
       "1              0.661290         0.720405        0.060569             1214  \n",
       "2              0.661290         0.723630        0.057244             1208  \n",
       "3              0.709677         0.760599        0.045057             1204  \n",
       "4              0.709677         0.760625        0.047805             1203  \n",
       "...                 ...              ...             ...              ...  \n",
       "1210           0.838710         0.829647        0.056432              337  \n",
       "1211           0.838710         0.824936        0.053006              496  \n",
       "1212           0.854839         0.834511        0.054857              156  \n",
       "1213           0.854839         0.837686        0.053661               90  \n",
       "1214           0.838710         0.821633        0.045313              643  \n",
       "\n",
       "[1215 rows x 25 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score is 0.8457501280081926 with params {'colsample_bylevel': 0.3, 'colsample_bytree': 0.9, 'gamma': 0.5, 'learning_rate': 0.05, 'max_depth': 4, 'n_estimators': 40, 'subsample': 0.6}\n"
     ]
    }
   ],
   "source": [
    "# Full Tuning - Part 2\n",
    "random.seed(10)\n",
    "\n",
    "xgb = XGBClassifier()\n",
    "\n",
    "xgb_parameters = {'max_depth': [2,3,4]\n",
    "                   , 'subsample': [0.6, 0.8, 0.9]\n",
    "                   , 'gamma': [0, 0.5, 1]\n",
    "                   , 'colsample_bytree': [0.4, 0.5, 0.9]\n",
    "                   , 'colsample_bylevel': [0.2, 0.3, 0.4]\n",
    "                   , 'learning_rate': [0.05]\n",
    "                   , 'n_estimators': [10, 20, 30, 40, 50]}\n",
    "\n",
    "stratified_10_fold_cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "xgb_grid_search = GridSearchCV(xgb, xgb_parameters, scoring='accuracy', cv=stratified_10_fold_cv)\n",
    "\n",
    "xgb_grid_search.fit(X_train, y_train)\n",
    "\n",
    "xgb_grid_search_results_full_2 = pd.DataFrame(xgb_grid_search.cv_results_)\n",
    "display(xgb_grid_search_results_full_2)\n",
    "\n",
    "print(\"best score is {} with params {}\".format(xgb_grid_search.best_score_, xgb_grid_search.best_params_))\n",
    "#best score is 0.8457501280081926 with params\n",
    "#{'colsample_bylevel': 0.3, 'colsample_bytree': 0.9, 'gamma': 0.5, 'learning_rate': 0.05, 'max_depth': 4, 'n_estimators': 40, 'subsample': 0.6}\n",
    "\n",
    "# save dataframe\n",
    "from datetime import datetime\n",
    "date = str(datetime.now().date()).replace(\"-\", \"\")\n",
    "xgb_grid_search_results_full_2.to_csv(f\"results/xgb_results_full_round4_2_learning=0.05_r3_{date}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "56f26de1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_colsample_bylevel</th>\n",
       "      <th>param_colsample_bytree</th>\n",
       "      <th>param_gamma</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>...</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.023281</td>\n",
       "      <td>0.003346</td>\n",
       "      <td>0.010147</td>\n",
       "      <td>0.001151</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.645161</td>\n",
       "      <td>0.661290</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.738095</td>\n",
       "      <td>0.056816</td>\n",
       "      <td>1210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.021142</td>\n",
       "      <td>0.004710</td>\n",
       "      <td>0.008830</td>\n",
       "      <td>0.001959</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.629032</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.741321</td>\n",
       "      <td>0.059607</td>\n",
       "      <td>1207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.017339</td>\n",
       "      <td>0.001338</td>\n",
       "      <td>0.007330</td>\n",
       "      <td>0.000460</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.661290</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.734869</td>\n",
       "      <td>0.053170</td>\n",
       "      <td>1215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.029686</td>\n",
       "      <td>0.004877</td>\n",
       "      <td>0.010679</td>\n",
       "      <td>0.006277</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>...</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.776728</td>\n",
       "      <td>0.041775</td>\n",
       "      <td>1197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.028296</td>\n",
       "      <td>0.005223</td>\n",
       "      <td>0.008654</td>\n",
       "      <td>0.001540</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>...</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.778341</td>\n",
       "      <td>0.046040</td>\n",
       "      <td>1192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1210</th>\n",
       "      <td>0.046617</td>\n",
       "      <td>0.003638</td>\n",
       "      <td>0.006846</td>\n",
       "      <td>0.000652</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4</td>\n",
       "      <td>40</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.831285</td>\n",
       "      <td>0.053063</td>\n",
       "      <td>569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1211</th>\n",
       "      <td>0.046081</td>\n",
       "      <td>0.002453</td>\n",
       "      <td>0.007303</td>\n",
       "      <td>0.000902</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4</td>\n",
       "      <td>40</td>\n",
       "      <td>...</td>\n",
       "      <td>0.903226</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.834511</td>\n",
       "      <td>0.055329</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1212</th>\n",
       "      <td>0.054877</td>\n",
       "      <td>0.003162</td>\n",
       "      <td>0.007232</td>\n",
       "      <td>0.000972</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4</td>\n",
       "      <td>50</td>\n",
       "      <td>...</td>\n",
       "      <td>0.903226</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.836098</td>\n",
       "      <td>0.055697</td>\n",
       "      <td>330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1213</th>\n",
       "      <td>0.048312</td>\n",
       "      <td>0.001028</td>\n",
       "      <td>0.005916</td>\n",
       "      <td>0.000878</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4</td>\n",
       "      <td>50</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.832898</td>\n",
       "      <td>0.049449</td>\n",
       "      <td>480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1214</th>\n",
       "      <td>0.051567</td>\n",
       "      <td>0.004369</td>\n",
       "      <td>0.006275</td>\n",
       "      <td>0.001148</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4</td>\n",
       "      <td>50</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.831336</td>\n",
       "      <td>0.046681</td>\n",
       "      <td>524</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1215 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0          0.023281      0.003346         0.010147        0.001151   \n",
       "1          0.021142      0.004710         0.008830        0.001959   \n",
       "2          0.017339      0.001338         0.007330        0.000460   \n",
       "3          0.029686      0.004877         0.010679        0.006277   \n",
       "4          0.028296      0.005223         0.008654        0.001540   \n",
       "...             ...           ...              ...             ...   \n",
       "1210       0.046617      0.003638         0.006846        0.000652   \n",
       "1211       0.046081      0.002453         0.007303        0.000902   \n",
       "1212       0.054877      0.003162         0.007232        0.000972   \n",
       "1213       0.048312      0.001028         0.005916        0.000878   \n",
       "1214       0.051567      0.004369         0.006275        0.001148   \n",
       "\n",
       "      param_colsample_bylevel  param_colsample_bytree  param_gamma  \\\n",
       "0                         0.2                     0.4          0.0   \n",
       "1                         0.2                     0.4          0.0   \n",
       "2                         0.2                     0.4          0.0   \n",
       "3                         0.2                     0.4          0.0   \n",
       "4                         0.2                     0.4          0.0   \n",
       "...                       ...                     ...          ...   \n",
       "1210                      0.4                     0.9          1.0   \n",
       "1211                      0.4                     0.9          1.0   \n",
       "1212                      0.4                     0.9          1.0   \n",
       "1213                      0.4                     0.9          1.0   \n",
       "1214                      0.4                     0.9          1.0   \n",
       "\n",
       "      param_learning_rate  param_max_depth  param_n_estimators  ...  \\\n",
       "0                     0.1                2                  10  ...   \n",
       "1                     0.1                2                  10  ...   \n",
       "2                     0.1                2                  10  ...   \n",
       "3                     0.1                2                  20  ...   \n",
       "4                     0.1                2                  20  ...   \n",
       "...                   ...              ...                 ...  ...   \n",
       "1210                  0.1                4                  40  ...   \n",
       "1211                  0.1                4                  40  ...   \n",
       "1212                  0.1                4                  50  ...   \n",
       "1213                  0.1                4                  50  ...   \n",
       "1214                  0.1                4                  50  ...   \n",
       "\n",
       "      split3_test_score split4_test_score  split5_test_score  \\\n",
       "0              0.790323          0.693548           0.774194   \n",
       "1              0.806452          0.693548           0.774194   \n",
       "2              0.758065          0.693548           0.774194   \n",
       "3              0.806452          0.758065           0.806452   \n",
       "4              0.790323          0.758065           0.838710   \n",
       "...                 ...               ...                ...   \n",
       "1210           0.870968          0.822581           0.790323   \n",
       "1211           0.903226          0.822581           0.806452   \n",
       "1212           0.903226          0.806452           0.822581   \n",
       "1213           0.870968          0.838710           0.790323   \n",
       "1214           0.870968          0.838710           0.806452   \n",
       "\n",
       "      split6_test_score  split7_test_score  split8_test_score  \\\n",
       "0              0.725806           0.645161           0.661290   \n",
       "1              0.741935           0.677419           0.629032   \n",
       "2              0.725806           0.677419           0.661290   \n",
       "3              0.790323           0.693548           0.709677   \n",
       "4              0.790323           0.693548           0.709677   \n",
       "...                 ...                ...                ...   \n",
       "1210           0.838710           0.822581           0.693548   \n",
       "1211           0.854839           0.806452           0.693548   \n",
       "1212           0.838710           0.822581           0.693548   \n",
       "1213           0.822581           0.822581           0.709677   \n",
       "1214           0.870968           0.806452           0.709677   \n",
       "\n",
       "      split9_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0              0.709677         0.738095        0.056816             1210  \n",
       "1              0.709677         0.741321        0.059607             1207  \n",
       "2              0.677419         0.734869        0.053170             1215  \n",
       "3              0.774194         0.776728        0.041775             1197  \n",
       "4              0.774194         0.778341        0.046040             1192  \n",
       "...                 ...              ...             ...              ...  \n",
       "1210           0.870968         0.831285        0.053063              569  \n",
       "1211           0.854839         0.834511        0.055329              400  \n",
       "1212           0.854839         0.836098        0.055697              330  \n",
       "1213           0.870968         0.832898        0.049449              480  \n",
       "1214           0.838710         0.831336        0.046681              524  \n",
       "\n",
       "[1215 rows x 25 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score is 0.8489759344598055 with params {'colsample_bylevel': 0.2, 'colsample_bytree': 0.9, 'gamma': 1, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 40, 'subsample': 0.6}\n"
     ]
    }
   ],
   "source": [
    "df4 = pd.read_csv(\"data\\\\xgb_results_full_4_learning=0.1_r3_20221124.csv\")\n",
    "df4.drop(df4.columns[0], axis=1, inplace=True)\n",
    "display(df4)\n",
    "print(\"best score is 0.8489759344598055 with params {'colsample_bylevel': 0.2, 'colsample_bytree': 0.9, 'gamma': 1, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 40, 'subsample': 0.6}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "38267cf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_colsample_bylevel</th>\n",
       "      <th>param_colsample_bytree</th>\n",
       "      <th>param_gamma</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>...</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.023281</td>\n",
       "      <td>0.003346</td>\n",
       "      <td>0.010147</td>\n",
       "      <td>0.001151</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.645161</td>\n",
       "      <td>0.661290</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.738095</td>\n",
       "      <td>0.056816</td>\n",
       "      <td>1210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.021142</td>\n",
       "      <td>0.004710</td>\n",
       "      <td>0.008830</td>\n",
       "      <td>0.001959</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.629032</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.741321</td>\n",
       "      <td>0.059607</td>\n",
       "      <td>1207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.017339</td>\n",
       "      <td>0.001338</td>\n",
       "      <td>0.007330</td>\n",
       "      <td>0.000460</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.661290</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.734869</td>\n",
       "      <td>0.053170</td>\n",
       "      <td>1215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.029686</td>\n",
       "      <td>0.004877</td>\n",
       "      <td>0.010679</td>\n",
       "      <td>0.006277</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>...</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.776728</td>\n",
       "      <td>0.041775</td>\n",
       "      <td>1197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.028296</td>\n",
       "      <td>0.005223</td>\n",
       "      <td>0.008654</td>\n",
       "      <td>0.001540</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>...</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.778341</td>\n",
       "      <td>0.046040</td>\n",
       "      <td>1192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1210</th>\n",
       "      <td>0.046617</td>\n",
       "      <td>0.003638</td>\n",
       "      <td>0.006846</td>\n",
       "      <td>0.000652</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4</td>\n",
       "      <td>40</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.831285</td>\n",
       "      <td>0.053063</td>\n",
       "      <td>569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1211</th>\n",
       "      <td>0.046081</td>\n",
       "      <td>0.002453</td>\n",
       "      <td>0.007303</td>\n",
       "      <td>0.000902</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4</td>\n",
       "      <td>40</td>\n",
       "      <td>...</td>\n",
       "      <td>0.903226</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.834511</td>\n",
       "      <td>0.055329</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1212</th>\n",
       "      <td>0.054877</td>\n",
       "      <td>0.003162</td>\n",
       "      <td>0.007232</td>\n",
       "      <td>0.000972</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4</td>\n",
       "      <td>50</td>\n",
       "      <td>...</td>\n",
       "      <td>0.903226</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.836098</td>\n",
       "      <td>0.055697</td>\n",
       "      <td>330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1213</th>\n",
       "      <td>0.048312</td>\n",
       "      <td>0.001028</td>\n",
       "      <td>0.005916</td>\n",
       "      <td>0.000878</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4</td>\n",
       "      <td>50</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.832898</td>\n",
       "      <td>0.049449</td>\n",
       "      <td>480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1214</th>\n",
       "      <td>0.051567</td>\n",
       "      <td>0.004369</td>\n",
       "      <td>0.006275</td>\n",
       "      <td>0.001148</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4</td>\n",
       "      <td>50</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.831336</td>\n",
       "      <td>0.046681</td>\n",
       "      <td>524</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1215 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0          0.023281      0.003346         0.010147        0.001151   \n",
       "1          0.021142      0.004710         0.008830        0.001959   \n",
       "2          0.017339      0.001338         0.007330        0.000460   \n",
       "3          0.029686      0.004877         0.010679        0.006277   \n",
       "4          0.028296      0.005223         0.008654        0.001540   \n",
       "...             ...           ...              ...             ...   \n",
       "1210       0.046617      0.003638         0.006846        0.000652   \n",
       "1211       0.046081      0.002453         0.007303        0.000902   \n",
       "1212       0.054877      0.003162         0.007232        0.000972   \n",
       "1213       0.048312      0.001028         0.005916        0.000878   \n",
       "1214       0.051567      0.004369         0.006275        0.001148   \n",
       "\n",
       "     param_colsample_bylevel param_colsample_bytree param_gamma  \\\n",
       "0                        0.2                    0.4           0   \n",
       "1                        0.2                    0.4           0   \n",
       "2                        0.2                    0.4           0   \n",
       "3                        0.2                    0.4           0   \n",
       "4                        0.2                    0.4           0   \n",
       "...                      ...                    ...         ...   \n",
       "1210                     0.4                    0.9           1   \n",
       "1211                     0.4                    0.9           1   \n",
       "1212                     0.4                    0.9           1   \n",
       "1213                     0.4                    0.9           1   \n",
       "1214                     0.4                    0.9           1   \n",
       "\n",
       "     param_learning_rate param_max_depth param_n_estimators  ...  \\\n",
       "0                    0.1               2                 10  ...   \n",
       "1                    0.1               2                 10  ...   \n",
       "2                    0.1               2                 10  ...   \n",
       "3                    0.1               2                 20  ...   \n",
       "4                    0.1               2                 20  ...   \n",
       "...                  ...             ...                ...  ...   \n",
       "1210                 0.1               4                 40  ...   \n",
       "1211                 0.1               4                 40  ...   \n",
       "1212                 0.1               4                 50  ...   \n",
       "1213                 0.1               4                 50  ...   \n",
       "1214                 0.1               4                 50  ...   \n",
       "\n",
       "     split3_test_score split4_test_score  split5_test_score  \\\n",
       "0             0.790323          0.693548           0.774194   \n",
       "1             0.806452          0.693548           0.774194   \n",
       "2             0.758065          0.693548           0.774194   \n",
       "3             0.806452          0.758065           0.806452   \n",
       "4             0.790323          0.758065           0.838710   \n",
       "...                ...               ...                ...   \n",
       "1210          0.870968          0.822581           0.790323   \n",
       "1211          0.903226          0.822581           0.806452   \n",
       "1212          0.903226          0.806452           0.822581   \n",
       "1213          0.870968          0.838710           0.790323   \n",
       "1214          0.870968          0.838710           0.806452   \n",
       "\n",
       "      split6_test_score  split7_test_score  split8_test_score  \\\n",
       "0              0.725806           0.645161           0.661290   \n",
       "1              0.741935           0.677419           0.629032   \n",
       "2              0.725806           0.677419           0.661290   \n",
       "3              0.790323           0.693548           0.709677   \n",
       "4              0.790323           0.693548           0.709677   \n",
       "...                 ...                ...                ...   \n",
       "1210           0.838710           0.822581           0.693548   \n",
       "1211           0.854839           0.806452           0.693548   \n",
       "1212           0.838710           0.822581           0.693548   \n",
       "1213           0.822581           0.822581           0.709677   \n",
       "1214           0.870968           0.806452           0.709677   \n",
       "\n",
       "      split9_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0              0.709677         0.738095        0.056816             1210  \n",
       "1              0.709677         0.741321        0.059607             1207  \n",
       "2              0.677419         0.734869        0.053170             1215  \n",
       "3              0.774194         0.776728        0.041775             1197  \n",
       "4              0.774194         0.778341        0.046040             1192  \n",
       "...                 ...              ...             ...              ...  \n",
       "1210           0.870968         0.831285        0.053063              569  \n",
       "1211           0.854839         0.834511        0.055329              400  \n",
       "1212           0.854839         0.836098        0.055697              330  \n",
       "1213           0.870968         0.832898        0.049449              480  \n",
       "1214           0.838710         0.831336        0.046681              524  \n",
       "\n",
       "[1215 rows x 25 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score is 0.8489759344598055 with params {'colsample_bylevel': 0.2, 'colsample_bytree': 0.9, 'gamma': 1, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 40, 'subsample': 0.6}\n"
     ]
    }
   ],
   "source": [
    "# Full Tuning - Part 4\n",
    "random.seed(10)\n",
    "\n",
    "xgb = XGBClassifier()\n",
    "\n",
    "xgb_parameters = {'max_depth': [2,3,4]\n",
    "                   , 'subsample': [0.6, 0.8, 0.9]\n",
    "                   , 'gamma': [0, 0.5, 1]\n",
    "                   , 'colsample_bytree': [0.4, 0.5, 0.9]\n",
    "                   , 'colsample_bylevel': [0.2, 0.3, 0.4]\n",
    "                   , 'learning_rate': [0.1]\n",
    "                   , 'n_estimators': [10, 20, 30, 40, 50]}\n",
    "\n",
    "stratified_10_fold_cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "xgb_grid_search = GridSearchCV(xgb, xgb_parameters, scoring='accuracy', cv=stratified_10_fold_cv)\n",
    "\n",
    "xgb_grid_search.fit(X_train, y_train)\n",
    "\n",
    "xgb_grid_search_results_full_4 = pd.DataFrame(xgb_grid_search.cv_results_)\n",
    "display(xgb_grid_search_results_full_4)\n",
    "\n",
    "print(\"best score is {} with params {}\".format(xgb_grid_search.best_score_, xgb_grid_search.best_params_))\n",
    "#best score is 0.8489759344598055 with params\n",
    "#{'colsample_bylevel': 0.2, 'colsample_bytree': 0.9, 'gamma': 1, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 40, 'subsample': 0.6}\n",
    "\n",
    "# save dataframe\n",
    "from datetime import datetime\n",
    "date = str(datetime.now().date()).replace(\"-\", \"\")\n",
    "xgb_grid_search_results_full_4.to_csv(f\"results/xgb_results_full_round4_4_learning=0.1_r3_{date}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4039a71d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_colsample_bylevel</th>\n",
       "      <th>param_colsample_bytree</th>\n",
       "      <th>param_gamma</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>...</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.016554</td>\n",
       "      <td>0.002537</td>\n",
       "      <td>0.007182</td>\n",
       "      <td>0.000959</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.15</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.757424</td>\n",
       "      <td>0.050947</td>\n",
       "      <td>1215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.016427</td>\n",
       "      <td>0.001717</td>\n",
       "      <td>0.007107</td>\n",
       "      <td>0.001197</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.15</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.757450</td>\n",
       "      <td>0.053333</td>\n",
       "      <td>1214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.016237</td>\n",
       "      <td>0.001671</td>\n",
       "      <td>0.006752</td>\n",
       "      <td>0.001091</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.15</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.760676</td>\n",
       "      <td>0.044198</td>\n",
       "      <td>1209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.021693</td>\n",
       "      <td>0.001708</td>\n",
       "      <td>0.006730</td>\n",
       "      <td>0.000781</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.15</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>...</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.786380</td>\n",
       "      <td>0.041426</td>\n",
       "      <td>1198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.022707</td>\n",
       "      <td>0.001195</td>\n",
       "      <td>0.006760</td>\n",
       "      <td>0.001250</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.15</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.887097</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.788070</td>\n",
       "      <td>0.060361</td>\n",
       "      <td>1193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1210</th>\n",
       "      <td>0.042887</td>\n",
       "      <td>0.006616</td>\n",
       "      <td>0.007578</td>\n",
       "      <td>0.000661</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.15</td>\n",
       "      <td>4</td>\n",
       "      <td>40</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.840937</td>\n",
       "      <td>0.052094</td>\n",
       "      <td>216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1211</th>\n",
       "      <td>0.040591</td>\n",
       "      <td>0.002564</td>\n",
       "      <td>0.007381</td>\n",
       "      <td>0.000488</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.15</td>\n",
       "      <td>4</td>\n",
       "      <td>40</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.826498</td>\n",
       "      <td>0.044226</td>\n",
       "      <td>844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1212</th>\n",
       "      <td>0.047273</td>\n",
       "      <td>0.000661</td>\n",
       "      <td>0.007281</td>\n",
       "      <td>0.000457</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.15</td>\n",
       "      <td>4</td>\n",
       "      <td>50</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.836047</td>\n",
       "      <td>0.049856</td>\n",
       "      <td>522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1213</th>\n",
       "      <td>0.046974</td>\n",
       "      <td>0.001218</td>\n",
       "      <td>0.007380</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.15</td>\n",
       "      <td>4</td>\n",
       "      <td>50</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.837711</td>\n",
       "      <td>0.051631</td>\n",
       "      <td>393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1214</th>\n",
       "      <td>0.046675</td>\n",
       "      <td>0.001163</td>\n",
       "      <td>0.007381</td>\n",
       "      <td>0.000488</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.15</td>\n",
       "      <td>4</td>\n",
       "      <td>50</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.826523</td>\n",
       "      <td>0.043519</td>\n",
       "      <td>838</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1215 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0          0.016554      0.002537         0.007182        0.000959   \n",
       "1          0.016427      0.001717         0.007107        0.001197   \n",
       "2          0.016237      0.001671         0.006752        0.001091   \n",
       "3          0.021693      0.001708         0.006730        0.000781   \n",
       "4          0.022707      0.001195         0.006760        0.001250   \n",
       "...             ...           ...              ...             ...   \n",
       "1210       0.042887      0.006616         0.007578        0.000661   \n",
       "1211       0.040591      0.002564         0.007381        0.000488   \n",
       "1212       0.047273      0.000661         0.007281        0.000457   \n",
       "1213       0.046974      0.001218         0.007380        0.000489   \n",
       "1214       0.046675      0.001163         0.007381        0.000488   \n",
       "\n",
       "      param_colsample_bylevel  param_colsample_bytree  param_gamma  \\\n",
       "0                         0.2                     0.4          0.0   \n",
       "1                         0.2                     0.4          0.0   \n",
       "2                         0.2                     0.4          0.0   \n",
       "3                         0.2                     0.4          0.0   \n",
       "4                         0.2                     0.4          0.0   \n",
       "...                       ...                     ...          ...   \n",
       "1210                      0.4                     0.9          1.0   \n",
       "1211                      0.4                     0.9          1.0   \n",
       "1212                      0.4                     0.9          1.0   \n",
       "1213                      0.4                     0.9          1.0   \n",
       "1214                      0.4                     0.9          1.0   \n",
       "\n",
       "      param_learning_rate  param_max_depth  param_n_estimators  ...  \\\n",
       "0                    0.15                2                  10  ...   \n",
       "1                    0.15                2                  10  ...   \n",
       "2                    0.15                2                  10  ...   \n",
       "3                    0.15                2                  20  ...   \n",
       "4                    0.15                2                  20  ...   \n",
       "...                   ...              ...                 ...  ...   \n",
       "1210                 0.15                4                  40  ...   \n",
       "1211                 0.15                4                  40  ...   \n",
       "1212                 0.15                4                  50  ...   \n",
       "1213                 0.15                4                  50  ...   \n",
       "1214                 0.15                4                  50  ...   \n",
       "\n",
       "      split3_test_score split4_test_score  split5_test_score  \\\n",
       "0              0.822581          0.677419           0.774194   \n",
       "1              0.822581          0.693548           0.774194   \n",
       "2              0.806452          0.693548           0.774194   \n",
       "3              0.806452          0.790323           0.822581   \n",
       "4              0.854839          0.790323           0.887097   \n",
       "...                 ...               ...                ...   \n",
       "1210           0.854839          0.822581           0.854839   \n",
       "1211           0.854839          0.822581           0.790323   \n",
       "1212           0.838710          0.822581           0.806452   \n",
       "1213           0.854839          0.838710           0.838710   \n",
       "1214           0.854839          0.822581           0.806452   \n",
       "\n",
       "      split6_test_score  split7_test_score  split8_test_score  \\\n",
       "0              0.758065           0.677419           0.709677   \n",
       "1              0.790323           0.677419           0.677419   \n",
       "2              0.774194           0.693548           0.709677   \n",
       "3              0.806452           0.693548           0.725806   \n",
       "4              0.806452           0.709677           0.677419   \n",
       "...                 ...                ...                ...   \n",
       "1210           0.854839           0.838710           0.693548   \n",
       "1211           0.854839           0.822581           0.709677   \n",
       "1212           0.838710           0.838710           0.709677   \n",
       "1213           0.870968           0.822581           0.693548   \n",
       "1214           0.838710           0.822581           0.709677   \n",
       "\n",
       "      split9_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0              0.758065         0.757424        0.050947             1215  \n",
       "1              0.758065         0.757450        0.053333             1214  \n",
       "2              0.774194         0.760676        0.044198             1209  \n",
       "3              0.774194         0.786380        0.041426             1198  \n",
       "4              0.758065         0.788070        0.060361             1193  \n",
       "...                 ...              ...             ...              ...  \n",
       "1210           0.870968         0.840937        0.052094              216  \n",
       "1211           0.838710         0.826498        0.044226              844  \n",
       "1212           0.854839         0.836047        0.049856              522  \n",
       "1213           0.838710         0.837711        0.051631              393  \n",
       "1214           0.854839         0.826523        0.043519              838  \n",
       "\n",
       "[1215 rows x 25 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score is 0.856989247311828 with params {'colsample_bylevel': 0.4, 'colsample_bytree': 0.4, 'gamma': 1, 'learning_rate': 0.15, 'max_depth': 4, 'n_estimators': 30, 'subsample': 0.9}\n"
     ]
    }
   ],
   "source": [
    "df5 = pd.read_csv(\"data\\\\xgb_results_full_5_learning=0.15_r3_20221124.csv\")\n",
    "df5.drop(df5.columns[0], axis=1, inplace=True)\n",
    "display(df5)\n",
    "print(\"best score is 0.856989247311828 with params {'colsample_bylevel': 0.4, 'colsample_bytree': 0.4, 'gamma': 1, 'learning_rate': 0.15, 'max_depth': 4, 'n_estimators': 30, 'subsample': 0.9}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "47aa628f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_colsample_bylevel</th>\n",
       "      <th>param_colsample_bytree</th>\n",
       "      <th>param_gamma</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>...</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.016554</td>\n",
       "      <td>0.002537</td>\n",
       "      <td>0.007182</td>\n",
       "      <td>0.000959</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.15</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.757424</td>\n",
       "      <td>0.050947</td>\n",
       "      <td>1215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.016427</td>\n",
       "      <td>0.001717</td>\n",
       "      <td>0.007107</td>\n",
       "      <td>0.001197</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.15</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.757450</td>\n",
       "      <td>0.053333</td>\n",
       "      <td>1214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.016237</td>\n",
       "      <td>0.001671</td>\n",
       "      <td>0.006752</td>\n",
       "      <td>0.001091</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.15</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.760676</td>\n",
       "      <td>0.044198</td>\n",
       "      <td>1209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.021693</td>\n",
       "      <td>0.001708</td>\n",
       "      <td>0.006730</td>\n",
       "      <td>0.000781</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.15</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>...</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.786380</td>\n",
       "      <td>0.041426</td>\n",
       "      <td>1198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.022707</td>\n",
       "      <td>0.001195</td>\n",
       "      <td>0.006760</td>\n",
       "      <td>0.001250</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.15</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.887097</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.788070</td>\n",
       "      <td>0.060361</td>\n",
       "      <td>1193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1210</th>\n",
       "      <td>0.042887</td>\n",
       "      <td>0.006616</td>\n",
       "      <td>0.007578</td>\n",
       "      <td>0.000661</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.15</td>\n",
       "      <td>4</td>\n",
       "      <td>40</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.840937</td>\n",
       "      <td>0.052094</td>\n",
       "      <td>216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1211</th>\n",
       "      <td>0.040591</td>\n",
       "      <td>0.002564</td>\n",
       "      <td>0.007381</td>\n",
       "      <td>0.000488</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.15</td>\n",
       "      <td>4</td>\n",
       "      <td>40</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.826498</td>\n",
       "      <td>0.044226</td>\n",
       "      <td>844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1212</th>\n",
       "      <td>0.047273</td>\n",
       "      <td>0.000661</td>\n",
       "      <td>0.007281</td>\n",
       "      <td>0.000457</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.15</td>\n",
       "      <td>4</td>\n",
       "      <td>50</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.836047</td>\n",
       "      <td>0.049856</td>\n",
       "      <td>522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1213</th>\n",
       "      <td>0.046974</td>\n",
       "      <td>0.001218</td>\n",
       "      <td>0.007380</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.15</td>\n",
       "      <td>4</td>\n",
       "      <td>50</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.837711</td>\n",
       "      <td>0.051631</td>\n",
       "      <td>393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1214</th>\n",
       "      <td>0.046675</td>\n",
       "      <td>0.001163</td>\n",
       "      <td>0.007381</td>\n",
       "      <td>0.000488</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.15</td>\n",
       "      <td>4</td>\n",
       "      <td>50</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.826523</td>\n",
       "      <td>0.043519</td>\n",
       "      <td>838</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1215 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0          0.016554      0.002537         0.007182        0.000959   \n",
       "1          0.016427      0.001717         0.007107        0.001197   \n",
       "2          0.016237      0.001671         0.006752        0.001091   \n",
       "3          0.021693      0.001708         0.006730        0.000781   \n",
       "4          0.022707      0.001195         0.006760        0.001250   \n",
       "...             ...           ...              ...             ...   \n",
       "1210       0.042887      0.006616         0.007578        0.000661   \n",
       "1211       0.040591      0.002564         0.007381        0.000488   \n",
       "1212       0.047273      0.000661         0.007281        0.000457   \n",
       "1213       0.046974      0.001218         0.007380        0.000489   \n",
       "1214       0.046675      0.001163         0.007381        0.000488   \n",
       "\n",
       "     param_colsample_bylevel param_colsample_bytree param_gamma  \\\n",
       "0                        0.2                    0.4           0   \n",
       "1                        0.2                    0.4           0   \n",
       "2                        0.2                    0.4           0   \n",
       "3                        0.2                    0.4           0   \n",
       "4                        0.2                    0.4           0   \n",
       "...                      ...                    ...         ...   \n",
       "1210                     0.4                    0.9           1   \n",
       "1211                     0.4                    0.9           1   \n",
       "1212                     0.4                    0.9           1   \n",
       "1213                     0.4                    0.9           1   \n",
       "1214                     0.4                    0.9           1   \n",
       "\n",
       "     param_learning_rate param_max_depth param_n_estimators  ...  \\\n",
       "0                   0.15               2                 10  ...   \n",
       "1                   0.15               2                 10  ...   \n",
       "2                   0.15               2                 10  ...   \n",
       "3                   0.15               2                 20  ...   \n",
       "4                   0.15               2                 20  ...   \n",
       "...                  ...             ...                ...  ...   \n",
       "1210                0.15               4                 40  ...   \n",
       "1211                0.15               4                 40  ...   \n",
       "1212                0.15               4                 50  ...   \n",
       "1213                0.15               4                 50  ...   \n",
       "1214                0.15               4                 50  ...   \n",
       "\n",
       "     split3_test_score split4_test_score  split5_test_score  \\\n",
       "0             0.822581          0.677419           0.774194   \n",
       "1             0.822581          0.693548           0.774194   \n",
       "2             0.806452          0.693548           0.774194   \n",
       "3             0.806452          0.790323           0.822581   \n",
       "4             0.854839          0.790323           0.887097   \n",
       "...                ...               ...                ...   \n",
       "1210          0.854839          0.822581           0.854839   \n",
       "1211          0.854839          0.822581           0.790323   \n",
       "1212          0.838710          0.822581           0.806452   \n",
       "1213          0.854839          0.838710           0.838710   \n",
       "1214          0.854839          0.822581           0.806452   \n",
       "\n",
       "      split6_test_score  split7_test_score  split8_test_score  \\\n",
       "0              0.758065           0.677419           0.709677   \n",
       "1              0.790323           0.677419           0.677419   \n",
       "2              0.774194           0.693548           0.709677   \n",
       "3              0.806452           0.693548           0.725806   \n",
       "4              0.806452           0.709677           0.677419   \n",
       "...                 ...                ...                ...   \n",
       "1210           0.854839           0.838710           0.693548   \n",
       "1211           0.854839           0.822581           0.709677   \n",
       "1212           0.838710           0.838710           0.709677   \n",
       "1213           0.870968           0.822581           0.693548   \n",
       "1214           0.838710           0.822581           0.709677   \n",
       "\n",
       "      split9_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0              0.758065         0.757424        0.050947             1215  \n",
       "1              0.758065         0.757450        0.053333             1214  \n",
       "2              0.774194         0.760676        0.044198             1209  \n",
       "3              0.774194         0.786380        0.041426             1198  \n",
       "4              0.758065         0.788070        0.060361             1193  \n",
       "...                 ...              ...             ...              ...  \n",
       "1210           0.870968         0.840937        0.052094              216  \n",
       "1211           0.838710         0.826498        0.044226              844  \n",
       "1212           0.854839         0.836047        0.049856              522  \n",
       "1213           0.838710         0.837711        0.051631              393  \n",
       "1214           0.854839         0.826523        0.043519              838  \n",
       "\n",
       "[1215 rows x 25 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score is 0.856989247311828 with params {'colsample_bylevel': 0.4, 'colsample_bytree': 0.4, 'gamma': 1, 'learning_rate': 0.15, 'max_depth': 4, 'n_estimators': 30, 'subsample': 0.9}\n"
     ]
    }
   ],
   "source": [
    "# Full Tuning - Part 5\n",
    "random.seed(10)\n",
    "\n",
    "xgb = XGBClassifier()\n",
    "\n",
    "xgb_parameters = {'max_depth': [2,3,4]\n",
    "                   , 'subsample': [0.6, 0.8, 0.9]\n",
    "                   , 'gamma': [0, 0.5, 1]\n",
    "                   , 'colsample_bytree': [0.4, 0.5, 0.9]\n",
    "                   , 'colsample_bylevel': [0.2, 0.3, 0.4]\n",
    "                   , 'learning_rate': [0.15]\n",
    "                   , 'n_estimators': [10, 20, 30, 40, 50]}\n",
    "\n",
    "stratified_10_fold_cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "xgb_grid_search = GridSearchCV(xgb, xgb_parameters, scoring='accuracy', cv=stratified_10_fold_cv)\n",
    "\n",
    "xgb_grid_search.fit(X_train, y_train)\n",
    "\n",
    "xgb_grid_search_results_full_5 = pd.DataFrame(xgb_grid_search.cv_results_)\n",
    "display(xgb_grid_search_results_full_5)\n",
    "\n",
    "print(\"best score is {} with params {}\".format(xgb_grid_search.best_score_, xgb_grid_search.best_params_))\n",
    "#best score is 0.856989247311828 with params\n",
    "#{'colsample_bylevel': 0.4, 'colsample_bytree': 0.4, 'gamma': 1, 'learning_rate': 0.15, 'max_depth': 4, 'n_estimators': 30, 'subsample': 0.9}\n",
    "\n",
    "# save dataframe\n",
    "from datetime import datetime\n",
    "date = str(datetime.now().date()).replace(\"-\", \"\")\n",
    "xgb_grid_search_results_full_5.to_csv(f\"results/xgb_results_full_round4_5_learning=0.15_r3_{date}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6660d344",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_colsample_bylevel</th>\n",
       "      <th>param_colsample_bytree</th>\n",
       "      <th>param_gamma</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>...</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.017553</td>\n",
       "      <td>0.003160</td>\n",
       "      <td>0.006982</td>\n",
       "      <td>0.000446</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.661290</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.661290</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.763850</td>\n",
       "      <td>0.060953</td>\n",
       "      <td>1214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.014960</td>\n",
       "      <td>0.000446</td>\n",
       "      <td>0.007181</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.768689</td>\n",
       "      <td>0.054639</td>\n",
       "      <td>1210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.014760</td>\n",
       "      <td>0.001323</td>\n",
       "      <td>0.006583</td>\n",
       "      <td>0.000798</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.765515</td>\n",
       "      <td>0.050031</td>\n",
       "      <td>1211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.020445</td>\n",
       "      <td>0.002610</td>\n",
       "      <td>0.005785</td>\n",
       "      <td>0.000870</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.800768</td>\n",
       "      <td>0.050666</td>\n",
       "      <td>1196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.022241</td>\n",
       "      <td>0.002404</td>\n",
       "      <td>0.006483</td>\n",
       "      <td>0.000499</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.903226</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.805658</td>\n",
       "      <td>0.055483</td>\n",
       "      <td>1176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1210</th>\n",
       "      <td>0.039993</td>\n",
       "      <td>0.000829</td>\n",
       "      <td>0.007979</td>\n",
       "      <td>0.000446</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>4</td>\n",
       "      <td>40</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.887097</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.850589</td>\n",
       "      <td>0.041824</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1211</th>\n",
       "      <td>0.057798</td>\n",
       "      <td>0.044078</td>\n",
       "      <td>0.008179</td>\n",
       "      <td>0.002352</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>4</td>\n",
       "      <td>40</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.823349</td>\n",
       "      <td>0.036404</td>\n",
       "      <td>966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1212</th>\n",
       "      <td>0.065325</td>\n",
       "      <td>0.017959</td>\n",
       "      <td>0.008279</td>\n",
       "      <td>0.000779</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>4</td>\n",
       "      <td>50</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.834434</td>\n",
       "      <td>0.055885</td>\n",
       "      <td>546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1213</th>\n",
       "      <td>0.067819</td>\n",
       "      <td>0.006180</td>\n",
       "      <td>0.008378</td>\n",
       "      <td>0.001196</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>4</td>\n",
       "      <td>50</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.837737</td>\n",
       "      <td>0.042732</td>\n",
       "      <td>317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1214</th>\n",
       "      <td>0.055651</td>\n",
       "      <td>0.002176</td>\n",
       "      <td>0.007880</td>\n",
       "      <td>0.001042</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>4</td>\n",
       "      <td>50</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.828111</td>\n",
       "      <td>0.042532</td>\n",
       "      <td>829</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1215 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0          0.017553      0.003160         0.006982        0.000446   \n",
       "1          0.014960      0.000446         0.007181        0.000399   \n",
       "2          0.014760      0.001323         0.006583        0.000798   \n",
       "3          0.020445      0.002610         0.005785        0.000870   \n",
       "4          0.022241      0.002404         0.006483        0.000499   \n",
       "...             ...           ...              ...             ...   \n",
       "1210       0.039993      0.000829         0.007979        0.000446   \n",
       "1211       0.057798      0.044078         0.008179        0.002352   \n",
       "1212       0.065325      0.017959         0.008279        0.000779   \n",
       "1213       0.067819      0.006180         0.008378        0.001196   \n",
       "1214       0.055651      0.002176         0.007880        0.001042   \n",
       "\n",
       "      param_colsample_bylevel  param_colsample_bytree  param_gamma  \\\n",
       "0                         0.2                     0.4          0.0   \n",
       "1                         0.2                     0.4          0.0   \n",
       "2                         0.2                     0.4          0.0   \n",
       "3                         0.2                     0.4          0.0   \n",
       "4                         0.2                     0.4          0.0   \n",
       "...                       ...                     ...          ...   \n",
       "1210                      0.4                     0.9          1.0   \n",
       "1211                      0.4                     0.9          1.0   \n",
       "1212                      0.4                     0.9          1.0   \n",
       "1213                      0.4                     0.9          1.0   \n",
       "1214                      0.4                     0.9          1.0   \n",
       "\n",
       "      param_learning_rate  param_max_depth  param_n_estimators  ...  \\\n",
       "0                     0.2                2                  10  ...   \n",
       "1                     0.2                2                  10  ...   \n",
       "2                     0.2                2                  10  ...   \n",
       "3                     0.2                2                  20  ...   \n",
       "4                     0.2                2                  20  ...   \n",
       "...                   ...              ...                 ...  ...   \n",
       "1210                  0.2                4                  40  ...   \n",
       "1211                  0.2                4                  40  ...   \n",
       "1212                  0.2                4                  50  ...   \n",
       "1213                  0.2                4                  50  ...   \n",
       "1214                  0.2                4                  50  ...   \n",
       "\n",
       "      split3_test_score split4_test_score  split5_test_score  \\\n",
       "0              0.838710          0.661290           0.790323   \n",
       "1              0.854839          0.693548           0.790323   \n",
       "2              0.838710          0.725806           0.790323   \n",
       "3              0.838710          0.774194           0.838710   \n",
       "4              0.838710          0.774194           0.903226   \n",
       "...                 ...               ...                ...   \n",
       "1210           0.870968          0.822581           0.854839   \n",
       "1211           0.854839          0.822581           0.806452   \n",
       "1212           0.838710          0.822581           0.790323   \n",
       "1213           0.838710          0.822581           0.822581   \n",
       "1214           0.870968          0.822581           0.790323   \n",
       "\n",
       "      split6_test_score  split7_test_score  split8_test_score  \\\n",
       "0              0.774194           0.661290           0.709677   \n",
       "1              0.774194           0.693548           0.693548   \n",
       "2              0.774194           0.677419           0.693548   \n",
       "3              0.806452           0.709677           0.709677   \n",
       "4              0.806452           0.741935           0.693548   \n",
       "...                 ...                ...                ...   \n",
       "1210           0.887097           0.838710           0.741935   \n",
       "1211           0.854839           0.822581           0.725806   \n",
       "1212           0.854839           0.838710           0.693548   \n",
       "1213           0.870968           0.838710           0.725806   \n",
       "1214           0.854839           0.806452           0.725806   \n",
       "\n",
       "      split9_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0              0.790323         0.763850        0.060953             1214  \n",
       "1              0.774194         0.768689        0.054639             1210  \n",
       "2              0.774194         0.765515        0.050031             1211  \n",
       "3              0.806452         0.800768        0.050666             1196  \n",
       "4              0.806452         0.805658        0.055483             1176  \n",
       "...                 ...              ...             ...              ...  \n",
       "1210           0.854839         0.850589        0.041824                6  \n",
       "1211           0.822581         0.823349        0.036404              966  \n",
       "1212           0.854839         0.834434        0.055885              546  \n",
       "1213           0.854839         0.837737        0.042732              317  \n",
       "1214           0.838710         0.828111        0.042532              829  \n",
       "\n",
       "[1215 rows x 25 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score is 0.8522529441884281 with params {'colsample_bylevel': 0.2, 'colsample_bytree': 0.9, 'gamma': 0.5, 'learning_rate': 0.2, 'max_depth': 2, 'n_estimators': 30, 'subsample': 0.6}\n"
     ]
    }
   ],
   "source": [
    "df6 = pd.read_csv(\"data\\\\xgb_results_full_6_learning=0.2_r3_20221124.csv\")\n",
    "df6.drop(df6.columns[0], axis=1, inplace=True)\n",
    "display(df6)\n",
    "print(\"best score is 0.8522529441884281 with params {'colsample_bylevel': 0.2, 'colsample_bytree': 0.9, 'gamma': 0.5, 'learning_rate': 0.2, 'max_depth': 2, 'n_estimators': 30, 'subsample': 0.6}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "10ee410e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_colsample_bylevel</th>\n",
       "      <th>param_colsample_bytree</th>\n",
       "      <th>param_gamma</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>...</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.017553</td>\n",
       "      <td>0.003160</td>\n",
       "      <td>0.006982</td>\n",
       "      <td>0.000446</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.661290</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.661290</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.763850</td>\n",
       "      <td>0.060953</td>\n",
       "      <td>1214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.014960</td>\n",
       "      <td>0.000446</td>\n",
       "      <td>0.007181</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.768689</td>\n",
       "      <td>0.054639</td>\n",
       "      <td>1210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.014760</td>\n",
       "      <td>0.001323</td>\n",
       "      <td>0.006583</td>\n",
       "      <td>0.000798</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.765515</td>\n",
       "      <td>0.050031</td>\n",
       "      <td>1211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.020445</td>\n",
       "      <td>0.002610</td>\n",
       "      <td>0.005785</td>\n",
       "      <td>0.000870</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.800768</td>\n",
       "      <td>0.050666</td>\n",
       "      <td>1196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.022241</td>\n",
       "      <td>0.002404</td>\n",
       "      <td>0.006483</td>\n",
       "      <td>0.000499</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.903226</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.805658</td>\n",
       "      <td>0.055483</td>\n",
       "      <td>1176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1210</th>\n",
       "      <td>0.039993</td>\n",
       "      <td>0.000829</td>\n",
       "      <td>0.007979</td>\n",
       "      <td>0.000446</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>4</td>\n",
       "      <td>40</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.887097</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.850589</td>\n",
       "      <td>0.041824</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1211</th>\n",
       "      <td>0.057798</td>\n",
       "      <td>0.044078</td>\n",
       "      <td>0.008179</td>\n",
       "      <td>0.002352</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>4</td>\n",
       "      <td>40</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.823349</td>\n",
       "      <td>0.036404</td>\n",
       "      <td>966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1212</th>\n",
       "      <td>0.065325</td>\n",
       "      <td>0.017959</td>\n",
       "      <td>0.008279</td>\n",
       "      <td>0.000779</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>4</td>\n",
       "      <td>50</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.834434</td>\n",
       "      <td>0.055885</td>\n",
       "      <td>546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1213</th>\n",
       "      <td>0.067819</td>\n",
       "      <td>0.006180</td>\n",
       "      <td>0.008378</td>\n",
       "      <td>0.001196</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>4</td>\n",
       "      <td>50</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.837737</td>\n",
       "      <td>0.042732</td>\n",
       "      <td>317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1214</th>\n",
       "      <td>0.055651</td>\n",
       "      <td>0.002176</td>\n",
       "      <td>0.007880</td>\n",
       "      <td>0.001042</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>4</td>\n",
       "      <td>50</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.828111</td>\n",
       "      <td>0.042532</td>\n",
       "      <td>829</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1215 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0          0.017553      0.003160         0.006982        0.000446   \n",
       "1          0.014960      0.000446         0.007181        0.000399   \n",
       "2          0.014760      0.001323         0.006583        0.000798   \n",
       "3          0.020445      0.002610         0.005785        0.000870   \n",
       "4          0.022241      0.002404         0.006483        0.000499   \n",
       "...             ...           ...              ...             ...   \n",
       "1210       0.039993      0.000829         0.007979        0.000446   \n",
       "1211       0.057798      0.044078         0.008179        0.002352   \n",
       "1212       0.065325      0.017959         0.008279        0.000779   \n",
       "1213       0.067819      0.006180         0.008378        0.001196   \n",
       "1214       0.055651      0.002176         0.007880        0.001042   \n",
       "\n",
       "     param_colsample_bylevel param_colsample_bytree param_gamma  \\\n",
       "0                        0.2                    0.4           0   \n",
       "1                        0.2                    0.4           0   \n",
       "2                        0.2                    0.4           0   \n",
       "3                        0.2                    0.4           0   \n",
       "4                        0.2                    0.4           0   \n",
       "...                      ...                    ...         ...   \n",
       "1210                     0.4                    0.9           1   \n",
       "1211                     0.4                    0.9           1   \n",
       "1212                     0.4                    0.9           1   \n",
       "1213                     0.4                    0.9           1   \n",
       "1214                     0.4                    0.9           1   \n",
       "\n",
       "     param_learning_rate param_max_depth param_n_estimators  ...  \\\n",
       "0                    0.2               2                 10  ...   \n",
       "1                    0.2               2                 10  ...   \n",
       "2                    0.2               2                 10  ...   \n",
       "3                    0.2               2                 20  ...   \n",
       "4                    0.2               2                 20  ...   \n",
       "...                  ...             ...                ...  ...   \n",
       "1210                 0.2               4                 40  ...   \n",
       "1211                 0.2               4                 40  ...   \n",
       "1212                 0.2               4                 50  ...   \n",
       "1213                 0.2               4                 50  ...   \n",
       "1214                 0.2               4                 50  ...   \n",
       "\n",
       "     split3_test_score split4_test_score  split5_test_score  \\\n",
       "0             0.838710          0.661290           0.790323   \n",
       "1             0.854839          0.693548           0.790323   \n",
       "2             0.838710          0.725806           0.790323   \n",
       "3             0.838710          0.774194           0.838710   \n",
       "4             0.838710          0.774194           0.903226   \n",
       "...                ...               ...                ...   \n",
       "1210          0.870968          0.822581           0.854839   \n",
       "1211          0.854839          0.822581           0.806452   \n",
       "1212          0.838710          0.822581           0.790323   \n",
       "1213          0.838710          0.822581           0.822581   \n",
       "1214          0.870968          0.822581           0.790323   \n",
       "\n",
       "      split6_test_score  split7_test_score  split8_test_score  \\\n",
       "0              0.774194           0.661290           0.709677   \n",
       "1              0.774194           0.693548           0.693548   \n",
       "2              0.774194           0.677419           0.693548   \n",
       "3              0.806452           0.709677           0.709677   \n",
       "4              0.806452           0.741935           0.693548   \n",
       "...                 ...                ...                ...   \n",
       "1210           0.887097           0.838710           0.741935   \n",
       "1211           0.854839           0.822581           0.725806   \n",
       "1212           0.854839           0.838710           0.693548   \n",
       "1213           0.870968           0.838710           0.725806   \n",
       "1214           0.854839           0.806452           0.725806   \n",
       "\n",
       "      split9_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0              0.790323         0.763850        0.060953             1214  \n",
       "1              0.774194         0.768689        0.054639             1210  \n",
       "2              0.774194         0.765515        0.050031             1211  \n",
       "3              0.806452         0.800768        0.050666             1196  \n",
       "4              0.806452         0.805658        0.055483             1176  \n",
       "...                 ...              ...             ...              ...  \n",
       "1210           0.854839         0.850589        0.041824                6  \n",
       "1211           0.822581         0.823349        0.036404              966  \n",
       "1212           0.854839         0.834434        0.055885              546  \n",
       "1213           0.854839         0.837737        0.042732              317  \n",
       "1214           0.838710         0.828111        0.042532              829  \n",
       "\n",
       "[1215 rows x 25 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score is 0.8522529441884281 with params {'colsample_bylevel': 0.2, 'colsample_bytree': 0.9, 'gamma': 0.5, 'learning_rate': 0.2, 'max_depth': 2, 'n_estimators': 30, 'subsample': 0.6}\n"
     ]
    }
   ],
   "source": [
    "# Full Tuning - Part 6\n",
    "random.seed(10)\n",
    "\n",
    "xgb = XGBClassifier()\n",
    "\n",
    "xgb_parameters = {'max_depth': [2,3,4]\n",
    "                   , 'subsample': [0.6, 0.8, 0.9]\n",
    "                   , 'gamma': [0, 0.5, 1]\n",
    "                   , 'colsample_bytree': [0.4, 0.5, 0.9]\n",
    "                   , 'colsample_bylevel': [0.2, 0.3, 0.4]\n",
    "                   , 'learning_rate': [0.2]\n",
    "                   , 'n_estimators': [10, 20, 30, 40, 50]}\n",
    "\n",
    "stratified_10_fold_cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "xgb_grid_search = GridSearchCV(xgb, xgb_parameters, scoring='accuracy', cv=stratified_10_fold_cv)\n",
    "\n",
    "xgb_grid_search.fit(X_train, y_train)\n",
    "\n",
    "xgb_grid_search_results_full_6 = pd.DataFrame(xgb_grid_search.cv_results_)\n",
    "display(xgb_grid_search_results_full_6)\n",
    "\n",
    "print(\"best score is {} with params {}\".format(xgb_grid_search.best_score_, xgb_grid_search.best_params_))\n",
    "#best score is 0.8522529441884281 with params\n",
    "#{'colsample_bylevel': 0.2, 'colsample_bytree': 0.9, 'gamma': 0.5, 'learning_rate': 0.2, 'max_depth': 2, 'n_estimators': 30, 'subsample': 0.6}\n",
    "\n",
    "# save dataframe\n",
    "from datetime import datetime\n",
    "date = str(datetime.now().date()).replace(\"-\", \"\")\n",
    "xgb_grid_search_results_full_6.to_csv(f\"results/xgb_results_full_round4_6_learning=0.2_r3_{date}.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57b04632",
   "metadata": {},
   "source": [
    "Combine single hyper parameter tuning to find best values for hyper parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9a382288",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_colsample_bylevel</th>\n",
       "      <th>param_colsample_bytree</th>\n",
       "      <th>param_gamma</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>...</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.021696</td>\n",
       "      <td>0.004852</td>\n",
       "      <td>0.009495</td>\n",
       "      <td>0.002555</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.661290</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.661290</td>\n",
       "      <td>0.661290</td>\n",
       "      <td>0.661290</td>\n",
       "      <td>0.720430</td>\n",
       "      <td>0.052226</td>\n",
       "      <td>4858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.023734</td>\n",
       "      <td>0.003344</td>\n",
       "      <td>0.010269</td>\n",
       "      <td>0.002012</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.661290</td>\n",
       "      <td>0.629032</td>\n",
       "      <td>0.661290</td>\n",
       "      <td>0.720405</td>\n",
       "      <td>0.060569</td>\n",
       "      <td>4860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.021329</td>\n",
       "      <td>0.002649</td>\n",
       "      <td>0.009234</td>\n",
       "      <td>0.001687</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.645161</td>\n",
       "      <td>0.645161</td>\n",
       "      <td>0.661290</td>\n",
       "      <td>0.723630</td>\n",
       "      <td>0.057244</td>\n",
       "      <td>4855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.031445</td>\n",
       "      <td>0.001912</td>\n",
       "      <td>0.009800</td>\n",
       "      <td>0.001109</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>...</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.760599</td>\n",
       "      <td>0.045057</td>\n",
       "      <td>4835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.034447</td>\n",
       "      <td>0.002939</td>\n",
       "      <td>0.010506</td>\n",
       "      <td>0.001006</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>...</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.760625</td>\n",
       "      <td>0.047805</td>\n",
       "      <td>4834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4855</th>\n",
       "      <td>0.039993</td>\n",
       "      <td>0.000829</td>\n",
       "      <td>0.007979</td>\n",
       "      <td>0.000446</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.20</td>\n",
       "      <td>4</td>\n",
       "      <td>40</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.887097</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.850589</td>\n",
       "      <td>0.041824</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4856</th>\n",
       "      <td>0.057798</td>\n",
       "      <td>0.044078</td>\n",
       "      <td>0.008179</td>\n",
       "      <td>0.002352</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.20</td>\n",
       "      <td>4</td>\n",
       "      <td>40</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.823349</td>\n",
       "      <td>0.036404</td>\n",
       "      <td>3249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4857</th>\n",
       "      <td>0.065325</td>\n",
       "      <td>0.017959</td>\n",
       "      <td>0.008279</td>\n",
       "      <td>0.000779</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.20</td>\n",
       "      <td>4</td>\n",
       "      <td>50</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.834434</td>\n",
       "      <td>0.055885</td>\n",
       "      <td>1740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4858</th>\n",
       "      <td>0.067819</td>\n",
       "      <td>0.006180</td>\n",
       "      <td>0.008378</td>\n",
       "      <td>0.001196</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.20</td>\n",
       "      <td>4</td>\n",
       "      <td>50</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.837737</td>\n",
       "      <td>0.042732</td>\n",
       "      <td>1033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4859</th>\n",
       "      <td>0.055651</td>\n",
       "      <td>0.002176</td>\n",
       "      <td>0.007880</td>\n",
       "      <td>0.001042</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.20</td>\n",
       "      <td>4</td>\n",
       "      <td>50</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.828111</td>\n",
       "      <td>0.042532</td>\n",
       "      <td>2692</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4860 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0          0.021696      0.004852         0.009495        0.002555   \n",
       "1          0.023734      0.003344         0.010269        0.002012   \n",
       "2          0.021329      0.002649         0.009234        0.001687   \n",
       "3          0.031445      0.001912         0.009800        0.001109   \n",
       "4          0.034447      0.002939         0.010506        0.001006   \n",
       "...             ...           ...              ...             ...   \n",
       "4855       0.039993      0.000829         0.007979        0.000446   \n",
       "4856       0.057798      0.044078         0.008179        0.002352   \n",
       "4857       0.065325      0.017959         0.008279        0.000779   \n",
       "4858       0.067819      0.006180         0.008378        0.001196   \n",
       "4859       0.055651      0.002176         0.007880        0.001042   \n",
       "\n",
       "      param_colsample_bylevel  param_colsample_bytree  param_gamma  \\\n",
       "0                         0.2                     0.4          0.0   \n",
       "1                         0.2                     0.4          0.0   \n",
       "2                         0.2                     0.4          0.0   \n",
       "3                         0.2                     0.4          0.0   \n",
       "4                         0.2                     0.4          0.0   \n",
       "...                       ...                     ...          ...   \n",
       "4855                      0.4                     0.9          1.0   \n",
       "4856                      0.4                     0.9          1.0   \n",
       "4857                      0.4                     0.9          1.0   \n",
       "4858                      0.4                     0.9          1.0   \n",
       "4859                      0.4                     0.9          1.0   \n",
       "\n",
       "      param_learning_rate  param_max_depth  param_n_estimators  ...  \\\n",
       "0                    0.05                2                  10  ...   \n",
       "1                    0.05                2                  10  ...   \n",
       "2                    0.05                2                  10  ...   \n",
       "3                    0.05                2                  20  ...   \n",
       "4                    0.05                2                  20  ...   \n",
       "...                   ...              ...                 ...  ...   \n",
       "4855                 0.20                4                  40  ...   \n",
       "4856                 0.20                4                  40  ...   \n",
       "4857                 0.20                4                  50  ...   \n",
       "4858                 0.20                4                  50  ...   \n",
       "4859                 0.20                4                  50  ...   \n",
       "\n",
       "      split3_test_score split4_test_score  split5_test_score  \\\n",
       "0              0.741935          0.661290           0.758065   \n",
       "1              0.774194          0.677419           0.758065   \n",
       "2              0.741935          0.709677           0.774194   \n",
       "3              0.774194          0.741935           0.790323   \n",
       "4              0.806452          0.725806           0.790323   \n",
       "...                 ...               ...                ...   \n",
       "4855           0.870968          0.822581           0.854839   \n",
       "4856           0.854839          0.822581           0.806452   \n",
       "4857           0.838710          0.822581           0.790323   \n",
       "4858           0.838710          0.822581           0.822581   \n",
       "4859           0.870968          0.822581           0.790323   \n",
       "\n",
       "      split6_test_score  split7_test_score  split8_test_score  \\\n",
       "0              0.725806           0.661290           0.661290   \n",
       "1              0.693548           0.661290           0.629032   \n",
       "2              0.709677           0.645161           0.645161   \n",
       "3              0.758065           0.693548           0.709677   \n",
       "4              0.774194           0.693548           0.693548   \n",
       "...                 ...                ...                ...   \n",
       "4855           0.887097           0.838710           0.741935   \n",
       "4856           0.854839           0.822581           0.725806   \n",
       "4857           0.854839           0.838710           0.693548   \n",
       "4858           0.870968           0.838710           0.725806   \n",
       "4859           0.854839           0.806452           0.725806   \n",
       "\n",
       "      split9_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0              0.661290         0.720430        0.052226             4858  \n",
       "1              0.661290         0.720405        0.060569             4860  \n",
       "2              0.661290         0.723630        0.057244             4855  \n",
       "3              0.709677         0.760599        0.045057             4835  \n",
       "4              0.709677         0.760625        0.047805             4834  \n",
       "...                 ...              ...             ...              ...  \n",
       "4855           0.854839         0.850589        0.041824               18  \n",
       "4856           0.822581         0.823349        0.036404             3249  \n",
       "4857           0.854839         0.834434        0.055885             1740  \n",
       "4858           0.854839         0.837737        0.042732             1033  \n",
       "4859           0.838710         0.828111        0.042532             2692  \n",
       "\n",
       "[4860 rows x 25 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score is 0.856989 with params {'colsample_bylevel': 0.4, 'colsample_bytree': 0.4, 'gamma': 1, 'learning_rate': 0.15, 'max_depth': 4, 'n_estimators': 30, 'subsample': 0.9}\n"
     ]
    }
   ],
   "source": [
    "# read single parts of round 3, concatenate and update index and rank_test_score\n",
    "\n",
    "df2 = pd.read_csv(\"data\\\\xgb_results_full_2_learning=0.05_r3_20221124.csv\")\n",
    "df2.drop(df2.columns[0], axis=1, inplace=True)\n",
    "\n",
    "df4 = pd.read_csv(\"data\\\\xgb_results_full_4_learning=0.1_r3_20221124.csv\")\n",
    "df4.drop(df4.columns[0], axis=1, inplace=True)\n",
    "\n",
    "df5 = pd.read_csv(\"data\\\\xgb_results_full_5_learning=0.15_r3_20221124.csv\")\n",
    "df5.drop(df5.columns[0], axis=1, inplace=True)\n",
    "\n",
    "df6 = pd.read_csv(\"data\\\\xgb_results_full_6_learning=0.2_r3_20221124.csv\")\n",
    "df6.drop(df6.columns[0], axis=1, inplace=True)\n",
    "\n",
    "df_full = pd.concat([df2,df4,df5,df6])\n",
    "\n",
    "#assign correct rank\n",
    "df_full = df_full.sort_values(by='mean_test_score', ascending=False)\n",
    "df_full['rank_test_score'] = range(1, len(df_full)+1)\n",
    "\n",
    "#get correct order and set new index\n",
    "df_full = df_full.sort_values(by=['param_colsample_bylevel', 'param_colsample_bytree', 'param_gamma', 'param_learning_rate', 'param_max_depth', 'param_n_estimators', 'param_subsample'])\n",
    "xgb_grid_search_results_round4 = df_full.set_index(np.array(range(len(df_full))))\n",
    "display(xgb_grid_search_results_round4)\n",
    "\n",
    "print(\"best score is 0.856989 with params {'colsample_bylevel': 0.4, 'colsample_bytree': 0.4, 'gamma': 1, 'learning_rate': 0.15, 'max_depth': 4, 'n_estimators': 30, 'subsample': 0.9}\")\n",
    "\n",
    "# save dataframe\n",
    "from datetime import datetime\n",
    "date = str(datetime.now().date()).replace(\"-\", \"\")\n",
    "xgb_grid_search_results_round4.to_csv(f\"results/xgb_results_round4_{date}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "137cdd22",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_subsample</th>\n",
       "      <th>param_colsample_bylevel</th>\n",
       "      <th>param_colsample_bytree</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_gamma</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3728</th>\n",
       "      <td>4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.15</td>\n",
       "      <td>30</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.856989</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3714</th>\n",
       "      <td>3</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.15</td>\n",
       "      <td>40</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.853840</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1401</th>\n",
       "      <td>2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.20</td>\n",
       "      <td>30</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.852253</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1551</th>\n",
       "      <td>3</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.15</td>\n",
       "      <td>30</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.852227</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1596</th>\n",
       "      <td>3</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.20</td>\n",
       "      <td>30</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.852202</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.05</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.722043</td>\n",
       "      <td>4856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.05</td>\n",
       "      <td>10</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.720430</td>\n",
       "      <td>4857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.05</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.720430</td>\n",
       "      <td>4858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>2</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.05</td>\n",
       "      <td>10</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.720405</td>\n",
       "      <td>4859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.05</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.720405</td>\n",
       "      <td>4860</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4860 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      param_max_depth  param_subsample  param_colsample_bylevel  \\\n",
       "3728                4              0.9                      0.4   \n",
       "3714                3              0.6                      0.4   \n",
       "1401                2              0.6                      0.2   \n",
       "1551                3              0.6                      0.2   \n",
       "1596                3              0.6                      0.2   \n",
       "...               ...              ...                      ...   \n",
       "360                 2              0.6                      0.2   \n",
       "180                 2              0.6                      0.2   \n",
       "0                   2              0.6                      0.2   \n",
       "181                 2              0.8                      0.2   \n",
       "1                   2              0.8                      0.2   \n",
       "\n",
       "      param_colsample_bytree  param_learning_rate  param_n_estimators  \\\n",
       "3728                     0.4                 0.15                  30   \n",
       "3714                     0.4                 0.15                  40   \n",
       "1401                     0.9                 0.20                  30   \n",
       "1551                     0.9                 0.15                  30   \n",
       "1596                     0.9                 0.20                  30   \n",
       "...                      ...                  ...                 ...   \n",
       "360                      0.4                 0.05                  10   \n",
       "180                      0.4                 0.05                  10   \n",
       "0                        0.4                 0.05                  10   \n",
       "181                      0.4                 0.05                  10   \n",
       "1                        0.4                 0.05                  10   \n",
       "\n",
       "      param_gamma  mean_test_score  rank_test_score  \n",
       "3728          1.0         0.856989                1  \n",
       "3714          1.0         0.853840                2  \n",
       "1401          0.5         0.852253                3  \n",
       "1551          1.0         0.852227                4  \n",
       "1596          1.0         0.852202                5  \n",
       "...           ...              ...              ...  \n",
       "360           1.0         0.722043             4856  \n",
       "180           0.5         0.720430             4857  \n",
       "0             0.0         0.720430             4858  \n",
       "181           0.5         0.720405             4859  \n",
       "1             0.0         0.720405             4860  \n",
       "\n",
       "[4860 rows x 9 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# store relevant columns and sort by rank_test_score\n",
    "cols_round4 = ['param_max_depth', 'param_subsample', 'param_colsample_bylevel', 'param_colsample_bytree', 'param_learning_rate', 'param_n_estimators', 'param_gamma', 'mean_test_score', 'rank_test_score']\n",
    "xgb_results_round4_sorted = xgb_grid_search_results_round4[cols_round4]\n",
    "xgb_results_round4_sorted = xgb_results_round4_sorted.sort_values(by='rank_test_score')\n",
    "display(xgb_results_round4_sorted)\n",
    "\n",
    "# save dataframe\n",
    "from datetime import datetime\n",
    "date = str(datetime.now().date()).replace(\"-\", \"\")\n",
    "xgb_results_round4_sorted.to_csv(f\"results/xgb_results_round4_sorted_{date}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f31aba85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.8171641791044776\n",
      "F1 Score = 0.7655502392344496\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.89      0.85       157\n",
      "           1       0.82      0.72      0.77       111\n",
      "\n",
      "    accuracy                           0.82       268\n",
      "   macro avg       0.82      0.80      0.81       268\n",
      "weighted avg       0.82      0.82      0.82       268\n",
      "\n",
      "Confusion Matrix:\n",
      "[[139  18]\n",
      " [ 31  80]]\n"
     ]
    }
   ],
   "source": [
    "# Fit and evaluate best model\n",
    "\n",
    "xgb_best = XGBClassifier(max_depth = 4, subsample = 0.9, colsample_bylevel = 0.4, colsample_bytree = 0.4, learning_rate = 0.15, n_estimators = 30, gamma = 1)\n",
    "xgb_best.fit(X_train, y_train)\n",
    "xgb_best_pred = xgb_best.predict(X_test)\n",
    "\n",
    "xgb_best_acc = accuracy_score(y_test, xgb_best_pred)\n",
    "print(\"Accuracy =\", xgb_best_acc) #0.8283582089552238\n",
    "\n",
    "xgb_best_f1 = f1_score(y_test, xgb_best_pred)\n",
    "print(\"F1 Score =\", xgb_best_f1) #0.7788461538461539\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, xgb_best_pred))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, xgb_best_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10317046",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba1a3507",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9882d10e",
   "metadata": {},
   "source": [
    "## Best Model by trying out some combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9a358d23",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.8470149253731343\n",
      "F1 Score = 0.8093023255813953\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.89      0.87       157\n",
      "           1       0.84      0.78      0.81       111\n",
      "\n",
      "    accuracy                           0.85       268\n",
      "   macro avg       0.85      0.84      0.84       268\n",
      "weighted avg       0.85      0.85      0.85       268\n",
      "\n",
      "Confusion Matrix:\n",
      "[[140  17]\n",
      " [ 24  87]]\n"
     ]
    }
   ],
   "source": [
    "# Fit and evaluate best model\n",
    "\n",
    "xgb_best = XGBClassifier(max_depth = 2, subsample = 0.7, colsample_bylevel = 0.4, colsample_bytree = 0.9, learning_rate = 0.7, n_estimators = 30, gamma = 1)\n",
    "xgb_best.fit(X_train, y_train)\n",
    "xgb_best_pred = xgb_best.predict(X_test)\n",
    "\n",
    "xgb_best_acc = accuracy_score(y_test, xgb_best_pred)\n",
    "print(\"Accuracy =\", xgb_best_acc) #0.8470149253731343\n",
    "\n",
    "xgb_best_f1 = f1_score(y_test, xgb_best_pred)\n",
    "print(\"F1 Score =\", xgb_best_f1) #0.8093023255813953\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, xgb_best_pred))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, xgb_best_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "318e6206",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 15 artists>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "feature_importance = xgb_best.feature_importances_\n",
    "feature_names = list(X_train.columns)\n",
    "plt.barh(feature_names, feature_importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "c8101d7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.746268656716418 with params max_depth = 2 subsample = 0.7 colsample_bylevel = 0.2 colsample_bytree = 0.5 learning_rate = 0.1 n_estimators = 30 gamma = 0\n",
      "0.7611940298507462 with params max_depth = 2 subsample = 0.7 colsample_bylevel = 0.2 colsample_bytree = 0.5 learning_rate = 0.15 n_estimators = 30 gamma = 0\n",
      "0.8208955223880597 with params max_depth = 2 subsample = 0.7 colsample_bylevel = 0.2 colsample_bytree = 0.5 learning_rate = 0.7 n_estimators = 30 gamma = 0\n",
      "0.832089552238806 with params max_depth = 2 subsample = 0.7 colsample_bylevel = 0.3 colsample_bytree = 0.6 learning_rate = 0.1 n_estimators = 30 gamma = 0\n",
      "0.835820895522388 with params max_depth = 2 subsample = 0.7 colsample_bylevel = 0.4 colsample_bytree = 0.9 learning_rate = 0.15 n_estimators = 30 gamma = 0\n",
      "0.8470149253731343 with params max_depth = 2 subsample = 0.7 colsample_bylevel = 0.4 colsample_bytree = 0.9 learning_rate = 0.7 n_estimators = 30 gamma = 1\n"
     ]
    }
   ],
   "source": [
    "# n = 90\n",
    "max_acc = 0\n",
    "for m in [2,3,4]:\n",
    "    for s in [0.7, 0.8, 0.9]:\n",
    "        for g in [0,1]:\n",
    "            for t in [0.5, 0.6, 0.9]:\n",
    "                for l in [0.2, 0.3, 0.4]:\n",
    "                    for r in [0.1, 0.15, 0.7]:\n",
    "                        xgb = XGBClassifier(max_depth = m, subsample = s, colsample_bylevel = l, colsample_bytree = t, learning_rate = r, n_estimators = 30, gamma = g)\n",
    "                        xgb.fit(X_train, y_train)\n",
    "                        pred = xgb.predict(X_test)\n",
    "                        acc = accuracy_score(y_test, pred)\n",
    "                        if acc > max_acc:\n",
    "                            max_acc = acc\n",
    "                            print(acc, \"with params max_depth =\", m, \"subsample =\", s, \"colsample_bylevel =\", l, \"colsample_bytree =\", t, \"learning_rate =\", r, \"n_estimators =\", 30, \"gamma =\", g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86652b50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ab4d20",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
