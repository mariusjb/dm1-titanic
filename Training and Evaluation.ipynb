{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7104d2ce",
   "metadata": {},
   "source": [
    "# Training and Evaluation of different Machine Learning Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "202391f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load required packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ce61838",
   "metadata": {},
   "source": [
    "## Train and Test Data\n",
    "We load the train and the test data which we splitted in _preprocessing.ipynb_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de0a10cb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Age_true</th>\n",
       "      <th>AgeGroup</th>\n",
       "      <th>FareGroup</th>\n",
       "      <th>CabinLvl</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "      <th>Title_Master</th>\n",
       "      <th>Title_Mrs</th>\n",
       "      <th>Title_Ms</th>\n",
       "      <th>Title_Noble</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pclass  SibSp  Parch  Age_true  AgeGroup  FareGroup  CabinLvl  Embarked_C  \\\n",
       "0       1      0      2         1         0          4         7           0   \n",
       "1       3      0      0         0         3          1         0           0   \n",
       "2       3      1      1         1         0          2         0           0   \n",
       "3       2      1      2         1         4          3         0           0   \n",
       "4       2      1      1         1         4          3         0           0   \n",
       "\n",
       "   Embarked_Q  Embarked_S  Title_Master  Title_Mrs  Title_Ms  Title_Noble  \\\n",
       "0           0           1             1          0         0            0   \n",
       "1           0           1             0          0         0            0   \n",
       "2           0           1             0          0         1            0   \n",
       "3           0           1             0          0         0            0   \n",
       "4           0           1             0          0         0            0   \n",
       "\n",
       "   Survived  \n",
       "0         1  \n",
       "1         0  \n",
       "2         1  \n",
       "3         0  \n",
       "4         0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Age_true</th>\n",
       "      <th>AgeGroup</th>\n",
       "      <th>FareGroup</th>\n",
       "      <th>CabinLvl</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "      <th>Title_Master</th>\n",
       "      <th>Title_Mrs</th>\n",
       "      <th>Title_Ms</th>\n",
       "      <th>Title_Noble</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pclass  SibSp  Parch  Age_true  AgeGroup  FareGroup  CabinLvl  Embarked_C  \\\n",
       "0       3      1      1         0         0          2         0           1   \n",
       "1       2      0      0         1         3          1         0           0   \n",
       "2       3      0      0         1         2          1         0           0   \n",
       "3       2      0      1         1         0          3         0           0   \n",
       "4       3      1      0         1         1          2         0           1   \n",
       "\n",
       "   Embarked_Q  Embarked_S  Title_Master  Title_Mrs  Title_Ms  Title_Noble  \\\n",
       "0           0           0             1          0         0            0   \n",
       "1           0           1             0          0         0            0   \n",
       "2           0           1             0          0         0            0   \n",
       "3           0           1             0          0         1            0   \n",
       "4           0           0             0          0         1            0   \n",
       "\n",
       "   Survived  \n",
       "0         1  \n",
       "1         0  \n",
       "2         0  \n",
       "3         1  \n",
       "4         1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# read train and test data\n",
    "\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "# train_data\n",
    "train_data_files = sorted([f for f in os.listdir(\"data\") if (f.endswith(\".csv\") and (f.startswith(\"train_data_\")))], reverse=True)\n",
    "latest_train_data = train_data_files[0]\n",
    "train_data = pd.read_csv(f\"data/{latest_train_data}\")\n",
    "\n",
    "# drop new generated index column\n",
    "train_data.drop(train_data.columns[0], axis=1, inplace=True)\n",
    "train_data.drop(\"Title_Mr\", axis=1, inplace=True)\n",
    "#train_data.drop(\"Parch\", axis=1, inplace=True)\n",
    "display(train_data.head())\n",
    "\n",
    "# split train_data for models\n",
    "y_train = train_data['Survived']\n",
    "X_train = train_data.drop('Survived', axis=1)\n",
    "\n",
    "\n",
    "# test_data\n",
    "test_data_files = sorted([f for f in os.listdir(\"data\") if (f.endswith(\".csv\") and (f.startswith(\"test_data_\")))], reverse=True)\n",
    "latest_test_data = test_data_files[0]\n",
    "test_data = pd.read_csv(f\"data/{latest_test_data}\")\n",
    "\n",
    "#drop new generated index column\n",
    "test_data.drop(test_data.columns[0], axis=1, inplace=True)\n",
    "test_data.drop(\"Title_Mr\", axis=1, inplace=True)\n",
    "#test_data.drop(\"Parch\", axis=1, inplace=True)\n",
    "display(test_data.head())\n",
    "\n",
    "# split test_data for models\n",
    "y_test = test_data['Survived']\n",
    "X_test = test_data.drop('Survived', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "389b3127",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "675b47e0",
   "metadata": {},
   "source": [
    "## Model 1: Baseline Model\n",
    "\n",
    "Option A: Our baseline model predicts \"No Survival\" (Class 0) for all passengers since 0 is the most common value of variable 'Survived' in the train data. This results in an accuracy of 58.58% and a f1 score of 0% on the test data.  \n",
    "Option B: Our baseline model predicts \"Survival\" (Class 1) for first-class passengers and \"No Survival\" (Class 0) if a passenger has ticket class 2 or 3. We determined those values by taking the most common value of the variable 'Survived' for each 'Pclass' in the train data. This results in an accuracy of 69.40% and a f1 score of 56.38% on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "149eba15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.585820895522388\n",
      "F1 Score = 0.0\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      1.00      0.74       157\n",
      "           1       0.00      0.00      0.00       111\n",
      "\n",
      "    accuracy                           0.59       268\n",
      "   macro avg       0.29      0.50      0.37       268\n",
      "weighted avg       0.34      0.59      0.43       268\n",
      "\n",
      "Confusion Matrix:\n",
      "[[157   0]\n",
      " [111   0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kikip\\anaconda3\\envs\\dm1_hws22\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\kikip\\anaconda3\\envs\\dm1_hws22\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\kikip\\anaconda3\\envs\\dm1_hws22\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Option A - predict \"No Survival\" for all passengers\n",
    "train_data.groupby('Survived').size()\n",
    "\n",
    "baseline_pred_A = pd.Series(np.zeros(len(y_test)))\n",
    "\n",
    "baseline_acc_A = accuracy_score(y_test, baseline_pred_A)\n",
    "print(\"Accuracy =\", baseline_acc_A) #0.585820895522388\n",
    "\n",
    "baseline_f1_A = f1_score(y_test, baseline_pred_A)\n",
    "print(\"F1 Score =\", baseline_f1_A) #0.0\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, baseline_pred_A))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, baseline_pred_A))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "62b13d8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pclass  Survived\n",
      "1       0            56\n",
      "        1            83\n",
      "2       0            69\n",
      "        1            63\n",
      "3       0           267\n",
      "        1            85\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Option B - predict \"Survival\" or \"No Survival\" based on 'Pclass'\n",
    "\n",
    "# for each 'PClass' find number of passengers that survived and did not survive\n",
    "print(train_data.groupby(['Pclass', 'Survived']).size())\n",
    "# if 'Pclass'==1, we predict 'Survived'=1, else we predict 'Survived'=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3a04d4b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.6940298507462687\n",
      "F1 Score = 0.5638297872340425\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.85      0.76       157\n",
      "           1       0.69      0.48      0.56       111\n",
      "\n",
      "    accuracy                           0.69       268\n",
      "   macro avg       0.69      0.66      0.66       268\n",
      "weighted avg       0.69      0.69      0.68       268\n",
      "\n",
      "Confusion Matrix:\n",
      "[[133  24]\n",
      " [ 58  53]]\n"
     ]
    }
   ],
   "source": [
    "# make prediction\n",
    "X_test['baseline_pred_B'] = 0\n",
    "X_test.loc[X_test['Pclass'] == 1, 'baseline_pred_B'] = 1\n",
    "baseline_pred_B = X_test.baseline_pred_B\n",
    "X_test.drop('baseline_pred_B', axis=1, inplace=True)\n",
    "\n",
    "# print performance measures\n",
    "baseline_acc_B = accuracy_score(y_test, baseline_pred_B)\n",
    "print(\"Accuracy =\", baseline_acc_B) #0.6940298507462687\n",
    "\n",
    "baseline_f1_B = f1_score(y_test, baseline_pred_B)\n",
    "print(\"F1 Score =\", baseline_f1_B) #0.5638297872340425\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, baseline_pred_B))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, baseline_pred_B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b87fee6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "41d03a15",
   "metadata": {},
   "source": [
    "## Model 2: XGBoost\n",
    "We train the _XGBClassifier_ from the _xgboost_-module. First, we train a simple model with the default parameters and then we perform grid search to determine the best hyper parameter combination for our data set.\n",
    "\n",
    "https://www.datacamp.com/tutorial/xgboost-in-python  \n",
    "https://thinkingneuron.com/how-to-create-a-classification-model-using-xgboost-in-python/  \n",
    "https://towardsdatascience.com/a-guide-to-xgboost-hyperparameters-87980c7f44a9 (Hyperparameter Cheatsheet)  \n",
    "https://towardsdatascience.com/beyond-grid-search-hypercharge-hyperparameter-tuning-for-xgboost-7c78f7a2929d (Step by Step Tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "556c7c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "949742ca",
   "metadata": {},
   "source": [
    "### Simple XGB-Classifier with default parameters\n",
    "As a baseline for the xgboost Classifier we train it with the default parameters which results in an accuracy of 79.10% and a f1 score of 73.08%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0a53a8be",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.8022388059701493\n",
      "F1 Score = 0.7439613526570048\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.88      0.84       157\n",
      "           1       0.80      0.69      0.74       111\n",
      "\n",
      "    accuracy                           0.80       268\n",
      "   macro avg       0.80      0.79      0.79       268\n",
      "weighted avg       0.80      0.80      0.80       268\n",
      "\n",
      "Confusion Matrix:\n",
      "[[138  19]\n",
      " [ 34  77]]\n"
     ]
    }
   ],
   "source": [
    "# simple XGB-Classifier with default parameters\n",
    "\n",
    "random.seed(10)\n",
    "\n",
    "xgb_simple = XGBClassifier()\n",
    "xgb_simple.fit(X_train, y_train)\n",
    "xgb_simple_pred = xgb_simple.predict(X_test)\n",
    "\n",
    "xgb_simple_acc = accuracy_score(y_test, xgb_simple_pred)\n",
    "print(\"Accuracy =\", xgb_simple_acc) #0.7910447761194029\n",
    "\n",
    "xgb_simple_f1 = f1_score(y_test, xgb_simple_pred)\n",
    "print(\"F1 Score =\", xgb_simple_f1) #0.7307692307692308\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, xgb_simple_pred))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, xgb_simple_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ec1b716",
   "metadata": {},
   "source": [
    "## Tests for best combinations -> delete later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b2b9fd3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cb6bcc1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.8134328358208955\n",
      "F1 Score = 0.7572815533980582\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.89      0.85       157\n",
      "           1       0.82      0.70      0.76       111\n",
      "\n",
      "    accuracy                           0.81       268\n",
      "   macro avg       0.82      0.80      0.80       268\n",
      "weighted avg       0.81      0.81      0.81       268\n",
      "\n",
      "Confusion Matrix:\n",
      "[[140  17]\n",
      " [ 33  78]]\n"
     ]
    }
   ],
   "source": [
    "# Fit and evaluate best model\n",
    "\n",
    "xgb_best = XGBClassifier(max_depth = 4, subsample = 0.9, colsample_bylevel = 0.4, colsample_bytree = 0.4, learning_rate = 0.15, n_estimators = 30, gamma = 1)\n",
    "xgb_best.fit(X_train, y_train)\n",
    "xgb_best_pred = xgb_best.predict(X_test)\n",
    "\n",
    "xgb_best_acc = accuracy_score(y_test, xgb_best_pred)\n",
    "print(\"Accuracy =\", xgb_best_acc) #0.8283582089552238\n",
    "\n",
    "xgb_best_f1 = f1_score(y_test, xgb_best_pred)\n",
    "print(\"F1 Score =\", xgb_best_f1) #0.7788461538461539\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, xgb_best_pred))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, xgb_best_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "599121cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.8171641791044776\n",
      "F1 Score = 0.7562189054726368\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.91      0.85       157\n",
      "           1       0.84      0.68      0.76       111\n",
      "\n",
      "    accuracy                           0.82       268\n",
      "   macro avg       0.82      0.80      0.80       268\n",
      "weighted avg       0.82      0.82      0.81       268\n",
      "\n",
      "Confusion Matrix:\n",
      "[[143  14]\n",
      " [ 35  76]]\n"
     ]
    }
   ],
   "source": [
    "# Fit and evaluate second best model with n_estimators=20\n",
    "\n",
    "xgb_best = XGBClassifier(max_depth = 3, subsample = 0.6, colsample_bylevel = 0.2, colsample_bytree = 0.9, learning_rate = 0.15, n_estimators = 20, gamma = 1)\n",
    "xgb_best.fit(X_train, y_train)\n",
    "xgb_best_pred = xgb_best.predict(X_test)\n",
    "\n",
    "xgb_best_acc = accuracy_score(y_test, xgb_best_pred)\n",
    "print(\"Accuracy =\", xgb_best_acc) #0.8395522388059702\n",
    "\n",
    "xgb_best_f1 = f1_score(y_test, xgb_best_pred)\n",
    "print(\"F1 Score =\", xgb_best_f1) #0.7922705314009663\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, xgb_best_pred))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, xgb_best_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2be46ad6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.8134328358208955\n",
      "F1 Score = 0.7572815533980582\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.89      0.85       157\n",
      "           1       0.82      0.70      0.76       111\n",
      "\n",
      "    accuracy                           0.81       268\n",
      "   macro avg       0.82      0.80      0.80       268\n",
      "weighted avg       0.81      0.81      0.81       268\n",
      "\n",
      "Confusion Matrix:\n",
      "[[140  17]\n",
      " [ 33  78]]\n"
     ]
    }
   ],
   "source": [
    "# Fit and evaluate best model\n",
    "\n",
    "xgb_best = XGBClassifier(max_depth = 4, subsample = 0.9, colsample_bylevel = 0.4, colsample_bytree = 0.4, learning_rate = 0.15, n_estimators = 30, gamma = 1)\n",
    "xgb_best.fit(X_train, y_train)\n",
    "xgb_best_pred = xgb_best.predict(X_test)\n",
    "\n",
    "xgb_best_acc = accuracy_score(y_test, xgb_best_pred)\n",
    "print(\"Accuracy =\", xgb_best_acc) #0.8283582089552238\n",
    "\n",
    "xgb_best_f1 = f1_score(y_test, xgb_best_pred)\n",
    "print(\"F1 Score =\", xgb_best_f1) #0.7788461538461539\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, xgb_best_pred))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, xgb_best_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "56c9f11e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.8171641791044776\n",
      "F1 Score = 0.772093023255814\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.87      0.85       157\n",
      "           1       0.80      0.75      0.77       111\n",
      "\n",
      "    accuracy                           0.82       268\n",
      "   macro avg       0.81      0.81      0.81       268\n",
      "weighted avg       0.82      0.82      0.82       268\n",
      "\n",
      "Confusion Matrix:\n",
      "[[136  21]\n",
      " [ 28  83]]\n"
     ]
    }
   ],
   "source": [
    "# Fit and evaluate best model\n",
    "\n",
    "xgb_best = XGBClassifier(max_depth = 3, subsample = 0.6, colsample_bylevel = 0.2, colsample_bytree = 0.9, learning_rate = 0.7, n_estimators = 100, gamma = 0)\n",
    "\n",
    "xgb_best.fit(X_train, y_train)\n",
    "xgb_best_pred = xgb_best.predict(X_test)\n",
    "\n",
    "xgb_best_acc = accuracy_score(y_test, xgb_best_pred)\n",
    "print(\"Accuracy =\", xgb_best_acc) #0.8470149253731343\n",
    "\n",
    "xgb_best_f1 = f1_score(y_test, xgb_best_pred)\n",
    "print(\"F1 Score =\", xgb_best_f1) #0.8038277511961723\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, xgb_best_pred))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, xgb_best_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3561ca96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.8097014925373134\n",
      "F1 Score = 0.7559808612440191\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.88      0.84       157\n",
      "           1       0.81      0.71      0.76       111\n",
      "\n",
      "    accuracy                           0.81       268\n",
      "   macro avg       0.81      0.80      0.80       268\n",
      "weighted avg       0.81      0.81      0.81       268\n",
      "\n",
      "Confusion Matrix:\n",
      "[[138  19]\n",
      " [ 32  79]]\n"
     ]
    }
   ],
   "source": [
    "# Lenas Parameter\n",
    "\n",
    "xgb_best = XGBClassifier(max_depth = 5, subsample = 0.9, colsample_bylevel = 0.8, colsample_bytree = 0.5, learning_rate = 0.008, n_estimators = 100, gamma = 0.9, scale_pos_weight = 1)\n",
    "xgb_best.fit(X_train, y_train)\n",
    "xgb_best_pred = xgb_best.predict(X_test)\n",
    "\n",
    "xgb_best_acc = accuracy_score(y_test, xgb_best_pred)\n",
    "print(\"Accuracy =\", xgb_best_acc) #0.8470149253731343\n",
    "\n",
    "xgb_best_f1 = f1_score(y_test, xgb_best_pred)\n",
    "print(\"F1 Score =\", xgb_best_f1) #0.8038277511961723\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, xgb_best_pred))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, xgb_best_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "171c9403",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c33b3f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "079b5fd7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9fb5892c",
   "metadata": {},
   "source": [
    "### Hyper parameter-Tuning for best hyper parameter setting\n",
    "\n",
    "We perform grid search to find the best hyper parameter setting using the following hyper parameters:\n",
    "- _max_depth_\n",
    "- _subsample_\n",
    "- _gamma_\n",
    "- _colsample_bytree_\n",
    "- _colsample_bylevel_\n",
    "- _learning_rate_\n",
    "- _n _estimators_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "387ab105",
   "metadata": {},
   "source": [
    "#### First Attempt\n",
    "We start by tuning on a small grid, i.e., we only use two possible values for each hyper parameter. The best combination of hyper parameters for this grid search is: {'colsample_bylevel': 0.3, 'colsample_bytree': 0.3, 'learning_rate': 0.3, 'max_depth': 3, 'n_estimators': 50, 'subsample': 0.8}. Then, we train the XGBoost Classifier with this hyper parameter setting on the whole train data which results in an accuracy of 82.09% and a f1 score of 77.36%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "48dc982a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_colsample_bylevel</th>\n",
       "      <th>param_colsample_bytree</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_subsample</th>\n",
       "      <th>...</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.041589</td>\n",
       "      <td>0.002445</td>\n",
       "      <td>0.006982</td>\n",
       "      <td>0.000772</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>3</td>\n",
       "      <td>50</td>\n",
       "      <td>0.3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.828111</td>\n",
       "      <td>0.053381</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.043582</td>\n",
       "      <td>0.009452</td>\n",
       "      <td>0.007281</td>\n",
       "      <td>0.000639</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>3</td>\n",
       "      <td>50</td>\n",
       "      <td>0.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.840911</td>\n",
       "      <td>0.054557</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.107213</td>\n",
       "      <td>0.046503</td>\n",
       "      <td>0.007082</td>\n",
       "      <td>0.000698</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>0.3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.834460</td>\n",
       "      <td>0.051520</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.073005</td>\n",
       "      <td>0.003420</td>\n",
       "      <td>0.006882</td>\n",
       "      <td>0.000828</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>0.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.887097</td>\n",
       "      <td>0.840911</td>\n",
       "      <td>0.060452</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.048371</td>\n",
       "      <td>0.007506</td>\n",
       "      <td>0.007880</td>\n",
       "      <td>0.001218</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "      <td>0.3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.824910</td>\n",
       "      <td>0.055406</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>0.079586</td>\n",
       "      <td>0.000746</td>\n",
       "      <td>0.007082</td>\n",
       "      <td>0.000299</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.7</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>0.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.816795</td>\n",
       "      <td>0.048534</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>0.049468</td>\n",
       "      <td>0.001558</td>\n",
       "      <td>0.007281</td>\n",
       "      <td>0.000457</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.7</td>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "      <td>0.3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.784869</td>\n",
       "      <td>0.050181</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>0.051462</td>\n",
       "      <td>0.001277</td>\n",
       "      <td>0.007680</td>\n",
       "      <td>0.000458</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.7</td>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "      <td>0.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.813646</td>\n",
       "      <td>0.055833</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>0.086868</td>\n",
       "      <td>0.000829</td>\n",
       "      <td>0.007679</td>\n",
       "      <td>0.000457</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.7</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>0.3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.807322</td>\n",
       "      <td>0.036917</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>0.092054</td>\n",
       "      <td>0.001097</td>\n",
       "      <td>0.007580</td>\n",
       "      <td>0.000488</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.7</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>0.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.808807</td>\n",
       "      <td>0.054185</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>64 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0        0.041589      0.002445         0.006982        0.000772   \n",
       "1        0.043582      0.009452         0.007281        0.000639   \n",
       "2        0.107213      0.046503         0.007082        0.000698   \n",
       "3        0.073005      0.003420         0.006882        0.000828   \n",
       "4        0.048371      0.007506         0.007880        0.001218   \n",
       "..            ...           ...              ...             ...   \n",
       "59       0.079586      0.000746         0.007082        0.000299   \n",
       "60       0.049468      0.001558         0.007281        0.000457   \n",
       "61       0.051462      0.001277         0.007680        0.000458   \n",
       "62       0.086868      0.000829         0.007679        0.000457   \n",
       "63       0.092054      0.001097         0.007580        0.000488   \n",
       "\n",
       "   param_colsample_bylevel param_colsample_bytree param_learning_rate  \\\n",
       "0                      0.3                    0.3                 0.3   \n",
       "1                      0.3                    0.3                 0.3   \n",
       "2                      0.3                    0.3                 0.3   \n",
       "3                      0.3                    0.3                 0.3   \n",
       "4                      0.3                    0.3                 0.3   \n",
       "..                     ...                    ...                 ...   \n",
       "59                     0.8                    0.8                 0.7   \n",
       "60                     0.8                    0.8                 0.7   \n",
       "61                     0.8                    0.8                 0.7   \n",
       "62                     0.8                    0.8                 0.7   \n",
       "63                     0.8                    0.8                 0.7   \n",
       "\n",
       "   param_max_depth param_n_estimators param_subsample  ... split3_test_score  \\\n",
       "0                3                 50             0.3  ...          0.870968   \n",
       "1                3                 50             0.8  ...          0.870968   \n",
       "2                3                100             0.3  ...          0.838710   \n",
       "3                3                100             0.8  ...          0.822581   \n",
       "4                5                 50             0.3  ...          0.854839   \n",
       "..             ...                ...             ...  ...               ...   \n",
       "59               3                100             0.8  ...          0.838710   \n",
       "60               5                 50             0.3  ...          0.806452   \n",
       "61               5                 50             0.8  ...          0.838710   \n",
       "62               5                100             0.3  ...          0.822581   \n",
       "63               5                100             0.8  ...          0.854839   \n",
       "\n",
       "    split4_test_score  split5_test_score  split6_test_score  \\\n",
       "0            0.838710           0.838710           0.806452   \n",
       "1            0.822581           0.870968           0.822581   \n",
       "2            0.838710           0.822581           0.838710   \n",
       "3            0.806452           0.854839           0.854839   \n",
       "4            0.790323           0.854839           0.822581   \n",
       "..                ...                ...                ...   \n",
       "59           0.790323           0.774194           0.854839   \n",
       "60           0.774194           0.725806           0.870968   \n",
       "61           0.806452           0.725806           0.870968   \n",
       "62           0.790323           0.790323           0.854839   \n",
       "63           0.758065           0.758065           0.838710   \n",
       "\n",
       "    split7_test_score  split8_test_score  split9_test_score  mean_test_score  \\\n",
       "0            0.838710           0.677419           0.838710         0.828111   \n",
       "1            0.838710           0.693548           0.854839         0.840911   \n",
       "2            0.822581           0.693548           0.854839         0.834460   \n",
       "3            0.870968           0.677419           0.887097         0.840911   \n",
       "4            0.854839           0.677419           0.838710         0.824910   \n",
       "..                ...                ...                ...              ...   \n",
       "59           0.806452           0.709677           0.806452         0.816795   \n",
       "60           0.758065           0.693548           0.838710         0.784869   \n",
       "61           0.790323           0.709677           0.854839         0.813646   \n",
       "62           0.806452           0.725806           0.822581         0.807322   \n",
       "63           0.790323           0.693548           0.854839         0.808807   \n",
       "\n",
       "    std_test_score  rank_test_score  \n",
       "0         0.053381               18  \n",
       "1         0.054557                1  \n",
       "2         0.051520                8  \n",
       "3         0.060452                1  \n",
       "4         0.055406               25  \n",
       "..             ...              ...  \n",
       "59        0.048534               44  \n",
       "60        0.050181               64  \n",
       "61        0.055833               46  \n",
       "62        0.036917               55  \n",
       "63        0.054185               53  \n",
       "\n",
       "[64 rows x 24 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score is 0.8409114183307732 with params {'colsample_bylevel': 0.3, 'colsample_bytree': 0.3, 'learning_rate': 0.3, 'max_depth': 3, 'n_estimators': 50, 'subsample': 0.8}\n"
     ]
    }
   ],
   "source": [
    "# First Attempt\n",
    "\n",
    "random.seed(10)\n",
    "\n",
    "# create an estimator\n",
    "xgb = XGBClassifier()\n",
    "\n",
    "# specify the parameter grid\n",
    "xgb_parameters = {\n",
    "    'max_depth': [3, 5]\n",
    "    , 'subsample': [0.3, 0.8]\n",
    "    , 'colsample_bytree': [0.3, 0.8]\n",
    "    , 'colsample_bylevel': [0.3, 0.8]\n",
    "    , 'learning_rate': [0.3, 0.7]\n",
    "    , 'n_estimators': [50, 100]\n",
    "    #, 'gamma': [0.5, 1, 3]\n",
    "}\n",
    "\n",
    "# specify the cross validation\n",
    "stratified_10_fold_cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "# create grid search instance\n",
    "xgb_grid_search = GridSearchCV(xgb, xgb_parameters, scoring='accuracy', cv=stratified_10_fold_cv)\n",
    "\n",
    "# run the grid search\n",
    "xgb_grid_search.fit(X_train, y_train)\n",
    "\n",
    "# print the results of all hyper parameter combinations\n",
    "xgb_grid_search_results_round1 = pd.DataFrame(xgb_grid_search.cv_results_)\n",
    "display(xgb_grid_search_results_round1)\n",
    "\n",
    "# print the best parameter setting\n",
    "print(\"best score is {} with params {}\".format(xgb_grid_search.best_score_, xgb_grid_search.best_params_))\n",
    "#best score is 0.8409114183307732 with params\n",
    "#{'colsample_bylevel': 0.3, 'colsample_bytree': 0.3, 'learning_rate': 0.3, 'max_depth': 3, 'n_estimators': 50, 'subsample': 0.8}\n",
    "\n",
    "# save dataframe\n",
    "from datetime import datetime\n",
    "date = str(datetime.now().date()).replace(\"-\", \"\")\n",
    "xgb_grid_search_results_round1.to_csv(f\"results/xgb_results_round1_{date}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4abbd5a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_subsample</th>\n",
       "      <th>param_colsample_bylevel</th>\n",
       "      <th>param_colsample_bytree</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>50</td>\n",
       "      <td>0.840911</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>100</td>\n",
       "      <td>0.840911</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.7</td>\n",
       "      <td>100</td>\n",
       "      <td>0.839247</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>5</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.3</td>\n",
       "      <td>50</td>\n",
       "      <td>0.836175</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>3</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.3</td>\n",
       "      <td>50</td>\n",
       "      <td>0.836098</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.7</td>\n",
       "      <td>50</td>\n",
       "      <td>0.797491</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.7</td>\n",
       "      <td>100</td>\n",
       "      <td>0.797491</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.7</td>\n",
       "      <td>100</td>\n",
       "      <td>0.795955</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.7</td>\n",
       "      <td>50</td>\n",
       "      <td>0.792857</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.7</td>\n",
       "      <td>50</td>\n",
       "      <td>0.784869</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>64 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   param_max_depth param_subsample param_colsample_bylevel  \\\n",
       "1                3             0.8                     0.3   \n",
       "3                3             0.8                     0.3   \n",
       "11               3             0.8                     0.3   \n",
       "21               5             0.8                     0.3   \n",
       "17               3             0.8                     0.3   \n",
       "..             ...             ...                     ...   \n",
       "28               5             0.3                     0.3   \n",
       "46               5             0.3                     0.8   \n",
       "30               5             0.3                     0.3   \n",
       "44               5             0.3                     0.8   \n",
       "60               5             0.3                     0.8   \n",
       "\n",
       "   param_colsample_bytree param_learning_rate param_n_estimators  \\\n",
       "1                     0.3                 0.3                 50   \n",
       "3                     0.3                 0.3                100   \n",
       "11                    0.3                 0.7                100   \n",
       "21                    0.8                 0.3                 50   \n",
       "17                    0.8                 0.3                 50   \n",
       "..                    ...                 ...                ...   \n",
       "28                    0.8                 0.7                 50   \n",
       "46                    0.3                 0.7                100   \n",
       "30                    0.8                 0.7                100   \n",
       "44                    0.3                 0.7                 50   \n",
       "60                    0.8                 0.7                 50   \n",
       "\n",
       "    mean_test_score  rank_test_score  \n",
       "1          0.840911                1  \n",
       "3          0.840911                1  \n",
       "11         0.839247                3  \n",
       "21         0.836175                4  \n",
       "17         0.836098                5  \n",
       "..              ...              ...  \n",
       "28         0.797491               60  \n",
       "46         0.797491               61  \n",
       "30         0.795955               62  \n",
       "44         0.792857               63  \n",
       "60         0.784869               64  \n",
       "\n",
       "[64 rows x 8 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# store relevant columns and sort by rank_test_score\n",
    "cols_round1 = ['param_max_depth', 'param_subsample', 'param_colsample_bylevel', 'param_colsample_bytree', 'param_learning_rate', 'param_n_estimators', 'mean_test_score', 'rank_test_score']\n",
    "xgb_results_round1_sorted = xgb_grid_search_results_round1[cols_round1]\n",
    "xgb_results_round1_sorted = xgb_results_round1_sorted.sort_values(by='rank_test_score')\n",
    "display(xgb_results_round1_sorted)\n",
    "\n",
    "# save dataframe\n",
    "from datetime import datetime\n",
    "date = str(datetime.now().date()).replace(\"-\", \"\")\n",
    "xgb_results_round1_sorted.to_csv(f\"results/xgb_results_round1_sorted_{date}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aec0ba87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.8208955223880597\n",
      "F1 Score = 0.7735849056603774\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.88      0.85       157\n",
      "           1       0.81      0.74      0.77       111\n",
      "\n",
      "    accuracy                           0.82       268\n",
      "   macro avg       0.82      0.81      0.81       268\n",
      "weighted avg       0.82      0.82      0.82       268\n",
      "\n",
      "Confusion Matrix:\n",
      "[[138  19]\n",
      " [ 29  82]]\n"
     ]
    }
   ],
   "source": [
    "# Fit and evaluate best model\n",
    "\n",
    "xgb_best = XGBClassifier(max_depth = 3, subsample = 0.8, colsample_bylevel = 0.3, colsample_bytree = 0.3, learning_rate = 0.3, n_estimators = 50)\n",
    "xgb_best.fit(X_train, y_train)\n",
    "xgb_best_pred = xgb_best.predict(X_test)\n",
    "\n",
    "xgb_best_acc = accuracy_score(y_test, xgb_best_pred)\n",
    "print(\"Accuracy =\", xgb_best_acc) #0.8208955223880597\n",
    "\n",
    "xgb_best_f1 = f1_score(y_test, xgb_best_pred)\n",
    "print(\"F1 Score =\", xgb_best_f1) #0.7735849056603774\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, xgb_best_pred))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, xgb_best_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "940748c1",
   "metadata": {},
   "source": [
    "#### Second Attempt\n",
    "We perform a hyper parameter tuning using the following parameters and values:  \n",
    "\n",
    "{'max_depth': [2,3,4,5]  \n",
    ", 'subsample': [0.5, 0.6, 0.7, 0.8, 0.9]  \n",
    ", 'colsample_bytree': [0.3, 0.4, 0.5, 0.6, 0.9]  \n",
    ", 'colsample_bylevel': [0.1, 0.2, 0.3, 0.4, 0.6, 0.7]  \n",
    ", 'learning_rate': [0.1, 0.15, 0.2, 0.25, 0.3, 0.4]  \n",
    ", 'n_estimators': [100, 150, 200, 250, 300]}  \n",
    "\n",
    "The best hyper parameter setting results to be {'colsample_bylevel': 0.4, 'colsample_bytree': 0.5, 'learning_rate': 0.15, 'max_depth': 2, 'n_estimators': 100, 'subsample': 0.7} which leads to an accuracy of 82.84% and a f1 score of 77.88% on the test data (after training the classifier on the whole train data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f96d3ba4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_colsample_bylevel</th>\n",
       "      <th>param_colsample_bytree</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_subsample</th>\n",
       "      <th>...</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.064527</td>\n",
       "      <td>0.004136</td>\n",
       "      <td>0.005885</td>\n",
       "      <td>0.000538</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.820020</td>\n",
       "      <td>0.048275</td>\n",
       "      <td>15186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.064327</td>\n",
       "      <td>0.002493</td>\n",
       "      <td>0.005885</td>\n",
       "      <td>0.000537</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.661290</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.823221</td>\n",
       "      <td>0.059057</td>\n",
       "      <td>12810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.063231</td>\n",
       "      <td>0.001954</td>\n",
       "      <td>0.005785</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.824782</td>\n",
       "      <td>0.057512</td>\n",
       "      <td>12084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.062235</td>\n",
       "      <td>0.001017</td>\n",
       "      <td>0.006082</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.661290</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.824834</td>\n",
       "      <td>0.059251</td>\n",
       "      <td>11402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.062333</td>\n",
       "      <td>0.002285</td>\n",
       "      <td>0.005784</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.828059</td>\n",
       "      <td>0.053977</td>\n",
       "      <td>8256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17995</th>\n",
       "      <td>0.228489</td>\n",
       "      <td>0.002462</td>\n",
       "      <td>0.007480</td>\n",
       "      <td>0.000499</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.802355</td>\n",
       "      <td>0.049888</td>\n",
       "      <td>17998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17996</th>\n",
       "      <td>0.228688</td>\n",
       "      <td>0.002142</td>\n",
       "      <td>0.007281</td>\n",
       "      <td>0.000457</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.800768</td>\n",
       "      <td>0.052893</td>\n",
       "      <td>17999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17997</th>\n",
       "      <td>0.228987</td>\n",
       "      <td>0.001197</td>\n",
       "      <td>0.007580</td>\n",
       "      <td>0.000488</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.810317</td>\n",
       "      <td>0.057193</td>\n",
       "      <td>17871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17998</th>\n",
       "      <td>0.228788</td>\n",
       "      <td>0.001620</td>\n",
       "      <td>0.007181</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.816692</td>\n",
       "      <td>0.055624</td>\n",
       "      <td>17108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17999</th>\n",
       "      <td>0.226893</td>\n",
       "      <td>0.002150</td>\n",
       "      <td>0.007381</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.818382</td>\n",
       "      <td>0.053516</td>\n",
       "      <td>16381</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18000 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0           0.064527      0.004136         0.005885        0.000538   \n",
       "1           0.064327      0.002493         0.005885        0.000537   \n",
       "2           0.063231      0.001954         0.005785        0.000399   \n",
       "3           0.062235      0.001017         0.006082        0.000300   \n",
       "4           0.062333      0.002285         0.005784        0.000399   \n",
       "...              ...           ...              ...             ...   \n",
       "17995       0.228489      0.002462         0.007480        0.000499   \n",
       "17996       0.228688      0.002142         0.007281        0.000457   \n",
       "17997       0.228987      0.001197         0.007580        0.000488   \n",
       "17998       0.228788      0.001620         0.007181        0.000399   \n",
       "17999       0.226893      0.002150         0.007381        0.000489   \n",
       "\n",
       "       param_colsample_bylevel  param_colsample_bytree  param_learning_rate  \\\n",
       "0                          0.1                     0.3                  0.1   \n",
       "1                          0.1                     0.3                  0.1   \n",
       "2                          0.1                     0.3                  0.1   \n",
       "3                          0.1                     0.3                  0.1   \n",
       "4                          0.1                     0.3                  0.1   \n",
       "...                        ...                     ...                  ...   \n",
       "17995                      0.7                     0.9                  0.4   \n",
       "17996                      0.7                     0.9                  0.4   \n",
       "17997                      0.7                     0.9                  0.4   \n",
       "17998                      0.7                     0.9                  0.4   \n",
       "17999                      0.7                     0.9                  0.4   \n",
       "\n",
       "       param_max_depth  param_n_estimators  param_subsample  ...  \\\n",
       "0                    2                 100              0.5  ...   \n",
       "1                    2                 100              0.6  ...   \n",
       "2                    2                 100              0.7  ...   \n",
       "3                    2                 100              0.8  ...   \n",
       "4                    2                 100              0.9  ...   \n",
       "...                ...                 ...              ...  ...   \n",
       "17995                5                 300              0.5  ...   \n",
       "17996                5                 300              0.6  ...   \n",
       "17997                5                 300              0.7  ...   \n",
       "17998                5                 300              0.8  ...   \n",
       "17999                5                 300              0.9  ...   \n",
       "\n",
       "      split3_test_score  split4_test_score  split5_test_score  \\\n",
       "0              0.822581           0.822581           0.806452   \n",
       "1              0.838710           0.822581           0.806452   \n",
       "2              0.838710           0.806452           0.806452   \n",
       "3              0.854839           0.822581           0.806452   \n",
       "4              0.854839           0.822581           0.838710   \n",
       "...                 ...                ...                ...   \n",
       "17995          0.822581           0.774194           0.806452   \n",
       "17996          0.822581           0.774194           0.790323   \n",
       "17997          0.870968           0.774194           0.774194   \n",
       "17998          0.822581           0.790323           0.774194   \n",
       "17999          0.806452           0.790323           0.774194   \n",
       "\n",
       "       split6_test_score  split7_test_score  split8_test_score  \\\n",
       "0               0.822581           0.806452           0.693548   \n",
       "1               0.838710           0.806452           0.661290   \n",
       "2               0.838710           0.806452           0.677419   \n",
       "3               0.854839           0.806452           0.661290   \n",
       "4               0.838710           0.806452           0.677419   \n",
       "...                  ...                ...                ...   \n",
       "17995           0.822581           0.774194           0.709677   \n",
       "17996           0.822581           0.790323           0.693548   \n",
       "17997           0.790323           0.790323           0.709677   \n",
       "17998           0.822581           0.790323           0.709677   \n",
       "17999           0.854839           0.790323           0.709677   \n",
       "\n",
       "       split9_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0               0.838710         0.820020        0.048275            15186  \n",
       "1               0.854839         0.823221        0.059057            12810  \n",
       "2               0.838710         0.824782        0.057512            12084  \n",
       "3               0.838710         0.824834        0.059251            11402  \n",
       "4               0.838710         0.828059        0.053977             8256  \n",
       "...                  ...              ...             ...              ...  \n",
       "17995           0.774194         0.802355        0.049888            17998  \n",
       "17996           0.790323         0.800768        0.052893            17999  \n",
       "17997           0.790323         0.810317        0.057193            17871  \n",
       "17998           0.806452         0.816692        0.055624            17108  \n",
       "17999           0.854839         0.818382        0.053516            16381  \n",
       "\n",
       "[18000 rows x 24 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score is 0.850563 with params {'colsample_bylevel': 0.4, 'colsample_bytree': 0.5, 'learning_rate': 0.15, 'max_depth': 2, 'n_estimators': 100, 'subsample': 0.7}\n"
     ]
    }
   ],
   "source": [
    "# read single parts of round 2, concatenate and update index and rank_test_score\n",
    "\n",
    "df1 = pd.read_csv(\"data\\\\xgb_results_full_1_bylevel=0.1_20221123.csv\")\n",
    "df1.drop(df1.columns[0], axis=1, inplace=True)\n",
    "\n",
    "df2 = pd.read_csv(\"data\\\\xgb_results_full_2_bylevel=0.2_20221123.csv\")\n",
    "df2.drop(df2.columns[0], axis=1, inplace=True)\n",
    "\n",
    "df3 = pd.read_csv(\"data\\\\xgb_results_full_3_bylevel=0.3_20221123.csv\")\n",
    "df3.drop(df3.columns[0], axis=1, inplace=True)\n",
    "\n",
    "df4 = pd.read_csv(\"data\\\\xgb_results_full_4_bylevel=0.4_20221123.csv\")\n",
    "df4.drop(df4.columns[0], axis=1, inplace=True)\n",
    "\n",
    "df5 = pd.read_csv(\"data\\\\xgb_results_full_5_bylevel=0.6_20221123.csv\")\n",
    "df5.drop(df5.columns[0], axis=1, inplace=True)\n",
    "\n",
    "df6 = pd.read_csv(\"data\\\\xgb_results_full_6_bylevel=0.7_20221123.csv\")\n",
    "df6.drop(df6.columns[0], axis=1, inplace=True)\n",
    "\n",
    "df_full = pd.concat([df1,df2,df3,df4,df5,df6])\n",
    "\n",
    "#assign correct rank\n",
    "df_full = df_full.sort_values(by='mean_test_score', ascending=False)\n",
    "df_full['rank_test_score'] = range(1, len(df_full)+1)\n",
    "\n",
    "#get correct order and set new index\n",
    "df_full = df_full.sort_values(by=['param_colsample_bylevel', 'param_colsample_bytree', 'param_learning_rate', 'param_max_depth', 'param_n_estimators', 'param_subsample'])\n",
    "xgb_grid_search_results_round2 = df_full.set_index(np.array(range(len(df_full))))\n",
    "display(xgb_grid_search_results_round2)\n",
    "\n",
    "print(\"best score is 0.850563 with params {'colsample_bylevel': 0.4, 'colsample_bytree': 0.5, 'learning_rate': 0.15, 'max_depth': 2, 'n_estimators': 100, 'subsample': 0.7}\")\n",
    "\n",
    "# save dataframe\n",
    "from datetime import datetime\n",
    "date = str(datetime.now().date()).replace(\"-\", \"\")\n",
    "xgb_grid_search_results_round2.to_csv(f\"results/xgb_results_round2_{date}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "435465f2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_colsample_bylevel</th>\n",
       "      <th>param_colsample_bytree</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_subsample</th>\n",
       "      <th>...</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.064527</td>\n",
       "      <td>0.004136</td>\n",
       "      <td>0.005885</td>\n",
       "      <td>0.000538</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.820020</td>\n",
       "      <td>0.048275</td>\n",
       "      <td>2840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.064327</td>\n",
       "      <td>0.002493</td>\n",
       "      <td>0.005885</td>\n",
       "      <td>0.000537</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.661290</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.823221</td>\n",
       "      <td>0.059057</td>\n",
       "      <td>5179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.063231</td>\n",
       "      <td>0.001954</td>\n",
       "      <td>0.005785</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.824782</td>\n",
       "      <td>0.057512</td>\n",
       "      <td>5860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.062235</td>\n",
       "      <td>0.001017</td>\n",
       "      <td>0.006082</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.661290</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.824834</td>\n",
       "      <td>0.059251</td>\n",
       "      <td>6715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.062333</td>\n",
       "      <td>0.002285</td>\n",
       "      <td>0.005784</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.828059</td>\n",
       "      <td>0.053977</td>\n",
       "      <td>9897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17995</th>\n",
       "      <td>0.228489</td>\n",
       "      <td>0.002462</td>\n",
       "      <td>0.007480</td>\n",
       "      <td>0.000499</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.802355</td>\n",
       "      <td>0.049888</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17996</th>\n",
       "      <td>0.228688</td>\n",
       "      <td>0.002142</td>\n",
       "      <td>0.007281</td>\n",
       "      <td>0.000457</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.800768</td>\n",
       "      <td>0.052893</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17997</th>\n",
       "      <td>0.228987</td>\n",
       "      <td>0.001197</td>\n",
       "      <td>0.007580</td>\n",
       "      <td>0.000488</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.810317</td>\n",
       "      <td>0.057193</td>\n",
       "      <td>139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17998</th>\n",
       "      <td>0.228788</td>\n",
       "      <td>0.001620</td>\n",
       "      <td>0.007181</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.816692</td>\n",
       "      <td>0.055624</td>\n",
       "      <td>893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17999</th>\n",
       "      <td>0.226893</td>\n",
       "      <td>0.002150</td>\n",
       "      <td>0.007381</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.818382</td>\n",
       "      <td>0.053516</td>\n",
       "      <td>1646</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18000 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0           0.064527      0.004136         0.005885        0.000538   \n",
       "1           0.064327      0.002493         0.005885        0.000537   \n",
       "2           0.063231      0.001954         0.005785        0.000399   \n",
       "3           0.062235      0.001017         0.006082        0.000300   \n",
       "4           0.062333      0.002285         0.005784        0.000399   \n",
       "...              ...           ...              ...             ...   \n",
       "17995       0.228489      0.002462         0.007480        0.000499   \n",
       "17996       0.228688      0.002142         0.007281        0.000457   \n",
       "17997       0.228987      0.001197         0.007580        0.000488   \n",
       "17998       0.228788      0.001620         0.007181        0.000399   \n",
       "17999       0.226893      0.002150         0.007381        0.000489   \n",
       "\n",
       "       param_colsample_bylevel  param_colsample_bytree  param_learning_rate  \\\n",
       "0                          0.1                     0.3                  0.1   \n",
       "1                          0.1                     0.3                  0.1   \n",
       "2                          0.1                     0.3                  0.1   \n",
       "3                          0.1                     0.3                  0.1   \n",
       "4                          0.1                     0.3                  0.1   \n",
       "...                        ...                     ...                  ...   \n",
       "17995                      0.7                     0.9                  0.4   \n",
       "17996                      0.7                     0.9                  0.4   \n",
       "17997                      0.7                     0.9                  0.4   \n",
       "17998                      0.7                     0.9                  0.4   \n",
       "17999                      0.7                     0.9                  0.4   \n",
       "\n",
       "       param_max_depth  param_n_estimators  param_subsample  ...  \\\n",
       "0                    2                 100              0.5  ...   \n",
       "1                    2                 100              0.6  ...   \n",
       "2                    2                 100              0.7  ...   \n",
       "3                    2                 100              0.8  ...   \n",
       "4                    2                 100              0.9  ...   \n",
       "...                ...                 ...              ...  ...   \n",
       "17995                5                 300              0.5  ...   \n",
       "17996                5                 300              0.6  ...   \n",
       "17997                5                 300              0.7  ...   \n",
       "17998                5                 300              0.8  ...   \n",
       "17999                5                 300              0.9  ...   \n",
       "\n",
       "      split3_test_score  split4_test_score  split5_test_score  \\\n",
       "0              0.822581           0.822581           0.806452   \n",
       "1              0.838710           0.822581           0.806452   \n",
       "2              0.838710           0.806452           0.806452   \n",
       "3              0.854839           0.822581           0.806452   \n",
       "4              0.854839           0.822581           0.838710   \n",
       "...                 ...                ...                ...   \n",
       "17995          0.822581           0.774194           0.806452   \n",
       "17996          0.822581           0.774194           0.790323   \n",
       "17997          0.870968           0.774194           0.774194   \n",
       "17998          0.822581           0.790323           0.774194   \n",
       "17999          0.806452           0.790323           0.774194   \n",
       "\n",
       "       split6_test_score  split7_test_score  split8_test_score  \\\n",
       "0               0.822581           0.806452           0.693548   \n",
       "1               0.838710           0.806452           0.661290   \n",
       "2               0.838710           0.806452           0.677419   \n",
       "3               0.854839           0.806452           0.661290   \n",
       "4               0.838710           0.806452           0.677419   \n",
       "...                  ...                ...                ...   \n",
       "17995           0.822581           0.774194           0.709677   \n",
       "17996           0.822581           0.790323           0.693548   \n",
       "17997           0.790323           0.790323           0.709677   \n",
       "17998           0.822581           0.790323           0.709677   \n",
       "17999           0.854839           0.790323           0.709677   \n",
       "\n",
       "       split9_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0               0.838710         0.820020        0.048275             2840  \n",
       "1               0.854839         0.823221        0.059057             5179  \n",
       "2               0.838710         0.824782        0.057512             5860  \n",
       "3               0.838710         0.824834        0.059251             6715  \n",
       "4               0.838710         0.828059        0.053977             9897  \n",
       "...                  ...              ...             ...              ...  \n",
       "17995           0.774194         0.802355        0.049888                3  \n",
       "17996           0.790323         0.800768        0.052893                2  \n",
       "17997           0.790323         0.810317        0.057193              139  \n",
       "17998           0.806452         0.816692        0.055624              893  \n",
       "17999           0.854839         0.818382        0.053516             1646  \n",
       "\n",
       "[18000 rows x 24 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Second Attempt\n",
    "\n",
    "random.seed(10)\n",
    "\n",
    "xgb = XGBClassifier()\n",
    "\n",
    "xgb_parameters = {'max_depth': [2,3,4,5]\n",
    "                , 'subsample': [0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "                , 'colsample_bytree': [0.3, 0.4, 0.5, 0.6, 0.9]\n",
    "                , 'colsample_bylevel': [0.1, 0.2, 0.3, 0.4, 0.6, 0.7]\n",
    "                , 'learning_rate': [0.1, 0.15, 0.2, 0.25, 0.3, 0.4]\n",
    "                , 'n_estimators': [100, 150, 200, 250, 300]}\n",
    "\n",
    "stratified_10_fold_cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "xgb_grid_search = GridSearchCV(xgb, xgb_parameters, scoring='accuracy', cv=stratified_10_fold_cv)\n",
    "\n",
    "xgb_grid_search.fit(X_train, y_train)\n",
    "\n",
    "xgb_grid_search_results_round2 = pd.DataFrame(xgb_grid_search.cv_results_)\n",
    "display(xgb_grid_search_results_round2)\n",
    "\n",
    "# print the best parameter setting\n",
    "print(\"best score is {} with params {}\".format(xgb_grid_search.best_score_, xgb_grid_search.best_params_))\n",
    "#best score is 0.850563 with params\n",
    "#{'colsample_bylevel': 0.4, 'colsample_bytree': 0.5, 'learning_rate': 0.15, 'max_depth': 2, 'n_estimators': 100, 'subsample': 0.7}\n",
    "\n",
    "# save dataframe\n",
    "from datetime import datetime\n",
    "date = str(datetime.now().date()).replace(\"-\", \"\")\n",
    "xgb_grid_search_results_round2.to_csv(f\"results/xgb_results_round2_{date}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e682b560",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_subsample</th>\n",
       "      <th>param_colsample_bylevel</th>\n",
       "      <th>param_colsample_bytree</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10302</th>\n",
       "      <td>2</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.15</td>\n",
       "      <td>100</td>\n",
       "      <td>0.850563</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7302</th>\n",
       "      <td>2</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.15</td>\n",
       "      <td>100</td>\n",
       "      <td>0.850563</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4976</th>\n",
       "      <td>5</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.15</td>\n",
       "      <td>100</td>\n",
       "      <td>0.850538</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1976</th>\n",
       "      <td>5</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.15</td>\n",
       "      <td>100</td>\n",
       "      <td>0.850538</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5419</th>\n",
       "      <td>2</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.10</td>\n",
       "      <td>250</td>\n",
       "      <td>0.849002</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7745</th>\n",
       "      <td>3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.40</td>\n",
       "      <td>300</td>\n",
       "      <td>0.803943</td>\n",
       "      <td>17996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13171</th>\n",
       "      <td>4</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.40</td>\n",
       "      <td>300</td>\n",
       "      <td>0.803917</td>\n",
       "      <td>17997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17995</th>\n",
       "      <td>5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.40</td>\n",
       "      <td>300</td>\n",
       "      <td>0.802355</td>\n",
       "      <td>17998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17996</th>\n",
       "      <td>5</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.40</td>\n",
       "      <td>300</td>\n",
       "      <td>0.800768</td>\n",
       "      <td>17999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17940</th>\n",
       "      <td>3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.40</td>\n",
       "      <td>250</td>\n",
       "      <td>0.800742</td>\n",
       "      <td>18000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18000 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       param_max_depth  param_subsample  param_colsample_bylevel  \\\n",
       "10302                2              0.7                      0.4   \n",
       "7302                 2              0.7                      0.3   \n",
       "4976                 5              0.6                      0.2   \n",
       "1976                 5              0.6                      0.1   \n",
       "5419                 2              0.9                      0.2   \n",
       "...                ...              ...                      ...   \n",
       "7745                 3              0.5                      0.3   \n",
       "13171                4              0.6                      0.6   \n",
       "17995                5              0.5                      0.7   \n",
       "17996                5              0.6                      0.7   \n",
       "17940                3              0.5                      0.7   \n",
       "\n",
       "       param_colsample_bytree  param_learning_rate  param_n_estimators  \\\n",
       "10302                     0.5                 0.15                 100   \n",
       "7302                      0.5                 0.15                 100   \n",
       "4976                      0.6                 0.15                 100   \n",
       "1976                      0.6                 0.15                 100   \n",
       "5419                      0.9                 0.10                 250   \n",
       "...                       ...                  ...                 ...   \n",
       "7745                      0.5                 0.40                 300   \n",
       "13171                     0.4                 0.40                 300   \n",
       "17995                     0.9                 0.40                 300   \n",
       "17996                     0.9                 0.40                 300   \n",
       "17940                     0.9                 0.40                 250   \n",
       "\n",
       "       mean_test_score  rank_test_score  \n",
       "10302         0.850563                1  \n",
       "7302          0.850563                2  \n",
       "4976          0.850538                3  \n",
       "1976          0.850538                4  \n",
       "5419          0.849002                5  \n",
       "...                ...              ...  \n",
       "7745          0.803943            17996  \n",
       "13171         0.803917            17997  \n",
       "17995         0.802355            17998  \n",
       "17996         0.800768            17999  \n",
       "17940         0.800742            18000  \n",
       "\n",
       "[18000 rows x 8 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# store relevant columns and sort by rank_test_score\n",
    "cols_round2 = ['param_max_depth', 'param_subsample', 'param_colsample_bylevel', 'param_colsample_bytree', 'param_learning_rate', 'param_n_estimators', 'mean_test_score', 'rank_test_score']\n",
    "xgb_results_round2_sorted = xgb_grid_search_results_round2[cols_round2]\n",
    "xgb_results_round2_sorted = xgb_results_round2_sorted.sort_values(by='rank_test_score')\n",
    "display(xgb_results_round2_sorted)\n",
    "\n",
    "# save dataframe\n",
    "from datetime import datetime\n",
    "date = str(datetime.now().date()).replace(\"-\", \"\")\n",
    "xgb_results_round2_sorted.to_csv(f\"results/xgb_results_round2_sorted_{date}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fc655747",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.8283582089552238\n",
      "F1 Score = 0.7788461538461539\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.90      0.86       157\n",
      "           1       0.84      0.73      0.78       111\n",
      "\n",
      "    accuracy                           0.83       268\n",
      "   macro avg       0.83      0.81      0.82       268\n",
      "weighted avg       0.83      0.83      0.83       268\n",
      "\n",
      "Confusion Matrix:\n",
      "[[141  16]\n",
      " [ 30  81]]\n"
     ]
    }
   ],
   "source": [
    "# Fit and evaluate best model\n",
    "\n",
    "xgb_best = XGBClassifier(max_depth = 2, subsample = 0.7, colsample_bylevel = 0.4, colsample_bytree = 0.5, learning_rate = 0.15, n_estimators = 100)\n",
    "xgb_best.fit(X_train, y_train)\n",
    "xgb_best_pred = xgb_best.predict(X_test)\n",
    "\n",
    "xgb_best_acc = accuracy_score(y_test, xgb_best_pred)\n",
    "print(\"Accuracy =\", xgb_best_acc) #0.8283582089552238\n",
    "\n",
    "xgb_best_f1 = f1_score(y_test, xgb_best_pred)\n",
    "print(\"F1 Score =\", xgb_best_f1) #0.7788461538461539\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, xgb_best_pred))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, xgb_best_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "250c3acb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d82f44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "66e8dc94",
   "metadata": {},
   "source": [
    "#### ausfÃ¼hrlich"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1dfcf6bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_colsample_bylevel</th>\n",
       "      <th>param_colsample_bytree</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_subsample</th>\n",
       "      <th>...</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.064527</td>\n",
       "      <td>0.004136</td>\n",
       "      <td>0.005885</td>\n",
       "      <td>5.376236e-04</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.820020</td>\n",
       "      <td>0.048275</td>\n",
       "      <td>2651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.064327</td>\n",
       "      <td>0.002493</td>\n",
       "      <td>0.005885</td>\n",
       "      <td>5.374151e-04</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.661290</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.823221</td>\n",
       "      <td>0.059057</td>\n",
       "      <td>2358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.063231</td>\n",
       "      <td>0.001954</td>\n",
       "      <td>0.005785</td>\n",
       "      <td>3.990535e-04</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.824782</td>\n",
       "      <td>0.057512</td>\n",
       "      <td>2252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.062235</td>\n",
       "      <td>0.001017</td>\n",
       "      <td>0.006082</td>\n",
       "      <td>3.001655e-04</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.661290</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.824834</td>\n",
       "      <td>0.059251</td>\n",
       "      <td>2175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.062333</td>\n",
       "      <td>0.002285</td>\n",
       "      <td>0.005784</td>\n",
       "      <td>3.991850e-04</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.828059</td>\n",
       "      <td>0.053977</td>\n",
       "      <td>1747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2995</th>\n",
       "      <td>0.180018</td>\n",
       "      <td>0.001496</td>\n",
       "      <td>0.007081</td>\n",
       "      <td>2.993507e-04</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.887097</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.828085</td>\n",
       "      <td>0.048801</td>\n",
       "      <td>1701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2996</th>\n",
       "      <td>0.182212</td>\n",
       "      <td>0.003339</td>\n",
       "      <td>0.006982</td>\n",
       "      <td>4.460618e-04</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.826421</td>\n",
       "      <td>0.052840</td>\n",
       "      <td>1992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2997</th>\n",
       "      <td>0.181813</td>\n",
       "      <td>0.001548</td>\n",
       "      <td>0.007082</td>\n",
       "      <td>2.990570e-04</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.824808</td>\n",
       "      <td>0.053239</td>\n",
       "      <td>2204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998</th>\n",
       "      <td>0.181666</td>\n",
       "      <td>0.001723</td>\n",
       "      <td>0.006982</td>\n",
       "      <td>4.529953e-07</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.823272</td>\n",
       "      <td>0.043729</td>\n",
       "      <td>2305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999</th>\n",
       "      <td>0.182113</td>\n",
       "      <td>0.002005</td>\n",
       "      <td>0.007081</td>\n",
       "      <td>2.993824e-04</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.823169</td>\n",
       "      <td>0.050024</td>\n",
       "      <td>2460</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0          0.064527      0.004136         0.005885    5.376236e-04   \n",
       "1          0.064327      0.002493         0.005885    5.374151e-04   \n",
       "2          0.063231      0.001954         0.005785    3.990535e-04   \n",
       "3          0.062235      0.001017         0.006082    3.001655e-04   \n",
       "4          0.062333      0.002285         0.005784    3.991850e-04   \n",
       "...             ...           ...              ...             ...   \n",
       "2995       0.180018      0.001496         0.007081    2.993507e-04   \n",
       "2996       0.182212      0.003339         0.006982    4.460618e-04   \n",
       "2997       0.181813      0.001548         0.007082    2.990570e-04   \n",
       "2998       0.181666      0.001723         0.006982    4.529953e-07   \n",
       "2999       0.182113      0.002005         0.007081    2.993824e-04   \n",
       "\n",
       "      param_colsample_bylevel  param_colsample_bytree  param_learning_rate  \\\n",
       "0                         0.1                     0.3                  0.1   \n",
       "1                         0.1                     0.3                  0.1   \n",
       "2                         0.1                     0.3                  0.1   \n",
       "3                         0.1                     0.3                  0.1   \n",
       "4                         0.1                     0.3                  0.1   \n",
       "...                       ...                     ...                  ...   \n",
       "2995                      0.1                     0.9                  0.4   \n",
       "2996                      0.1                     0.9                  0.4   \n",
       "2997                      0.1                     0.9                  0.4   \n",
       "2998                      0.1                     0.9                  0.4   \n",
       "2999                      0.1                     0.9                  0.4   \n",
       "\n",
       "      param_max_depth  param_n_estimators  param_subsample  ...  \\\n",
       "0                   2                 100              0.5  ...   \n",
       "1                   2                 100              0.6  ...   \n",
       "2                   2                 100              0.7  ...   \n",
       "3                   2                 100              0.8  ...   \n",
       "4                   2                 100              0.9  ...   \n",
       "...               ...                 ...              ...  ...   \n",
       "2995                5                 300              0.5  ...   \n",
       "2996                5                 300              0.6  ...   \n",
       "2997                5                 300              0.7  ...   \n",
       "2998                5                 300              0.8  ...   \n",
       "2999                5                 300              0.9  ...   \n",
       "\n",
       "     split3_test_score  split4_test_score  split5_test_score  \\\n",
       "0             0.822581           0.822581           0.806452   \n",
       "1             0.838710           0.822581           0.806452   \n",
       "2             0.838710           0.806452           0.806452   \n",
       "3             0.854839           0.822581           0.806452   \n",
       "4             0.854839           0.822581           0.838710   \n",
       "...                ...                ...                ...   \n",
       "2995          0.887097           0.806452           0.774194   \n",
       "2996          0.870968           0.774194           0.758065   \n",
       "2997          0.870968           0.790323           0.790323   \n",
       "2998          0.870968           0.790323           0.774194   \n",
       "2999          0.854839           0.806452           0.774194   \n",
       "\n",
       "      split6_test_score  split7_test_score  split8_test_score  \\\n",
       "0              0.822581           0.806452           0.693548   \n",
       "1              0.838710           0.806452           0.661290   \n",
       "2              0.838710           0.806452           0.677419   \n",
       "3              0.854839           0.806452           0.661290   \n",
       "4              0.838710           0.806452           0.677419   \n",
       "...                 ...                ...                ...   \n",
       "2995           0.822581           0.822581           0.725806   \n",
       "2996           0.806452           0.838710           0.741935   \n",
       "2997           0.790323           0.854839           0.709677   \n",
       "2998           0.806452           0.854839           0.741935   \n",
       "2999           0.806452           0.822581           0.725806   \n",
       "\n",
       "      split9_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0              0.838710         0.820020        0.048275             2651  \n",
       "1              0.854839         0.823221        0.059057             2358  \n",
       "2              0.838710         0.824782        0.057512             2252  \n",
       "3              0.838710         0.824834        0.059251             2175  \n",
       "4              0.838710         0.828059        0.053977             1747  \n",
       "...                 ...              ...             ...              ...  \n",
       "2995           0.854839         0.828085        0.048801             1701  \n",
       "2996           0.854839         0.826421        0.052840             1992  \n",
       "2997           0.822581         0.824808        0.053239             2204  \n",
       "2998           0.822581         0.823272        0.043729             2305  \n",
       "2999           0.806452         0.823169        0.050024             2460  \n",
       "\n",
       "[3000 rows x 24 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score is 0.8505376344086022 with params {'colsample_bylevel': 0.1, 'colsample_bytree': 0.6, 'learning_rate': 0.15, 'max_depth': 5, 'n_estimators': 100, 'subsample': 0.6}\n"
     ]
    }
   ],
   "source": [
    "df1 = pd.read_csv(\"data\\\\xgb_results_full_1_bylevel=0.1_20221123.csv\")\n",
    "df1.drop(df1.columns[0], axis=1, inplace=True)\n",
    "display(df1)\n",
    "print(\"best score is 0.8505376344086022 with params {'colsample_bylevel': 0.1, 'colsample_bytree': 0.6, 'learning_rate': 0.15, 'max_depth': 5, 'n_estimators': 100, 'subsample': 0.6}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "714bfa65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_colsample_bylevel</th>\n",
       "      <th>param_colsample_bytree</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_subsample</th>\n",
       "      <th>...</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.064527</td>\n",
       "      <td>0.004136</td>\n",
       "      <td>0.005885</td>\n",
       "      <td>5.376236e-04</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.820020</td>\n",
       "      <td>0.048275</td>\n",
       "      <td>2651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.064327</td>\n",
       "      <td>0.002493</td>\n",
       "      <td>0.005885</td>\n",
       "      <td>5.374151e-04</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.661290</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.823221</td>\n",
       "      <td>0.059057</td>\n",
       "      <td>2358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.063231</td>\n",
       "      <td>0.001954</td>\n",
       "      <td>0.005785</td>\n",
       "      <td>3.990535e-04</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.824782</td>\n",
       "      <td>0.057512</td>\n",
       "      <td>2252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.062235</td>\n",
       "      <td>0.001017</td>\n",
       "      <td>0.006082</td>\n",
       "      <td>3.001655e-04</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.661290</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.824834</td>\n",
       "      <td>0.059251</td>\n",
       "      <td>2175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.062333</td>\n",
       "      <td>0.002285</td>\n",
       "      <td>0.005784</td>\n",
       "      <td>3.991850e-04</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.828059</td>\n",
       "      <td>0.053977</td>\n",
       "      <td>1747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2995</th>\n",
       "      <td>0.180018</td>\n",
       "      <td>0.001496</td>\n",
       "      <td>0.007081</td>\n",
       "      <td>2.993507e-04</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.887097</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.828085</td>\n",
       "      <td>0.048801</td>\n",
       "      <td>1701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2996</th>\n",
       "      <td>0.182212</td>\n",
       "      <td>0.003339</td>\n",
       "      <td>0.006982</td>\n",
       "      <td>4.460618e-04</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.826421</td>\n",
       "      <td>0.052840</td>\n",
       "      <td>1992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2997</th>\n",
       "      <td>0.181813</td>\n",
       "      <td>0.001548</td>\n",
       "      <td>0.007082</td>\n",
       "      <td>2.990570e-04</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.824808</td>\n",
       "      <td>0.053239</td>\n",
       "      <td>2204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998</th>\n",
       "      <td>0.181666</td>\n",
       "      <td>0.001723</td>\n",
       "      <td>0.006982</td>\n",
       "      <td>4.529953e-07</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.823272</td>\n",
       "      <td>0.043729</td>\n",
       "      <td>2305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999</th>\n",
       "      <td>0.182113</td>\n",
       "      <td>0.002005</td>\n",
       "      <td>0.007081</td>\n",
       "      <td>2.993824e-04</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.823169</td>\n",
       "      <td>0.050024</td>\n",
       "      <td>2460</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0          0.064527      0.004136         0.005885    5.376236e-04   \n",
       "1          0.064327      0.002493         0.005885    5.374151e-04   \n",
       "2          0.063231      0.001954         0.005785    3.990535e-04   \n",
       "3          0.062235      0.001017         0.006082    3.001655e-04   \n",
       "4          0.062333      0.002285         0.005784    3.991850e-04   \n",
       "...             ...           ...              ...             ...   \n",
       "2995       0.180018      0.001496         0.007081    2.993507e-04   \n",
       "2996       0.182212      0.003339         0.006982    4.460618e-04   \n",
       "2997       0.181813      0.001548         0.007082    2.990570e-04   \n",
       "2998       0.181666      0.001723         0.006982    4.529953e-07   \n",
       "2999       0.182113      0.002005         0.007081    2.993824e-04   \n",
       "\n",
       "     param_colsample_bylevel param_colsample_bytree param_learning_rate  \\\n",
       "0                        0.1                    0.3                 0.1   \n",
       "1                        0.1                    0.3                 0.1   \n",
       "2                        0.1                    0.3                 0.1   \n",
       "3                        0.1                    0.3                 0.1   \n",
       "4                        0.1                    0.3                 0.1   \n",
       "...                      ...                    ...                 ...   \n",
       "2995                     0.1                    0.9                 0.4   \n",
       "2996                     0.1                    0.9                 0.4   \n",
       "2997                     0.1                    0.9                 0.4   \n",
       "2998                     0.1                    0.9                 0.4   \n",
       "2999                     0.1                    0.9                 0.4   \n",
       "\n",
       "     param_max_depth param_n_estimators param_subsample  ...  \\\n",
       "0                  2                100             0.5  ...   \n",
       "1                  2                100             0.6  ...   \n",
       "2                  2                100             0.7  ...   \n",
       "3                  2                100             0.8  ...   \n",
       "4                  2                100             0.9  ...   \n",
       "...              ...                ...             ...  ...   \n",
       "2995               5                300             0.5  ...   \n",
       "2996               5                300             0.6  ...   \n",
       "2997               5                300             0.7  ...   \n",
       "2998               5                300             0.8  ...   \n",
       "2999               5                300             0.9  ...   \n",
       "\n",
       "     split3_test_score  split4_test_score  split5_test_score  \\\n",
       "0             0.822581           0.822581           0.806452   \n",
       "1             0.838710           0.822581           0.806452   \n",
       "2             0.838710           0.806452           0.806452   \n",
       "3             0.854839           0.822581           0.806452   \n",
       "4             0.854839           0.822581           0.838710   \n",
       "...                ...                ...                ...   \n",
       "2995          0.887097           0.806452           0.774194   \n",
       "2996          0.870968           0.774194           0.758065   \n",
       "2997          0.870968           0.790323           0.790323   \n",
       "2998          0.870968           0.790323           0.774194   \n",
       "2999          0.854839           0.806452           0.774194   \n",
       "\n",
       "      split6_test_score  split7_test_score  split8_test_score  \\\n",
       "0              0.822581           0.806452           0.693548   \n",
       "1              0.838710           0.806452           0.661290   \n",
       "2              0.838710           0.806452           0.677419   \n",
       "3              0.854839           0.806452           0.661290   \n",
       "4              0.838710           0.806452           0.677419   \n",
       "...                 ...                ...                ...   \n",
       "2995           0.822581           0.822581           0.725806   \n",
       "2996           0.806452           0.838710           0.741935   \n",
       "2997           0.790323           0.854839           0.709677   \n",
       "2998           0.806452           0.854839           0.741935   \n",
       "2999           0.806452           0.822581           0.725806   \n",
       "\n",
       "      split9_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0              0.838710         0.820020        0.048275             2651  \n",
       "1              0.854839         0.823221        0.059057             2358  \n",
       "2              0.838710         0.824782        0.057512             2252  \n",
       "3              0.838710         0.824834        0.059251             2175  \n",
       "4              0.838710         0.828059        0.053977             1747  \n",
       "...                 ...              ...             ...              ...  \n",
       "2995           0.854839         0.828085        0.048801             1701  \n",
       "2996           0.854839         0.826421        0.052840             1992  \n",
       "2997           0.822581         0.824808        0.053239             2204  \n",
       "2998           0.822581         0.823272        0.043729             2305  \n",
       "2999           0.806452         0.823169        0.050024             2460  \n",
       "\n",
       "[3000 rows x 24 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score is 0.8505376344086022 with params {'colsample_bylevel': 0.1, 'colsample_bytree': 0.6, 'learning_rate': 0.15, 'max_depth': 5, 'n_estimators': 100, 'subsample': 0.6}\n"
     ]
    }
   ],
   "source": [
    "# Full Tuning - Part 1\n",
    "random.seed(10)\n",
    "\n",
    "xgb = XGBClassifier()\n",
    "\n",
    "xgb_parameters = {'max_depth': [2,3,4,5]\n",
    "                   , 'subsample': [0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "                   , 'colsample_bytree': [0.3, 0.4, 0.5, 0.6, 0.9]\n",
    "                   , 'colsample_bylevel': [0.1]\n",
    "                   , 'learning_rate': [0.1, 0.15, 0.2, 0.25, 0.3, 0.4]\n",
    "                   , 'n_estimators': [100, 150, 200, 250, 300]}\n",
    "\n",
    "stratified_10_fold_cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "xgb_grid_search = GridSearchCV(xgb, xgb_parameters, scoring='accuracy', cv=stratified_10_fold_cv)\n",
    "\n",
    "xgb_grid_search.fit(X_train, y_train)\n",
    "\n",
    "xgb_grid_search_results_full_1 = pd.DataFrame(xgb_grid_search.cv_results_)\n",
    "display(xgb_grid_search_results_full_1)\n",
    "\n",
    "print(\"best score is {} with params {}\".format(xgb_grid_search.best_score_, xgb_grid_search.best_params_))\n",
    "\n",
    "# best values for\n",
    "\n",
    "# save dataframe\n",
    "from datetime import datetime\n",
    "date = str(datetime.now().date()).replace(\"-\", \"\")\n",
    "xgb_grid_search_results_full_1.to_csv(f\"results/xgb_results_full_round2_1_bylevel=0.1_{date}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a821b1df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_colsample_bylevel</th>\n",
       "      <th>param_colsample_bytree</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_subsample</th>\n",
       "      <th>...</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.062133</td>\n",
       "      <td>0.002485</td>\n",
       "      <td>0.006284</td>\n",
       "      <td>0.000639</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.820020</td>\n",
       "      <td>0.048275</td>\n",
       "      <td>2663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.063131</td>\n",
       "      <td>0.003027</td>\n",
       "      <td>0.006683</td>\n",
       "      <td>0.000457</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.661290</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.823221</td>\n",
       "      <td>0.059057</td>\n",
       "      <td>2338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.060438</td>\n",
       "      <td>0.000798</td>\n",
       "      <td>0.006782</td>\n",
       "      <td>0.000398</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.824782</td>\n",
       "      <td>0.057512</td>\n",
       "      <td>2222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.059541</td>\n",
       "      <td>0.000779</td>\n",
       "      <td>0.006682</td>\n",
       "      <td>0.000457</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.661290</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.824834</td>\n",
       "      <td>0.059251</td>\n",
       "      <td>2132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.059840</td>\n",
       "      <td>0.001092</td>\n",
       "      <td>0.006782</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.828059</td>\n",
       "      <td>0.053977</td>\n",
       "      <td>1661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2995</th>\n",
       "      <td>0.195577</td>\n",
       "      <td>0.001636</td>\n",
       "      <td>0.017653</td>\n",
       "      <td>0.031683</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.819918</td>\n",
       "      <td>0.052433</td>\n",
       "      <td>2744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2996</th>\n",
       "      <td>0.221308</td>\n",
       "      <td>0.011234</td>\n",
       "      <td>0.006782</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.819995</td>\n",
       "      <td>0.058351</td>\n",
       "      <td>2693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2997</th>\n",
       "      <td>0.226194</td>\n",
       "      <td>0.002309</td>\n",
       "      <td>0.007082</td>\n",
       "      <td>0.000299</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.821582</td>\n",
       "      <td>0.054587</td>\n",
       "      <td>2581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998</th>\n",
       "      <td>0.199167</td>\n",
       "      <td>0.006213</td>\n",
       "      <td>0.007381</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.823195</td>\n",
       "      <td>0.052389</td>\n",
       "      <td>2389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999</th>\n",
       "      <td>0.196574</td>\n",
       "      <td>0.001133</td>\n",
       "      <td>0.007480</td>\n",
       "      <td>0.000499</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.826395</td>\n",
       "      <td>0.049816</td>\n",
       "      <td>2002</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0          0.062133      0.002485         0.006284        0.000639   \n",
       "1          0.063131      0.003027         0.006683        0.000457   \n",
       "2          0.060438      0.000798         0.006782        0.000398   \n",
       "3          0.059541      0.000779         0.006682        0.000457   \n",
       "4          0.059840      0.001092         0.006782        0.000399   \n",
       "...             ...           ...              ...             ...   \n",
       "2995       0.195577      0.001636         0.017653        0.031683   \n",
       "2996       0.221308      0.011234         0.006782        0.000399   \n",
       "2997       0.226194      0.002309         0.007082        0.000299   \n",
       "2998       0.199167      0.006213         0.007381        0.000489   \n",
       "2999       0.196574      0.001133         0.007480        0.000499   \n",
       "\n",
       "      param_colsample_bylevel  param_colsample_bytree  param_learning_rate  \\\n",
       "0                         0.2                     0.3                  0.1   \n",
       "1                         0.2                     0.3                  0.1   \n",
       "2                         0.2                     0.3                  0.1   \n",
       "3                         0.2                     0.3                  0.1   \n",
       "4                         0.2                     0.3                  0.1   \n",
       "...                       ...                     ...                  ...   \n",
       "2995                      0.2                     0.9                  0.4   \n",
       "2996                      0.2                     0.9                  0.4   \n",
       "2997                      0.2                     0.9                  0.4   \n",
       "2998                      0.2                     0.9                  0.4   \n",
       "2999                      0.2                     0.9                  0.4   \n",
       "\n",
       "      param_max_depth  param_n_estimators  param_subsample  ...  \\\n",
       "0                   2                 100              0.5  ...   \n",
       "1                   2                 100              0.6  ...   \n",
       "2                   2                 100              0.7  ...   \n",
       "3                   2                 100              0.8  ...   \n",
       "4                   2                 100              0.9  ...   \n",
       "...               ...                 ...              ...  ...   \n",
       "2995                5                 300              0.5  ...   \n",
       "2996                5                 300              0.6  ...   \n",
       "2997                5                 300              0.7  ...   \n",
       "2998                5                 300              0.8  ...   \n",
       "2999                5                 300              0.9  ...   \n",
       "\n",
       "     split3_test_score  split4_test_score  split5_test_score  \\\n",
       "0             0.822581           0.822581           0.806452   \n",
       "1             0.838710           0.822581           0.806452   \n",
       "2             0.838710           0.806452           0.806452   \n",
       "3             0.854839           0.822581           0.806452   \n",
       "4             0.854839           0.822581           0.838710   \n",
       "...                ...                ...                ...   \n",
       "2995          0.822581           0.806452           0.774194   \n",
       "2996          0.838710           0.806452           0.774194   \n",
       "2997          0.838710           0.790323           0.758065   \n",
       "2998          0.838710           0.822581           0.774194   \n",
       "2999          0.838710           0.806452           0.790323   \n",
       "\n",
       "      split6_test_score  split7_test_score  split8_test_score  \\\n",
       "0              0.822581           0.806452           0.693548   \n",
       "1              0.838710           0.806452           0.661290   \n",
       "2              0.838710           0.806452           0.677419   \n",
       "3              0.854839           0.806452           0.661290   \n",
       "4              0.838710           0.806452           0.677419   \n",
       "...                 ...                ...                ...   \n",
       "2995           0.790323           0.790323           0.741935   \n",
       "2996           0.822581           0.838710           0.693548   \n",
       "2997           0.806452           0.854839           0.725806   \n",
       "2998           0.838710           0.822581           0.725806   \n",
       "2999           0.838710           0.822581           0.725806   \n",
       "\n",
       "      split9_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0              0.838710         0.820020        0.048275             2663  \n",
       "1              0.854839         0.823221        0.059057             2338  \n",
       "2              0.838710         0.824782        0.057512             2222  \n",
       "3              0.838710         0.824834        0.059251             2132  \n",
       "4              0.838710         0.828059        0.053977             1661  \n",
       "...                 ...              ...             ...              ...  \n",
       "2995           0.822581         0.819918        0.052433             2744  \n",
       "2996           0.822581         0.819995        0.058351             2693  \n",
       "2997           0.822581         0.821582        0.054587             2581  \n",
       "2998           0.790323         0.823195        0.052389             2389  \n",
       "2999           0.806452         0.826395        0.049816             2002  \n",
       "\n",
       "[3000 rows x 24 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score is 0.8505376344086022 with params {'colsample_bylevel': 0.2, 'colsample_bytree': 0.6, 'learning_rate': 0.15, 'max_depth': 5, 'n_estimators': 100, 'subsample': 0.6}\n"
     ]
    }
   ],
   "source": [
    "df2 = pd.read_csv(\"data\\\\xgb_results_full_2_bylevel=0.2_20221123.csv\")\n",
    "df2.drop(df2.columns[0], axis=1, inplace=True)\n",
    "display(df2)\n",
    "print(\"best score is 0.8505376344086022 with params {'colsample_bylevel': 0.2, 'colsample_bytree': 0.6, 'learning_rate': 0.15, 'max_depth': 5, 'n_estimators': 100, 'subsample': 0.6}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cf6243bd",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_colsample_bylevel</th>\n",
       "      <th>param_colsample_bytree</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_subsample</th>\n",
       "      <th>...</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.062133</td>\n",
       "      <td>0.002485</td>\n",
       "      <td>0.006284</td>\n",
       "      <td>0.000639</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.820020</td>\n",
       "      <td>0.048275</td>\n",
       "      <td>2663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.063131</td>\n",
       "      <td>0.003027</td>\n",
       "      <td>0.006683</td>\n",
       "      <td>0.000457</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.661290</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.823221</td>\n",
       "      <td>0.059057</td>\n",
       "      <td>2338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.060438</td>\n",
       "      <td>0.000798</td>\n",
       "      <td>0.006782</td>\n",
       "      <td>0.000398</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.824782</td>\n",
       "      <td>0.057512</td>\n",
       "      <td>2222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.059541</td>\n",
       "      <td>0.000779</td>\n",
       "      <td>0.006682</td>\n",
       "      <td>0.000457</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.661290</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.824834</td>\n",
       "      <td>0.059251</td>\n",
       "      <td>2132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.059840</td>\n",
       "      <td>0.001092</td>\n",
       "      <td>0.006782</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.828059</td>\n",
       "      <td>0.053977</td>\n",
       "      <td>1661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2995</th>\n",
       "      <td>0.195577</td>\n",
       "      <td>0.001636</td>\n",
       "      <td>0.017653</td>\n",
       "      <td>0.031683</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.819918</td>\n",
       "      <td>0.052433</td>\n",
       "      <td>2744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2996</th>\n",
       "      <td>0.221308</td>\n",
       "      <td>0.011234</td>\n",
       "      <td>0.006782</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.819995</td>\n",
       "      <td>0.058351</td>\n",
       "      <td>2693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2997</th>\n",
       "      <td>0.226194</td>\n",
       "      <td>0.002309</td>\n",
       "      <td>0.007082</td>\n",
       "      <td>0.000299</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.821582</td>\n",
       "      <td>0.054587</td>\n",
       "      <td>2581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998</th>\n",
       "      <td>0.199167</td>\n",
       "      <td>0.006213</td>\n",
       "      <td>0.007381</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.823195</td>\n",
       "      <td>0.052389</td>\n",
       "      <td>2389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999</th>\n",
       "      <td>0.196574</td>\n",
       "      <td>0.001133</td>\n",
       "      <td>0.007480</td>\n",
       "      <td>0.000499</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.826395</td>\n",
       "      <td>0.049816</td>\n",
       "      <td>2002</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0          0.062133      0.002485         0.006284        0.000639   \n",
       "1          0.063131      0.003027         0.006683        0.000457   \n",
       "2          0.060438      0.000798         0.006782        0.000398   \n",
       "3          0.059541      0.000779         0.006682        0.000457   \n",
       "4          0.059840      0.001092         0.006782        0.000399   \n",
       "...             ...           ...              ...             ...   \n",
       "2995       0.195577      0.001636         0.017653        0.031683   \n",
       "2996       0.221308      0.011234         0.006782        0.000399   \n",
       "2997       0.226194      0.002309         0.007082        0.000299   \n",
       "2998       0.199167      0.006213         0.007381        0.000489   \n",
       "2999       0.196574      0.001133         0.007480        0.000499   \n",
       "\n",
       "     param_colsample_bylevel param_colsample_bytree param_learning_rate  \\\n",
       "0                        0.2                    0.3                 0.1   \n",
       "1                        0.2                    0.3                 0.1   \n",
       "2                        0.2                    0.3                 0.1   \n",
       "3                        0.2                    0.3                 0.1   \n",
       "4                        0.2                    0.3                 0.1   \n",
       "...                      ...                    ...                 ...   \n",
       "2995                     0.2                    0.9                 0.4   \n",
       "2996                     0.2                    0.9                 0.4   \n",
       "2997                     0.2                    0.9                 0.4   \n",
       "2998                     0.2                    0.9                 0.4   \n",
       "2999                     0.2                    0.9                 0.4   \n",
       "\n",
       "     param_max_depth param_n_estimators param_subsample  ...  \\\n",
       "0                  2                100             0.5  ...   \n",
       "1                  2                100             0.6  ...   \n",
       "2                  2                100             0.7  ...   \n",
       "3                  2                100             0.8  ...   \n",
       "4                  2                100             0.9  ...   \n",
       "...              ...                ...             ...  ...   \n",
       "2995               5                300             0.5  ...   \n",
       "2996               5                300             0.6  ...   \n",
       "2997               5                300             0.7  ...   \n",
       "2998               5                300             0.8  ...   \n",
       "2999               5                300             0.9  ...   \n",
       "\n",
       "     split3_test_score  split4_test_score  split5_test_score  \\\n",
       "0             0.822581           0.822581           0.806452   \n",
       "1             0.838710           0.822581           0.806452   \n",
       "2             0.838710           0.806452           0.806452   \n",
       "3             0.854839           0.822581           0.806452   \n",
       "4             0.854839           0.822581           0.838710   \n",
       "...                ...                ...                ...   \n",
       "2995          0.822581           0.806452           0.774194   \n",
       "2996          0.838710           0.806452           0.774194   \n",
       "2997          0.838710           0.790323           0.758065   \n",
       "2998          0.838710           0.822581           0.774194   \n",
       "2999          0.838710           0.806452           0.790323   \n",
       "\n",
       "      split6_test_score  split7_test_score  split8_test_score  \\\n",
       "0              0.822581           0.806452           0.693548   \n",
       "1              0.838710           0.806452           0.661290   \n",
       "2              0.838710           0.806452           0.677419   \n",
       "3              0.854839           0.806452           0.661290   \n",
       "4              0.838710           0.806452           0.677419   \n",
       "...                 ...                ...                ...   \n",
       "2995           0.790323           0.790323           0.741935   \n",
       "2996           0.822581           0.838710           0.693548   \n",
       "2997           0.806452           0.854839           0.725806   \n",
       "2998           0.838710           0.822581           0.725806   \n",
       "2999           0.838710           0.822581           0.725806   \n",
       "\n",
       "      split9_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0              0.838710         0.820020        0.048275             2663  \n",
       "1              0.854839         0.823221        0.059057             2338  \n",
       "2              0.838710         0.824782        0.057512             2222  \n",
       "3              0.838710         0.824834        0.059251             2132  \n",
       "4              0.838710         0.828059        0.053977             1661  \n",
       "...                 ...              ...             ...              ...  \n",
       "2995           0.822581         0.819918        0.052433             2744  \n",
       "2996           0.822581         0.819995        0.058351             2693  \n",
       "2997           0.822581         0.821582        0.054587             2581  \n",
       "2998           0.790323         0.823195        0.052389             2389  \n",
       "2999           0.806452         0.826395        0.049816             2002  \n",
       "\n",
       "[3000 rows x 24 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score is 0.8505376344086022 with params {'colsample_bylevel': 0.2, 'colsample_bytree': 0.6, 'learning_rate': 0.15, 'max_depth': 5, 'n_estimators': 100, 'subsample': 0.6}\n"
     ]
    }
   ],
   "source": [
    "# Full Tuning - Part 2\n",
    "random.seed(10)\n",
    "\n",
    "xgb = XGBClassifier()\n",
    "\n",
    "xgb_parameters = {'max_depth': [2,3,4,5]\n",
    "                   , 'subsample': [0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "                   , 'colsample_bytree': [0.3, 0.4, 0.5, 0.6, 0.9]\n",
    "                   , 'colsample_bylevel': [0.2]\n",
    "                   , 'learning_rate': [0.1, 0.15, 0.2, 0.25, 0.3, 0.4]\n",
    "                   , 'n_estimators': [100, 150, 200, 250, 300]}\n",
    "\n",
    "stratified_10_fold_cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "xgb_grid_search = GridSearchCV(xgb, xgb_parameters, scoring='accuracy', cv=stratified_10_fold_cv)\n",
    "\n",
    "xgb_grid_search.fit(X_train, y_train)\n",
    "\n",
    "xgb_grid_search_results_full_2 = pd.DataFrame(xgb_grid_search.cv_results_)\n",
    "display(xgb_grid_search_results_full_2)\n",
    "\n",
    "print(\"best score is {} with params {}\".format(xgb_grid_search.best_score_, xgb_grid_search.best_params_))\n",
    "#best score is 0.8505376344086022 with params\n",
    "#{'colsample_bylevel': 0.2, 'colsample_bytree': 0.6, 'learning_rate': 0.15, 'max_depth': 5, 'n_estimators': 100, 'subsample': 0.6}\n",
    "\n",
    "# save dataframe\n",
    "from datetime import datetime\n",
    "date = str(datetime.now().date()).replace(\"-\", \"\")\n",
    "xgb_grid_search_results_full_2.to_csv(f\"results/xgb_results_full_round2_2_bylevel=0.2_{date}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9c3c4e54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_colsample_bylevel</th>\n",
       "      <th>param_colsample_bytree</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_subsample</th>\n",
       "      <th>...</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.062034</td>\n",
       "      <td>0.001596</td>\n",
       "      <td>0.006882</td>\n",
       "      <td>0.000537</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.820020</td>\n",
       "      <td>0.048275</td>\n",
       "      <td>2509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.068327</td>\n",
       "      <td>0.005910</td>\n",
       "      <td>0.006573</td>\n",
       "      <td>0.000502</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.661290</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.823221</td>\n",
       "      <td>0.059057</td>\n",
       "      <td>2140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.065225</td>\n",
       "      <td>0.003191</td>\n",
       "      <td>0.006683</td>\n",
       "      <td>0.000457</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.824782</td>\n",
       "      <td>0.057512</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.063630</td>\n",
       "      <td>0.001596</td>\n",
       "      <td>0.006483</td>\n",
       "      <td>0.000499</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.661290</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.824834</td>\n",
       "      <td>0.059251</td>\n",
       "      <td>1898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.061435</td>\n",
       "      <td>0.001493</td>\n",
       "      <td>0.006483</td>\n",
       "      <td>0.000498</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.828059</td>\n",
       "      <td>0.053977</td>\n",
       "      <td>1394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2995</th>\n",
       "      <td>0.206226</td>\n",
       "      <td>0.002782</td>\n",
       "      <td>0.007182</td>\n",
       "      <td>0.000598</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.813646</td>\n",
       "      <td>0.044452</td>\n",
       "      <td>2900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2996</th>\n",
       "      <td>0.207998</td>\n",
       "      <td>0.002457</td>\n",
       "      <td>0.007280</td>\n",
       "      <td>0.000457</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.818459</td>\n",
       "      <td>0.053856</td>\n",
       "      <td>2648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2997</th>\n",
       "      <td>0.207744</td>\n",
       "      <td>0.000898</td>\n",
       "      <td>0.007480</td>\n",
       "      <td>0.000499</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.813594</td>\n",
       "      <td>0.056215</td>\n",
       "      <td>2908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998</th>\n",
       "      <td>0.208343</td>\n",
       "      <td>0.001863</td>\n",
       "      <td>0.007280</td>\n",
       "      <td>0.000457</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.815207</td>\n",
       "      <td>0.053961</td>\n",
       "      <td>2850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999</th>\n",
       "      <td>0.207644</td>\n",
       "      <td>0.001882</td>\n",
       "      <td>0.007381</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.820020</td>\n",
       "      <td>0.055129</td>\n",
       "      <td>2509</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0          0.062034      0.001596         0.006882        0.000537   \n",
       "1          0.068327      0.005910         0.006573        0.000502   \n",
       "2          0.065225      0.003191         0.006683        0.000457   \n",
       "3          0.063630      0.001596         0.006483        0.000499   \n",
       "4          0.061435      0.001493         0.006483        0.000498   \n",
       "...             ...           ...              ...             ...   \n",
       "2995       0.206226      0.002782         0.007182        0.000598   \n",
       "2996       0.207998      0.002457         0.007280        0.000457   \n",
       "2997       0.207744      0.000898         0.007480        0.000499   \n",
       "2998       0.208343      0.001863         0.007280        0.000457   \n",
       "2999       0.207644      0.001882         0.007381        0.000489   \n",
       "\n",
       "      param_colsample_bylevel  param_colsample_bytree  param_learning_rate  \\\n",
       "0                         0.3                     0.3                  0.1   \n",
       "1                         0.3                     0.3                  0.1   \n",
       "2                         0.3                     0.3                  0.1   \n",
       "3                         0.3                     0.3                  0.1   \n",
       "4                         0.3                     0.3                  0.1   \n",
       "...                       ...                     ...                  ...   \n",
       "2995                      0.3                     0.9                  0.4   \n",
       "2996                      0.3                     0.9                  0.4   \n",
       "2997                      0.3                     0.9                  0.4   \n",
       "2998                      0.3                     0.9                  0.4   \n",
       "2999                      0.3                     0.9                  0.4   \n",
       "\n",
       "      param_max_depth  param_n_estimators  param_subsample  ...  \\\n",
       "0                   2                 100              0.5  ...   \n",
       "1                   2                 100              0.6  ...   \n",
       "2                   2                 100              0.7  ...   \n",
       "3                   2                 100              0.8  ...   \n",
       "4                   2                 100              0.9  ...   \n",
       "...               ...                 ...              ...  ...   \n",
       "2995                5                 300              0.5  ...   \n",
       "2996                5                 300              0.6  ...   \n",
       "2997                5                 300              0.7  ...   \n",
       "2998                5                 300              0.8  ...   \n",
       "2999                5                 300              0.9  ...   \n",
       "\n",
       "     split3_test_score  split4_test_score  split5_test_score  \\\n",
       "0             0.822581           0.822581           0.806452   \n",
       "1             0.838710           0.822581           0.806452   \n",
       "2             0.838710           0.806452           0.806452   \n",
       "3             0.854839           0.822581           0.806452   \n",
       "4             0.854839           0.822581           0.838710   \n",
       "...                ...                ...                ...   \n",
       "2995          0.838710           0.790323           0.774194   \n",
       "2996          0.854839           0.774194           0.790323   \n",
       "2997          0.854839           0.790323           0.758065   \n",
       "2998          0.854839           0.790323           0.790323   \n",
       "2999          0.822581           0.790323           0.774194   \n",
       "\n",
       "      split6_test_score  split7_test_score  split8_test_score  \\\n",
       "0              0.822581           0.806452           0.693548   \n",
       "1              0.838710           0.806452           0.661290   \n",
       "2              0.838710           0.806452           0.677419   \n",
       "3              0.854839           0.806452           0.661290   \n",
       "4              0.838710           0.806452           0.677419   \n",
       "...                 ...                ...                ...   \n",
       "2995           0.838710           0.822581           0.709677   \n",
       "2996           0.854839           0.806452           0.693548   \n",
       "2997           0.822581           0.806452           0.709677   \n",
       "2998           0.822581           0.806452           0.693548   \n",
       "2999           0.854839           0.806452           0.709677   \n",
       "\n",
       "      split9_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0              0.838710         0.820020        0.048275             2509  \n",
       "1              0.854839         0.823221        0.059057             2140  \n",
       "2              0.838710         0.824782        0.057512             2021  \n",
       "3              0.838710         0.824834        0.059251             1898  \n",
       "4              0.838710         0.828059        0.053977             1394  \n",
       "...                 ...              ...             ...              ...  \n",
       "2995           0.822581         0.813646        0.044452             2900  \n",
       "2996           0.854839         0.818459        0.053856             2648  \n",
       "2997           0.822581         0.813594        0.056215             2908  \n",
       "2998           0.822581         0.815207        0.053961             2850  \n",
       "2999           0.854839         0.820020        0.055129             2509  \n",
       "\n",
       "[3000 rows x 24 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score is 0.850563236047107 with params {'colsample_bylevel': 0.3, 'colsample_bytree': 0.5, 'learning_rate': 0.15, 'max_depth': 2, 'n_estimators': 100, 'subsample': 0.7}\n"
     ]
    }
   ],
   "source": [
    "df3 = pd.read_csv(\"data\\\\xgb_results_full_3_bylevel=0.3_20221123.csv\")\n",
    "df3.drop(df3.columns[0], axis=1, inplace=True)\n",
    "display(df3)\n",
    "print(\"best score is 0.850563236047107 with params {'colsample_bylevel': 0.3, 'colsample_bytree': 0.5, 'learning_rate': 0.15, 'max_depth': 2, 'n_estimators': 100, 'subsample': 0.7}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "96404602",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_colsample_bylevel</th>\n",
       "      <th>param_colsample_bytree</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_subsample</th>\n",
       "      <th>...</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.062034</td>\n",
       "      <td>0.001596</td>\n",
       "      <td>0.006882</td>\n",
       "      <td>0.000537</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.820020</td>\n",
       "      <td>0.048275</td>\n",
       "      <td>2509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.068327</td>\n",
       "      <td>0.005910</td>\n",
       "      <td>0.006573</td>\n",
       "      <td>0.000502</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.661290</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.823221</td>\n",
       "      <td>0.059057</td>\n",
       "      <td>2140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.065225</td>\n",
       "      <td>0.003191</td>\n",
       "      <td>0.006683</td>\n",
       "      <td>0.000457</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.824782</td>\n",
       "      <td>0.057512</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.063630</td>\n",
       "      <td>0.001596</td>\n",
       "      <td>0.006483</td>\n",
       "      <td>0.000499</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.661290</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.824834</td>\n",
       "      <td>0.059251</td>\n",
       "      <td>1898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.061435</td>\n",
       "      <td>0.001493</td>\n",
       "      <td>0.006483</td>\n",
       "      <td>0.000498</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.828059</td>\n",
       "      <td>0.053977</td>\n",
       "      <td>1394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2995</th>\n",
       "      <td>0.206226</td>\n",
       "      <td>0.002782</td>\n",
       "      <td>0.007182</td>\n",
       "      <td>0.000598</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.813646</td>\n",
       "      <td>0.044452</td>\n",
       "      <td>2900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2996</th>\n",
       "      <td>0.207998</td>\n",
       "      <td>0.002457</td>\n",
       "      <td>0.007280</td>\n",
       "      <td>0.000457</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.818459</td>\n",
       "      <td>0.053856</td>\n",
       "      <td>2648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2997</th>\n",
       "      <td>0.207744</td>\n",
       "      <td>0.000898</td>\n",
       "      <td>0.007480</td>\n",
       "      <td>0.000499</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.813594</td>\n",
       "      <td>0.056215</td>\n",
       "      <td>2908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998</th>\n",
       "      <td>0.208343</td>\n",
       "      <td>0.001863</td>\n",
       "      <td>0.007280</td>\n",
       "      <td>0.000457</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.815207</td>\n",
       "      <td>0.053961</td>\n",
       "      <td>2850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999</th>\n",
       "      <td>0.207644</td>\n",
       "      <td>0.001882</td>\n",
       "      <td>0.007381</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.820020</td>\n",
       "      <td>0.055129</td>\n",
       "      <td>2509</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0          0.062034      0.001596         0.006882        0.000537   \n",
       "1          0.068327      0.005910         0.006573        0.000502   \n",
       "2          0.065225      0.003191         0.006683        0.000457   \n",
       "3          0.063630      0.001596         0.006483        0.000499   \n",
       "4          0.061435      0.001493         0.006483        0.000498   \n",
       "...             ...           ...              ...             ...   \n",
       "2995       0.206226      0.002782         0.007182        0.000598   \n",
       "2996       0.207998      0.002457         0.007280        0.000457   \n",
       "2997       0.207744      0.000898         0.007480        0.000499   \n",
       "2998       0.208343      0.001863         0.007280        0.000457   \n",
       "2999       0.207644      0.001882         0.007381        0.000489   \n",
       "\n",
       "     param_colsample_bylevel param_colsample_bytree param_learning_rate  \\\n",
       "0                        0.3                    0.3                 0.1   \n",
       "1                        0.3                    0.3                 0.1   \n",
       "2                        0.3                    0.3                 0.1   \n",
       "3                        0.3                    0.3                 0.1   \n",
       "4                        0.3                    0.3                 0.1   \n",
       "...                      ...                    ...                 ...   \n",
       "2995                     0.3                    0.9                 0.4   \n",
       "2996                     0.3                    0.9                 0.4   \n",
       "2997                     0.3                    0.9                 0.4   \n",
       "2998                     0.3                    0.9                 0.4   \n",
       "2999                     0.3                    0.9                 0.4   \n",
       "\n",
       "     param_max_depth param_n_estimators param_subsample  ...  \\\n",
       "0                  2                100             0.5  ...   \n",
       "1                  2                100             0.6  ...   \n",
       "2                  2                100             0.7  ...   \n",
       "3                  2                100             0.8  ...   \n",
       "4                  2                100             0.9  ...   \n",
       "...              ...                ...             ...  ...   \n",
       "2995               5                300             0.5  ...   \n",
       "2996               5                300             0.6  ...   \n",
       "2997               5                300             0.7  ...   \n",
       "2998               5                300             0.8  ...   \n",
       "2999               5                300             0.9  ...   \n",
       "\n",
       "     split3_test_score  split4_test_score  split5_test_score  \\\n",
       "0             0.822581           0.822581           0.806452   \n",
       "1             0.838710           0.822581           0.806452   \n",
       "2             0.838710           0.806452           0.806452   \n",
       "3             0.854839           0.822581           0.806452   \n",
       "4             0.854839           0.822581           0.838710   \n",
       "...                ...                ...                ...   \n",
       "2995          0.838710           0.790323           0.774194   \n",
       "2996          0.854839           0.774194           0.790323   \n",
       "2997          0.854839           0.790323           0.758065   \n",
       "2998          0.854839           0.790323           0.790323   \n",
       "2999          0.822581           0.790323           0.774194   \n",
       "\n",
       "      split6_test_score  split7_test_score  split8_test_score  \\\n",
       "0              0.822581           0.806452           0.693548   \n",
       "1              0.838710           0.806452           0.661290   \n",
       "2              0.838710           0.806452           0.677419   \n",
       "3              0.854839           0.806452           0.661290   \n",
       "4              0.838710           0.806452           0.677419   \n",
       "...                 ...                ...                ...   \n",
       "2995           0.838710           0.822581           0.709677   \n",
       "2996           0.854839           0.806452           0.693548   \n",
       "2997           0.822581           0.806452           0.709677   \n",
       "2998           0.822581           0.806452           0.693548   \n",
       "2999           0.854839           0.806452           0.709677   \n",
       "\n",
       "      split9_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0              0.838710         0.820020        0.048275             2509  \n",
       "1              0.854839         0.823221        0.059057             2140  \n",
       "2              0.838710         0.824782        0.057512             2021  \n",
       "3              0.838710         0.824834        0.059251             1898  \n",
       "4              0.838710         0.828059        0.053977             1394  \n",
       "...                 ...              ...             ...              ...  \n",
       "2995           0.822581         0.813646        0.044452             2900  \n",
       "2996           0.854839         0.818459        0.053856             2648  \n",
       "2997           0.822581         0.813594        0.056215             2908  \n",
       "2998           0.822581         0.815207        0.053961             2850  \n",
       "2999           0.854839         0.820020        0.055129             2509  \n",
       "\n",
       "[3000 rows x 24 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score is 0.850563236047107 with params {'colsample_bylevel': 0.3, 'colsample_bytree': 0.5, 'learning_rate': 0.15, 'max_depth': 2, 'n_estimators': 100, 'subsample': 0.7}\n"
     ]
    }
   ],
   "source": [
    "# Full Tuning - Part 3\n",
    "random.seed(10)\n",
    "\n",
    "xgb = XGBClassifier()\n",
    "\n",
    "xgb_parameters = {'max_depth': [2,3,4,5]\n",
    "                   , 'subsample': [0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "                   , 'colsample_bytree': [0.3, 0.4, 0.5, 0.6, 0.9]\n",
    "                   , 'colsample_bylevel': [0.3]\n",
    "                   , 'learning_rate': [0.1, 0.15, 0.2, 0.25, 0.3, 0.4]\n",
    "                   , 'n_estimators': [100, 150, 200, 250, 300]}\n",
    "\n",
    "stratified_10_fold_cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "xgb_grid_search = GridSearchCV(xgb, xgb_parameters, scoring='accuracy', cv=stratified_10_fold_cv)\n",
    "\n",
    "xgb_grid_search.fit(X_train, y_train)\n",
    "\n",
    "xgb_grid_search_results_full_3 = pd.DataFrame(xgb_grid_search.cv_results_)\n",
    "display(xgb_grid_search_results_full_3)\n",
    "\n",
    "print(\"best score is {} with params {}\".format(xgb_grid_search.best_score_, xgb_grid_search.best_params_))\n",
    "#best score is 0.850563236047107 with params\n",
    "#{'colsample_bylevel': 0.3, 'colsample_bytree': 0.5, 'learning_rate': 0.15, 'max_depth': 2, 'n_estimators': 100, 'subsample': 0.7}\n",
    "\n",
    "# save dataframe\n",
    "from datetime import datetime\n",
    "date = str(datetime.now().date()).replace(\"-\", \"\")\n",
    "xgb_grid_search_results_full_3.to_csv(f\"results/xgb_results_full_round2_3_bylevel=0.3_{date}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1205514d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_colsample_bylevel</th>\n",
       "      <th>param_colsample_bytree</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_subsample</th>\n",
       "      <th>...</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.061735</td>\n",
       "      <td>0.001296</td>\n",
       "      <td>0.006482</td>\n",
       "      <td>0.000669</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.820020</td>\n",
       "      <td>0.048275</td>\n",
       "      <td>2502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.063031</td>\n",
       "      <td>0.002778</td>\n",
       "      <td>0.006483</td>\n",
       "      <td>0.000669</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.661290</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.823221</td>\n",
       "      <td>0.059057</td>\n",
       "      <td>2077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.060638</td>\n",
       "      <td>0.000746</td>\n",
       "      <td>0.006782</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.824782</td>\n",
       "      <td>0.057512</td>\n",
       "      <td>1941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.060339</td>\n",
       "      <td>0.000919</td>\n",
       "      <td>0.006483</td>\n",
       "      <td>0.000499</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.661290</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.824834</td>\n",
       "      <td>0.059251</td>\n",
       "      <td>1818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.059840</td>\n",
       "      <td>0.001180</td>\n",
       "      <td>0.006682</td>\n",
       "      <td>0.000457</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.828059</td>\n",
       "      <td>0.053977</td>\n",
       "      <td>1289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2995</th>\n",
       "      <td>0.218216</td>\n",
       "      <td>0.004179</td>\n",
       "      <td>0.007181</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.808807</td>\n",
       "      <td>0.046180</td>\n",
       "      <td>2975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2996</th>\n",
       "      <td>0.221009</td>\n",
       "      <td>0.003402</td>\n",
       "      <td>0.007480</td>\n",
       "      <td>0.000499</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.812007</td>\n",
       "      <td>0.049754</td>\n",
       "      <td>2922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2997</th>\n",
       "      <td>0.221308</td>\n",
       "      <td>0.004515</td>\n",
       "      <td>0.007380</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.816795</td>\n",
       "      <td>0.050406</td>\n",
       "      <td>2770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998</th>\n",
       "      <td>0.219213</td>\n",
       "      <td>0.003908</td>\n",
       "      <td>0.007194</td>\n",
       "      <td>0.000425</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.816820</td>\n",
       "      <td>0.047212</td>\n",
       "      <td>2763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999</th>\n",
       "      <td>0.216122</td>\n",
       "      <td>0.003092</td>\n",
       "      <td>0.007381</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.818382</td>\n",
       "      <td>0.050014</td>\n",
       "      <td>2693</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0          0.061735      0.001296         0.006482        0.000669   \n",
       "1          0.063031      0.002778         0.006483        0.000669   \n",
       "2          0.060638      0.000746         0.006782        0.000399   \n",
       "3          0.060339      0.000919         0.006483        0.000499   \n",
       "4          0.059840      0.001180         0.006682        0.000457   \n",
       "...             ...           ...              ...             ...   \n",
       "2995       0.218216      0.004179         0.007181        0.000399   \n",
       "2996       0.221009      0.003402         0.007480        0.000499   \n",
       "2997       0.221308      0.004515         0.007380        0.000489   \n",
       "2998       0.219213      0.003908         0.007194        0.000425   \n",
       "2999       0.216122      0.003092         0.007381        0.000489   \n",
       "\n",
       "      param_colsample_bylevel  param_colsample_bytree  param_learning_rate  \\\n",
       "0                         0.4                     0.3                  0.1   \n",
       "1                         0.4                     0.3                  0.1   \n",
       "2                         0.4                     0.3                  0.1   \n",
       "3                         0.4                     0.3                  0.1   \n",
       "4                         0.4                     0.3                  0.1   \n",
       "...                       ...                     ...                  ...   \n",
       "2995                      0.4                     0.9                  0.4   \n",
       "2996                      0.4                     0.9                  0.4   \n",
       "2997                      0.4                     0.9                  0.4   \n",
       "2998                      0.4                     0.9                  0.4   \n",
       "2999                      0.4                     0.9                  0.4   \n",
       "\n",
       "      param_max_depth  param_n_estimators  param_subsample  ...  \\\n",
       "0                   2                 100              0.5  ...   \n",
       "1                   2                 100              0.6  ...   \n",
       "2                   2                 100              0.7  ...   \n",
       "3                   2                 100              0.8  ...   \n",
       "4                   2                 100              0.9  ...   \n",
       "...               ...                 ...              ...  ...   \n",
       "2995                5                 300              0.5  ...   \n",
       "2996                5                 300              0.6  ...   \n",
       "2997                5                 300              0.7  ...   \n",
       "2998                5                 300              0.8  ...   \n",
       "2999                5                 300              0.9  ...   \n",
       "\n",
       "     split3_test_score  split4_test_score  split5_test_score  \\\n",
       "0             0.822581           0.822581           0.806452   \n",
       "1             0.838710           0.822581           0.806452   \n",
       "2             0.838710           0.806452           0.806452   \n",
       "3             0.854839           0.822581           0.806452   \n",
       "4             0.854839           0.822581           0.838710   \n",
       "...                ...                ...                ...   \n",
       "2995          0.838710           0.758065           0.790323   \n",
       "2996          0.838710           0.790323           0.806452   \n",
       "2997          0.838710           0.790323           0.790323   \n",
       "2998          0.838710           0.790323           0.806452   \n",
       "2999          0.822581           0.774194           0.774194   \n",
       "\n",
       "      split6_test_score  split7_test_score  split8_test_score  \\\n",
       "0              0.822581           0.806452           0.693548   \n",
       "1              0.838710           0.806452           0.661290   \n",
       "2              0.838710           0.806452           0.677419   \n",
       "3              0.854839           0.806452           0.661290   \n",
       "4              0.838710           0.806452           0.677419   \n",
       "...                 ...                ...                ...   \n",
       "2995           0.806452           0.790323           0.741935   \n",
       "2996           0.838710           0.774194           0.725806   \n",
       "2997           0.790323           0.822581           0.725806   \n",
       "2998           0.838710           0.790323           0.725806   \n",
       "2999           0.854839           0.790323           0.725806   \n",
       "\n",
       "      split9_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0              0.838710         0.820020        0.048275             2502  \n",
       "1              0.854839         0.823221        0.059057             2077  \n",
       "2              0.838710         0.824782        0.057512             1941  \n",
       "3              0.838710         0.824834        0.059251             1818  \n",
       "4              0.838710         0.828059        0.053977             1289  \n",
       "...                 ...              ...             ...              ...  \n",
       "2995           0.822581         0.808807        0.046180             2975  \n",
       "2996           0.790323         0.812007        0.049754             2922  \n",
       "2997           0.822581         0.816795        0.050406             2770  \n",
       "2998           0.806452         0.816820        0.047212             2763  \n",
       "2999           0.838710         0.818382        0.050014             2693  \n",
       "\n",
       "[3000 rows x 24 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score is 0.850563236047107 with params {'colsample_bylevel': 0.4, 'colsample_bytree': 0.5, 'learning_rate': 0.15, 'max_depth': 2, 'n_estimators': 100, 'subsample': 0.7}\n"
     ]
    }
   ],
   "source": [
    "df4 = pd.read_csv(\"data\\\\xgb_results_full_4_bylevel=0.4_20221123.csv\")\n",
    "df4.drop(df4.columns[0], axis=1, inplace=True)\n",
    "display(df4)\n",
    "print(\"best score is 0.850563236047107 with params {'colsample_bylevel': 0.4, 'colsample_bytree': 0.5, 'learning_rate': 0.15, 'max_depth': 2, 'n_estimators': 100, 'subsample': 0.7}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b8606396",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_colsample_bylevel</th>\n",
       "      <th>param_colsample_bytree</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_subsample</th>\n",
       "      <th>...</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.061735</td>\n",
       "      <td>0.001296</td>\n",
       "      <td>0.006482</td>\n",
       "      <td>0.000669</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.820020</td>\n",
       "      <td>0.048275</td>\n",
       "      <td>2502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.063031</td>\n",
       "      <td>0.002778</td>\n",
       "      <td>0.006483</td>\n",
       "      <td>0.000669</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.661290</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.823221</td>\n",
       "      <td>0.059057</td>\n",
       "      <td>2077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.060638</td>\n",
       "      <td>0.000746</td>\n",
       "      <td>0.006782</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.824782</td>\n",
       "      <td>0.057512</td>\n",
       "      <td>1941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.060339</td>\n",
       "      <td>0.000919</td>\n",
       "      <td>0.006483</td>\n",
       "      <td>0.000499</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.661290</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.824834</td>\n",
       "      <td>0.059251</td>\n",
       "      <td>1818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.059840</td>\n",
       "      <td>0.001180</td>\n",
       "      <td>0.006682</td>\n",
       "      <td>0.000457</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.828059</td>\n",
       "      <td>0.053977</td>\n",
       "      <td>1289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2995</th>\n",
       "      <td>0.218216</td>\n",
       "      <td>0.004179</td>\n",
       "      <td>0.007181</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.808807</td>\n",
       "      <td>0.046180</td>\n",
       "      <td>2975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2996</th>\n",
       "      <td>0.221009</td>\n",
       "      <td>0.003402</td>\n",
       "      <td>0.007480</td>\n",
       "      <td>0.000499</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.812007</td>\n",
       "      <td>0.049754</td>\n",
       "      <td>2922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2997</th>\n",
       "      <td>0.221308</td>\n",
       "      <td>0.004515</td>\n",
       "      <td>0.007380</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.816795</td>\n",
       "      <td>0.050406</td>\n",
       "      <td>2770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998</th>\n",
       "      <td>0.219213</td>\n",
       "      <td>0.003908</td>\n",
       "      <td>0.007194</td>\n",
       "      <td>0.000425</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.816820</td>\n",
       "      <td>0.047212</td>\n",
       "      <td>2763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999</th>\n",
       "      <td>0.216122</td>\n",
       "      <td>0.003092</td>\n",
       "      <td>0.007381</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.818382</td>\n",
       "      <td>0.050014</td>\n",
       "      <td>2693</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0          0.061735      0.001296         0.006482        0.000669   \n",
       "1          0.063031      0.002778         0.006483        0.000669   \n",
       "2          0.060638      0.000746         0.006782        0.000399   \n",
       "3          0.060339      0.000919         0.006483        0.000499   \n",
       "4          0.059840      0.001180         0.006682        0.000457   \n",
       "...             ...           ...              ...             ...   \n",
       "2995       0.218216      0.004179         0.007181        0.000399   \n",
       "2996       0.221009      0.003402         0.007480        0.000499   \n",
       "2997       0.221308      0.004515         0.007380        0.000489   \n",
       "2998       0.219213      0.003908         0.007194        0.000425   \n",
       "2999       0.216122      0.003092         0.007381        0.000489   \n",
       "\n",
       "     param_colsample_bylevel param_colsample_bytree param_learning_rate  \\\n",
       "0                        0.4                    0.3                 0.1   \n",
       "1                        0.4                    0.3                 0.1   \n",
       "2                        0.4                    0.3                 0.1   \n",
       "3                        0.4                    0.3                 0.1   \n",
       "4                        0.4                    0.3                 0.1   \n",
       "...                      ...                    ...                 ...   \n",
       "2995                     0.4                    0.9                 0.4   \n",
       "2996                     0.4                    0.9                 0.4   \n",
       "2997                     0.4                    0.9                 0.4   \n",
       "2998                     0.4                    0.9                 0.4   \n",
       "2999                     0.4                    0.9                 0.4   \n",
       "\n",
       "     param_max_depth param_n_estimators param_subsample  ...  \\\n",
       "0                  2                100             0.5  ...   \n",
       "1                  2                100             0.6  ...   \n",
       "2                  2                100             0.7  ...   \n",
       "3                  2                100             0.8  ...   \n",
       "4                  2                100             0.9  ...   \n",
       "...              ...                ...             ...  ...   \n",
       "2995               5                300             0.5  ...   \n",
       "2996               5                300             0.6  ...   \n",
       "2997               5                300             0.7  ...   \n",
       "2998               5                300             0.8  ...   \n",
       "2999               5                300             0.9  ...   \n",
       "\n",
       "     split3_test_score  split4_test_score  split5_test_score  \\\n",
       "0             0.822581           0.822581           0.806452   \n",
       "1             0.838710           0.822581           0.806452   \n",
       "2             0.838710           0.806452           0.806452   \n",
       "3             0.854839           0.822581           0.806452   \n",
       "4             0.854839           0.822581           0.838710   \n",
       "...                ...                ...                ...   \n",
       "2995          0.838710           0.758065           0.790323   \n",
       "2996          0.838710           0.790323           0.806452   \n",
       "2997          0.838710           0.790323           0.790323   \n",
       "2998          0.838710           0.790323           0.806452   \n",
       "2999          0.822581           0.774194           0.774194   \n",
       "\n",
       "      split6_test_score  split7_test_score  split8_test_score  \\\n",
       "0              0.822581           0.806452           0.693548   \n",
       "1              0.838710           0.806452           0.661290   \n",
       "2              0.838710           0.806452           0.677419   \n",
       "3              0.854839           0.806452           0.661290   \n",
       "4              0.838710           0.806452           0.677419   \n",
       "...                 ...                ...                ...   \n",
       "2995           0.806452           0.790323           0.741935   \n",
       "2996           0.838710           0.774194           0.725806   \n",
       "2997           0.790323           0.822581           0.725806   \n",
       "2998           0.838710           0.790323           0.725806   \n",
       "2999           0.854839           0.790323           0.725806   \n",
       "\n",
       "      split9_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0              0.838710         0.820020        0.048275             2502  \n",
       "1              0.854839         0.823221        0.059057             2077  \n",
       "2              0.838710         0.824782        0.057512             1941  \n",
       "3              0.838710         0.824834        0.059251             1818  \n",
       "4              0.838710         0.828059        0.053977             1289  \n",
       "...                 ...              ...             ...              ...  \n",
       "2995           0.822581         0.808807        0.046180             2975  \n",
       "2996           0.790323         0.812007        0.049754             2922  \n",
       "2997           0.822581         0.816795        0.050406             2770  \n",
       "2998           0.806452         0.816820        0.047212             2763  \n",
       "2999           0.838710         0.818382        0.050014             2693  \n",
       "\n",
       "[3000 rows x 24 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score is 0.850563236047107 with params {'colsample_bylevel': 0.4, 'colsample_bytree': 0.5, 'learning_rate': 0.15, 'max_depth': 2, 'n_estimators': 100, 'subsample': 0.7}\n"
     ]
    }
   ],
   "source": [
    "# Full Tuning - Part 4\n",
    "random.seed(10)\n",
    "\n",
    "xgb = XGBClassifier()\n",
    "\n",
    "xgb_parameters = {'max_depth': [2,3,4,5]\n",
    "                   , 'subsample': [0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "                   , 'colsample_bytree': [0.3, 0.4, 0.5, 0.6, 0.9]\n",
    "                   , 'colsample_bylevel': [0.4]\n",
    "                   , 'learning_rate': [0.1, 0.15, 0.2, 0.25, 0.3, 0.4]\n",
    "                   , 'n_estimators': [100, 150, 200, 250, 300]}\n",
    "\n",
    "stratified_10_fold_cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "xgb_grid_search = GridSearchCV(xgb, xgb_parameters, scoring='accuracy', cv=stratified_10_fold_cv)\n",
    "\n",
    "xgb_grid_search.fit(X_train, y_train)\n",
    "\n",
    "xgb_grid_search_results_full_4 = pd.DataFrame(xgb_grid_search.cv_results_)\n",
    "display(xgb_grid_search_results_full_4)\n",
    "\n",
    "print(\"best score is {} with params {}\".format(xgb_grid_search.best_score_, xgb_grid_search.best_params_))\n",
    "#best score is 0.850563236047107 with params\n",
    "#{'colsample_bylevel': 0.4, 'colsample_bytree': 0.5, 'learning_rate': 0.15, 'max_depth': 2, 'n_estimators': 100, 'subsample': 0.7}\n",
    "\n",
    "# save dataframe\n",
    "from datetime import datetime\n",
    "date = str(datetime.now().date()).replace(\"-\", \"\")\n",
    "xgb_grid_search_results_full_4.to_csv(f\"results/xgb_results_full_round2_4_bylevel=0.4_{date}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9153372b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_colsample_bylevel</th>\n",
       "      <th>param_colsample_bytree</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_subsample</th>\n",
       "      <th>...</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.063530</td>\n",
       "      <td>0.002446</td>\n",
       "      <td>0.006383</td>\n",
       "      <td>0.000662</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.834537</td>\n",
       "      <td>0.044892</td>\n",
       "      <td>215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.065725</td>\n",
       "      <td>0.003351</td>\n",
       "      <td>0.006882</td>\n",
       "      <td>0.000299</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.832949</td>\n",
       "      <td>0.048291</td>\n",
       "      <td>320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.062236</td>\n",
       "      <td>0.001196</td>\n",
       "      <td>0.006780</td>\n",
       "      <td>0.000398</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.887097</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.842601</td>\n",
       "      <td>0.046342</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.061335</td>\n",
       "      <td>0.001798</td>\n",
       "      <td>0.006583</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.834562</td>\n",
       "      <td>0.050284</td>\n",
       "      <td>208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.060937</td>\n",
       "      <td>0.000698</td>\n",
       "      <td>0.006483</td>\n",
       "      <td>0.000669</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.887097</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.832924</td>\n",
       "      <td>0.057218</td>\n",
       "      <td>327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2995</th>\n",
       "      <td>0.219613</td>\n",
       "      <td>0.001532</td>\n",
       "      <td>0.007380</td>\n",
       "      <td>0.000488</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.805504</td>\n",
       "      <td>0.051226</td>\n",
       "      <td>2997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2996</th>\n",
       "      <td>0.222105</td>\n",
       "      <td>0.001787</td>\n",
       "      <td>0.006882</td>\n",
       "      <td>0.000698</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.810317</td>\n",
       "      <td>0.059764</td>\n",
       "      <td>2968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2997</th>\n",
       "      <td>0.221906</td>\n",
       "      <td>0.002534</td>\n",
       "      <td>0.007281</td>\n",
       "      <td>0.000457</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.818331</td>\n",
       "      <td>0.051641</td>\n",
       "      <td>2706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998</th>\n",
       "      <td>0.224599</td>\n",
       "      <td>0.011023</td>\n",
       "      <td>0.007380</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.816718</td>\n",
       "      <td>0.054669</td>\n",
       "      <td>2825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999</th>\n",
       "      <td>0.219812</td>\n",
       "      <td>0.002609</td>\n",
       "      <td>0.007381</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.807220</td>\n",
       "      <td>0.045482</td>\n",
       "      <td>2983</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0          0.063530      0.002446         0.006383        0.000662   \n",
       "1          0.065725      0.003351         0.006882        0.000299   \n",
       "2          0.062236      0.001196         0.006780        0.000398   \n",
       "3          0.061335      0.001798         0.006583        0.000489   \n",
       "4          0.060937      0.000698         0.006483        0.000669   \n",
       "...             ...           ...              ...             ...   \n",
       "2995       0.219613      0.001532         0.007380        0.000488   \n",
       "2996       0.222105      0.001787         0.006882        0.000698   \n",
       "2997       0.221906      0.002534         0.007281        0.000457   \n",
       "2998       0.224599      0.011023         0.007380        0.000489   \n",
       "2999       0.219812      0.002609         0.007381        0.000489   \n",
       "\n",
       "      param_colsample_bylevel  param_colsample_bytree  param_learning_rate  \\\n",
       "0                         0.6                     0.3                  0.1   \n",
       "1                         0.6                     0.3                  0.1   \n",
       "2                         0.6                     0.3                  0.1   \n",
       "3                         0.6                     0.3                  0.1   \n",
       "4                         0.6                     0.3                  0.1   \n",
       "...                       ...                     ...                  ...   \n",
       "2995                      0.6                     0.9                  0.4   \n",
       "2996                      0.6                     0.9                  0.4   \n",
       "2997                      0.6                     0.9                  0.4   \n",
       "2998                      0.6                     0.9                  0.4   \n",
       "2999                      0.6                     0.9                  0.4   \n",
       "\n",
       "      param_max_depth  param_n_estimators  param_subsample  ...  \\\n",
       "0                   2                 100              0.5  ...   \n",
       "1                   2                 100              0.6  ...   \n",
       "2                   2                 100              0.7  ...   \n",
       "3                   2                 100              0.8  ...   \n",
       "4                   2                 100              0.9  ...   \n",
       "...               ...                 ...              ...  ...   \n",
       "2995                5                 300              0.5  ...   \n",
       "2996                5                 300              0.6  ...   \n",
       "2997                5                 300              0.7  ...   \n",
       "2998                5                 300              0.8  ...   \n",
       "2999                5                 300              0.9  ...   \n",
       "\n",
       "     split3_test_score  split4_test_score  split5_test_score  \\\n",
       "0             0.870968           0.822581           0.838710   \n",
       "1             0.854839           0.822581           0.854839   \n",
       "2             0.887097           0.838710           0.854839   \n",
       "3             0.870968           0.822581           0.870968   \n",
       "4             0.870968           0.822581           0.887097   \n",
       "...                ...                ...                ...   \n",
       "2995          0.806452           0.741935           0.774194   \n",
       "2996          0.854839           0.790323           0.758065   \n",
       "2997          0.838710           0.774194           0.790323   \n",
       "2998          0.838710           0.790323           0.758065   \n",
       "2999          0.822581           0.790323           0.758065   \n",
       "\n",
       "      split6_test_score  split7_test_score  split8_test_score  \\\n",
       "0              0.854839           0.822581           0.709677   \n",
       "1              0.854839           0.822581           0.693548   \n",
       "2              0.854839           0.838710           0.709677   \n",
       "3              0.838710           0.822581           0.693548   \n",
       "4              0.822581           0.806452           0.677419   \n",
       "...                 ...                ...                ...   \n",
       "2995           0.806452           0.790323           0.741935   \n",
       "2996           0.822581           0.741935           0.725806   \n",
       "2997           0.822581           0.774194           0.725806   \n",
       "2998           0.822581           0.806452           0.709677   \n",
       "2999           0.838710           0.806452           0.709677   \n",
       "\n",
       "      split9_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0              0.838710         0.834537        0.044892              215  \n",
       "1              0.854839         0.832949        0.048291              320  \n",
       "2              0.854839         0.842601        0.046342               17  \n",
       "3              0.854839         0.834562        0.050284              208  \n",
       "4              0.854839         0.832924        0.057218              327  \n",
       "...                 ...              ...             ...              ...  \n",
       "2995           0.806452         0.805504        0.051226             2997  \n",
       "2996           0.806452         0.810317        0.059764             2968  \n",
       "2997           0.822581         0.818331        0.051641             2706  \n",
       "2998           0.806452         0.816718        0.054669             2825  \n",
       "2999           0.822581         0.807220        0.045482             2983  \n",
       "\n",
       "[3000 rows x 24 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score is 0.8458269329237071 with params {'colsample_bylevel': 0.6, 'colsample_bytree': 0.4, 'learning_rate': 0.1, 'max_depth': 2, 'n_estimators': 100, 'subsample': 0.8}\n"
     ]
    }
   ],
   "source": [
    "df5 = pd.read_csv(\"data\\\\xgb_results_full_5_bylevel=0.6_20221123.csv\")\n",
    "df5.drop(df5.columns[0], axis=1, inplace=True)\n",
    "display(df5)\n",
    "print(\"best score is 0.8458269329237071 with params {'colsample_bylevel': 0.6, 'colsample_bytree': 0.4, 'learning_rate': 0.1, 'max_depth': 2, 'n_estimators': 100, 'subsample': 0.8}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "04f9734e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_colsample_bylevel</th>\n",
       "      <th>param_colsample_bytree</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_subsample</th>\n",
       "      <th>...</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.063530</td>\n",
       "      <td>0.002446</td>\n",
       "      <td>0.006383</td>\n",
       "      <td>0.000662</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.834537</td>\n",
       "      <td>0.044892</td>\n",
       "      <td>215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.065725</td>\n",
       "      <td>0.003351</td>\n",
       "      <td>0.006882</td>\n",
       "      <td>0.000299</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.832949</td>\n",
       "      <td>0.048291</td>\n",
       "      <td>320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.062236</td>\n",
       "      <td>0.001196</td>\n",
       "      <td>0.006780</td>\n",
       "      <td>0.000398</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.887097</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.842601</td>\n",
       "      <td>0.046342</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.061335</td>\n",
       "      <td>0.001798</td>\n",
       "      <td>0.006583</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.834562</td>\n",
       "      <td>0.050284</td>\n",
       "      <td>208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.060937</td>\n",
       "      <td>0.000698</td>\n",
       "      <td>0.006483</td>\n",
       "      <td>0.000669</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.887097</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.832924</td>\n",
       "      <td>0.057218</td>\n",
       "      <td>327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2995</th>\n",
       "      <td>0.219613</td>\n",
       "      <td>0.001532</td>\n",
       "      <td>0.007380</td>\n",
       "      <td>0.000488</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.805504</td>\n",
       "      <td>0.051226</td>\n",
       "      <td>2997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2996</th>\n",
       "      <td>0.222105</td>\n",
       "      <td>0.001787</td>\n",
       "      <td>0.006882</td>\n",
       "      <td>0.000698</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.810317</td>\n",
       "      <td>0.059764</td>\n",
       "      <td>2968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2997</th>\n",
       "      <td>0.221906</td>\n",
       "      <td>0.002534</td>\n",
       "      <td>0.007281</td>\n",
       "      <td>0.000457</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.818331</td>\n",
       "      <td>0.051641</td>\n",
       "      <td>2706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998</th>\n",
       "      <td>0.224599</td>\n",
       "      <td>0.011023</td>\n",
       "      <td>0.007380</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.816718</td>\n",
       "      <td>0.054669</td>\n",
       "      <td>2825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999</th>\n",
       "      <td>0.219812</td>\n",
       "      <td>0.002609</td>\n",
       "      <td>0.007381</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.807220</td>\n",
       "      <td>0.045482</td>\n",
       "      <td>2983</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0          0.063530      0.002446         0.006383        0.000662   \n",
       "1          0.065725      0.003351         0.006882        0.000299   \n",
       "2          0.062236      0.001196         0.006780        0.000398   \n",
       "3          0.061335      0.001798         0.006583        0.000489   \n",
       "4          0.060937      0.000698         0.006483        0.000669   \n",
       "...             ...           ...              ...             ...   \n",
       "2995       0.219613      0.001532         0.007380        0.000488   \n",
       "2996       0.222105      0.001787         0.006882        0.000698   \n",
       "2997       0.221906      0.002534         0.007281        0.000457   \n",
       "2998       0.224599      0.011023         0.007380        0.000489   \n",
       "2999       0.219812      0.002609         0.007381        0.000489   \n",
       "\n",
       "     param_colsample_bylevel param_colsample_bytree param_learning_rate  \\\n",
       "0                        0.6                    0.3                 0.1   \n",
       "1                        0.6                    0.3                 0.1   \n",
       "2                        0.6                    0.3                 0.1   \n",
       "3                        0.6                    0.3                 0.1   \n",
       "4                        0.6                    0.3                 0.1   \n",
       "...                      ...                    ...                 ...   \n",
       "2995                     0.6                    0.9                 0.4   \n",
       "2996                     0.6                    0.9                 0.4   \n",
       "2997                     0.6                    0.9                 0.4   \n",
       "2998                     0.6                    0.9                 0.4   \n",
       "2999                     0.6                    0.9                 0.4   \n",
       "\n",
       "     param_max_depth param_n_estimators param_subsample  ...  \\\n",
       "0                  2                100             0.5  ...   \n",
       "1                  2                100             0.6  ...   \n",
       "2                  2                100             0.7  ...   \n",
       "3                  2                100             0.8  ...   \n",
       "4                  2                100             0.9  ...   \n",
       "...              ...                ...             ...  ...   \n",
       "2995               5                300             0.5  ...   \n",
       "2996               5                300             0.6  ...   \n",
       "2997               5                300             0.7  ...   \n",
       "2998               5                300             0.8  ...   \n",
       "2999               5                300             0.9  ...   \n",
       "\n",
       "     split3_test_score  split4_test_score  split5_test_score  \\\n",
       "0             0.870968           0.822581           0.838710   \n",
       "1             0.854839           0.822581           0.854839   \n",
       "2             0.887097           0.838710           0.854839   \n",
       "3             0.870968           0.822581           0.870968   \n",
       "4             0.870968           0.822581           0.887097   \n",
       "...                ...                ...                ...   \n",
       "2995          0.806452           0.741935           0.774194   \n",
       "2996          0.854839           0.790323           0.758065   \n",
       "2997          0.838710           0.774194           0.790323   \n",
       "2998          0.838710           0.790323           0.758065   \n",
       "2999          0.822581           0.790323           0.758065   \n",
       "\n",
       "      split6_test_score  split7_test_score  split8_test_score  \\\n",
       "0              0.854839           0.822581           0.709677   \n",
       "1              0.854839           0.822581           0.693548   \n",
       "2              0.854839           0.838710           0.709677   \n",
       "3              0.838710           0.822581           0.693548   \n",
       "4              0.822581           0.806452           0.677419   \n",
       "...                 ...                ...                ...   \n",
       "2995           0.806452           0.790323           0.741935   \n",
       "2996           0.822581           0.741935           0.725806   \n",
       "2997           0.822581           0.774194           0.725806   \n",
       "2998           0.822581           0.806452           0.709677   \n",
       "2999           0.838710           0.806452           0.709677   \n",
       "\n",
       "      split9_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0              0.838710         0.834537        0.044892              215  \n",
       "1              0.854839         0.832949        0.048291              320  \n",
       "2              0.854839         0.842601        0.046342               17  \n",
       "3              0.854839         0.834562        0.050284              208  \n",
       "4              0.854839         0.832924        0.057218              327  \n",
       "...                 ...              ...             ...              ...  \n",
       "2995           0.806452         0.805504        0.051226             2997  \n",
       "2996           0.806452         0.810317        0.059764             2968  \n",
       "2997           0.822581         0.818331        0.051641             2706  \n",
       "2998           0.806452         0.816718        0.054669             2825  \n",
       "2999           0.822581         0.807220        0.045482             2983  \n",
       "\n",
       "[3000 rows x 24 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score is 0.8458269329237071 with params {'colsample_bylevel': 0.6, 'colsample_bytree': 0.4, 'learning_rate': 0.1, 'max_depth': 2, 'n_estimators': 100, 'subsample': 0.8}\n"
     ]
    }
   ],
   "source": [
    "# Full Tuning - Part 5\n",
    "random.seed(10)\n",
    "\n",
    "xgb = XGBClassifier()\n",
    "\n",
    "xgb_parameters = {'max_depth': [2,3,4,5]\n",
    "                   , 'subsample': [0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "                   , 'colsample_bytree': [0.3, 0.4, 0.5, 0.6, 0.9]\n",
    "                   , 'colsample_bylevel': [0.6]\n",
    "                   , 'learning_rate': [0.1, 0.15, 0.2, 0.25, 0.3, 0.4]\n",
    "                   , 'n_estimators': [100, 150, 200, 250, 300]}\n",
    "\n",
    "stratified_10_fold_cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "xgb_grid_search = GridSearchCV(xgb, xgb_parameters, scoring='accuracy', cv=stratified_10_fold_cv)\n",
    "\n",
    "xgb_grid_search.fit(X_train, y_train)\n",
    "\n",
    "xgb_grid_search_results_full_5 = pd.DataFrame(xgb_grid_search.cv_results_)\n",
    "display(xgb_grid_search_results_full_5)\n",
    "\n",
    "print(\"best score is {} with params {}\".format(xgb_grid_search.best_score_, xgb_grid_search.best_params_))\n",
    "#best score is 0.8458269329237071 with params\n",
    "#{'colsample_bylevel': 0.6, 'colsample_bytree': 0.4, 'learning_rate': 0.1, 'max_depth': 2, 'n_estimators': 100, 'subsample': 0.8}\n",
    "\n",
    "# save dataframe\n",
    "from datetime import datetime\n",
    "date = str(datetime.now().date()).replace(\"-\", \"\")\n",
    "xgb_grid_search_results_full_5.to_csv(f\"results/xgb_results_full_round2_5_bylevel=0.6_{date}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b6962257",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_colsample_bylevel</th>\n",
       "      <th>param_colsample_bytree</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_subsample</th>\n",
       "      <th>...</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.063128</td>\n",
       "      <td>0.002527</td>\n",
       "      <td>0.006483</td>\n",
       "      <td>0.000669</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.834537</td>\n",
       "      <td>0.044892</td>\n",
       "      <td>218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.065325</td>\n",
       "      <td>0.003097</td>\n",
       "      <td>0.006882</td>\n",
       "      <td>0.000537</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.832949</td>\n",
       "      <td>0.048291</td>\n",
       "      <td>327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.061886</td>\n",
       "      <td>0.000566</td>\n",
       "      <td>0.006583</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.887097</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.842601</td>\n",
       "      <td>0.046342</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.061137</td>\n",
       "      <td>0.000638</td>\n",
       "      <td>0.006882</td>\n",
       "      <td>0.000299</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.834562</td>\n",
       "      <td>0.050284</td>\n",
       "      <td>210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.060537</td>\n",
       "      <td>0.000638</td>\n",
       "      <td>0.006682</td>\n",
       "      <td>0.000457</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.887097</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.832924</td>\n",
       "      <td>0.057218</td>\n",
       "      <td>333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2995</th>\n",
       "      <td>0.228489</td>\n",
       "      <td>0.002462</td>\n",
       "      <td>0.007480</td>\n",
       "      <td>0.000499</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.802355</td>\n",
       "      <td>0.049888</td>\n",
       "      <td>2998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2996</th>\n",
       "      <td>0.228688</td>\n",
       "      <td>0.002142</td>\n",
       "      <td>0.007281</td>\n",
       "      <td>0.000457</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.800768</td>\n",
       "      <td>0.052893</td>\n",
       "      <td>2999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2997</th>\n",
       "      <td>0.228987</td>\n",
       "      <td>0.001197</td>\n",
       "      <td>0.007580</td>\n",
       "      <td>0.000488</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.810317</td>\n",
       "      <td>0.057193</td>\n",
       "      <td>2964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998</th>\n",
       "      <td>0.228788</td>\n",
       "      <td>0.001620</td>\n",
       "      <td>0.007181</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.816692</td>\n",
       "      <td>0.055624</td>\n",
       "      <td>2812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999</th>\n",
       "      <td>0.226893</td>\n",
       "      <td>0.002150</td>\n",
       "      <td>0.007381</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.818382</td>\n",
       "      <td>0.053516</td>\n",
       "      <td>2629</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0          0.063128      0.002527         0.006483        0.000669   \n",
       "1          0.065325      0.003097         0.006882        0.000537   \n",
       "2          0.061886      0.000566         0.006583        0.000489   \n",
       "3          0.061137      0.000638         0.006882        0.000299   \n",
       "4          0.060537      0.000638         0.006682        0.000457   \n",
       "...             ...           ...              ...             ...   \n",
       "2995       0.228489      0.002462         0.007480        0.000499   \n",
       "2996       0.228688      0.002142         0.007281        0.000457   \n",
       "2997       0.228987      0.001197         0.007580        0.000488   \n",
       "2998       0.228788      0.001620         0.007181        0.000399   \n",
       "2999       0.226893      0.002150         0.007381        0.000489   \n",
       "\n",
       "      param_colsample_bylevel  param_colsample_bytree  param_learning_rate  \\\n",
       "0                         0.7                     0.3                  0.1   \n",
       "1                         0.7                     0.3                  0.1   \n",
       "2                         0.7                     0.3                  0.1   \n",
       "3                         0.7                     0.3                  0.1   \n",
       "4                         0.7                     0.3                  0.1   \n",
       "...                       ...                     ...                  ...   \n",
       "2995                      0.7                     0.9                  0.4   \n",
       "2996                      0.7                     0.9                  0.4   \n",
       "2997                      0.7                     0.9                  0.4   \n",
       "2998                      0.7                     0.9                  0.4   \n",
       "2999                      0.7                     0.9                  0.4   \n",
       "\n",
       "      param_max_depth  param_n_estimators  param_subsample  ...  \\\n",
       "0                   2                 100              0.5  ...   \n",
       "1                   2                 100              0.6  ...   \n",
       "2                   2                 100              0.7  ...   \n",
       "3                   2                 100              0.8  ...   \n",
       "4                   2                 100              0.9  ...   \n",
       "...               ...                 ...              ...  ...   \n",
       "2995                5                 300              0.5  ...   \n",
       "2996                5                 300              0.6  ...   \n",
       "2997                5                 300              0.7  ...   \n",
       "2998                5                 300              0.8  ...   \n",
       "2999                5                 300              0.9  ...   \n",
       "\n",
       "     split3_test_score  split4_test_score  split5_test_score  \\\n",
       "0             0.870968           0.822581           0.838710   \n",
       "1             0.854839           0.822581           0.854839   \n",
       "2             0.887097           0.838710           0.854839   \n",
       "3             0.870968           0.822581           0.870968   \n",
       "4             0.870968           0.822581           0.887097   \n",
       "...                ...                ...                ...   \n",
       "2995          0.822581           0.774194           0.806452   \n",
       "2996          0.822581           0.774194           0.790323   \n",
       "2997          0.870968           0.774194           0.774194   \n",
       "2998          0.822581           0.790323           0.774194   \n",
       "2999          0.806452           0.790323           0.774194   \n",
       "\n",
       "      split6_test_score  split7_test_score  split8_test_score  \\\n",
       "0              0.854839           0.822581           0.709677   \n",
       "1              0.854839           0.822581           0.693548   \n",
       "2              0.854839           0.838710           0.709677   \n",
       "3              0.838710           0.822581           0.693548   \n",
       "4              0.822581           0.806452           0.677419   \n",
       "...                 ...                ...                ...   \n",
       "2995           0.822581           0.774194           0.709677   \n",
       "2996           0.822581           0.790323           0.693548   \n",
       "2997           0.790323           0.790323           0.709677   \n",
       "2998           0.822581           0.790323           0.709677   \n",
       "2999           0.854839           0.790323           0.709677   \n",
       "\n",
       "      split9_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0              0.838710         0.834537        0.044892              218  \n",
       "1              0.854839         0.832949        0.048291              327  \n",
       "2              0.854839         0.842601        0.046342               16  \n",
       "3              0.854839         0.834562        0.050284              210  \n",
       "4              0.854839         0.832924        0.057218              333  \n",
       "...                 ...              ...             ...              ...  \n",
       "2995           0.774194         0.802355        0.049888             2998  \n",
       "2996           0.790323         0.800768        0.052893             2999  \n",
       "2997           0.790323         0.810317        0.057193             2964  \n",
       "2998           0.806452         0.816692        0.055624             2812  \n",
       "2999           0.854839         0.818382        0.053516             2629  \n",
       "\n",
       "[3000 rows x 24 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score is 0.8490015360983103 with params {'colsample_bylevel': 0.7, 'colsample_bytree': 0.4, 'learning_rate': 0.1, 'max_depth': 2, 'n_estimators': 150, 'subsample': 0.9}\n"
     ]
    }
   ],
   "source": [
    "df6 = pd.read_csv(\"data\\\\xgb_results_full_6_bylevel=0.7_20221123.csv\")\n",
    "df6.drop(df6.columns[0], axis=1, inplace=True)\n",
    "display(df6)\n",
    "print(\"best score is 0.8490015360983103 with params {'colsample_bylevel': 0.7, 'colsample_bytree': 0.4, 'learning_rate': 0.1, 'max_depth': 2, 'n_estimators': 150, 'subsample': 0.9}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dc96b622",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_colsample_bylevel</th>\n",
       "      <th>param_colsample_bytree</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_subsample</th>\n",
       "      <th>...</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.063128</td>\n",
       "      <td>0.002527</td>\n",
       "      <td>0.006483</td>\n",
       "      <td>0.000669</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.834537</td>\n",
       "      <td>0.044892</td>\n",
       "      <td>218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.065325</td>\n",
       "      <td>0.003097</td>\n",
       "      <td>0.006882</td>\n",
       "      <td>0.000537</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.832949</td>\n",
       "      <td>0.048291</td>\n",
       "      <td>327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.061886</td>\n",
       "      <td>0.000566</td>\n",
       "      <td>0.006583</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.887097</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.842601</td>\n",
       "      <td>0.046342</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.061137</td>\n",
       "      <td>0.000638</td>\n",
       "      <td>0.006882</td>\n",
       "      <td>0.000299</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.834562</td>\n",
       "      <td>0.050284</td>\n",
       "      <td>210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.060537</td>\n",
       "      <td>0.000638</td>\n",
       "      <td>0.006682</td>\n",
       "      <td>0.000457</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.887097</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.832924</td>\n",
       "      <td>0.057218</td>\n",
       "      <td>333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2995</th>\n",
       "      <td>0.228489</td>\n",
       "      <td>0.002462</td>\n",
       "      <td>0.007480</td>\n",
       "      <td>0.000499</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.802355</td>\n",
       "      <td>0.049888</td>\n",
       "      <td>2998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2996</th>\n",
       "      <td>0.228688</td>\n",
       "      <td>0.002142</td>\n",
       "      <td>0.007281</td>\n",
       "      <td>0.000457</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.800768</td>\n",
       "      <td>0.052893</td>\n",
       "      <td>2999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2997</th>\n",
       "      <td>0.228987</td>\n",
       "      <td>0.001197</td>\n",
       "      <td>0.007580</td>\n",
       "      <td>0.000488</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.810317</td>\n",
       "      <td>0.057193</td>\n",
       "      <td>2964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998</th>\n",
       "      <td>0.228788</td>\n",
       "      <td>0.001620</td>\n",
       "      <td>0.007181</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.816692</td>\n",
       "      <td>0.055624</td>\n",
       "      <td>2812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999</th>\n",
       "      <td>0.226893</td>\n",
       "      <td>0.002150</td>\n",
       "      <td>0.007381</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.818382</td>\n",
       "      <td>0.053516</td>\n",
       "      <td>2629</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0          0.063128      0.002527         0.006483        0.000669   \n",
       "1          0.065325      0.003097         0.006882        0.000537   \n",
       "2          0.061886      0.000566         0.006583        0.000489   \n",
       "3          0.061137      0.000638         0.006882        0.000299   \n",
       "4          0.060537      0.000638         0.006682        0.000457   \n",
       "...             ...           ...              ...             ...   \n",
       "2995       0.228489      0.002462         0.007480        0.000499   \n",
       "2996       0.228688      0.002142         0.007281        0.000457   \n",
       "2997       0.228987      0.001197         0.007580        0.000488   \n",
       "2998       0.228788      0.001620         0.007181        0.000399   \n",
       "2999       0.226893      0.002150         0.007381        0.000489   \n",
       "\n",
       "     param_colsample_bylevel param_colsample_bytree param_learning_rate  \\\n",
       "0                        0.7                    0.3                 0.1   \n",
       "1                        0.7                    0.3                 0.1   \n",
       "2                        0.7                    0.3                 0.1   \n",
       "3                        0.7                    0.3                 0.1   \n",
       "4                        0.7                    0.3                 0.1   \n",
       "...                      ...                    ...                 ...   \n",
       "2995                     0.7                    0.9                 0.4   \n",
       "2996                     0.7                    0.9                 0.4   \n",
       "2997                     0.7                    0.9                 0.4   \n",
       "2998                     0.7                    0.9                 0.4   \n",
       "2999                     0.7                    0.9                 0.4   \n",
       "\n",
       "     param_max_depth param_n_estimators param_subsample  ...  \\\n",
       "0                  2                100             0.5  ...   \n",
       "1                  2                100             0.6  ...   \n",
       "2                  2                100             0.7  ...   \n",
       "3                  2                100             0.8  ...   \n",
       "4                  2                100             0.9  ...   \n",
       "...              ...                ...             ...  ...   \n",
       "2995               5                300             0.5  ...   \n",
       "2996               5                300             0.6  ...   \n",
       "2997               5                300             0.7  ...   \n",
       "2998               5                300             0.8  ...   \n",
       "2999               5                300             0.9  ...   \n",
       "\n",
       "     split3_test_score  split4_test_score  split5_test_score  \\\n",
       "0             0.870968           0.822581           0.838710   \n",
       "1             0.854839           0.822581           0.854839   \n",
       "2             0.887097           0.838710           0.854839   \n",
       "3             0.870968           0.822581           0.870968   \n",
       "4             0.870968           0.822581           0.887097   \n",
       "...                ...                ...                ...   \n",
       "2995          0.822581           0.774194           0.806452   \n",
       "2996          0.822581           0.774194           0.790323   \n",
       "2997          0.870968           0.774194           0.774194   \n",
       "2998          0.822581           0.790323           0.774194   \n",
       "2999          0.806452           0.790323           0.774194   \n",
       "\n",
       "      split6_test_score  split7_test_score  split8_test_score  \\\n",
       "0              0.854839           0.822581           0.709677   \n",
       "1              0.854839           0.822581           0.693548   \n",
       "2              0.854839           0.838710           0.709677   \n",
       "3              0.838710           0.822581           0.693548   \n",
       "4              0.822581           0.806452           0.677419   \n",
       "...                 ...                ...                ...   \n",
       "2995           0.822581           0.774194           0.709677   \n",
       "2996           0.822581           0.790323           0.693548   \n",
       "2997           0.790323           0.790323           0.709677   \n",
       "2998           0.822581           0.790323           0.709677   \n",
       "2999           0.854839           0.790323           0.709677   \n",
       "\n",
       "      split9_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0              0.838710         0.834537        0.044892              218  \n",
       "1              0.854839         0.832949        0.048291              327  \n",
       "2              0.854839         0.842601        0.046342               16  \n",
       "3              0.854839         0.834562        0.050284              210  \n",
       "4              0.854839         0.832924        0.057218              333  \n",
       "...                 ...              ...             ...              ...  \n",
       "2995           0.774194         0.802355        0.049888             2998  \n",
       "2996           0.790323         0.800768        0.052893             2999  \n",
       "2997           0.790323         0.810317        0.057193             2964  \n",
       "2998           0.806452         0.816692        0.055624             2812  \n",
       "2999           0.854839         0.818382        0.053516             2629  \n",
       "\n",
       "[3000 rows x 24 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score is 0.8490015360983103 with params {'colsample_bylevel': 0.7, 'colsample_bytree': 0.4, 'learning_rate': 0.1, 'max_depth': 2, 'n_estimators': 150, 'subsample': 0.9}\n"
     ]
    }
   ],
   "source": [
    "# Full Tuning - Part 6\n",
    "random.seed(10)\n",
    "\n",
    "xgb = XGBClassifier()\n",
    "\n",
    "xgb_parameters = {'max_depth': [2,3,4,5]\n",
    "                   , 'subsample': [0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "                   , 'colsample_bytree': [0.3, 0.4, 0.5, 0.6, 0.9]\n",
    "                   , 'colsample_bylevel': [0.7]\n",
    "                   , 'learning_rate': [0.1, 0.15, 0.2, 0.25, 0.3, 0.4]\n",
    "                   , 'n_estimators': [100, 150, 200, 250, 300]}\n",
    "\n",
    "stratified_10_fold_cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "xgb_grid_search = GridSearchCV(xgb, xgb_parameters, scoring='accuracy', cv=stratified_10_fold_cv)\n",
    "\n",
    "xgb_grid_search.fit(X_train, y_train)\n",
    "\n",
    "xgb_grid_search_results_full_6 = pd.DataFrame(xgb_grid_search.cv_results_)\n",
    "display(xgb_grid_search_results_full_6)\n",
    "\n",
    "print(\"best score is {} with params {}\".format(xgb_grid_search.best_score_, xgb_grid_search.best_params_))\n",
    "#best score is 0.8490015360983103 with params\n",
    "#{'colsample_bylevel': 0.7, 'colsample_bytree': 0.4, 'learning_rate': 0.1, 'max_depth': 2, 'n_estimators': 150, 'subsample': 0.9}\n",
    "\n",
    "# save dataframe\n",
    "from datetime import datetime\n",
    "date = str(datetime.now().date()).replace(\"-\", \"\")\n",
    "xgb_grid_search_results_full_6.to_csv(f\"results/xgb_results_full_round2_6_bylevel=0.7_{date}.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd55526d",
   "metadata": {},
   "source": [
    "Combine single hyper parameter tuning to find best values for hyper parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9b22556b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_colsample_bylevel</th>\n",
       "      <th>param_colsample_bytree</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_subsample</th>\n",
       "      <th>...</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.064527</td>\n",
       "      <td>0.004136</td>\n",
       "      <td>0.005885</td>\n",
       "      <td>0.000538</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.820020</td>\n",
       "      <td>0.048275</td>\n",
       "      <td>15186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.064327</td>\n",
       "      <td>0.002493</td>\n",
       "      <td>0.005885</td>\n",
       "      <td>0.000537</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.661290</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.823221</td>\n",
       "      <td>0.059057</td>\n",
       "      <td>12810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.063231</td>\n",
       "      <td>0.001954</td>\n",
       "      <td>0.005785</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.824782</td>\n",
       "      <td>0.057512</td>\n",
       "      <td>12084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.062235</td>\n",
       "      <td>0.001017</td>\n",
       "      <td>0.006082</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.661290</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.824834</td>\n",
       "      <td>0.059251</td>\n",
       "      <td>11402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.062333</td>\n",
       "      <td>0.002285</td>\n",
       "      <td>0.005784</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.828059</td>\n",
       "      <td>0.053977</td>\n",
       "      <td>8256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17995</th>\n",
       "      <td>0.228489</td>\n",
       "      <td>0.002462</td>\n",
       "      <td>0.007480</td>\n",
       "      <td>0.000499</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.802355</td>\n",
       "      <td>0.049888</td>\n",
       "      <td>17998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17996</th>\n",
       "      <td>0.228688</td>\n",
       "      <td>0.002142</td>\n",
       "      <td>0.007281</td>\n",
       "      <td>0.000457</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.800768</td>\n",
       "      <td>0.052893</td>\n",
       "      <td>17999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17997</th>\n",
       "      <td>0.228987</td>\n",
       "      <td>0.001197</td>\n",
       "      <td>0.007580</td>\n",
       "      <td>0.000488</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.810317</td>\n",
       "      <td>0.057193</td>\n",
       "      <td>17871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17998</th>\n",
       "      <td>0.228788</td>\n",
       "      <td>0.001620</td>\n",
       "      <td>0.007181</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.816692</td>\n",
       "      <td>0.055624</td>\n",
       "      <td>17108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17999</th>\n",
       "      <td>0.226893</td>\n",
       "      <td>0.002150</td>\n",
       "      <td>0.007381</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.818382</td>\n",
       "      <td>0.053516</td>\n",
       "      <td>16381</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18000 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0           0.064527      0.004136         0.005885        0.000538   \n",
       "1           0.064327      0.002493         0.005885        0.000537   \n",
       "2           0.063231      0.001954         0.005785        0.000399   \n",
       "3           0.062235      0.001017         0.006082        0.000300   \n",
       "4           0.062333      0.002285         0.005784        0.000399   \n",
       "...              ...           ...              ...             ...   \n",
       "17995       0.228489      0.002462         0.007480        0.000499   \n",
       "17996       0.228688      0.002142         0.007281        0.000457   \n",
       "17997       0.228987      0.001197         0.007580        0.000488   \n",
       "17998       0.228788      0.001620         0.007181        0.000399   \n",
       "17999       0.226893      0.002150         0.007381        0.000489   \n",
       "\n",
       "       param_colsample_bylevel  param_colsample_bytree  param_learning_rate  \\\n",
       "0                          0.1                     0.3                  0.1   \n",
       "1                          0.1                     0.3                  0.1   \n",
       "2                          0.1                     0.3                  0.1   \n",
       "3                          0.1                     0.3                  0.1   \n",
       "4                          0.1                     0.3                  0.1   \n",
       "...                        ...                     ...                  ...   \n",
       "17995                      0.7                     0.9                  0.4   \n",
       "17996                      0.7                     0.9                  0.4   \n",
       "17997                      0.7                     0.9                  0.4   \n",
       "17998                      0.7                     0.9                  0.4   \n",
       "17999                      0.7                     0.9                  0.4   \n",
       "\n",
       "       param_max_depth  param_n_estimators  param_subsample  ...  \\\n",
       "0                    2                 100              0.5  ...   \n",
       "1                    2                 100              0.6  ...   \n",
       "2                    2                 100              0.7  ...   \n",
       "3                    2                 100              0.8  ...   \n",
       "4                    2                 100              0.9  ...   \n",
       "...                ...                 ...              ...  ...   \n",
       "17995                5                 300              0.5  ...   \n",
       "17996                5                 300              0.6  ...   \n",
       "17997                5                 300              0.7  ...   \n",
       "17998                5                 300              0.8  ...   \n",
       "17999                5                 300              0.9  ...   \n",
       "\n",
       "      split3_test_score  split4_test_score  split5_test_score  \\\n",
       "0              0.822581           0.822581           0.806452   \n",
       "1              0.838710           0.822581           0.806452   \n",
       "2              0.838710           0.806452           0.806452   \n",
       "3              0.854839           0.822581           0.806452   \n",
       "4              0.854839           0.822581           0.838710   \n",
       "...                 ...                ...                ...   \n",
       "17995          0.822581           0.774194           0.806452   \n",
       "17996          0.822581           0.774194           0.790323   \n",
       "17997          0.870968           0.774194           0.774194   \n",
       "17998          0.822581           0.790323           0.774194   \n",
       "17999          0.806452           0.790323           0.774194   \n",
       "\n",
       "       split6_test_score  split7_test_score  split8_test_score  \\\n",
       "0               0.822581           0.806452           0.693548   \n",
       "1               0.838710           0.806452           0.661290   \n",
       "2               0.838710           0.806452           0.677419   \n",
       "3               0.854839           0.806452           0.661290   \n",
       "4               0.838710           0.806452           0.677419   \n",
       "...                  ...                ...                ...   \n",
       "17995           0.822581           0.774194           0.709677   \n",
       "17996           0.822581           0.790323           0.693548   \n",
       "17997           0.790323           0.790323           0.709677   \n",
       "17998           0.822581           0.790323           0.709677   \n",
       "17999           0.854839           0.790323           0.709677   \n",
       "\n",
       "       split9_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0               0.838710         0.820020        0.048275            15186  \n",
       "1               0.854839         0.823221        0.059057            12810  \n",
       "2               0.838710         0.824782        0.057512            12084  \n",
       "3               0.838710         0.824834        0.059251            11402  \n",
       "4               0.838710         0.828059        0.053977             8256  \n",
       "...                  ...              ...             ...              ...  \n",
       "17995           0.774194         0.802355        0.049888            17998  \n",
       "17996           0.790323         0.800768        0.052893            17999  \n",
       "17997           0.790323         0.810317        0.057193            17871  \n",
       "17998           0.806452         0.816692        0.055624            17108  \n",
       "17999           0.854839         0.818382        0.053516            16381  \n",
       "\n",
       "[18000 rows x 24 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score is 0.850563 with params {'colsample_bylevel': 0.4, 'colsample_bytree': 0.5, 'learning_rate': 0.15, 'max_depth': 2, 'n_estimators': 100, 'subsample': 0.7}\n"
     ]
    }
   ],
   "source": [
    "# read single parts of round 2, concatenate and update index and rank_test_score\n",
    "\n",
    "df1 = pd.read_csv(\"data\\\\xgb_results_full_1_bylevel=0.1_20221123.csv\")\n",
    "df1.drop(df1.columns[0], axis=1, inplace=True)\n",
    "\n",
    "df2 = pd.read_csv(\"data\\\\xgb_results_full_2_bylevel=0.2_20221123.csv\")\n",
    "df2.drop(df2.columns[0], axis=1, inplace=True)\n",
    "\n",
    "df3 = pd.read_csv(\"data\\\\xgb_results_full_3_bylevel=0.3_20221123.csv\")\n",
    "df3.drop(df3.columns[0], axis=1, inplace=True)\n",
    "\n",
    "df4 = pd.read_csv(\"data\\\\xgb_results_full_4_bylevel=0.4_20221123.csv\")\n",
    "df4.drop(df4.columns[0], axis=1, inplace=True)\n",
    "\n",
    "df5 = pd.read_csv(\"data\\\\xgb_results_full_5_bylevel=0.6_20221123.csv\")\n",
    "df5.drop(df5.columns[0], axis=1, inplace=True)\n",
    "\n",
    "df6 = pd.read_csv(\"data\\\\xgb_results_full_6_bylevel=0.7_20221123.csv\")\n",
    "df6.drop(df6.columns[0], axis=1, inplace=True)\n",
    "\n",
    "df_full = pd.concat([df1,df2,df3,df4,df5,df6])\n",
    "\n",
    "#assign correct rank\n",
    "df_full = df_full.sort_values(by='mean_test_score', ascending=False)\n",
    "df_full['rank_test_score'] = range(1, len(df_full)+1)\n",
    "\n",
    "#get correct order and set new index\n",
    "df_full = df_full.sort_values(by=['param_colsample_bylevel', 'param_colsample_bytree', 'param_learning_rate', 'param_max_depth', 'param_n_estimators', 'param_subsample'])\n",
    "xgb_grid_search_results_round2 = df_full.set_index(np.array(range(len(df_full))))\n",
    "display(xgb_grid_search_results_round2)\n",
    "\n",
    "print(\"best score is 0.850563 with params {'colsample_bylevel': 0.4, 'colsample_bytree': 0.5, 'learning_rate': 0.15, 'max_depth': 2, 'n_estimators': 100, 'subsample': 0.7}\")\n",
    "\n",
    "# save dataframe\n",
    "from datetime import datetime\n",
    "date = str(datetime.now().date()).replace(\"-\", \"\")\n",
    "xgb_grid_search_results_round2.to_csv(f\"results/xgb_results_round2_{date}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "22eaf083",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_subsample</th>\n",
       "      <th>param_colsample_bylevel</th>\n",
       "      <th>param_colsample_bytree</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10302</th>\n",
       "      <td>2</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.15</td>\n",
       "      <td>100</td>\n",
       "      <td>0.850563</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7302</th>\n",
       "      <td>2</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.15</td>\n",
       "      <td>100</td>\n",
       "      <td>0.850563</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4976</th>\n",
       "      <td>5</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.15</td>\n",
       "      <td>100</td>\n",
       "      <td>0.850538</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1976</th>\n",
       "      <td>5</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.15</td>\n",
       "      <td>100</td>\n",
       "      <td>0.850538</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5419</th>\n",
       "      <td>2</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.10</td>\n",
       "      <td>250</td>\n",
       "      <td>0.849002</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7745</th>\n",
       "      <td>3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.40</td>\n",
       "      <td>300</td>\n",
       "      <td>0.803943</td>\n",
       "      <td>17996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13171</th>\n",
       "      <td>4</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.40</td>\n",
       "      <td>300</td>\n",
       "      <td>0.803917</td>\n",
       "      <td>17997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17995</th>\n",
       "      <td>5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.40</td>\n",
       "      <td>300</td>\n",
       "      <td>0.802355</td>\n",
       "      <td>17998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17996</th>\n",
       "      <td>5</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.40</td>\n",
       "      <td>300</td>\n",
       "      <td>0.800768</td>\n",
       "      <td>17999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17940</th>\n",
       "      <td>3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.40</td>\n",
       "      <td>250</td>\n",
       "      <td>0.800742</td>\n",
       "      <td>18000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18000 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       param_max_depth  param_subsample  param_colsample_bylevel  \\\n",
       "10302                2              0.7                      0.4   \n",
       "7302                 2              0.7                      0.3   \n",
       "4976                 5              0.6                      0.2   \n",
       "1976                 5              0.6                      0.1   \n",
       "5419                 2              0.9                      0.2   \n",
       "...                ...              ...                      ...   \n",
       "7745                 3              0.5                      0.3   \n",
       "13171                4              0.6                      0.6   \n",
       "17995                5              0.5                      0.7   \n",
       "17996                5              0.6                      0.7   \n",
       "17940                3              0.5                      0.7   \n",
       "\n",
       "       param_colsample_bytree  param_learning_rate  param_n_estimators  \\\n",
       "10302                     0.5                 0.15                 100   \n",
       "7302                      0.5                 0.15                 100   \n",
       "4976                      0.6                 0.15                 100   \n",
       "1976                      0.6                 0.15                 100   \n",
       "5419                      0.9                 0.10                 250   \n",
       "...                       ...                  ...                 ...   \n",
       "7745                      0.5                 0.40                 300   \n",
       "13171                     0.4                 0.40                 300   \n",
       "17995                     0.9                 0.40                 300   \n",
       "17996                     0.9                 0.40                 300   \n",
       "17940                     0.9                 0.40                 250   \n",
       "\n",
       "       mean_test_score  rank_test_score  \n",
       "10302         0.850563                1  \n",
       "7302          0.850563                2  \n",
       "4976          0.850538                3  \n",
       "1976          0.850538                4  \n",
       "5419          0.849002                5  \n",
       "...                ...              ...  \n",
       "7745          0.803943            17996  \n",
       "13171         0.803917            17997  \n",
       "17995         0.802355            17998  \n",
       "17996         0.800768            17999  \n",
       "17940         0.800742            18000  \n",
       "\n",
       "[18000 rows x 8 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# store relevant columns and sort by rank_test_score\n",
    "cols_full = ['param_max_depth', 'param_subsample', 'param_colsample_bylevel', 'param_colsample_bytree', 'param_learning_rate', 'param_n_estimators', 'mean_test_score', 'rank_test_score']\n",
    "xgb_results_round2_sorted = xgb_grid_search_results_round2[cols_full]\n",
    "xgb_results_round2_sorted = xgb_results_round2_sorted.sort_values(by='rank_test_score')\n",
    "display(xgb_results_round2_sorted)\n",
    "\n",
    "# save dataframe\n",
    "from datetime import datetime\n",
    "date = str(datetime.now().date()).replace(\"-\", \"\")\n",
    "xgb_results_round2_sorted.to_csv(f\"results/xgb_results_round2_sorted_{date}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "31aeddd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.8283582089552238\n",
      "F1 Score = 0.7788461538461539\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.90      0.86       157\n",
      "           1       0.84      0.73      0.78       111\n",
      "\n",
      "    accuracy                           0.83       268\n",
      "   macro avg       0.83      0.81      0.82       268\n",
      "weighted avg       0.83      0.83      0.83       268\n",
      "\n",
      "Confusion Matrix:\n",
      "[[141  16]\n",
      " [ 30  81]]\n"
     ]
    }
   ],
   "source": [
    "# Fit and evaluate best model\n",
    "\n",
    "xgb_best = XGBClassifier(max_depth = 2, subsample = 0.7, colsample_bylevel = 0.4, colsample_bytree = 0.5, learning_rate = 0.15, n_estimators = 100)\n",
    "xgb_best.fit(X_train, y_train)\n",
    "xgb_best_pred = xgb_best.predict(X_test)\n",
    "\n",
    "xgb_best_acc = accuracy_score(y_test, xgb_best_pred)\n",
    "print(\"Accuracy =\", xgb_best_acc) #0.8283582089552238\n",
    "\n",
    "xgb_best_f1 = f1_score(y_test, xgb_best_pred)\n",
    "print(\"F1 Score =\", xgb_best_f1) #0.7788461538461539\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, xgb_best_pred))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, xgb_best_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56268403",
   "metadata": {},
   "source": [
    "beim nÃ¤chsten Tuning:  \n",
    "- param_subsample ungleich 0.5\n",
    "- param_colsample_bytree ungleich 0.3\n",
    "- param_colsample_bylevel ungleich 0.6\n",
    "- param_learning_rate kleiner gleich 0.2\n",
    "- param_n_estimators ungleich 200 und ungleich 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f05c0475",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc874cb6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af95c214",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2f3a4dda",
   "metadata": {},
   "source": [
    "#### Third Attempt\n",
    "We perform a second hyper parameter tuning, adjusting the parameter grid according to the results of round 2. We use the following parameters and values:  \n",
    "\n",
    "{'max_depth': [2,3,4,5]  \n",
    ", 'subsample': [0.6, 0.7, 0.8, 0.9]  \n",
    ", 'gamma': [0, 1, 10]  \n",
    ", 'colsample_bytree': [0.4, 0.5, 0.6, 0.9]  \n",
    ", 'colsample_bylevel': [0.1, 0.2, 0.3, 0.4]  \n",
    ", 'learning_rate': [0.01, 0.05, 0.08, 0.1, 0.15, 0.2]  \n",
    ", 'n_estimators': [30, 50, 80, 100, 150, 200]}  \n",
    "\n",
    "The best hyper parameter setting results to be xxx which leads to an accuracy of xxx% and a f1 score of xxx% on the test data (after training the classifier on the whole train data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dfb85f37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_colsample_bylevel</th>\n",
       "      <th>param_colsample_bytree</th>\n",
       "      <th>param_gamma</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>...</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.028623</td>\n",
       "      <td>0.002525</td>\n",
       "      <td>0.007181</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.741295</td>\n",
       "      <td>0.048078</td>\n",
       "      <td>27618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.027127</td>\n",
       "      <td>0.000598</td>\n",
       "      <td>0.007082</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.742908</td>\n",
       "      <td>0.049390</td>\n",
       "      <td>27616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.027028</td>\n",
       "      <td>0.000698</td>\n",
       "      <td>0.007580</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.752586</td>\n",
       "      <td>0.048690</td>\n",
       "      <td>27568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.027427</td>\n",
       "      <td>0.000920</td>\n",
       "      <td>0.007381</td>\n",
       "      <td>0.000662</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.742960</td>\n",
       "      <td>0.043040</td>\n",
       "      <td>27614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.040093</td>\n",
       "      <td>0.001465</td>\n",
       "      <td>0.007082</td>\n",
       "      <td>0.000536</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>...</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.765463</td>\n",
       "      <td>0.037846</td>\n",
       "      <td>27462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27643</th>\n",
       "      <td>0.129354</td>\n",
       "      <td>0.001184</td>\n",
       "      <td>0.007281</td>\n",
       "      <td>0.000457</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.20</td>\n",
       "      <td>5</td>\n",
       "      <td>150</td>\n",
       "      <td>...</td>\n",
       "      <td>0.887097</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.919355</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.826600</td>\n",
       "      <td>0.059814</td>\n",
       "      <td>14497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27644</th>\n",
       "      <td>0.168948</td>\n",
       "      <td>0.001739</td>\n",
       "      <td>0.007581</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.20</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.919355</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.828187</td>\n",
       "      <td>0.060472</td>\n",
       "      <td>13496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27645</th>\n",
       "      <td>0.170344</td>\n",
       "      <td>0.002515</td>\n",
       "      <td>0.007481</td>\n",
       "      <td>0.000498</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.20</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.887097</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.824936</td>\n",
       "      <td>0.057195</td>\n",
       "      <td>15641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27646</th>\n",
       "      <td>0.169896</td>\n",
       "      <td>0.002405</td>\n",
       "      <td>0.007281</td>\n",
       "      <td>0.000457</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.20</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.824910</td>\n",
       "      <td>0.045101</td>\n",
       "      <td>15655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27647</th>\n",
       "      <td>0.169047</td>\n",
       "      <td>0.001201</td>\n",
       "      <td>0.007281</td>\n",
       "      <td>0.000457</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.20</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.887097</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.919355</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.826600</td>\n",
       "      <td>0.059814</td>\n",
       "      <td>14482</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27648 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0           0.028623      0.002525         0.007181        0.000399   \n",
       "1           0.027127      0.000598         0.007082        0.000300   \n",
       "2           0.027028      0.000698         0.007580        0.000489   \n",
       "3           0.027427      0.000920         0.007381        0.000662   \n",
       "4           0.040093      0.001465         0.007082        0.000536   \n",
       "...              ...           ...              ...             ...   \n",
       "27643       0.129354      0.001184         0.007281        0.000457   \n",
       "27644       0.168948      0.001739         0.007581        0.000489   \n",
       "27645       0.170344      0.002515         0.007481        0.000498   \n",
       "27646       0.169896      0.002405         0.007281        0.000457   \n",
       "27647       0.169047      0.001201         0.007281        0.000457   \n",
       "\n",
       "       param_colsample_bylevel  param_colsample_bytree  param_gamma  \\\n",
       "0                          0.1                     0.4            0   \n",
       "1                          0.1                     0.4            0   \n",
       "2                          0.1                     0.4            0   \n",
       "3                          0.1                     0.4            0   \n",
       "4                          0.1                     0.4            0   \n",
       "...                        ...                     ...          ...   \n",
       "27643                      0.4                     0.9           10   \n",
       "27644                      0.4                     0.9           10   \n",
       "27645                      0.4                     0.9           10   \n",
       "27646                      0.4                     0.9           10   \n",
       "27647                      0.4                     0.9           10   \n",
       "\n",
       "       param_learning_rate  param_max_depth  param_n_estimators  ...  \\\n",
       "0                     0.01                2                  30  ...   \n",
       "1                     0.01                2                  30  ...   \n",
       "2                     0.01                2                  30  ...   \n",
       "3                     0.01                2                  30  ...   \n",
       "4                     0.01                2                  50  ...   \n",
       "...                    ...              ...                 ...  ...   \n",
       "27643                 0.20                5                 150  ...   \n",
       "27644                 0.20                5                 200  ...   \n",
       "27645                 0.20                5                 200  ...   \n",
       "27646                 0.20                5                 200  ...   \n",
       "27647                 0.20                5                 200  ...   \n",
       "\n",
       "       split3_test_score split4_test_score  split5_test_score  \\\n",
       "0               0.758065          0.741935           0.741935   \n",
       "1               0.774194          0.741935           0.741935   \n",
       "2               0.774194          0.758065           0.774194   \n",
       "3               0.790323          0.725806           0.709677   \n",
       "4               0.790323          0.774194           0.774194   \n",
       "...                  ...               ...                ...   \n",
       "27643           0.887097          0.806452           0.919355   \n",
       "27644           0.919355          0.838710           0.870968   \n",
       "27645           0.870968          0.806452           0.887097   \n",
       "27646           0.870968          0.806452           0.854839   \n",
       "27647           0.887097          0.806452           0.919355   \n",
       "\n",
       "       split6_test_score  split7_test_score  split8_test_score  \\\n",
       "0               0.725806           0.677419           0.693548   \n",
       "1               0.725806           0.677419           0.677419   \n",
       "2               0.741935           0.693548           0.677419   \n",
       "3               0.741935           0.709677           0.709677   \n",
       "4               0.725806           0.693548           0.725806   \n",
       "...                  ...                ...                ...   \n",
       "27643           0.822581           0.806452           0.693548   \n",
       "27644           0.806452           0.806452           0.677419   \n",
       "27645           0.806452           0.822581           0.677419   \n",
       "27646           0.822581           0.806452           0.709677   \n",
       "27647           0.822581           0.806452           0.693548   \n",
       "\n",
       "       split9_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0               0.677419         0.741295        0.048078            27618  \n",
       "1               0.693548         0.742908        0.049390            27616  \n",
       "2               0.709677         0.752586        0.048690            27568  \n",
       "3               0.677419         0.742960        0.043040            27614  \n",
       "4               0.758065         0.765463        0.037846            27462  \n",
       "...                  ...              ...             ...              ...  \n",
       "27643           0.822581         0.826600        0.059814            14497  \n",
       "27644           0.838710         0.828187        0.060472            13496  \n",
       "27645           0.838710         0.824936        0.057195            15641  \n",
       "27646           0.822581         0.824910        0.045101            15655  \n",
       "27647           0.822581         0.826600        0.059814            14482  \n",
       "\n",
       "[27648 rows x 25 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score is 0.850563 with params {'colsample_bylevel': 0.4, 'colsample_bytree': 0.4, 'gamma': 1, 'learning_rate': 0.15, 'max_depth': 4, 'n_estimators': 30, 'subsample': 0.9}\n"
     ]
    }
   ],
   "source": [
    "# read single parts of round 3, concatenate and update index and rank_test_score\n",
    "\n",
    "df1 = pd.read_csv(\"data\\\\xgb_results_full_1_learning=0.01_20221124.csv\")\n",
    "df1.drop(df1.columns[0], axis=1, inplace=True)\n",
    "\n",
    "df2 = pd.read_csv(\"data\\\\xgb_results_full_2_learning=0.05_20221124.csv\")\n",
    "df2.drop(df2.columns[0], axis=1, inplace=True)\n",
    "\n",
    "df3 = pd.read_csv(\"data\\\\xgb_results_full_3_learning=0.08_20221124.csv\")\n",
    "df3.drop(df3.columns[0], axis=1, inplace=True)\n",
    "\n",
    "df4 = pd.read_csv(\"data\\\\xgb_results_full_4_learning=0.1_20221124.csv\")\n",
    "df4.drop(df4.columns[0], axis=1, inplace=True)\n",
    "\n",
    "df5 = pd.read_csv(\"data\\\\xgb_results_full_5_learning=0.15_20221124.csv\")\n",
    "df5.drop(df5.columns[0], axis=1, inplace=True)\n",
    "\n",
    "df6 = pd.read_csv(\"data\\\\xgb_results_full_6_learning=0.2_20221124.csv\")\n",
    "df6.drop(df6.columns[0], axis=1, inplace=True)\n",
    "\n",
    "df_full = pd.concat([df1,df2,df3,df4,df5,df6])\n",
    "\n",
    "#assign correct rank\n",
    "df_full = df_full.sort_values(by='mean_test_score', ascending=False)\n",
    "df_full['rank_test_score'] = range(1, len(df_full)+1)\n",
    "\n",
    "#get correct order and set new index\n",
    "df_full = df_full.sort_values(by=['param_colsample_bylevel', 'param_colsample_bytree', 'param_gamma', 'param_learning_rate', 'param_max_depth', 'param_n_estimators', 'param_subsample'])\n",
    "xgb_grid_search_results_round3 = df_full.set_index(np.array(range(len(df_full))))\n",
    "display(xgb_grid_search_results_round3)\n",
    "\n",
    "print(\"best score is 0.850563 with params {'colsample_bylevel': 0.4, 'colsample_bytree': 0.4, 'gamma': 1, 'learning_rate': 0.15, 'max_depth': 4, 'n_estimators': 30, 'subsample': 0.9}\")\n",
    "\n",
    "# save dataframe\n",
    "from datetime import datetime\n",
    "date = str(datetime.now().date()).replace(\"-\", \"\")\n",
    "xgb_grid_search_results_round3.to_csv(f\"results/xgb_results_round3_{date}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ef1cdad4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_colsample_bylevel</th>\n",
       "      <th>param_colsample_bytree</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_subsample</th>\n",
       "      <th>...</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.064527</td>\n",
       "      <td>0.004136</td>\n",
       "      <td>0.005885</td>\n",
       "      <td>0.000538</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.820020</td>\n",
       "      <td>0.048275</td>\n",
       "      <td>2840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.064327</td>\n",
       "      <td>0.002493</td>\n",
       "      <td>0.005885</td>\n",
       "      <td>0.000537</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.661290</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.823221</td>\n",
       "      <td>0.059057</td>\n",
       "      <td>5179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.063231</td>\n",
       "      <td>0.001954</td>\n",
       "      <td>0.005785</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.824782</td>\n",
       "      <td>0.057512</td>\n",
       "      <td>5860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.062235</td>\n",
       "      <td>0.001017</td>\n",
       "      <td>0.006082</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.661290</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.824834</td>\n",
       "      <td>0.059251</td>\n",
       "      <td>6715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.062333</td>\n",
       "      <td>0.002285</td>\n",
       "      <td>0.005784</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.828059</td>\n",
       "      <td>0.053977</td>\n",
       "      <td>9897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17995</th>\n",
       "      <td>0.228489</td>\n",
       "      <td>0.002462</td>\n",
       "      <td>0.007480</td>\n",
       "      <td>0.000499</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.802355</td>\n",
       "      <td>0.049888</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17996</th>\n",
       "      <td>0.228688</td>\n",
       "      <td>0.002142</td>\n",
       "      <td>0.007281</td>\n",
       "      <td>0.000457</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.800768</td>\n",
       "      <td>0.052893</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17997</th>\n",
       "      <td>0.228987</td>\n",
       "      <td>0.001197</td>\n",
       "      <td>0.007580</td>\n",
       "      <td>0.000488</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.810317</td>\n",
       "      <td>0.057193</td>\n",
       "      <td>139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17998</th>\n",
       "      <td>0.228788</td>\n",
       "      <td>0.001620</td>\n",
       "      <td>0.007181</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.816692</td>\n",
       "      <td>0.055624</td>\n",
       "      <td>893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17999</th>\n",
       "      <td>0.226893</td>\n",
       "      <td>0.002150</td>\n",
       "      <td>0.007381</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.818382</td>\n",
       "      <td>0.053516</td>\n",
       "      <td>1646</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18000 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0           0.064527      0.004136         0.005885        0.000538   \n",
       "1           0.064327      0.002493         0.005885        0.000537   \n",
       "2           0.063231      0.001954         0.005785        0.000399   \n",
       "3           0.062235      0.001017         0.006082        0.000300   \n",
       "4           0.062333      0.002285         0.005784        0.000399   \n",
       "...              ...           ...              ...             ...   \n",
       "17995       0.228489      0.002462         0.007480        0.000499   \n",
       "17996       0.228688      0.002142         0.007281        0.000457   \n",
       "17997       0.228987      0.001197         0.007580        0.000488   \n",
       "17998       0.228788      0.001620         0.007181        0.000399   \n",
       "17999       0.226893      0.002150         0.007381        0.000489   \n",
       "\n",
       "       param_colsample_bylevel  param_colsample_bytree  param_learning_rate  \\\n",
       "0                          0.1                     0.3                  0.1   \n",
       "1                          0.1                     0.3                  0.1   \n",
       "2                          0.1                     0.3                  0.1   \n",
       "3                          0.1                     0.3                  0.1   \n",
       "4                          0.1                     0.3                  0.1   \n",
       "...                        ...                     ...                  ...   \n",
       "17995                      0.7                     0.9                  0.4   \n",
       "17996                      0.7                     0.9                  0.4   \n",
       "17997                      0.7                     0.9                  0.4   \n",
       "17998                      0.7                     0.9                  0.4   \n",
       "17999                      0.7                     0.9                  0.4   \n",
       "\n",
       "       param_max_depth  param_n_estimators  param_subsample  ...  \\\n",
       "0                    2                 100              0.5  ...   \n",
       "1                    2                 100              0.6  ...   \n",
       "2                    2                 100              0.7  ...   \n",
       "3                    2                 100              0.8  ...   \n",
       "4                    2                 100              0.9  ...   \n",
       "...                ...                 ...              ...  ...   \n",
       "17995                5                 300              0.5  ...   \n",
       "17996                5                 300              0.6  ...   \n",
       "17997                5                 300              0.7  ...   \n",
       "17998                5                 300              0.8  ...   \n",
       "17999                5                 300              0.9  ...   \n",
       "\n",
       "      split3_test_score  split4_test_score  split5_test_score  \\\n",
       "0              0.822581           0.822581           0.806452   \n",
       "1              0.838710           0.822581           0.806452   \n",
       "2              0.838710           0.806452           0.806452   \n",
       "3              0.854839           0.822581           0.806452   \n",
       "4              0.854839           0.822581           0.838710   \n",
       "...                 ...                ...                ...   \n",
       "17995          0.822581           0.774194           0.806452   \n",
       "17996          0.822581           0.774194           0.790323   \n",
       "17997          0.870968           0.774194           0.774194   \n",
       "17998          0.822581           0.790323           0.774194   \n",
       "17999          0.806452           0.790323           0.774194   \n",
       "\n",
       "       split6_test_score  split7_test_score  split8_test_score  \\\n",
       "0               0.822581           0.806452           0.693548   \n",
       "1               0.838710           0.806452           0.661290   \n",
       "2               0.838710           0.806452           0.677419   \n",
       "3               0.854839           0.806452           0.661290   \n",
       "4               0.838710           0.806452           0.677419   \n",
       "...                  ...                ...                ...   \n",
       "17995           0.822581           0.774194           0.709677   \n",
       "17996           0.822581           0.790323           0.693548   \n",
       "17997           0.790323           0.790323           0.709677   \n",
       "17998           0.822581           0.790323           0.709677   \n",
       "17999           0.854839           0.790323           0.709677   \n",
       "\n",
       "       split9_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0               0.838710         0.820020        0.048275             2840  \n",
       "1               0.854839         0.823221        0.059057             5179  \n",
       "2               0.838710         0.824782        0.057512             5860  \n",
       "3               0.838710         0.824834        0.059251             6715  \n",
       "4               0.838710         0.828059        0.053977             9897  \n",
       "...                  ...              ...             ...              ...  \n",
       "17995           0.774194         0.802355        0.049888                3  \n",
       "17996           0.790323         0.800768        0.052893                2  \n",
       "17997           0.790323         0.810317        0.057193              139  \n",
       "17998           0.806452         0.816692        0.055624              893  \n",
       "17999           0.854839         0.818382        0.053516             1646  \n",
       "\n",
       "[18000 rows x 24 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Third Attempt\n",
    "\n",
    "random.seed(10)\n",
    "\n",
    "xgb = XGBClassifier()\n",
    "\n",
    "xgb_parameters = {'max_depth': [2,3,4,5]\n",
    "                   , 'subsample': [0.6, 0.7, 0.8, 0.9]\n",
    "                   , 'gamma': [0, 1, 10]\n",
    "                   , 'colsample_bytree': [0.4, 0.5, 0.6, 0.9]\n",
    "                   , 'colsample_bylevel': [0.1, 0.2, 0.3, 0.4]\n",
    "                   , 'learning_rate': [0.01, 0.05, 0.08, 0.1, 0.15, 0.2]\n",
    "                   , 'n_estimators': [30, 50, 80, 100, 150, 200]}\n",
    "\n",
    "stratified_10_fold_cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "xgb_grid_search = GridSearchCV(xgb, xgb_parameters, scoring='accuracy', cv=stratified_10_fold_cv)\n",
    "\n",
    "xgb_grid_search.fit(X_train, y_train)\n",
    "\n",
    "xgb_grid_search_results_round3 = pd.DataFrame(xgb_grid_search.cv_results_)\n",
    "display(xgb_grid_search_results_round3)\n",
    "\n",
    "# print the best parameter setting\n",
    "print(\"best score is {} with params {}\".format(xgb_grid_search.best_score_, xgb_grid_search.best_params_))\n",
    "#best score is 0.850563 with params {'colsample_bylevel': 0.4, 'colsample_bytree': 0.4, 'gamma': 1, 'learning_rate': 0.15, 'max_depth': 4, 'n_estimators': 30, 'subsample': 0.9}\n",
    "\n",
    "# save dataframe\n",
    "from datetime import datetime\n",
    "date = str(datetime.now().date()).replace(\"-\", \"\")\n",
    "xgb_grid_search_results_round3.to_csv(f\"results/xgb_results_round3_{date}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0acf7bf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_subsample</th>\n",
       "      <th>param_colsample_bylevel</th>\n",
       "      <th>param_colsample_bytree</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_gamma</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21747</th>\n",
       "      <td>4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.15</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>0.856989</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13080</th>\n",
       "      <td>3</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.15</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>0.852227</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13176</th>\n",
       "      <td>3</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.20</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>0.852202</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21720</th>\n",
       "      <td>3</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.15</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>0.852202</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23470</th>\n",
       "      <td>3</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.15</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>0.852151</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6340</th>\n",
       "      <td>2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.01</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>0.718920</td>\n",
       "      <td>27644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6339</th>\n",
       "      <td>2</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.01</td>\n",
       "      <td>30</td>\n",
       "      <td>10</td>\n",
       "      <td>0.709217</td>\n",
       "      <td>27645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6338</th>\n",
       "      <td>2</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.01</td>\n",
       "      <td>30</td>\n",
       "      <td>10</td>\n",
       "      <td>0.705991</td>\n",
       "      <td>27646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6336</th>\n",
       "      <td>2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.01</td>\n",
       "      <td>30</td>\n",
       "      <td>10</td>\n",
       "      <td>0.704403</td>\n",
       "      <td>27647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6337</th>\n",
       "      <td>2</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.01</td>\n",
       "      <td>30</td>\n",
       "      <td>10</td>\n",
       "      <td>0.702765</td>\n",
       "      <td>27648</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27648 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       param_max_depth  param_subsample  param_colsample_bylevel  \\\n",
       "21747                4              0.9                      0.4   \n",
       "13080                3              0.6                      0.2   \n",
       "13176                3              0.6                      0.2   \n",
       "21720                3              0.6                      0.4   \n",
       "23470                3              0.8                      0.4   \n",
       "...                ...              ...                      ...   \n",
       "6340                 2              0.6                      0.1   \n",
       "6339                 2              0.9                      0.1   \n",
       "6338                 2              0.8                      0.1   \n",
       "6336                 2              0.6                      0.1   \n",
       "6337                 2              0.7                      0.1   \n",
       "\n",
       "       param_colsample_bytree  param_learning_rate  param_n_estimators  \\\n",
       "21747                     0.4                 0.15                  30   \n",
       "13080                     0.9                 0.15                  30   \n",
       "13176                     0.9                 0.20                  30   \n",
       "21720                     0.4                 0.15                  30   \n",
       "23470                     0.5                 0.15                 200   \n",
       "...                       ...                  ...                 ...   \n",
       "6340                      0.9                 0.01                  50   \n",
       "6339                      0.9                 0.01                  30   \n",
       "6338                      0.9                 0.01                  30   \n",
       "6336                      0.9                 0.01                  30   \n",
       "6337                      0.9                 0.01                  30   \n",
       "\n",
       "       param_gamma  mean_test_score  rank_test_score  \n",
       "21747            1         0.856989                1  \n",
       "13080            1         0.852227                2  \n",
       "13176            1         0.852202                3  \n",
       "21720            1         0.852202                4  \n",
       "23470            1         0.852151                5  \n",
       "...            ...              ...              ...  \n",
       "6340            10         0.718920            27644  \n",
       "6339            10         0.709217            27645  \n",
       "6338            10         0.705991            27646  \n",
       "6336            10         0.704403            27647  \n",
       "6337            10         0.702765            27648  \n",
       "\n",
       "[27648 rows x 9 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# store relevant columns and sort by rank_test_score\n",
    "cols_round3 = ['param_max_depth', 'param_subsample', 'param_colsample_bylevel', 'param_colsample_bytree', 'param_learning_rate', 'param_n_estimators', 'param_gamma', 'mean_test_score', 'rank_test_score']\n",
    "xgb_results_round3_sorted = xgb_grid_search_results_round3[cols_round3]\n",
    "xgb_results_round3_sorted = xgb_results_round3_sorted.sort_values(by='rank_test_score')\n",
    "display(xgb_results_round3_sorted)\n",
    "\n",
    "# save dataframe\n",
    "from datetime import datetime\n",
    "date = str(datetime.now().date()).replace(\"-\", \"\")\n",
    "xgb_results_round3_sorted.to_csv(f\"results/xgb_results_round3_sorted_{date}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "11f0488a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.8283582089552238\n",
      "F1 Score = 0.7788461538461539\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.90      0.86       157\n",
      "           1       0.84      0.73      0.78       111\n",
      "\n",
      "    accuracy                           0.83       268\n",
      "   macro avg       0.83      0.81      0.82       268\n",
      "weighted avg       0.83      0.83      0.83       268\n",
      "\n",
      "Confusion Matrix:\n",
      "[[141  16]\n",
      " [ 30  81]]\n"
     ]
    }
   ],
   "source": [
    "# Fit and evaluate best model\n",
    "\n",
    "xgb_best = XGBClassifier(max_depth = 4, subsample = 0.9, colsample_bylevel = 0.4, colsample_bytree = 0.4, learning_rate = 0.15, n_estimators = 30, gamma = 1)\n",
    "xgb_best.fit(X_train, y_train)\n",
    "xgb_best_pred = xgb_best.predict(X_test)\n",
    "\n",
    "xgb_best_acc = accuracy_score(y_test, xgb_best_pred)\n",
    "print(\"Accuracy =\", xgb_best_acc) #0.8283582089552238\n",
    "\n",
    "xgb_best_f1 = f1_score(y_test, xgb_best_pred)\n",
    "print(\"F1 Score =\", xgb_best_f1) #0.7788461538461539\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, xgb_best_pred))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, xgb_best_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "871fce0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ec32490",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b5d3a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "486b0ff9",
   "metadata": {},
   "source": [
    "#### ausfÃ¼hrlich"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ea249e06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_colsample_bylevel</th>\n",
       "      <th>param_colsample_bytree</th>\n",
       "      <th>param_gamma</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>...</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.028623</td>\n",
       "      <td>0.002525</td>\n",
       "      <td>0.007181</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.741295</td>\n",
       "      <td>0.048078</td>\n",
       "      <td>4578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.027127</td>\n",
       "      <td>0.000598</td>\n",
       "      <td>0.007082</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.742908</td>\n",
       "      <td>0.049390</td>\n",
       "      <td>4575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.027028</td>\n",
       "      <td>0.000698</td>\n",
       "      <td>0.007580</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.752586</td>\n",
       "      <td>0.048690</td>\n",
       "      <td>4530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.027427</td>\n",
       "      <td>0.000920</td>\n",
       "      <td>0.007381</td>\n",
       "      <td>0.000662</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.742960</td>\n",
       "      <td>0.043040</td>\n",
       "      <td>4573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.040093</td>\n",
       "      <td>0.001465</td>\n",
       "      <td>0.007082</td>\n",
       "      <td>0.000536</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>...</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.765463</td>\n",
       "      <td>0.037846</td>\n",
       "      <td>4434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4603</th>\n",
       "      <td>0.129553</td>\n",
       "      <td>0.002379</td>\n",
       "      <td>0.007381</td>\n",
       "      <td>0.000488</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.01</td>\n",
       "      <td>5</td>\n",
       "      <td>150</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.813774</td>\n",
       "      <td>0.047909</td>\n",
       "      <td>2050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4604</th>\n",
       "      <td>0.169746</td>\n",
       "      <td>0.002475</td>\n",
       "      <td>0.007680</td>\n",
       "      <td>0.000457</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.01</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.816948</td>\n",
       "      <td>0.046448</td>\n",
       "      <td>1787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4605</th>\n",
       "      <td>0.169550</td>\n",
       "      <td>0.002185</td>\n",
       "      <td>0.007381</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.01</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.815335</td>\n",
       "      <td>0.050783</td>\n",
       "      <td>1939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4606</th>\n",
       "      <td>0.170743</td>\n",
       "      <td>0.003753</td>\n",
       "      <td>0.007481</td>\n",
       "      <td>0.000499</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.01</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.812186</td>\n",
       "      <td>0.050956</td>\n",
       "      <td>2153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4607</th>\n",
       "      <td>0.168649</td>\n",
       "      <td>0.001371</td>\n",
       "      <td>0.007380</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.01</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.813774</td>\n",
       "      <td>0.047909</td>\n",
       "      <td>2050</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4608 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0          0.028623      0.002525         0.007181        0.000399   \n",
       "1          0.027127      0.000598         0.007082        0.000300   \n",
       "2          0.027028      0.000698         0.007580        0.000489   \n",
       "3          0.027427      0.000920         0.007381        0.000662   \n",
       "4          0.040093      0.001465         0.007082        0.000536   \n",
       "...             ...           ...              ...             ...   \n",
       "4603       0.129553      0.002379         0.007381        0.000488   \n",
       "4604       0.169746      0.002475         0.007680        0.000457   \n",
       "4605       0.169550      0.002185         0.007381        0.000489   \n",
       "4606       0.170743      0.003753         0.007481        0.000499   \n",
       "4607       0.168649      0.001371         0.007380        0.000489   \n",
       "\n",
       "      param_colsample_bylevel  param_colsample_bytree  param_gamma  \\\n",
       "0                         0.1                     0.4            0   \n",
       "1                         0.1                     0.4            0   \n",
       "2                         0.1                     0.4            0   \n",
       "3                         0.1                     0.4            0   \n",
       "4                         0.1                     0.4            0   \n",
       "...                       ...                     ...          ...   \n",
       "4603                      0.4                     0.9           10   \n",
       "4604                      0.4                     0.9           10   \n",
       "4605                      0.4                     0.9           10   \n",
       "4606                      0.4                     0.9           10   \n",
       "4607                      0.4                     0.9           10   \n",
       "\n",
       "      param_learning_rate  param_max_depth  param_n_estimators  ...  \\\n",
       "0                    0.01                2                  30  ...   \n",
       "1                    0.01                2                  30  ...   \n",
       "2                    0.01                2                  30  ...   \n",
       "3                    0.01                2                  30  ...   \n",
       "4                    0.01                2                  50  ...   \n",
       "...                   ...              ...                 ...  ...   \n",
       "4603                 0.01                5                 150  ...   \n",
       "4604                 0.01                5                 200  ...   \n",
       "4605                 0.01                5                 200  ...   \n",
       "4606                 0.01                5                 200  ...   \n",
       "4607                 0.01                5                 200  ...   \n",
       "\n",
       "      split3_test_score split4_test_score  split5_test_score  \\\n",
       "0              0.758065          0.741935           0.741935   \n",
       "1              0.774194          0.741935           0.741935   \n",
       "2              0.774194          0.758065           0.774194   \n",
       "3              0.790323          0.725806           0.709677   \n",
       "4              0.790323          0.774194           0.774194   \n",
       "...                 ...               ...                ...   \n",
       "4603           0.838710          0.822581           0.870968   \n",
       "4604           0.838710          0.822581           0.870968   \n",
       "4605           0.838710          0.822581           0.870968   \n",
       "4606           0.838710          0.822581           0.870968   \n",
       "4607           0.838710          0.822581           0.870968   \n",
       "\n",
       "      split6_test_score  split7_test_score  split8_test_score  \\\n",
       "0              0.725806           0.677419           0.693548   \n",
       "1              0.725806           0.677419           0.677419   \n",
       "2              0.741935           0.693548           0.677419   \n",
       "3              0.741935           0.709677           0.709677   \n",
       "4              0.725806           0.693548           0.725806   \n",
       "...                 ...                ...                ...   \n",
       "4603           0.822581           0.806452           0.693548   \n",
       "4604           0.822581           0.806452           0.693548   \n",
       "4605           0.822581           0.806452           0.677419   \n",
       "4606           0.822581           0.822581           0.677419   \n",
       "4607           0.822581           0.806452           0.693548   \n",
       "\n",
       "      split9_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0              0.677419         0.741295        0.048078             4578  \n",
       "1              0.693548         0.742908        0.049390             4575  \n",
       "2              0.709677         0.752586        0.048690             4530  \n",
       "3              0.677419         0.742960        0.043040             4573  \n",
       "4              0.758065         0.765463        0.037846             4434  \n",
       "...                 ...              ...             ...              ...  \n",
       "4603           0.822581         0.813774        0.047909             2050  \n",
       "4604           0.822581         0.816948        0.046448             1787  \n",
       "4605           0.822581         0.815335        0.050783             1939  \n",
       "4606           0.822581         0.812186        0.050956             2153  \n",
       "4607           0.822581         0.813774        0.047909             2050  \n",
       "\n",
       "[4608 rows x 25 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score is 0.8505376344086022 with params {'colsample_bylevel': 0.1, 'colsample_bytree': 0.6, 'learning_rate': 0.15, 'max_depth': 5, 'n_estimators': 100, 'subsample': 0.6}\n"
     ]
    }
   ],
   "source": [
    "df1 = pd.read_csv(\"data\\\\xgb_results_full_1_learning=0.01_20221124.csv\")\n",
    "df1.drop(df1.columns[0], axis=1, inplace=True)\n",
    "display(df1)\n",
    "print(\"best score is 0.8505376344086022 with params {'colsample_bylevel': 0.1, 'colsample_bytree': 0.6, 'learning_rate': 0.15, 'max_depth': 5, 'n_estimators': 100, 'subsample': 0.6}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "042c4de6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_colsample_bylevel</th>\n",
       "      <th>param_colsample_bytree</th>\n",
       "      <th>param_gamma</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>...</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.028623</td>\n",
       "      <td>0.002525</td>\n",
       "      <td>0.007181</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.741295</td>\n",
       "      <td>0.048078</td>\n",
       "      <td>4578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.027127</td>\n",
       "      <td>0.000598</td>\n",
       "      <td>0.007082</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.742908</td>\n",
       "      <td>0.049390</td>\n",
       "      <td>4575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.027028</td>\n",
       "      <td>0.000698</td>\n",
       "      <td>0.007580</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.752586</td>\n",
       "      <td>0.048690</td>\n",
       "      <td>4530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.027427</td>\n",
       "      <td>0.000920</td>\n",
       "      <td>0.007381</td>\n",
       "      <td>0.000662</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.742960</td>\n",
       "      <td>0.043040</td>\n",
       "      <td>4573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.040093</td>\n",
       "      <td>0.001465</td>\n",
       "      <td>0.007082</td>\n",
       "      <td>0.000536</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>...</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.765463</td>\n",
       "      <td>0.037846</td>\n",
       "      <td>4434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4603</th>\n",
       "      <td>0.129553</td>\n",
       "      <td>0.002379</td>\n",
       "      <td>0.007381</td>\n",
       "      <td>0.000488</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.01</td>\n",
       "      <td>5</td>\n",
       "      <td>150</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.813774</td>\n",
       "      <td>0.047909</td>\n",
       "      <td>2050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4604</th>\n",
       "      <td>0.169746</td>\n",
       "      <td>0.002475</td>\n",
       "      <td>0.007680</td>\n",
       "      <td>0.000457</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.01</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.816948</td>\n",
       "      <td>0.046448</td>\n",
       "      <td>1787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4605</th>\n",
       "      <td>0.169550</td>\n",
       "      <td>0.002185</td>\n",
       "      <td>0.007381</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.01</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.815335</td>\n",
       "      <td>0.050783</td>\n",
       "      <td>1939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4606</th>\n",
       "      <td>0.170743</td>\n",
       "      <td>0.003753</td>\n",
       "      <td>0.007481</td>\n",
       "      <td>0.000499</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.01</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.812186</td>\n",
       "      <td>0.050956</td>\n",
       "      <td>2153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4607</th>\n",
       "      <td>0.168649</td>\n",
       "      <td>0.001371</td>\n",
       "      <td>0.007380</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.01</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.813774</td>\n",
       "      <td>0.047909</td>\n",
       "      <td>2050</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4608 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0          0.028623      0.002525         0.007181        0.000399   \n",
       "1          0.027127      0.000598         0.007082        0.000300   \n",
       "2          0.027028      0.000698         0.007580        0.000489   \n",
       "3          0.027427      0.000920         0.007381        0.000662   \n",
       "4          0.040093      0.001465         0.007082        0.000536   \n",
       "...             ...           ...              ...             ...   \n",
       "4603       0.129553      0.002379         0.007381        0.000488   \n",
       "4604       0.169746      0.002475         0.007680        0.000457   \n",
       "4605       0.169550      0.002185         0.007381        0.000489   \n",
       "4606       0.170743      0.003753         0.007481        0.000499   \n",
       "4607       0.168649      0.001371         0.007380        0.000489   \n",
       "\n",
       "     param_colsample_bylevel param_colsample_bytree param_gamma  \\\n",
       "0                        0.1                    0.4           0   \n",
       "1                        0.1                    0.4           0   \n",
       "2                        0.1                    0.4           0   \n",
       "3                        0.1                    0.4           0   \n",
       "4                        0.1                    0.4           0   \n",
       "...                      ...                    ...         ...   \n",
       "4603                     0.4                    0.9          10   \n",
       "4604                     0.4                    0.9          10   \n",
       "4605                     0.4                    0.9          10   \n",
       "4606                     0.4                    0.9          10   \n",
       "4607                     0.4                    0.9          10   \n",
       "\n",
       "     param_learning_rate param_max_depth param_n_estimators  ...  \\\n",
       "0                   0.01               2                 30  ...   \n",
       "1                   0.01               2                 30  ...   \n",
       "2                   0.01               2                 30  ...   \n",
       "3                   0.01               2                 30  ...   \n",
       "4                   0.01               2                 50  ...   \n",
       "...                  ...             ...                ...  ...   \n",
       "4603                0.01               5                150  ...   \n",
       "4604                0.01               5                200  ...   \n",
       "4605                0.01               5                200  ...   \n",
       "4606                0.01               5                200  ...   \n",
       "4607                0.01               5                200  ...   \n",
       "\n",
       "     split3_test_score split4_test_score  split5_test_score  \\\n",
       "0             0.758065          0.741935           0.741935   \n",
       "1             0.774194          0.741935           0.741935   \n",
       "2             0.774194          0.758065           0.774194   \n",
       "3             0.790323          0.725806           0.709677   \n",
       "4             0.790323          0.774194           0.774194   \n",
       "...                ...               ...                ...   \n",
       "4603          0.838710          0.822581           0.870968   \n",
       "4604          0.838710          0.822581           0.870968   \n",
       "4605          0.838710          0.822581           0.870968   \n",
       "4606          0.838710          0.822581           0.870968   \n",
       "4607          0.838710          0.822581           0.870968   \n",
       "\n",
       "      split6_test_score  split7_test_score  split8_test_score  \\\n",
       "0              0.725806           0.677419           0.693548   \n",
       "1              0.725806           0.677419           0.677419   \n",
       "2              0.741935           0.693548           0.677419   \n",
       "3              0.741935           0.709677           0.709677   \n",
       "4              0.725806           0.693548           0.725806   \n",
       "...                 ...                ...                ...   \n",
       "4603           0.822581           0.806452           0.693548   \n",
       "4604           0.822581           0.806452           0.693548   \n",
       "4605           0.822581           0.806452           0.677419   \n",
       "4606           0.822581           0.822581           0.677419   \n",
       "4607           0.822581           0.806452           0.693548   \n",
       "\n",
       "      split9_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0              0.677419         0.741295        0.048078             4578  \n",
       "1              0.693548         0.742908        0.049390             4575  \n",
       "2              0.709677         0.752586        0.048690             4530  \n",
       "3              0.677419         0.742960        0.043040             4573  \n",
       "4              0.758065         0.765463        0.037846             4434  \n",
       "...                 ...              ...             ...              ...  \n",
       "4603           0.822581         0.813774        0.047909             2050  \n",
       "4604           0.822581         0.816948        0.046448             1787  \n",
       "4605           0.822581         0.815335        0.050783             1939  \n",
       "4606           0.822581         0.812186        0.050956             2153  \n",
       "4607           0.822581         0.813774        0.047909             2050  \n",
       "\n",
       "[4608 rows x 25 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score is 0.844162826420891 with params {'colsample_bylevel': 0.3, 'colsample_bytree': 0.9, 'gamma': 1, 'learning_rate': 0.01, 'max_depth': 5, 'n_estimators': 200, 'subsample': 0.7}\n"
     ]
    }
   ],
   "source": [
    "# Full Tuning - Part 1\n",
    "random.seed(10)\n",
    "\n",
    "xgb = XGBClassifier()\n",
    "\n",
    "xgb_parameters = {'max_depth': [2,3,4,5]\n",
    "                   , 'subsample': [0.6, 0.7, 0.8, 0.9]\n",
    "                   , 'gamma': [0, 1, 10]\n",
    "                   , 'colsample_bytree': [0.4, 0.5, 0.6, 0.9]\n",
    "                   , 'colsample_bylevel': [0.1, 0.2, 0.3, 0.4]\n",
    "                   , 'learning_rate': [0.01]\n",
    "                   , 'n_estimators': [30, 50, 80, 100, 150, 200]}\n",
    "\n",
    "stratified_10_fold_cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "xgb_grid_search = GridSearchCV(xgb, xgb_parameters, scoring='accuracy', cv=stratified_10_fold_cv)\n",
    "\n",
    "xgb_grid_search.fit(X_train, y_train)\n",
    "\n",
    "xgb_grid_search_results_full_1 = pd.DataFrame(xgb_grid_search.cv_results_)\n",
    "display(xgb_grid_search_results_full_1)\n",
    "\n",
    "print(\"best score is {} with params {}\".format(xgb_grid_search.best_score_, xgb_grid_search.best_params_))\n",
    "#best score is 0.844162826420891 with params\n",
    "{'colsample_bylevel': 0.3, 'colsample_bytree': 0.9, 'gamma': 1, 'learning_rate': 0.01, 'max_depth': 5, 'n_estimators': 200, 'subsample': 0.7}\n",
    "\n",
    "# save dataframe\n",
    "from datetime import datetime\n",
    "date = str(datetime.now().date()).replace(\"-\", \"\")\n",
    "xgb_grid_search_results_full_1.to_csv(f\"results/xgb_results_full_round3_1_learning=0.01_{date}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c6d50dac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_colsample_bylevel</th>\n",
       "      <th>param_colsample_bytree</th>\n",
       "      <th>param_gamma</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>...</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.028523</td>\n",
       "      <td>0.001197</td>\n",
       "      <td>0.007181</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.775090</td>\n",
       "      <td>0.045213</td>\n",
       "      <td>4574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.027227</td>\n",
       "      <td>0.000779</td>\n",
       "      <td>0.006981</td>\n",
       "      <td>0.000772</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.765463</td>\n",
       "      <td>0.044700</td>\n",
       "      <td>4590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.030020</td>\n",
       "      <td>0.003261</td>\n",
       "      <td>0.007580</td>\n",
       "      <td>0.000662</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.775090</td>\n",
       "      <td>0.048492</td>\n",
       "      <td>4576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.027626</td>\n",
       "      <td>0.001097</td>\n",
       "      <td>0.007480</td>\n",
       "      <td>0.000499</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.776677</td>\n",
       "      <td>0.047735</td>\n",
       "      <td>4572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.039397</td>\n",
       "      <td>0.000667</td>\n",
       "      <td>0.007378</td>\n",
       "      <td>0.000491</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>...</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.799155</td>\n",
       "      <td>0.059192</td>\n",
       "      <td>4360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4603</th>\n",
       "      <td>0.130850</td>\n",
       "      <td>0.001882</td>\n",
       "      <td>0.007381</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.05</td>\n",
       "      <td>5</td>\n",
       "      <td>150</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.919355</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.816999</td>\n",
       "      <td>0.059810</td>\n",
       "      <td>3203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4604</th>\n",
       "      <td>0.171740</td>\n",
       "      <td>0.001773</td>\n",
       "      <td>0.007580</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.05</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.919355</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.818612</td>\n",
       "      <td>0.053929</td>\n",
       "      <td>2994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4605</th>\n",
       "      <td>0.171541</td>\n",
       "      <td>0.002318</td>\n",
       "      <td>0.007381</td>\n",
       "      <td>0.000488</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.05</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.919355</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.823400</td>\n",
       "      <td>0.053525</td>\n",
       "      <td>2604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4606</th>\n",
       "      <td>0.171951</td>\n",
       "      <td>0.002359</td>\n",
       "      <td>0.007469</td>\n",
       "      <td>0.000504</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.05</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.887097</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.816999</td>\n",
       "      <td>0.046733</td>\n",
       "      <td>3198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4607</th>\n",
       "      <td>0.170743</td>\n",
       "      <td>0.001773</td>\n",
       "      <td>0.007580</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.05</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.903226</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.815387</td>\n",
       "      <td>0.057189</td>\n",
       "      <td>3367</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4608 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0          0.028523      0.001197         0.007181        0.000399   \n",
       "1          0.027227      0.000779         0.006981        0.000772   \n",
       "2          0.030020      0.003261         0.007580        0.000662   \n",
       "3          0.027626      0.001097         0.007480        0.000499   \n",
       "4          0.039397      0.000667         0.007378        0.000491   \n",
       "...             ...           ...              ...             ...   \n",
       "4603       0.130850      0.001882         0.007381        0.000489   \n",
       "4604       0.171740      0.001773         0.007580        0.000489   \n",
       "4605       0.171541      0.002318         0.007381        0.000488   \n",
       "4606       0.171951      0.002359         0.007469        0.000504   \n",
       "4607       0.170743      0.001773         0.007580        0.000489   \n",
       "\n",
       "      param_colsample_bylevel  param_colsample_bytree  param_gamma  \\\n",
       "0                         0.1                     0.4            0   \n",
       "1                         0.1                     0.4            0   \n",
       "2                         0.1                     0.4            0   \n",
       "3                         0.1                     0.4            0   \n",
       "4                         0.1                     0.4            0   \n",
       "...                       ...                     ...          ...   \n",
       "4603                      0.4                     0.9           10   \n",
       "4604                      0.4                     0.9           10   \n",
       "4605                      0.4                     0.9           10   \n",
       "4606                      0.4                     0.9           10   \n",
       "4607                      0.4                     0.9           10   \n",
       "\n",
       "      param_learning_rate  param_max_depth  param_n_estimators  ...  \\\n",
       "0                    0.05                2                  30  ...   \n",
       "1                    0.05                2                  30  ...   \n",
       "2                    0.05                2                  30  ...   \n",
       "3                    0.05                2                  30  ...   \n",
       "4                    0.05                2                  50  ...   \n",
       "...                   ...              ...                 ...  ...   \n",
       "4603                 0.05                5                 150  ...   \n",
       "4604                 0.05                5                 200  ...   \n",
       "4605                 0.05                5                 200  ...   \n",
       "4606                 0.05                5                 200  ...   \n",
       "4607                 0.05                5                 200  ...   \n",
       "\n",
       "      split3_test_score split4_test_score  split5_test_score  \\\n",
       "0              0.774194          0.741935           0.806452   \n",
       "1              0.774194          0.741935           0.790323   \n",
       "2              0.806452          0.758065           0.806452   \n",
       "3              0.806452          0.741935           0.790323   \n",
       "4              0.806452          0.806452           0.870968   \n",
       "...                 ...               ...                ...   \n",
       "4603           0.838710          0.806452           0.919355   \n",
       "4604           0.838710          0.822581           0.919355   \n",
       "4605           0.838710          0.822581           0.919355   \n",
       "4606           0.838710          0.822581           0.887097   \n",
       "4607           0.838710          0.806452           0.903226   \n",
       "\n",
       "      split6_test_score  split7_test_score  split8_test_score  \\\n",
       "0              0.806452           0.677419           0.725806   \n",
       "1              0.790323           0.677419           0.709677   \n",
       "2              0.790323           0.677419           0.709677   \n",
       "3              0.806452           0.677419           0.725806   \n",
       "4              0.806452           0.693548           0.693548   \n",
       "...                 ...                ...                ...   \n",
       "4603           0.822581           0.790323           0.693548   \n",
       "4604           0.822581           0.806452           0.693548   \n",
       "4605           0.822581           0.822581           0.693548   \n",
       "4606           0.822581           0.806452           0.709677   \n",
       "4607           0.822581           0.790323           0.693548   \n",
       "\n",
       "      split9_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0              0.774194         0.775090        0.045213             4574  \n",
       "1              0.758065         0.765463        0.044700             4590  \n",
       "2              0.758065         0.775090        0.048492             4576  \n",
       "3              0.758065         0.776677        0.047735             4572  \n",
       "4              0.790323         0.799155        0.059192             4360  \n",
       "...                 ...              ...             ...              ...  \n",
       "4603           0.838710         0.816999        0.059810             3203  \n",
       "4604           0.822581         0.818612        0.053929             2994  \n",
       "4605           0.822581         0.823400        0.053525             2604  \n",
       "4606           0.822581         0.816999        0.046733             3198  \n",
       "4607           0.838710         0.815387        0.057189             3367  \n",
       "\n",
       "[4608 rows x 25 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score is 0.8506144393241168 with params {'colsample_bylevel': 0.2, 'colsample_bytree': 0.9, 'gamma': 1, 'learning_rate': 0.05, 'max_depth': 4, 'n_estimators': 100, 'subsample': 0.7}\n"
     ]
    }
   ],
   "source": [
    "df2 = pd.read_csv(\"data\\\\xgb_results_full_2_learning=0.05_20221124.csv\")\n",
    "df2.drop(df2.columns[0], axis=1, inplace=True)\n",
    "display(df2)\n",
    "print(\"best score is 0.8506144393241168 with params {'colsample_bylevel': 0.2, 'colsample_bytree': 0.9, 'gamma': 1, 'learning_rate': 0.05, 'max_depth': 4, 'n_estimators': 100, 'subsample': 0.7}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cecd42a5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_colsample_bylevel</th>\n",
       "      <th>param_colsample_bytree</th>\n",
       "      <th>param_gamma</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>...</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.028523</td>\n",
       "      <td>0.001197</td>\n",
       "      <td>0.007181</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.775090</td>\n",
       "      <td>0.045213</td>\n",
       "      <td>4574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.027227</td>\n",
       "      <td>0.000779</td>\n",
       "      <td>0.006981</td>\n",
       "      <td>0.000772</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.765463</td>\n",
       "      <td>0.044700</td>\n",
       "      <td>4590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.030020</td>\n",
       "      <td>0.003261</td>\n",
       "      <td>0.007580</td>\n",
       "      <td>0.000662</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.775090</td>\n",
       "      <td>0.048492</td>\n",
       "      <td>4576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.027626</td>\n",
       "      <td>0.001097</td>\n",
       "      <td>0.007480</td>\n",
       "      <td>0.000499</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.776677</td>\n",
       "      <td>0.047735</td>\n",
       "      <td>4572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.039397</td>\n",
       "      <td>0.000667</td>\n",
       "      <td>0.007378</td>\n",
       "      <td>0.000491</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>...</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.799155</td>\n",
       "      <td>0.059192</td>\n",
       "      <td>4360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4603</th>\n",
       "      <td>0.130850</td>\n",
       "      <td>0.001882</td>\n",
       "      <td>0.007381</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.05</td>\n",
       "      <td>5</td>\n",
       "      <td>150</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.919355</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.816999</td>\n",
       "      <td>0.059810</td>\n",
       "      <td>3203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4604</th>\n",
       "      <td>0.171740</td>\n",
       "      <td>0.001773</td>\n",
       "      <td>0.007580</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.05</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.919355</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.818612</td>\n",
       "      <td>0.053929</td>\n",
       "      <td>2994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4605</th>\n",
       "      <td>0.171541</td>\n",
       "      <td>0.002318</td>\n",
       "      <td>0.007381</td>\n",
       "      <td>0.000488</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.05</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.919355</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.823400</td>\n",
       "      <td>0.053525</td>\n",
       "      <td>2604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4606</th>\n",
       "      <td>0.171951</td>\n",
       "      <td>0.002359</td>\n",
       "      <td>0.007469</td>\n",
       "      <td>0.000504</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.05</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.887097</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.816999</td>\n",
       "      <td>0.046733</td>\n",
       "      <td>3198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4607</th>\n",
       "      <td>0.170743</td>\n",
       "      <td>0.001773</td>\n",
       "      <td>0.007580</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.05</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.903226</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.815387</td>\n",
       "      <td>0.057189</td>\n",
       "      <td>3367</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4608 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0          0.028523      0.001197         0.007181        0.000399   \n",
       "1          0.027227      0.000779         0.006981        0.000772   \n",
       "2          0.030020      0.003261         0.007580        0.000662   \n",
       "3          0.027626      0.001097         0.007480        0.000499   \n",
       "4          0.039397      0.000667         0.007378        0.000491   \n",
       "...             ...           ...              ...             ...   \n",
       "4603       0.130850      0.001882         0.007381        0.000489   \n",
       "4604       0.171740      0.001773         0.007580        0.000489   \n",
       "4605       0.171541      0.002318         0.007381        0.000488   \n",
       "4606       0.171951      0.002359         0.007469        0.000504   \n",
       "4607       0.170743      0.001773         0.007580        0.000489   \n",
       "\n",
       "     param_colsample_bylevel param_colsample_bytree param_gamma  \\\n",
       "0                        0.1                    0.4           0   \n",
       "1                        0.1                    0.4           0   \n",
       "2                        0.1                    0.4           0   \n",
       "3                        0.1                    0.4           0   \n",
       "4                        0.1                    0.4           0   \n",
       "...                      ...                    ...         ...   \n",
       "4603                     0.4                    0.9          10   \n",
       "4604                     0.4                    0.9          10   \n",
       "4605                     0.4                    0.9          10   \n",
       "4606                     0.4                    0.9          10   \n",
       "4607                     0.4                    0.9          10   \n",
       "\n",
       "     param_learning_rate param_max_depth param_n_estimators  ...  \\\n",
       "0                   0.05               2                 30  ...   \n",
       "1                   0.05               2                 30  ...   \n",
       "2                   0.05               2                 30  ...   \n",
       "3                   0.05               2                 30  ...   \n",
       "4                   0.05               2                 50  ...   \n",
       "...                  ...             ...                ...  ...   \n",
       "4603                0.05               5                150  ...   \n",
       "4604                0.05               5                200  ...   \n",
       "4605                0.05               5                200  ...   \n",
       "4606                0.05               5                200  ...   \n",
       "4607                0.05               5                200  ...   \n",
       "\n",
       "     split3_test_score split4_test_score  split5_test_score  \\\n",
       "0             0.774194          0.741935           0.806452   \n",
       "1             0.774194          0.741935           0.790323   \n",
       "2             0.806452          0.758065           0.806452   \n",
       "3             0.806452          0.741935           0.790323   \n",
       "4             0.806452          0.806452           0.870968   \n",
       "...                ...               ...                ...   \n",
       "4603          0.838710          0.806452           0.919355   \n",
       "4604          0.838710          0.822581           0.919355   \n",
       "4605          0.838710          0.822581           0.919355   \n",
       "4606          0.838710          0.822581           0.887097   \n",
       "4607          0.838710          0.806452           0.903226   \n",
       "\n",
       "      split6_test_score  split7_test_score  split8_test_score  \\\n",
       "0              0.806452           0.677419           0.725806   \n",
       "1              0.790323           0.677419           0.709677   \n",
       "2              0.790323           0.677419           0.709677   \n",
       "3              0.806452           0.677419           0.725806   \n",
       "4              0.806452           0.693548           0.693548   \n",
       "...                 ...                ...                ...   \n",
       "4603           0.822581           0.790323           0.693548   \n",
       "4604           0.822581           0.806452           0.693548   \n",
       "4605           0.822581           0.822581           0.693548   \n",
       "4606           0.822581           0.806452           0.709677   \n",
       "4607           0.822581           0.790323           0.693548   \n",
       "\n",
       "      split9_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0              0.774194         0.775090        0.045213             4574  \n",
       "1              0.758065         0.765463        0.044700             4590  \n",
       "2              0.758065         0.775090        0.048492             4576  \n",
       "3              0.758065         0.776677        0.047735             4572  \n",
       "4              0.790323         0.799155        0.059192             4360  \n",
       "...                 ...              ...             ...              ...  \n",
       "4603           0.838710         0.816999        0.059810             3203  \n",
       "4604           0.822581         0.818612        0.053929             2994  \n",
       "4605           0.822581         0.823400        0.053525             2604  \n",
       "4606           0.822581         0.816999        0.046733             3198  \n",
       "4607           0.838710         0.815387        0.057189             3367  \n",
       "\n",
       "[4608 rows x 25 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score is 0.8506144393241168 with params {'colsample_bylevel': 0.2, 'colsample_bytree': 0.9, 'gamma': 1, 'learning_rate': 0.05, 'max_depth': 4, 'n_estimators': 100, 'subsample': 0.7}\n"
     ]
    }
   ],
   "source": [
    "# Full Tuning - Part 2\n",
    "random.seed(10)\n",
    "\n",
    "xgb = XGBClassifier()\n",
    "\n",
    "xgb_parameters = {'max_depth': [2,3,4,5]\n",
    "                   , 'subsample': [0.6, 0.7, 0.8, 0.9]\n",
    "                   , 'gamma': [0, 1, 10]\n",
    "                   , 'colsample_bytree': [0.4, 0.5, 0.6, 0.9]\n",
    "                   , 'colsample_bylevel': [0.1, 0.2, 0.3, 0.4]\n",
    "                   , 'learning_rate': [0.05]\n",
    "                   , 'n_estimators': [30, 50, 80, 100, 150, 200]}\n",
    "\n",
    "stratified_10_fold_cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "xgb_grid_search = GridSearchCV(xgb, xgb_parameters, scoring='accuracy', cv=stratified_10_fold_cv)\n",
    "\n",
    "xgb_grid_search.fit(X_train, y_train)\n",
    "\n",
    "xgb_grid_search_results_full_2 = pd.DataFrame(xgb_grid_search.cv_results_)\n",
    "display(xgb_grid_search_results_full_2)\n",
    "\n",
    "print(\"best score is {} with params {}\".format(xgb_grid_search.best_score_, xgb_grid_search.best_params_))\n",
    "#best score is 0.8506144393241168 with params\n",
    "#{'colsample_bylevel': 0.2, 'colsample_bytree': 0.9, 'gamma': 1, 'learning_rate': 0.05, 'max_depth': 4, 'n_estimators': 100, 'subsample': 0.7}\n",
    "\n",
    "# save dataframe\n",
    "from datetime import datetime\n",
    "date = str(datetime.now().date()).replace(\"-\", \"\")\n",
    "xgb_grid_search_results_full_2.to_csv(f\"results/xgb_results_full_round3_2_learning=0.05_{date}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "de35f20c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_colsample_bylevel</th>\n",
       "      <th>param_colsample_bytree</th>\n",
       "      <th>param_gamma</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>...</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.028224</td>\n",
       "      <td>0.001548</td>\n",
       "      <td>0.007181</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.08</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.791193</td>\n",
       "      <td>0.044965</td>\n",
       "      <td>4563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.026928</td>\n",
       "      <td>0.000772</td>\n",
       "      <td>0.007181</td>\n",
       "      <td>0.000599</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.08</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.789555</td>\n",
       "      <td>0.044749</td>\n",
       "      <td>4576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.029339</td>\n",
       "      <td>0.001735</td>\n",
       "      <td>0.007479</td>\n",
       "      <td>0.000498</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.08</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.789580</td>\n",
       "      <td>0.046896</td>\n",
       "      <td>4572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.028622</td>\n",
       "      <td>0.001947</td>\n",
       "      <td>0.007481</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.08</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.792780</td>\n",
       "      <td>0.044102</td>\n",
       "      <td>4551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.039893</td>\n",
       "      <td>0.001261</td>\n",
       "      <td>0.007380</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.08</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.812007</td>\n",
       "      <td>0.056776</td>\n",
       "      <td>4032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4603</th>\n",
       "      <td>0.129553</td>\n",
       "      <td>0.001133</td>\n",
       "      <td>0.007580</td>\n",
       "      <td>0.000488</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.08</td>\n",
       "      <td>5</td>\n",
       "      <td>150</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.919355</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.824962</td>\n",
       "      <td>0.052356</td>\n",
       "      <td>2818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4604</th>\n",
       "      <td>0.170643</td>\n",
       "      <td>0.001863</td>\n",
       "      <td>0.007581</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.08</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.903226</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.820225</td>\n",
       "      <td>0.053767</td>\n",
       "      <td>3155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4605</th>\n",
       "      <td>0.170045</td>\n",
       "      <td>0.001561</td>\n",
       "      <td>0.007281</td>\n",
       "      <td>0.000457</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.08</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.887097</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.816974</td>\n",
       "      <td>0.048018</td>\n",
       "      <td>3490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4606</th>\n",
       "      <td>0.169746</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>0.007480</td>\n",
       "      <td>0.000499</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.08</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.903226</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.816999</td>\n",
       "      <td>0.050944</td>\n",
       "      <td>3455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4607</th>\n",
       "      <td>0.170444</td>\n",
       "      <td>0.002693</td>\n",
       "      <td>0.007181</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.08</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.919355</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.823374</td>\n",
       "      <td>0.053036</td>\n",
       "      <td>2921</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4608 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0          0.028224      0.001548         0.007181        0.000399   \n",
       "1          0.026928      0.000772         0.007181        0.000599   \n",
       "2          0.029339      0.001735         0.007479        0.000498   \n",
       "3          0.028622      0.001947         0.007481        0.000500   \n",
       "4          0.039893      0.001261         0.007380        0.000489   \n",
       "...             ...           ...              ...             ...   \n",
       "4603       0.129553      0.001133         0.007580        0.000488   \n",
       "4604       0.170643      0.001863         0.007581        0.000489   \n",
       "4605       0.170045      0.001561         0.007281        0.000457   \n",
       "4606       0.169746      0.000977         0.007480        0.000499   \n",
       "4607       0.170444      0.002693         0.007181        0.000399   \n",
       "\n",
       "      param_colsample_bylevel  param_colsample_bytree  param_gamma  \\\n",
       "0                         0.1                     0.4            0   \n",
       "1                         0.1                     0.4            0   \n",
       "2                         0.1                     0.4            0   \n",
       "3                         0.1                     0.4            0   \n",
       "4                         0.1                     0.4            0   \n",
       "...                       ...                     ...          ...   \n",
       "4603                      0.4                     0.9           10   \n",
       "4604                      0.4                     0.9           10   \n",
       "4605                      0.4                     0.9           10   \n",
       "4606                      0.4                     0.9           10   \n",
       "4607                      0.4                     0.9           10   \n",
       "\n",
       "      param_learning_rate  param_max_depth  param_n_estimators  ...  \\\n",
       "0                    0.08                2                  30  ...   \n",
       "1                    0.08                2                  30  ...   \n",
       "2                    0.08                2                  30  ...   \n",
       "3                    0.08                2                  30  ...   \n",
       "4                    0.08                2                  50  ...   \n",
       "...                   ...              ...                 ...  ...   \n",
       "4603                 0.08                5                 150  ...   \n",
       "4604                 0.08                5                 200  ...   \n",
       "4605                 0.08                5                 200  ...   \n",
       "4606                 0.08                5                 200  ...   \n",
       "4607                 0.08                5                 200  ...   \n",
       "\n",
       "      split3_test_score split4_test_score  split5_test_score  \\\n",
       "0              0.806452          0.774194           0.822581   \n",
       "1              0.806452          0.774194           0.822581   \n",
       "2              0.838710          0.774194           0.822581   \n",
       "3              0.838710          0.774194           0.822581   \n",
       "4              0.854839          0.790323           0.870968   \n",
       "...                 ...               ...                ...   \n",
       "4603           0.838710          0.806452           0.919355   \n",
       "4604           0.870968          0.806452           0.903226   \n",
       "4605           0.838710          0.822581           0.887097   \n",
       "4606           0.838710          0.806452           0.903226   \n",
       "4607           0.838710          0.806452           0.919355   \n",
       "\n",
       "      split6_test_score  split7_test_score  split8_test_score  \\\n",
       "0              0.822581           0.693548           0.725806   \n",
       "1              0.790323           0.709677           0.709677   \n",
       "2              0.790323           0.709677           0.709677   \n",
       "3              0.790323           0.725806           0.709677   \n",
       "4              0.806452           0.741935           0.693548   \n",
       "...                 ...                ...                ...   \n",
       "4603           0.822581           0.806452           0.709677   \n",
       "4604           0.822581           0.822581           0.693548   \n",
       "4605           0.822581           0.806452           0.693548   \n",
       "4606           0.822581           0.806452           0.709677   \n",
       "4607           0.822581           0.806452           0.709677   \n",
       "\n",
       "      split9_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0              0.806452         0.791193        0.044965             4563  \n",
       "1              0.806452         0.789555        0.044749             4576  \n",
       "2              0.790323         0.789580        0.046896             4572  \n",
       "3              0.790323         0.792780        0.044102             4551  \n",
       "4              0.806452         0.812007        0.056776             4032  \n",
       "...                 ...              ...             ...              ...  \n",
       "4603           0.822581         0.824962        0.052356             2818  \n",
       "4604           0.822581         0.820225        0.053767             3155  \n",
       "4605           0.822581         0.816974        0.048018             3490  \n",
       "4606           0.822581         0.816999        0.050944             3455  \n",
       "4607           0.822581         0.823374        0.053036             2921  \n",
       "\n",
       "[4608 rows x 25 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score is 0.8506400409626217 with params {'colsample_bylevel': 0.2, 'colsample_bytree': 0.5, 'gamma': 1, 'learning_rate': 0.08, 'max_depth': 2, 'n_estimators': 150, 'subsample': 0.8}\n"
     ]
    }
   ],
   "source": [
    "df3 = pd.read_csv(\"data\\\\xgb_results_full_3_learning=0.08_20221124.csv\")\n",
    "df3.drop(df3.columns[0], axis=1, inplace=True)\n",
    "display(df3)\n",
    "print(\"best score is 0.8506400409626217 with params {'colsample_bylevel': 0.2, 'colsample_bytree': 0.5, 'gamma': 1, 'learning_rate': 0.08, 'max_depth': 2, 'n_estimators': 150, 'subsample': 0.8}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3ae2939c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_colsample_bylevel</th>\n",
       "      <th>param_colsample_bytree</th>\n",
       "      <th>param_gamma</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>...</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.028224</td>\n",
       "      <td>0.001548</td>\n",
       "      <td>0.007181</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.08</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.791193</td>\n",
       "      <td>0.044965</td>\n",
       "      <td>4563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.026928</td>\n",
       "      <td>0.000772</td>\n",
       "      <td>0.007181</td>\n",
       "      <td>0.000599</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.08</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.789555</td>\n",
       "      <td>0.044749</td>\n",
       "      <td>4576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.029339</td>\n",
       "      <td>0.001735</td>\n",
       "      <td>0.007479</td>\n",
       "      <td>0.000498</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.08</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.789580</td>\n",
       "      <td>0.046896</td>\n",
       "      <td>4572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.028622</td>\n",
       "      <td>0.001947</td>\n",
       "      <td>0.007481</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.08</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.792780</td>\n",
       "      <td>0.044102</td>\n",
       "      <td>4551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.039893</td>\n",
       "      <td>0.001261</td>\n",
       "      <td>0.007380</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.08</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.812007</td>\n",
       "      <td>0.056776</td>\n",
       "      <td>4032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4603</th>\n",
       "      <td>0.129553</td>\n",
       "      <td>0.001133</td>\n",
       "      <td>0.007580</td>\n",
       "      <td>0.000488</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.08</td>\n",
       "      <td>5</td>\n",
       "      <td>150</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.919355</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.824962</td>\n",
       "      <td>0.052356</td>\n",
       "      <td>2818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4604</th>\n",
       "      <td>0.170643</td>\n",
       "      <td>0.001863</td>\n",
       "      <td>0.007581</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.08</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.903226</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.820225</td>\n",
       "      <td>0.053767</td>\n",
       "      <td>3155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4605</th>\n",
       "      <td>0.170045</td>\n",
       "      <td>0.001561</td>\n",
       "      <td>0.007281</td>\n",
       "      <td>0.000457</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.08</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.887097</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.816974</td>\n",
       "      <td>0.048018</td>\n",
       "      <td>3490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4606</th>\n",
       "      <td>0.169746</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>0.007480</td>\n",
       "      <td>0.000499</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.08</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.903226</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.816999</td>\n",
       "      <td>0.050944</td>\n",
       "      <td>3455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4607</th>\n",
       "      <td>0.170444</td>\n",
       "      <td>0.002693</td>\n",
       "      <td>0.007181</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.08</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.919355</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.823374</td>\n",
       "      <td>0.053036</td>\n",
       "      <td>2921</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4608 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0          0.028224      0.001548         0.007181        0.000399   \n",
       "1          0.026928      0.000772         0.007181        0.000599   \n",
       "2          0.029339      0.001735         0.007479        0.000498   \n",
       "3          0.028622      0.001947         0.007481        0.000500   \n",
       "4          0.039893      0.001261         0.007380        0.000489   \n",
       "...             ...           ...              ...             ...   \n",
       "4603       0.129553      0.001133         0.007580        0.000488   \n",
       "4604       0.170643      0.001863         0.007581        0.000489   \n",
       "4605       0.170045      0.001561         0.007281        0.000457   \n",
       "4606       0.169746      0.000977         0.007480        0.000499   \n",
       "4607       0.170444      0.002693         0.007181        0.000399   \n",
       "\n",
       "     param_colsample_bylevel param_colsample_bytree param_gamma  \\\n",
       "0                        0.1                    0.4           0   \n",
       "1                        0.1                    0.4           0   \n",
       "2                        0.1                    0.4           0   \n",
       "3                        0.1                    0.4           0   \n",
       "4                        0.1                    0.4           0   \n",
       "...                      ...                    ...         ...   \n",
       "4603                     0.4                    0.9          10   \n",
       "4604                     0.4                    0.9          10   \n",
       "4605                     0.4                    0.9          10   \n",
       "4606                     0.4                    0.9          10   \n",
       "4607                     0.4                    0.9          10   \n",
       "\n",
       "     param_learning_rate param_max_depth param_n_estimators  ...  \\\n",
       "0                   0.08               2                 30  ...   \n",
       "1                   0.08               2                 30  ...   \n",
       "2                   0.08               2                 30  ...   \n",
       "3                   0.08               2                 30  ...   \n",
       "4                   0.08               2                 50  ...   \n",
       "...                  ...             ...                ...  ...   \n",
       "4603                0.08               5                150  ...   \n",
       "4604                0.08               5                200  ...   \n",
       "4605                0.08               5                200  ...   \n",
       "4606                0.08               5                200  ...   \n",
       "4607                0.08               5                200  ...   \n",
       "\n",
       "     split3_test_score split4_test_score  split5_test_score  \\\n",
       "0             0.806452          0.774194           0.822581   \n",
       "1             0.806452          0.774194           0.822581   \n",
       "2             0.838710          0.774194           0.822581   \n",
       "3             0.838710          0.774194           0.822581   \n",
       "4             0.854839          0.790323           0.870968   \n",
       "...                ...               ...                ...   \n",
       "4603          0.838710          0.806452           0.919355   \n",
       "4604          0.870968          0.806452           0.903226   \n",
       "4605          0.838710          0.822581           0.887097   \n",
       "4606          0.838710          0.806452           0.903226   \n",
       "4607          0.838710          0.806452           0.919355   \n",
       "\n",
       "      split6_test_score  split7_test_score  split8_test_score  \\\n",
       "0              0.822581           0.693548           0.725806   \n",
       "1              0.790323           0.709677           0.709677   \n",
       "2              0.790323           0.709677           0.709677   \n",
       "3              0.790323           0.725806           0.709677   \n",
       "4              0.806452           0.741935           0.693548   \n",
       "...                 ...                ...                ...   \n",
       "4603           0.822581           0.806452           0.709677   \n",
       "4604           0.822581           0.822581           0.693548   \n",
       "4605           0.822581           0.806452           0.693548   \n",
       "4606           0.822581           0.806452           0.709677   \n",
       "4607           0.822581           0.806452           0.709677   \n",
       "\n",
       "      split9_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0              0.806452         0.791193        0.044965             4563  \n",
       "1              0.806452         0.789555        0.044749             4576  \n",
       "2              0.790323         0.789580        0.046896             4572  \n",
       "3              0.790323         0.792780        0.044102             4551  \n",
       "4              0.806452         0.812007        0.056776             4032  \n",
       "...                 ...              ...             ...              ...  \n",
       "4603           0.822581         0.824962        0.052356             2818  \n",
       "4604           0.822581         0.820225        0.053767             3155  \n",
       "4605           0.822581         0.816974        0.048018             3490  \n",
       "4606           0.822581         0.816999        0.050944             3455  \n",
       "4607           0.822581         0.823374        0.053036             2921  \n",
       "\n",
       "[4608 rows x 25 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score is 0.8506400409626217 with params {'colsample_bylevel': 0.2, 'colsample_bytree': 0.5, 'gamma': 1, 'learning_rate': 0.08, 'max_depth': 2, 'n_estimators': 150, 'subsample': 0.8}\n"
     ]
    }
   ],
   "source": [
    "# Full Tuning - Part 3\n",
    "random.seed(10)\n",
    "\n",
    "xgb = XGBClassifier()\n",
    "\n",
    "xgb_parameters = {'max_depth': [2,3,4,5]\n",
    "                   , 'subsample': [0.6, 0.7, 0.8, 0.9]\n",
    "                   , 'gamma': [0, 1, 10]\n",
    "                   , 'colsample_bytree': [0.4, 0.5, 0.6, 0.9]\n",
    "                   , 'colsample_bylevel': [0.1, 0.2, 0.3, 0.4]\n",
    "                   , 'learning_rate': [0.08]\n",
    "                   , 'n_estimators': [30, 50, 80, 100, 150, 200]}\n",
    "\n",
    "stratified_10_fold_cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "xgb_grid_search = GridSearchCV(xgb, xgb_parameters, scoring='accuracy', cv=stratified_10_fold_cv)\n",
    "\n",
    "xgb_grid_search.fit(X_train, y_train)\n",
    "\n",
    "xgb_grid_search_results_full_3 = pd.DataFrame(xgb_grid_search.cv_results_)\n",
    "display(xgb_grid_search_results_full_3)\n",
    "\n",
    "print(\"best score is {} with params {}\".format(xgb_grid_search.best_score_, xgb_grid_search.best_params_))\n",
    "#best score is 0.8506400409626217 with params\n",
    "#{'colsample_bylevel': 0.2, 'colsample_bytree': 0.5, 'gamma': 1, 'learning_rate': 0.08, 'max_depth': 2, 'n_estimators': 150, 'subsample': 0.8}\n",
    "\n",
    "# save dataframe\n",
    "from datetime import datetime\n",
    "date = str(datetime.now().date()).replace(\"-\", \"\")\n",
    "xgb_grid_search_results_full_3.to_csv(f\"results/xgb_results_full_round3_3_learning=0.08_{date}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9eef9359",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_colsample_bylevel</th>\n",
       "      <th>param_colsample_bytree</th>\n",
       "      <th>param_gamma</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>...</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.027726</td>\n",
       "      <td>0.001246</td>\n",
       "      <td>0.007381</td>\n",
       "      <td>0.000662</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.791219</td>\n",
       "      <td>0.043138</td>\n",
       "      <td>4572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.027127</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>0.007081</td>\n",
       "      <td>0.000698</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.797619</td>\n",
       "      <td>0.056310</td>\n",
       "      <td>4538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.027725</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>0.007582</td>\n",
       "      <td>0.000486</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.800819</td>\n",
       "      <td>0.053966</td>\n",
       "      <td>4506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.028225</td>\n",
       "      <td>0.001002</td>\n",
       "      <td>0.007579</td>\n",
       "      <td>0.000661</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.799232</td>\n",
       "      <td>0.049960</td>\n",
       "      <td>4523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.041589</td>\n",
       "      <td>0.000779</td>\n",
       "      <td>0.007481</td>\n",
       "      <td>0.000499</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.812007</td>\n",
       "      <td>0.054003</td>\n",
       "      <td>4127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4603</th>\n",
       "      <td>0.128755</td>\n",
       "      <td>0.000698</td>\n",
       "      <td>0.007581</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.1</td>\n",
       "      <td>5</td>\n",
       "      <td>150</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.919355</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.818587</td>\n",
       "      <td>0.059897</td>\n",
       "      <td>3439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4604</th>\n",
       "      <td>0.181969</td>\n",
       "      <td>0.018973</td>\n",
       "      <td>0.007281</td>\n",
       "      <td>0.000457</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.1</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.903226</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.818612</td>\n",
       "      <td>0.058941</td>\n",
       "      <td>3420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4605</th>\n",
       "      <td>0.176428</td>\n",
       "      <td>0.003770</td>\n",
       "      <td>0.007381</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.1</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.887097</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.815463</td>\n",
       "      <td>0.055569</td>\n",
       "      <td>3709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4606</th>\n",
       "      <td>0.171740</td>\n",
       "      <td>0.003450</td>\n",
       "      <td>0.007381</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.1</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.903226</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.812238</td>\n",
       "      <td>0.052148</td>\n",
       "      <td>4000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4607</th>\n",
       "      <td>0.170743</td>\n",
       "      <td>0.002706</td>\n",
       "      <td>0.007680</td>\n",
       "      <td>0.000457</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.1</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.919355</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.821761</td>\n",
       "      <td>0.060591</td>\n",
       "      <td>3170</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4608 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0          0.027726      0.001246         0.007381        0.000662   \n",
       "1          0.027127      0.000977         0.007081        0.000698   \n",
       "2          0.027725      0.000977         0.007582        0.000486   \n",
       "3          0.028225      0.001002         0.007579        0.000661   \n",
       "4          0.041589      0.000779         0.007481        0.000499   \n",
       "...             ...           ...              ...             ...   \n",
       "4603       0.128755      0.000698         0.007581        0.000489   \n",
       "4604       0.181969      0.018973         0.007281        0.000457   \n",
       "4605       0.176428      0.003770         0.007381        0.000489   \n",
       "4606       0.171740      0.003450         0.007381        0.000489   \n",
       "4607       0.170743      0.002706         0.007680        0.000457   \n",
       "\n",
       "      param_colsample_bylevel  param_colsample_bytree  param_gamma  \\\n",
       "0                         0.1                     0.4            0   \n",
       "1                         0.1                     0.4            0   \n",
       "2                         0.1                     0.4            0   \n",
       "3                         0.1                     0.4            0   \n",
       "4                         0.1                     0.4            0   \n",
       "...                       ...                     ...          ...   \n",
       "4603                      0.4                     0.9           10   \n",
       "4604                      0.4                     0.9           10   \n",
       "4605                      0.4                     0.9           10   \n",
       "4606                      0.4                     0.9           10   \n",
       "4607                      0.4                     0.9           10   \n",
       "\n",
       "      param_learning_rate  param_max_depth  param_n_estimators  ...  \\\n",
       "0                     0.1                2                  30  ...   \n",
       "1                     0.1                2                  30  ...   \n",
       "2                     0.1                2                  30  ...   \n",
       "3                     0.1                2                  30  ...   \n",
       "4                     0.1                2                  50  ...   \n",
       "...                   ...              ...                 ...  ...   \n",
       "4603                  0.1                5                 150  ...   \n",
       "4604                  0.1                5                 200  ...   \n",
       "4605                  0.1                5                 200  ...   \n",
       "4606                  0.1                5                 200  ...   \n",
       "4607                  0.1                5                 200  ...   \n",
       "\n",
       "      split3_test_score split4_test_score  split5_test_score  \\\n",
       "0              0.838710          0.790323           0.822581   \n",
       "1              0.838710          0.774194           0.870968   \n",
       "2              0.838710          0.774194           0.870968   \n",
       "3              0.838710          0.790323           0.854839   \n",
       "4              0.870968          0.790323           0.854839   \n",
       "...                 ...               ...                ...   \n",
       "4603           0.838710          0.806452           0.919355   \n",
       "4604           0.870968          0.806452           0.903226   \n",
       "4605           0.870968          0.822581           0.887097   \n",
       "4606           0.838710          0.806452           0.903226   \n",
       "4607           0.838710          0.806452           0.919355   \n",
       "\n",
       "      split6_test_score  split7_test_score  split8_test_score  \\\n",
       "0              0.790323           0.709677           0.709677   \n",
       "1              0.806452           0.725806           0.677419   \n",
       "2              0.806452           0.725806           0.693548   \n",
       "3              0.806452           0.725806           0.693548   \n",
       "4              0.806452           0.758065           0.693548   \n",
       "...                 ...                ...                ...   \n",
       "4603           0.822581           0.806452           0.677419   \n",
       "4604           0.822581           0.822581           0.677419   \n",
       "4605           0.822581           0.822581           0.693548   \n",
       "4606           0.822581           0.806452           0.709677   \n",
       "4607           0.822581           0.806452           0.677419   \n",
       "\n",
       "      split9_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0              0.806452         0.791219        0.043138             4572  \n",
       "1              0.806452         0.797619        0.056310             4538  \n",
       "2              0.806452         0.800819        0.053966             4506  \n",
       "3              0.806452         0.799232        0.049960             4523  \n",
       "4              0.790323         0.812007        0.054003             4127  \n",
       "...                 ...              ...             ...              ...  \n",
       "4603           0.838710         0.818587        0.059897             3439  \n",
       "4604           0.822581         0.818612        0.058941             3420  \n",
       "4605           0.822581         0.815463        0.055569             3709  \n",
       "4606           0.822581         0.812238        0.052148             4000  \n",
       "4607           0.838710         0.821761        0.060591             3170  \n",
       "\n",
       "[4608 rows x 25 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score is 0.8506400409626217 with params {'colsample_bylevel': 0.3, 'colsample_bytree': 0.5, 'gamma': 1, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 100, 'subsample': 0.8}\n"
     ]
    }
   ],
   "source": [
    "df4 = pd.read_csv(\"data\\\\xgb_results_full_4_learning=0.1_20221124.csv\")\n",
    "df4.drop(df4.columns[0], axis=1, inplace=True)\n",
    "display(df4)\n",
    "print(\"best score is 0.8506400409626217 with params {'colsample_bylevel': 0.3, 'colsample_bytree': 0.5, 'gamma': 1, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 100, 'subsample': 0.8}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "81c3993c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_colsample_bylevel</th>\n",
       "      <th>param_colsample_bytree</th>\n",
       "      <th>param_gamma</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>...</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.027726</td>\n",
       "      <td>0.001246</td>\n",
       "      <td>0.007381</td>\n",
       "      <td>0.000662</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.791219</td>\n",
       "      <td>0.043138</td>\n",
       "      <td>4572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.027127</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>0.007081</td>\n",
       "      <td>0.000698</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.797619</td>\n",
       "      <td>0.056310</td>\n",
       "      <td>4538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.027725</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>0.007582</td>\n",
       "      <td>0.000486</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.800819</td>\n",
       "      <td>0.053966</td>\n",
       "      <td>4506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.028225</td>\n",
       "      <td>0.001002</td>\n",
       "      <td>0.007579</td>\n",
       "      <td>0.000661</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.799232</td>\n",
       "      <td>0.049960</td>\n",
       "      <td>4523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.041589</td>\n",
       "      <td>0.000779</td>\n",
       "      <td>0.007481</td>\n",
       "      <td>0.000499</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.812007</td>\n",
       "      <td>0.054003</td>\n",
       "      <td>4127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4603</th>\n",
       "      <td>0.128755</td>\n",
       "      <td>0.000698</td>\n",
       "      <td>0.007581</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.1</td>\n",
       "      <td>5</td>\n",
       "      <td>150</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.919355</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.818587</td>\n",
       "      <td>0.059897</td>\n",
       "      <td>3439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4604</th>\n",
       "      <td>0.181969</td>\n",
       "      <td>0.018973</td>\n",
       "      <td>0.007281</td>\n",
       "      <td>0.000457</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.1</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.903226</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.818612</td>\n",
       "      <td>0.058941</td>\n",
       "      <td>3420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4605</th>\n",
       "      <td>0.176428</td>\n",
       "      <td>0.003770</td>\n",
       "      <td>0.007381</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.1</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.887097</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.815463</td>\n",
       "      <td>0.055569</td>\n",
       "      <td>3709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4606</th>\n",
       "      <td>0.171740</td>\n",
       "      <td>0.003450</td>\n",
       "      <td>0.007381</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.1</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.903226</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.812238</td>\n",
       "      <td>0.052148</td>\n",
       "      <td>4000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4607</th>\n",
       "      <td>0.170743</td>\n",
       "      <td>0.002706</td>\n",
       "      <td>0.007680</td>\n",
       "      <td>0.000457</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.1</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.919355</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.821761</td>\n",
       "      <td>0.060591</td>\n",
       "      <td>3170</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4608 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0          0.027726      0.001246         0.007381        0.000662   \n",
       "1          0.027127      0.000977         0.007081        0.000698   \n",
       "2          0.027725      0.000977         0.007582        0.000486   \n",
       "3          0.028225      0.001002         0.007579        0.000661   \n",
       "4          0.041589      0.000779         0.007481        0.000499   \n",
       "...             ...           ...              ...             ...   \n",
       "4603       0.128755      0.000698         0.007581        0.000489   \n",
       "4604       0.181969      0.018973         0.007281        0.000457   \n",
       "4605       0.176428      0.003770         0.007381        0.000489   \n",
       "4606       0.171740      0.003450         0.007381        0.000489   \n",
       "4607       0.170743      0.002706         0.007680        0.000457   \n",
       "\n",
       "     param_colsample_bylevel param_colsample_bytree param_gamma  \\\n",
       "0                        0.1                    0.4           0   \n",
       "1                        0.1                    0.4           0   \n",
       "2                        0.1                    0.4           0   \n",
       "3                        0.1                    0.4           0   \n",
       "4                        0.1                    0.4           0   \n",
       "...                      ...                    ...         ...   \n",
       "4603                     0.4                    0.9          10   \n",
       "4604                     0.4                    0.9          10   \n",
       "4605                     0.4                    0.9          10   \n",
       "4606                     0.4                    0.9          10   \n",
       "4607                     0.4                    0.9          10   \n",
       "\n",
       "     param_learning_rate param_max_depth param_n_estimators  ...  \\\n",
       "0                    0.1               2                 30  ...   \n",
       "1                    0.1               2                 30  ...   \n",
       "2                    0.1               2                 30  ...   \n",
       "3                    0.1               2                 30  ...   \n",
       "4                    0.1               2                 50  ...   \n",
       "...                  ...             ...                ...  ...   \n",
       "4603                 0.1               5                150  ...   \n",
       "4604                 0.1               5                200  ...   \n",
       "4605                 0.1               5                200  ...   \n",
       "4606                 0.1               5                200  ...   \n",
       "4607                 0.1               5                200  ...   \n",
       "\n",
       "     split3_test_score split4_test_score  split5_test_score  \\\n",
       "0             0.838710          0.790323           0.822581   \n",
       "1             0.838710          0.774194           0.870968   \n",
       "2             0.838710          0.774194           0.870968   \n",
       "3             0.838710          0.790323           0.854839   \n",
       "4             0.870968          0.790323           0.854839   \n",
       "...                ...               ...                ...   \n",
       "4603          0.838710          0.806452           0.919355   \n",
       "4604          0.870968          0.806452           0.903226   \n",
       "4605          0.870968          0.822581           0.887097   \n",
       "4606          0.838710          0.806452           0.903226   \n",
       "4607          0.838710          0.806452           0.919355   \n",
       "\n",
       "      split6_test_score  split7_test_score  split8_test_score  \\\n",
       "0              0.790323           0.709677           0.709677   \n",
       "1              0.806452           0.725806           0.677419   \n",
       "2              0.806452           0.725806           0.693548   \n",
       "3              0.806452           0.725806           0.693548   \n",
       "4              0.806452           0.758065           0.693548   \n",
       "...                 ...                ...                ...   \n",
       "4603           0.822581           0.806452           0.677419   \n",
       "4604           0.822581           0.822581           0.677419   \n",
       "4605           0.822581           0.822581           0.693548   \n",
       "4606           0.822581           0.806452           0.709677   \n",
       "4607           0.822581           0.806452           0.677419   \n",
       "\n",
       "      split9_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0              0.806452         0.791219        0.043138             4572  \n",
       "1              0.806452         0.797619        0.056310             4538  \n",
       "2              0.806452         0.800819        0.053966             4506  \n",
       "3              0.806452         0.799232        0.049960             4523  \n",
       "4              0.790323         0.812007        0.054003             4127  \n",
       "...                 ...              ...             ...              ...  \n",
       "4603           0.838710         0.818587        0.059897             3439  \n",
       "4604           0.822581         0.818612        0.058941             3420  \n",
       "4605           0.822581         0.815463        0.055569             3709  \n",
       "4606           0.822581         0.812238        0.052148             4000  \n",
       "4607           0.838710         0.821761        0.060591             3170  \n",
       "\n",
       "[4608 rows x 25 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score is 0.8506400409626217 with params {'colsample_bylevel': 0.3, 'colsample_bytree': 0.5, 'gamma': 1, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 100, 'subsample': 0.8}\n"
     ]
    }
   ],
   "source": [
    "# Full Tuning - Part 4\n",
    "random.seed(10)\n",
    "\n",
    "xgb = XGBClassifier()\n",
    "\n",
    "xgb_parameters = {'max_depth': [2,3,4,5]\n",
    "                   , 'subsample': [0.6, 0.7, 0.8, 0.9]\n",
    "                   , 'gamma': [0, 1, 10]\n",
    "                   , 'colsample_bytree': [0.4, 0.5, 0.6, 0.9]\n",
    "                   , 'colsample_bylevel': [0.1, 0.2, 0.3, 0.4]\n",
    "                   , 'learning_rate': [0.1]\n",
    "                   , 'n_estimators': [30, 50, 80, 100, 150, 200]}\n",
    "\n",
    "stratified_10_fold_cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "xgb_grid_search = GridSearchCV(xgb, xgb_parameters, scoring='accuracy', cv=stratified_10_fold_cv)\n",
    "\n",
    "xgb_grid_search.fit(X_train, y_train)\n",
    "\n",
    "xgb_grid_search_results_full_4 = pd.DataFrame(xgb_grid_search.cv_results_)\n",
    "display(xgb_grid_search_results_full_4)\n",
    "\n",
    "print(\"best score is {} with params {}\".format(xgb_grid_search.best_score_, xgb_grid_search.best_params_))\n",
    "#best score is 0.8506400409626217 with params\n",
    "#{'colsample_bylevel': 0.3, 'colsample_bytree': 0.5, 'gamma': 1, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 100, 'subsample': 0.8}\n",
    "\n",
    "# save dataframe\n",
    "from datetime import datetime\n",
    "date = str(datetime.now().date()).replace(\"-\", \"\")\n",
    "xgb_grid_search_results_full_4.to_csv(f\"results/xgb_results_full_round3_4_learning=0.1_{date}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "83e43f97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_colsample_bylevel</th>\n",
       "      <th>param_colsample_bytree</th>\n",
       "      <th>param_gamma</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>...</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.028225</td>\n",
       "      <td>0.001002</td>\n",
       "      <td>0.007380</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.15</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.807220</td>\n",
       "      <td>0.059458</td>\n",
       "      <td>4384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.027726</td>\n",
       "      <td>0.000870</td>\n",
       "      <td>0.006783</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.15</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.887097</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.805658</td>\n",
       "      <td>0.060796</td>\n",
       "      <td>4446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.028425</td>\n",
       "      <td>0.001357</td>\n",
       "      <td>0.007184</td>\n",
       "      <td>0.000398</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.15</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.804019</td>\n",
       "      <td>0.053790</td>\n",
       "      <td>4484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.029920</td>\n",
       "      <td>0.001262</td>\n",
       "      <td>0.007680</td>\n",
       "      <td>0.001184</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.15</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.818484</td>\n",
       "      <td>0.052359</td>\n",
       "      <td>3585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.039893</td>\n",
       "      <td>0.001180</td>\n",
       "      <td>0.007580</td>\n",
       "      <td>0.000662</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.15</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.820097</td>\n",
       "      <td>0.044768</td>\n",
       "      <td>3445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4603</th>\n",
       "      <td>0.129254</td>\n",
       "      <td>0.001017</td>\n",
       "      <td>0.007382</td>\n",
       "      <td>0.000488</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.15</td>\n",
       "      <td>5</td>\n",
       "      <td>150</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.903226</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.812212</td>\n",
       "      <td>0.054700</td>\n",
       "      <td>4012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4604</th>\n",
       "      <td>0.171740</td>\n",
       "      <td>0.001657</td>\n",
       "      <td>0.007480</td>\n",
       "      <td>0.000499</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.15</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.813722</td>\n",
       "      <td>0.052700</td>\n",
       "      <td>3948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4605</th>\n",
       "      <td>0.170244</td>\n",
       "      <td>0.001342</td>\n",
       "      <td>0.007780</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.15</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.820123</td>\n",
       "      <td>0.057714</td>\n",
       "      <td>3430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4606</th>\n",
       "      <td>0.170145</td>\n",
       "      <td>0.001795</td>\n",
       "      <td>0.007281</td>\n",
       "      <td>0.000457</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.15</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.903226</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.817025</td>\n",
       "      <td>0.051360</td>\n",
       "      <td>3604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4607</th>\n",
       "      <td>0.170145</td>\n",
       "      <td>0.002410</td>\n",
       "      <td>0.007580</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.15</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.903226</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.812212</td>\n",
       "      <td>0.054700</td>\n",
       "      <td>4012</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4608 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0          0.028225      0.001002         0.007380        0.000489   \n",
       "1          0.027726      0.000870         0.006783        0.000977   \n",
       "2          0.028425      0.001357         0.007184        0.000398   \n",
       "3          0.029920      0.001262         0.007680        0.001184   \n",
       "4          0.039893      0.001180         0.007580        0.000662   \n",
       "...             ...           ...              ...             ...   \n",
       "4603       0.129254      0.001017         0.007382        0.000488   \n",
       "4604       0.171740      0.001657         0.007480        0.000499   \n",
       "4605       0.170244      0.001342         0.007780        0.000399   \n",
       "4606       0.170145      0.001795         0.007281        0.000457   \n",
       "4607       0.170145      0.002410         0.007580        0.000489   \n",
       "\n",
       "      param_colsample_bylevel  param_colsample_bytree  param_gamma  \\\n",
       "0                         0.1                     0.4            0   \n",
       "1                         0.1                     0.4            0   \n",
       "2                         0.1                     0.4            0   \n",
       "3                         0.1                     0.4            0   \n",
       "4                         0.1                     0.4            0   \n",
       "...                       ...                     ...          ...   \n",
       "4603                      0.4                     0.9           10   \n",
       "4604                      0.4                     0.9           10   \n",
       "4605                      0.4                     0.9           10   \n",
       "4606                      0.4                     0.9           10   \n",
       "4607                      0.4                     0.9           10   \n",
       "\n",
       "      param_learning_rate  param_max_depth  param_n_estimators  ...  \\\n",
       "0                    0.15                2                  30  ...   \n",
       "1                    0.15                2                  30  ...   \n",
       "2                    0.15                2                  30  ...   \n",
       "3                    0.15                2                  30  ...   \n",
       "4                    0.15                2                  50  ...   \n",
       "...                   ...              ...                 ...  ...   \n",
       "4603                 0.15                5                 150  ...   \n",
       "4604                 0.15                5                 200  ...   \n",
       "4605                 0.15                5                 200  ...   \n",
       "4606                 0.15                5                 200  ...   \n",
       "4607                 0.15                5                 200  ...   \n",
       "\n",
       "      split3_test_score split4_test_score  split5_test_score  \\\n",
       "0              0.870968          0.790323           0.870968   \n",
       "1              0.854839          0.806452           0.887097   \n",
       "2              0.838710          0.790323           0.854839   \n",
       "3              0.870968          0.806452           0.870968   \n",
       "4              0.870968          0.790323           0.854839   \n",
       "...                 ...               ...                ...   \n",
       "4603           0.838710          0.806452           0.903226   \n",
       "4604           0.838710          0.822581           0.854839   \n",
       "4605           0.870968          0.806452           0.870968   \n",
       "4606           0.838710          0.806452           0.903226   \n",
       "4607           0.838710          0.806452           0.903226   \n",
       "\n",
       "      split6_test_score  split7_test_score  split8_test_score  \\\n",
       "0              0.822581           0.709677           0.693548   \n",
       "1              0.822581           0.725806           0.677419   \n",
       "2              0.838710           0.725806           0.693548   \n",
       "3              0.822581           0.725806           0.725806   \n",
       "4              0.838710           0.758065           0.725806   \n",
       "...                 ...                ...                ...   \n",
       "4603           0.822581           0.806452           0.693548   \n",
       "4604           0.806452           0.806452           0.677419   \n",
       "4605           0.822581           0.806452           0.677419   \n",
       "4606           0.822581           0.806452           0.709677   \n",
       "4607           0.822581           0.806452           0.693548   \n",
       "\n",
       "      split9_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0              0.790323         0.807220        0.059458             4384  \n",
       "1              0.790323         0.805658        0.060796             4446  \n",
       "2              0.790323         0.804019        0.053790             4484  \n",
       "3              0.822581         0.818484        0.052359             3585  \n",
       "4              0.822581         0.820097        0.044768             3445  \n",
       "...                 ...              ...             ...              ...  \n",
       "4603           0.822581         0.812212        0.054700             4012  \n",
       "4604           0.838710         0.813722        0.052700             3948  \n",
       "4605           0.822581         0.820123        0.057714             3430  \n",
       "4606           0.838710         0.817025        0.051360             3604  \n",
       "4607           0.822581         0.812212        0.054700             4012  \n",
       "\n",
       "[4608 rows x 25 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score is 0.856989247311828 with params {'colsample_bylevel': 0.4, 'colsample_bytree': 0.4, 'gamma': 1, 'learning_rate': 0.15, 'max_depth': 4, 'n_estimators': 30, 'subsample': 0.9}\n"
     ]
    }
   ],
   "source": [
    "df5 = pd.read_csv(\"data\\\\xgb_results_full_5_learning=0.15_20221124.csv\")\n",
    "df5.drop(df5.columns[0], axis=1, inplace=True)\n",
    "display(df5)\n",
    "print(\"best score is 0.856989247311828 with params {'colsample_bylevel': 0.4, 'colsample_bytree': 0.4, 'gamma': 1, 'learning_rate': 0.15, 'max_depth': 4, 'n_estimators': 30, 'subsample': 0.9}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8e53020f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_colsample_bylevel</th>\n",
       "      <th>param_colsample_bytree</th>\n",
       "      <th>param_gamma</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>...</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.028225</td>\n",
       "      <td>0.001002</td>\n",
       "      <td>0.007380</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.15</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.807220</td>\n",
       "      <td>0.059458</td>\n",
       "      <td>4384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.027726</td>\n",
       "      <td>0.000870</td>\n",
       "      <td>0.006783</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.15</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.887097</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.805658</td>\n",
       "      <td>0.060796</td>\n",
       "      <td>4446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.028425</td>\n",
       "      <td>0.001357</td>\n",
       "      <td>0.007184</td>\n",
       "      <td>0.000398</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.15</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.804019</td>\n",
       "      <td>0.053790</td>\n",
       "      <td>4484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.029920</td>\n",
       "      <td>0.001262</td>\n",
       "      <td>0.007680</td>\n",
       "      <td>0.001184</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.15</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.818484</td>\n",
       "      <td>0.052359</td>\n",
       "      <td>3585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.039893</td>\n",
       "      <td>0.001180</td>\n",
       "      <td>0.007580</td>\n",
       "      <td>0.000662</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.15</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.820097</td>\n",
       "      <td>0.044768</td>\n",
       "      <td>3445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4603</th>\n",
       "      <td>0.129254</td>\n",
       "      <td>0.001017</td>\n",
       "      <td>0.007382</td>\n",
       "      <td>0.000488</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.15</td>\n",
       "      <td>5</td>\n",
       "      <td>150</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.903226</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.812212</td>\n",
       "      <td>0.054700</td>\n",
       "      <td>4012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4604</th>\n",
       "      <td>0.171740</td>\n",
       "      <td>0.001657</td>\n",
       "      <td>0.007480</td>\n",
       "      <td>0.000499</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.15</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.813722</td>\n",
       "      <td>0.052700</td>\n",
       "      <td>3948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4605</th>\n",
       "      <td>0.170244</td>\n",
       "      <td>0.001342</td>\n",
       "      <td>0.007780</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.15</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.820123</td>\n",
       "      <td>0.057714</td>\n",
       "      <td>3430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4606</th>\n",
       "      <td>0.170145</td>\n",
       "      <td>0.001795</td>\n",
       "      <td>0.007281</td>\n",
       "      <td>0.000457</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.15</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.903226</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.817025</td>\n",
       "      <td>0.051360</td>\n",
       "      <td>3604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4607</th>\n",
       "      <td>0.170145</td>\n",
       "      <td>0.002410</td>\n",
       "      <td>0.007580</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.15</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.903226</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.812212</td>\n",
       "      <td>0.054700</td>\n",
       "      <td>4012</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4608 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0          0.028225      0.001002         0.007380        0.000489   \n",
       "1          0.027726      0.000870         0.006783        0.000977   \n",
       "2          0.028425      0.001357         0.007184        0.000398   \n",
       "3          0.029920      0.001262         0.007680        0.001184   \n",
       "4          0.039893      0.001180         0.007580        0.000662   \n",
       "...             ...           ...              ...             ...   \n",
       "4603       0.129254      0.001017         0.007382        0.000488   \n",
       "4604       0.171740      0.001657         0.007480        0.000499   \n",
       "4605       0.170244      0.001342         0.007780        0.000399   \n",
       "4606       0.170145      0.001795         0.007281        0.000457   \n",
       "4607       0.170145      0.002410         0.007580        0.000489   \n",
       "\n",
       "     param_colsample_bylevel param_colsample_bytree param_gamma  \\\n",
       "0                        0.1                    0.4           0   \n",
       "1                        0.1                    0.4           0   \n",
       "2                        0.1                    0.4           0   \n",
       "3                        0.1                    0.4           0   \n",
       "4                        0.1                    0.4           0   \n",
       "...                      ...                    ...         ...   \n",
       "4603                     0.4                    0.9          10   \n",
       "4604                     0.4                    0.9          10   \n",
       "4605                     0.4                    0.9          10   \n",
       "4606                     0.4                    0.9          10   \n",
       "4607                     0.4                    0.9          10   \n",
       "\n",
       "     param_learning_rate param_max_depth param_n_estimators  ...  \\\n",
       "0                   0.15               2                 30  ...   \n",
       "1                   0.15               2                 30  ...   \n",
       "2                   0.15               2                 30  ...   \n",
       "3                   0.15               2                 30  ...   \n",
       "4                   0.15               2                 50  ...   \n",
       "...                  ...             ...                ...  ...   \n",
       "4603                0.15               5                150  ...   \n",
       "4604                0.15               5                200  ...   \n",
       "4605                0.15               5                200  ...   \n",
       "4606                0.15               5                200  ...   \n",
       "4607                0.15               5                200  ...   \n",
       "\n",
       "     split3_test_score split4_test_score  split5_test_score  \\\n",
       "0             0.870968          0.790323           0.870968   \n",
       "1             0.854839          0.806452           0.887097   \n",
       "2             0.838710          0.790323           0.854839   \n",
       "3             0.870968          0.806452           0.870968   \n",
       "4             0.870968          0.790323           0.854839   \n",
       "...                ...               ...                ...   \n",
       "4603          0.838710          0.806452           0.903226   \n",
       "4604          0.838710          0.822581           0.854839   \n",
       "4605          0.870968          0.806452           0.870968   \n",
       "4606          0.838710          0.806452           0.903226   \n",
       "4607          0.838710          0.806452           0.903226   \n",
       "\n",
       "      split6_test_score  split7_test_score  split8_test_score  \\\n",
       "0              0.822581           0.709677           0.693548   \n",
       "1              0.822581           0.725806           0.677419   \n",
       "2              0.838710           0.725806           0.693548   \n",
       "3              0.822581           0.725806           0.725806   \n",
       "4              0.838710           0.758065           0.725806   \n",
       "...                 ...                ...                ...   \n",
       "4603           0.822581           0.806452           0.693548   \n",
       "4604           0.806452           0.806452           0.677419   \n",
       "4605           0.822581           0.806452           0.677419   \n",
       "4606           0.822581           0.806452           0.709677   \n",
       "4607           0.822581           0.806452           0.693548   \n",
       "\n",
       "      split9_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0              0.790323         0.807220        0.059458             4384  \n",
       "1              0.790323         0.805658        0.060796             4446  \n",
       "2              0.790323         0.804019        0.053790             4484  \n",
       "3              0.822581         0.818484        0.052359             3585  \n",
       "4              0.822581         0.820097        0.044768             3445  \n",
       "...                 ...              ...             ...              ...  \n",
       "4603           0.822581         0.812212        0.054700             4012  \n",
       "4604           0.838710         0.813722        0.052700             3948  \n",
       "4605           0.822581         0.820123        0.057714             3430  \n",
       "4606           0.838710         0.817025        0.051360             3604  \n",
       "4607           0.822581         0.812212        0.054700             4012  \n",
       "\n",
       "[4608 rows x 25 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score is 0.856989247311828 with params {'colsample_bylevel': 0.4, 'colsample_bytree': 0.4, 'gamma': 1, 'learning_rate': 0.15, 'max_depth': 4, 'n_estimators': 30, 'subsample': 0.9}\n"
     ]
    }
   ],
   "source": [
    "# Full Tuning - Part 5\n",
    "random.seed(10)\n",
    "\n",
    "xgb = XGBClassifier()\n",
    "\n",
    "xgb_parameters = {'max_depth': [2,3,4,5]\n",
    "                   , 'subsample': [0.6, 0.7, 0.8, 0.9]\n",
    "                   , 'gamma': [0, 1, 10]\n",
    "                   , 'colsample_bytree': [0.4, 0.5, 0.6, 0.9]\n",
    "                   , 'colsample_bylevel': [0.1, 0.2, 0.3, 0.4]\n",
    "                   , 'learning_rate': [0.15]\n",
    "                   , 'n_estimators': [30, 50, 80, 100, 150, 200]}\n",
    "\n",
    "stratified_10_fold_cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "xgb_grid_search = GridSearchCV(xgb, xgb_parameters, scoring='accuracy', cv=stratified_10_fold_cv)\n",
    "\n",
    "xgb_grid_search.fit(X_train, y_train)\n",
    "\n",
    "xgb_grid_search_results_full_5 = pd.DataFrame(xgb_grid_search.cv_results_)\n",
    "display(xgb_grid_search_results_full_5)\n",
    "\n",
    "print(\"best score is {} with params {}\".format(xgb_grid_search.best_score_, xgb_grid_search.best_params_))\n",
    "#best score is 0.856989247311828 with params\n",
    "#{'colsample_bylevel': 0.4, 'colsample_bytree': 0.4, 'gamma': 1, 'learning_rate': 0.15, 'max_depth': 4, 'n_estimators': 30, 'subsample': 0.9}\n",
    "\n",
    "# save dataframe\n",
    "from datetime import datetime\n",
    "date = str(datetime.now().date()).replace(\"-\", \"\")\n",
    "xgb_grid_search_results_full_5.to_csv(f\"results/xgb_results_full_round3_5_learning=0.15_{date}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "addcfcca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_colsample_bylevel</th>\n",
       "      <th>param_colsample_bytree</th>\n",
       "      <th>param_gamma</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>...</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.028224</td>\n",
       "      <td>0.000897</td>\n",
       "      <td>0.007381</td>\n",
       "      <td>0.000488</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.821582</td>\n",
       "      <td>0.063111</td>\n",
       "      <td>3320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.027226</td>\n",
       "      <td>0.000639</td>\n",
       "      <td>0.006683</td>\n",
       "      <td>0.000897</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>0.887097</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.887097</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.829647</td>\n",
       "      <td>0.062955</td>\n",
       "      <td>2389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.029321</td>\n",
       "      <td>0.001353</td>\n",
       "      <td>0.007580</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.887097</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.816846</td>\n",
       "      <td>0.062937</td>\n",
       "      <td>3729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.028125</td>\n",
       "      <td>0.001657</td>\n",
       "      <td>0.007281</td>\n",
       "      <td>0.000457</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>0.887097</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.829647</td>\n",
       "      <td>0.060854</td>\n",
       "      <td>2389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.039993</td>\n",
       "      <td>0.001133</td>\n",
       "      <td>0.007181</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.887097</td>\n",
       "      <td>0.821710</td>\n",
       "      <td>0.053554</td>\n",
       "      <td>3262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4603</th>\n",
       "      <td>0.129354</td>\n",
       "      <td>0.001184</td>\n",
       "      <td>0.007281</td>\n",
       "      <td>0.000457</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5</td>\n",
       "      <td>150</td>\n",
       "      <td>...</td>\n",
       "      <td>0.887097</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.919355</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.826600</td>\n",
       "      <td>0.059814</td>\n",
       "      <td>2710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4604</th>\n",
       "      <td>0.168948</td>\n",
       "      <td>0.001739</td>\n",
       "      <td>0.007581</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.919355</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.828187</td>\n",
       "      <td>0.060472</td>\n",
       "      <td>2464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4605</th>\n",
       "      <td>0.170344</td>\n",
       "      <td>0.002515</td>\n",
       "      <td>0.007481</td>\n",
       "      <td>0.000498</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.887097</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.824936</td>\n",
       "      <td>0.057195</td>\n",
       "      <td>2943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4606</th>\n",
       "      <td>0.169896</td>\n",
       "      <td>0.002405</td>\n",
       "      <td>0.007281</td>\n",
       "      <td>0.000457</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.824910</td>\n",
       "      <td>0.045101</td>\n",
       "      <td>2951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4607</th>\n",
       "      <td>0.169047</td>\n",
       "      <td>0.001201</td>\n",
       "      <td>0.007281</td>\n",
       "      <td>0.000457</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.887097</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.919355</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.826600</td>\n",
       "      <td>0.059814</td>\n",
       "      <td>2710</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4608 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0          0.028224      0.000897         0.007381        0.000488   \n",
       "1          0.027226      0.000639         0.006683        0.000897   \n",
       "2          0.029321      0.001353         0.007580        0.000489   \n",
       "3          0.028125      0.001657         0.007281        0.000457   \n",
       "4          0.039993      0.001133         0.007181        0.000399   \n",
       "...             ...           ...              ...             ...   \n",
       "4603       0.129354      0.001184         0.007281        0.000457   \n",
       "4604       0.168948      0.001739         0.007581        0.000489   \n",
       "4605       0.170344      0.002515         0.007481        0.000498   \n",
       "4606       0.169896      0.002405         0.007281        0.000457   \n",
       "4607       0.169047      0.001201         0.007281        0.000457   \n",
       "\n",
       "      param_colsample_bylevel  param_colsample_bytree  param_gamma  \\\n",
       "0                         0.1                     0.4            0   \n",
       "1                         0.1                     0.4            0   \n",
       "2                         0.1                     0.4            0   \n",
       "3                         0.1                     0.4            0   \n",
       "4                         0.1                     0.4            0   \n",
       "...                       ...                     ...          ...   \n",
       "4603                      0.4                     0.9           10   \n",
       "4604                      0.4                     0.9           10   \n",
       "4605                      0.4                     0.9           10   \n",
       "4606                      0.4                     0.9           10   \n",
       "4607                      0.4                     0.9           10   \n",
       "\n",
       "      param_learning_rate  param_max_depth  param_n_estimators  ...  \\\n",
       "0                     0.2                2                  30  ...   \n",
       "1                     0.2                2                  30  ...   \n",
       "2                     0.2                2                  30  ...   \n",
       "3                     0.2                2                  30  ...   \n",
       "4                     0.2                2                  50  ...   \n",
       "...                   ...              ...                 ...  ...   \n",
       "4603                  0.2                5                 150  ...   \n",
       "4604                  0.2                5                 200  ...   \n",
       "4605                  0.2                5                 200  ...   \n",
       "4606                  0.2                5                 200  ...   \n",
       "4607                  0.2                5                 200  ...   \n",
       "\n",
       "      split3_test_score split4_test_score  split5_test_score  \\\n",
       "0              0.870968          0.790323           0.854839   \n",
       "1              0.887097          0.806452           0.887097   \n",
       "2              0.870968          0.806452           0.887097   \n",
       "3              0.887097          0.790323           0.870968   \n",
       "4              0.854839          0.790323           0.854839   \n",
       "...                 ...               ...                ...   \n",
       "4603           0.887097          0.806452           0.919355   \n",
       "4604           0.919355          0.838710           0.870968   \n",
       "4605           0.870968          0.806452           0.887097   \n",
       "4606           0.870968          0.806452           0.854839   \n",
       "4607           0.887097          0.806452           0.919355   \n",
       "\n",
       "      split6_test_score  split7_test_score  split8_test_score  \\\n",
       "0              0.838710           0.725806           0.693548   \n",
       "1              0.822581           0.741935           0.693548   \n",
       "2              0.822581           0.725806           0.677419   \n",
       "3              0.822581           0.758065           0.693548   \n",
       "4              0.838710           0.741935           0.709677   \n",
       "...                 ...                ...                ...   \n",
       "4603           0.822581           0.806452           0.693548   \n",
       "4604           0.806452           0.806452           0.677419   \n",
       "4605           0.806452           0.822581           0.677419   \n",
       "4606           0.822581           0.806452           0.709677   \n",
       "4607           0.822581           0.806452           0.693548   \n",
       "\n",
       "      split9_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0              0.822581         0.821582        0.063111             3320  \n",
       "1              0.838710         0.829647        0.062955             2389  \n",
       "2              0.822581         0.816846        0.062937             3729  \n",
       "3              0.854839         0.829647        0.060854             2389  \n",
       "4              0.887097         0.821710        0.053554             3262  \n",
       "...                 ...              ...             ...              ...  \n",
       "4603           0.822581         0.826600        0.059814             2710  \n",
       "4604           0.838710         0.828187        0.060472             2464  \n",
       "4605           0.838710         0.824936        0.057195             2943  \n",
       "4606           0.822581         0.824910        0.045101             2951  \n",
       "4607           0.822581         0.826600        0.059814             2710  \n",
       "\n",
       "[4608 rows x 25 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score is 0.8522017409114184 with params {'colsample_bylevel': 0.2, 'colsample_bytree': 0.9, 'gamma': 1, 'learning_rate': 0.2, 'max_depth': 3, 'n_estimators': 30, 'subsample': 0.6}\n"
     ]
    }
   ],
   "source": [
    "df6 = pd.read_csv(\"data\\\\xgb_results_full_6_learning=0.2_20221124.csv\")\n",
    "df6.drop(df6.columns[0], axis=1, inplace=True)\n",
    "display(df6)\n",
    "print(\"best score is 0.8522017409114184 with params {'colsample_bylevel': 0.2, 'colsample_bytree': 0.9, 'gamma': 1, 'learning_rate': 0.2, 'max_depth': 3, 'n_estimators': 30, 'subsample': 0.6}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "de9ada4d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_colsample_bylevel</th>\n",
       "      <th>param_colsample_bytree</th>\n",
       "      <th>param_gamma</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>...</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.028224</td>\n",
       "      <td>0.000897</td>\n",
       "      <td>0.007381</td>\n",
       "      <td>0.000488</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.821582</td>\n",
       "      <td>0.063111</td>\n",
       "      <td>3320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.027226</td>\n",
       "      <td>0.000639</td>\n",
       "      <td>0.006683</td>\n",
       "      <td>0.000897</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>0.887097</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.887097</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.829647</td>\n",
       "      <td>0.062955</td>\n",
       "      <td>2389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.029321</td>\n",
       "      <td>0.001353</td>\n",
       "      <td>0.007580</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.887097</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.816846</td>\n",
       "      <td>0.062937</td>\n",
       "      <td>3729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.028125</td>\n",
       "      <td>0.001657</td>\n",
       "      <td>0.007281</td>\n",
       "      <td>0.000457</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>0.887097</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.829647</td>\n",
       "      <td>0.060854</td>\n",
       "      <td>2389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.039993</td>\n",
       "      <td>0.001133</td>\n",
       "      <td>0.007181</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.887097</td>\n",
       "      <td>0.821710</td>\n",
       "      <td>0.053554</td>\n",
       "      <td>3262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4603</th>\n",
       "      <td>0.129354</td>\n",
       "      <td>0.001184</td>\n",
       "      <td>0.007281</td>\n",
       "      <td>0.000457</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5</td>\n",
       "      <td>150</td>\n",
       "      <td>...</td>\n",
       "      <td>0.887097</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.919355</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.826600</td>\n",
       "      <td>0.059814</td>\n",
       "      <td>2710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4604</th>\n",
       "      <td>0.168948</td>\n",
       "      <td>0.001739</td>\n",
       "      <td>0.007581</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.919355</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.828187</td>\n",
       "      <td>0.060472</td>\n",
       "      <td>2464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4605</th>\n",
       "      <td>0.170344</td>\n",
       "      <td>0.002515</td>\n",
       "      <td>0.007481</td>\n",
       "      <td>0.000498</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.887097</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.824936</td>\n",
       "      <td>0.057195</td>\n",
       "      <td>2943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4606</th>\n",
       "      <td>0.169896</td>\n",
       "      <td>0.002405</td>\n",
       "      <td>0.007281</td>\n",
       "      <td>0.000457</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.824910</td>\n",
       "      <td>0.045101</td>\n",
       "      <td>2951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4607</th>\n",
       "      <td>0.169047</td>\n",
       "      <td>0.001201</td>\n",
       "      <td>0.007281</td>\n",
       "      <td>0.000457</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.887097</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.919355</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.826600</td>\n",
       "      <td>0.059814</td>\n",
       "      <td>2710</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4608 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0          0.028224      0.000897         0.007381        0.000488   \n",
       "1          0.027226      0.000639         0.006683        0.000897   \n",
       "2          0.029321      0.001353         0.007580        0.000489   \n",
       "3          0.028125      0.001657         0.007281        0.000457   \n",
       "4          0.039993      0.001133         0.007181        0.000399   \n",
       "...             ...           ...              ...             ...   \n",
       "4603       0.129354      0.001184         0.007281        0.000457   \n",
       "4604       0.168948      0.001739         0.007581        0.000489   \n",
       "4605       0.170344      0.002515         0.007481        0.000498   \n",
       "4606       0.169896      0.002405         0.007281        0.000457   \n",
       "4607       0.169047      0.001201         0.007281        0.000457   \n",
       "\n",
       "     param_colsample_bylevel param_colsample_bytree param_gamma  \\\n",
       "0                        0.1                    0.4           0   \n",
       "1                        0.1                    0.4           0   \n",
       "2                        0.1                    0.4           0   \n",
       "3                        0.1                    0.4           0   \n",
       "4                        0.1                    0.4           0   \n",
       "...                      ...                    ...         ...   \n",
       "4603                     0.4                    0.9          10   \n",
       "4604                     0.4                    0.9          10   \n",
       "4605                     0.4                    0.9          10   \n",
       "4606                     0.4                    0.9          10   \n",
       "4607                     0.4                    0.9          10   \n",
       "\n",
       "     param_learning_rate param_max_depth param_n_estimators  ...  \\\n",
       "0                    0.2               2                 30  ...   \n",
       "1                    0.2               2                 30  ...   \n",
       "2                    0.2               2                 30  ...   \n",
       "3                    0.2               2                 30  ...   \n",
       "4                    0.2               2                 50  ...   \n",
       "...                  ...             ...                ...  ...   \n",
       "4603                 0.2               5                150  ...   \n",
       "4604                 0.2               5                200  ...   \n",
       "4605                 0.2               5                200  ...   \n",
       "4606                 0.2               5                200  ...   \n",
       "4607                 0.2               5                200  ...   \n",
       "\n",
       "     split3_test_score split4_test_score  split5_test_score  \\\n",
       "0             0.870968          0.790323           0.854839   \n",
       "1             0.887097          0.806452           0.887097   \n",
       "2             0.870968          0.806452           0.887097   \n",
       "3             0.887097          0.790323           0.870968   \n",
       "4             0.854839          0.790323           0.854839   \n",
       "...                ...               ...                ...   \n",
       "4603          0.887097          0.806452           0.919355   \n",
       "4604          0.919355          0.838710           0.870968   \n",
       "4605          0.870968          0.806452           0.887097   \n",
       "4606          0.870968          0.806452           0.854839   \n",
       "4607          0.887097          0.806452           0.919355   \n",
       "\n",
       "      split6_test_score  split7_test_score  split8_test_score  \\\n",
       "0              0.838710           0.725806           0.693548   \n",
       "1              0.822581           0.741935           0.693548   \n",
       "2              0.822581           0.725806           0.677419   \n",
       "3              0.822581           0.758065           0.693548   \n",
       "4              0.838710           0.741935           0.709677   \n",
       "...                 ...                ...                ...   \n",
       "4603           0.822581           0.806452           0.693548   \n",
       "4604           0.806452           0.806452           0.677419   \n",
       "4605           0.806452           0.822581           0.677419   \n",
       "4606           0.822581           0.806452           0.709677   \n",
       "4607           0.822581           0.806452           0.693548   \n",
       "\n",
       "      split9_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0              0.822581         0.821582        0.063111             3320  \n",
       "1              0.838710         0.829647        0.062955             2389  \n",
       "2              0.822581         0.816846        0.062937             3729  \n",
       "3              0.854839         0.829647        0.060854             2389  \n",
       "4              0.887097         0.821710        0.053554             3262  \n",
       "...                 ...              ...             ...              ...  \n",
       "4603           0.822581         0.826600        0.059814             2710  \n",
       "4604           0.838710         0.828187        0.060472             2464  \n",
       "4605           0.838710         0.824936        0.057195             2943  \n",
       "4606           0.822581         0.824910        0.045101             2951  \n",
       "4607           0.822581         0.826600        0.059814             2710  \n",
       "\n",
       "[4608 rows x 25 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score is 0.8522017409114184 with params {'colsample_bylevel': 0.2, 'colsample_bytree': 0.9, 'gamma': 1, 'learning_rate': 0.2, 'max_depth': 3, 'n_estimators': 30, 'subsample': 0.6}\n"
     ]
    }
   ],
   "source": [
    "# Full Tuning - Part 6\n",
    "random.seed(10)\n",
    "\n",
    "xgb = XGBClassifier()\n",
    "\n",
    "xgb_parameters = {'max_depth': [2,3,4,5]\n",
    "                   , 'subsample': [0.6, 0.7, 0.8, 0.9]\n",
    "                   , 'gamma': [0, 1, 10]\n",
    "                   , 'colsample_bytree': [0.4, 0.5, 0.6, 0.9]\n",
    "                   , 'colsample_bylevel': [0.1, 0.2, 0.3, 0.4]\n",
    "                   , 'learning_rate': [0.2]\n",
    "                   , 'n_estimators': [30, 50, 80, 100, 150, 200]}\n",
    "\n",
    "stratified_10_fold_cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "xgb_grid_search = GridSearchCV(xgb, xgb_parameters, scoring='accuracy', cv=stratified_10_fold_cv)\n",
    "\n",
    "xgb_grid_search.fit(X_train, y_train)\n",
    "\n",
    "xgb_grid_search_results_full_6 = pd.DataFrame(xgb_grid_search.cv_results_)\n",
    "display(xgb_grid_search_results_full_6)\n",
    "\n",
    "print(\"best score is {} with params {}\".format(xgb_grid_search.best_score_, xgb_grid_search.best_params_))\n",
    "#best score is 0.8522017409114184 with params\n",
    "#{'colsample_bylevel': 0.2, 'colsample_bytree': 0.9, 'gamma': 1, 'learning_rate': 0.2, 'max_depth': 3, 'n_estimators': 30, 'subsample': 0.6}\n",
    "\n",
    "# save dataframe\n",
    "from datetime import datetime\n",
    "date = str(datetime.now().date()).replace(\"-\", \"\")\n",
    "xgb_grid_search_results_full_6.to_csv(f\"results/xgb_results_full_round3_6_learning=0.2_{date}.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b07bc15",
   "metadata": {},
   "source": [
    "Combine single hyper parameter tuning to find best values for hyper parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "aab3352c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_colsample_bylevel</th>\n",
       "      <th>param_colsample_bytree</th>\n",
       "      <th>param_gamma</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>...</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.028623</td>\n",
       "      <td>0.002525</td>\n",
       "      <td>0.007181</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.741295</td>\n",
       "      <td>0.048078</td>\n",
       "      <td>27618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.027127</td>\n",
       "      <td>0.000598</td>\n",
       "      <td>0.007082</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.742908</td>\n",
       "      <td>0.049390</td>\n",
       "      <td>27616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.027028</td>\n",
       "      <td>0.000698</td>\n",
       "      <td>0.007580</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.752586</td>\n",
       "      <td>0.048690</td>\n",
       "      <td>27568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.027427</td>\n",
       "      <td>0.000920</td>\n",
       "      <td>0.007381</td>\n",
       "      <td>0.000662</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.742960</td>\n",
       "      <td>0.043040</td>\n",
       "      <td>27614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.040093</td>\n",
       "      <td>0.001465</td>\n",
       "      <td>0.007082</td>\n",
       "      <td>0.000536</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>...</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.765463</td>\n",
       "      <td>0.037846</td>\n",
       "      <td>27462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27643</th>\n",
       "      <td>0.129354</td>\n",
       "      <td>0.001184</td>\n",
       "      <td>0.007281</td>\n",
       "      <td>0.000457</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.20</td>\n",
       "      <td>5</td>\n",
       "      <td>150</td>\n",
       "      <td>...</td>\n",
       "      <td>0.887097</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.919355</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.826600</td>\n",
       "      <td>0.059814</td>\n",
       "      <td>14497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27644</th>\n",
       "      <td>0.168948</td>\n",
       "      <td>0.001739</td>\n",
       "      <td>0.007581</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.20</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.919355</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.828187</td>\n",
       "      <td>0.060472</td>\n",
       "      <td>13496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27645</th>\n",
       "      <td>0.170344</td>\n",
       "      <td>0.002515</td>\n",
       "      <td>0.007481</td>\n",
       "      <td>0.000498</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.20</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.887097</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.824936</td>\n",
       "      <td>0.057195</td>\n",
       "      <td>15641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27646</th>\n",
       "      <td>0.169896</td>\n",
       "      <td>0.002405</td>\n",
       "      <td>0.007281</td>\n",
       "      <td>0.000457</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.20</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.824910</td>\n",
       "      <td>0.045101</td>\n",
       "      <td>15655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27647</th>\n",
       "      <td>0.169047</td>\n",
       "      <td>0.001201</td>\n",
       "      <td>0.007281</td>\n",
       "      <td>0.000457</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.20</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.887097</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.919355</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.826600</td>\n",
       "      <td>0.059814</td>\n",
       "      <td>14482</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27648 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0           0.028623      0.002525         0.007181        0.000399   \n",
       "1           0.027127      0.000598         0.007082        0.000300   \n",
       "2           0.027028      0.000698         0.007580        0.000489   \n",
       "3           0.027427      0.000920         0.007381        0.000662   \n",
       "4           0.040093      0.001465         0.007082        0.000536   \n",
       "...              ...           ...              ...             ...   \n",
       "27643       0.129354      0.001184         0.007281        0.000457   \n",
       "27644       0.168948      0.001739         0.007581        0.000489   \n",
       "27645       0.170344      0.002515         0.007481        0.000498   \n",
       "27646       0.169896      0.002405         0.007281        0.000457   \n",
       "27647       0.169047      0.001201         0.007281        0.000457   \n",
       "\n",
       "       param_colsample_bylevel  param_colsample_bytree  param_gamma  \\\n",
       "0                          0.1                     0.4            0   \n",
       "1                          0.1                     0.4            0   \n",
       "2                          0.1                     0.4            0   \n",
       "3                          0.1                     0.4            0   \n",
       "4                          0.1                     0.4            0   \n",
       "...                        ...                     ...          ...   \n",
       "27643                      0.4                     0.9           10   \n",
       "27644                      0.4                     0.9           10   \n",
       "27645                      0.4                     0.9           10   \n",
       "27646                      0.4                     0.9           10   \n",
       "27647                      0.4                     0.9           10   \n",
       "\n",
       "       param_learning_rate  param_max_depth  param_n_estimators  ...  \\\n",
       "0                     0.01                2                  30  ...   \n",
       "1                     0.01                2                  30  ...   \n",
       "2                     0.01                2                  30  ...   \n",
       "3                     0.01                2                  30  ...   \n",
       "4                     0.01                2                  50  ...   \n",
       "...                    ...              ...                 ...  ...   \n",
       "27643                 0.20                5                 150  ...   \n",
       "27644                 0.20                5                 200  ...   \n",
       "27645                 0.20                5                 200  ...   \n",
       "27646                 0.20                5                 200  ...   \n",
       "27647                 0.20                5                 200  ...   \n",
       "\n",
       "       split3_test_score split4_test_score  split5_test_score  \\\n",
       "0               0.758065          0.741935           0.741935   \n",
       "1               0.774194          0.741935           0.741935   \n",
       "2               0.774194          0.758065           0.774194   \n",
       "3               0.790323          0.725806           0.709677   \n",
       "4               0.790323          0.774194           0.774194   \n",
       "...                  ...               ...                ...   \n",
       "27643           0.887097          0.806452           0.919355   \n",
       "27644           0.919355          0.838710           0.870968   \n",
       "27645           0.870968          0.806452           0.887097   \n",
       "27646           0.870968          0.806452           0.854839   \n",
       "27647           0.887097          0.806452           0.919355   \n",
       "\n",
       "       split6_test_score  split7_test_score  split8_test_score  \\\n",
       "0               0.725806           0.677419           0.693548   \n",
       "1               0.725806           0.677419           0.677419   \n",
       "2               0.741935           0.693548           0.677419   \n",
       "3               0.741935           0.709677           0.709677   \n",
       "4               0.725806           0.693548           0.725806   \n",
       "...                  ...                ...                ...   \n",
       "27643           0.822581           0.806452           0.693548   \n",
       "27644           0.806452           0.806452           0.677419   \n",
       "27645           0.806452           0.822581           0.677419   \n",
       "27646           0.822581           0.806452           0.709677   \n",
       "27647           0.822581           0.806452           0.693548   \n",
       "\n",
       "       split9_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0               0.677419         0.741295        0.048078            27618  \n",
       "1               0.693548         0.742908        0.049390            27616  \n",
       "2               0.709677         0.752586        0.048690            27568  \n",
       "3               0.677419         0.742960        0.043040            27614  \n",
       "4               0.758065         0.765463        0.037846            27462  \n",
       "...                  ...              ...             ...              ...  \n",
       "27643           0.822581         0.826600        0.059814            14497  \n",
       "27644           0.838710         0.828187        0.060472            13496  \n",
       "27645           0.838710         0.824936        0.057195            15641  \n",
       "27646           0.822581         0.824910        0.045101            15655  \n",
       "27647           0.822581         0.826600        0.059814            14482  \n",
       "\n",
       "[27648 rows x 25 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score is 0.850563 with params {'colsample_bylevel': 0.4, 'colsample_bytree': 0.4, 'gamma': 1, 'learning_rate': 0.15, 'max_depth': 4, 'n_estimators': 30, 'subsample': 0.9}\n"
     ]
    }
   ],
   "source": [
    "# read single parts of round 3, concatenate and update index and rank_test_score\n",
    "\n",
    "df1 = pd.read_csv(\"data\\\\xgb_results_full_1_learning=0.01_20221124.csv\")\n",
    "df1.drop(df1.columns[0], axis=1, inplace=True)\n",
    "\n",
    "df2 = pd.read_csv(\"data\\\\xgb_results_full_2_learning=0.05_20221124.csv\")\n",
    "df2.drop(df2.columns[0], axis=1, inplace=True)\n",
    "\n",
    "df3 = pd.read_csv(\"data\\\\xgb_results_full_3_learning=0.08_20221124.csv\")\n",
    "df3.drop(df3.columns[0], axis=1, inplace=True)\n",
    "\n",
    "df4 = pd.read_csv(\"data\\\\xgb_results_full_4_learning=0.1_20221124.csv\")\n",
    "df4.drop(df4.columns[0], axis=1, inplace=True)\n",
    "\n",
    "df5 = pd.read_csv(\"data\\\\xgb_results_full_5_learning=0.15_20221124.csv\")\n",
    "df5.drop(df5.columns[0], axis=1, inplace=True)\n",
    "\n",
    "df6 = pd.read_csv(\"data\\\\xgb_results_full_6_learning=0.2_20221124.csv\")\n",
    "df6.drop(df6.columns[0], axis=1, inplace=True)\n",
    "\n",
    "df_full = pd.concat([df1,df2,df3,df4,df5,df6])\n",
    "\n",
    "#assign correct rank\n",
    "df_full = df_full.sort_values(by='mean_test_score', ascending=False)\n",
    "df_full['rank_test_score'] = range(1, len(df_full)+1)\n",
    "\n",
    "#get correct order and set new index\n",
    "df_full = df_full.sort_values(by=['param_colsample_bylevel', 'param_colsample_bytree', 'param_gamma', 'param_learning_rate', 'param_max_depth', 'param_n_estimators', 'param_subsample'])\n",
    "xgb_grid_search_results_round3 = df_full.set_index(np.array(range(len(df_full))))\n",
    "display(xgb_grid_search_results_round3)\n",
    "\n",
    "print(\"best score is 0.850563 with params {'colsample_bylevel': 0.4, 'colsample_bytree': 0.4, 'gamma': 1, 'learning_rate': 0.15, 'max_depth': 4, 'n_estimators': 30, 'subsample': 0.9}\")\n",
    "\n",
    "# save dataframe\n",
    "from datetime import datetime\n",
    "date = str(datetime.now().date()).replace(\"-\", \"\")\n",
    "xgb_grid_search_results_round3.to_csv(f\"results/xgb_results_round3_{date}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ffd07def",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_subsample</th>\n",
       "      <th>param_colsample_bylevel</th>\n",
       "      <th>param_colsample_bytree</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_gamma</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21747</th>\n",
       "      <td>4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.15</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>0.856989</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13080</th>\n",
       "      <td>3</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.15</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>0.852227</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13176</th>\n",
       "      <td>3</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.20</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>0.852202</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21720</th>\n",
       "      <td>3</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.15</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>0.852202</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23470</th>\n",
       "      <td>3</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.15</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>0.852151</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6340</th>\n",
       "      <td>2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.01</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>0.718920</td>\n",
       "      <td>27644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6339</th>\n",
       "      <td>2</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.01</td>\n",
       "      <td>30</td>\n",
       "      <td>10</td>\n",
       "      <td>0.709217</td>\n",
       "      <td>27645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6338</th>\n",
       "      <td>2</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.01</td>\n",
       "      <td>30</td>\n",
       "      <td>10</td>\n",
       "      <td>0.705991</td>\n",
       "      <td>27646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6336</th>\n",
       "      <td>2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.01</td>\n",
       "      <td>30</td>\n",
       "      <td>10</td>\n",
       "      <td>0.704403</td>\n",
       "      <td>27647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6337</th>\n",
       "      <td>2</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.01</td>\n",
       "      <td>30</td>\n",
       "      <td>10</td>\n",
       "      <td>0.702765</td>\n",
       "      <td>27648</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27648 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       param_max_depth  param_subsample  param_colsample_bylevel  \\\n",
       "21747                4              0.9                      0.4   \n",
       "13080                3              0.6                      0.2   \n",
       "13176                3              0.6                      0.2   \n",
       "21720                3              0.6                      0.4   \n",
       "23470                3              0.8                      0.4   \n",
       "...                ...              ...                      ...   \n",
       "6340                 2              0.6                      0.1   \n",
       "6339                 2              0.9                      0.1   \n",
       "6338                 2              0.8                      0.1   \n",
       "6336                 2              0.6                      0.1   \n",
       "6337                 2              0.7                      0.1   \n",
       "\n",
       "       param_colsample_bytree  param_learning_rate  param_n_estimators  \\\n",
       "21747                     0.4                 0.15                  30   \n",
       "13080                     0.9                 0.15                  30   \n",
       "13176                     0.9                 0.20                  30   \n",
       "21720                     0.4                 0.15                  30   \n",
       "23470                     0.5                 0.15                 200   \n",
       "...                       ...                  ...                 ...   \n",
       "6340                      0.9                 0.01                  50   \n",
       "6339                      0.9                 0.01                  30   \n",
       "6338                      0.9                 0.01                  30   \n",
       "6336                      0.9                 0.01                  30   \n",
       "6337                      0.9                 0.01                  30   \n",
       "\n",
       "       param_gamma  mean_test_score  rank_test_score  \n",
       "21747            1         0.856989                1  \n",
       "13080            1         0.852227                2  \n",
       "13176            1         0.852202                3  \n",
       "21720            1         0.852202                4  \n",
       "23470            1         0.852151                5  \n",
       "...            ...              ...              ...  \n",
       "6340            10         0.718920            27644  \n",
       "6339            10         0.709217            27645  \n",
       "6338            10         0.705991            27646  \n",
       "6336            10         0.704403            27647  \n",
       "6337            10         0.702765            27648  \n",
       "\n",
       "[27648 rows x 9 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# store relevant columns and sort by rank_test_score\n",
    "cols_round3 = ['param_max_depth', 'param_subsample', 'param_colsample_bylevel', 'param_colsample_bytree', 'param_learning_rate', 'param_n_estimators', 'param_gamma', 'mean_test_score', 'rank_test_score']\n",
    "xgb_results_round3_sorted = xgb_grid_search_results_round3[cols_round3]\n",
    "xgb_results_round3_sorted = xgb_results_round3_sorted.sort_values(by='rank_test_score')\n",
    "display(xgb_results_round3_sorted)\n",
    "\n",
    "# save dataframe\n",
    "from datetime import datetime\n",
    "date = str(datetime.now().date()).replace(\"-\", \"\")\n",
    "xgb_results_round3_sorted.to_csv(f\"results/xgb_results_round3_sorted_{date}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ff9a854a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.8283582089552238\n",
      "F1 Score = 0.7788461538461539\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.90      0.86       157\n",
      "           1       0.84      0.73      0.78       111\n",
      "\n",
      "    accuracy                           0.83       268\n",
      "   macro avg       0.83      0.81      0.82       268\n",
      "weighted avg       0.83      0.83      0.83       268\n",
      "\n",
      "Confusion Matrix:\n",
      "[[141  16]\n",
      " [ 30  81]]\n"
     ]
    }
   ],
   "source": [
    "# Fit and evaluate best model\n",
    "\n",
    "xgb_best = XGBClassifier(max_depth = 4, subsample = 0.9, colsample_bylevel = 0.4, colsample_bytree = 0.4, learning_rate = 0.15, n_estimators = 30, gamma = 1)\n",
    "xgb_best.fit(X_train, y_train)\n",
    "xgb_best_pred = xgb_best.predict(X_test)\n",
    "\n",
    "xgb_best_acc = accuracy_score(y_test, xgb_best_pred)\n",
    "print(\"Accuracy =\", xgb_best_acc) #0.8283582089552238\n",
    "\n",
    "xgb_best_f1 = f1_score(y_test, xgb_best_pred)\n",
    "print(\"F1 Score =\", xgb_best_f1) #0.7788461538461539\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, xgb_best_pred))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, xgb_best_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "077c8219",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.8395522388059702\n",
      "F1 Score = 0.7922705314009663\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.91      0.87       157\n",
      "           1       0.85      0.74      0.79       111\n",
      "\n",
      "    accuracy                           0.84       268\n",
      "   macro avg       0.84      0.82      0.83       268\n",
      "weighted avg       0.84      0.84      0.84       268\n",
      "\n",
      "Confusion Matrix:\n",
      "[[143  14]\n",
      " [ 29  82]]\n"
     ]
    }
   ],
   "source": [
    "# Fit and evaluate second best model with n_estimators=20\n",
    "\n",
    "xgb_best = XGBClassifier(max_depth = 3, subsample = 0.6, colsample_bylevel = 0.2, colsample_bytree = 0.9, learning_rate = 0.15, n_estimators = 20, gamma = 1)\n",
    "xgb_best.fit(X_train, y_train)\n",
    "xgb_best_pred = xgb_best.predict(X_test)\n",
    "\n",
    "xgb_best_acc = accuracy_score(y_test, xgb_best_pred)\n",
    "print(\"Accuracy =\", xgb_best_acc) #0.8395522388059702\n",
    "\n",
    "xgb_best_f1 = f1_score(y_test, xgb_best_pred)\n",
    "print(\"F1 Score =\", xgb_best_f1) #0.7922705314009663\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, xgb_best_pred))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, xgb_best_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4514dfe0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d157f690",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ccfb2ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b4d25208",
   "metadata": {},
   "source": [
    "#### Fourth Attempt\n",
    "We perform a third hyper parameter tuning, adjusting the parameter grid according to the results of round 3. We use the following parameters and values:  \n",
    "\n",
    "{'max_depth': [2,3,4]  \n",
    ", 'subsample': [0.6, 0.8, 0.9]  \n",
    ", 'gamma': [0, 0.5, 1]  \n",
    ", 'colsample_bytree': [0.4, 0.5, 0.9]  \n",
    ", 'colsample_bylevel': [0.2, 0.3, 0.4]  \n",
    ", 'learning_rate': [0.05 0.1, 0.15, 0.2]  \n",
    ", 'n_estimators': [10, 20, 30, 40, 50]}\n",
    "\n",
    "The best hyper parameter setting results to be xxx which leads to an accuracy of xxx% and a f1 score of xxx% on the test data (after training the classifier on the whole train data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "46b05a84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_colsample_bylevel</th>\n",
       "      <th>param_colsample_bytree</th>\n",
       "      <th>param_gamma</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>...</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.021696</td>\n",
       "      <td>0.004852</td>\n",
       "      <td>0.009495</td>\n",
       "      <td>0.002555</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.661290</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.661290</td>\n",
       "      <td>0.661290</td>\n",
       "      <td>0.661290</td>\n",
       "      <td>0.720430</td>\n",
       "      <td>0.052226</td>\n",
       "      <td>4858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.023734</td>\n",
       "      <td>0.003344</td>\n",
       "      <td>0.010269</td>\n",
       "      <td>0.002012</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.661290</td>\n",
       "      <td>0.629032</td>\n",
       "      <td>0.661290</td>\n",
       "      <td>0.720405</td>\n",
       "      <td>0.060569</td>\n",
       "      <td>4860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.021329</td>\n",
       "      <td>0.002649</td>\n",
       "      <td>0.009234</td>\n",
       "      <td>0.001687</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.645161</td>\n",
       "      <td>0.645161</td>\n",
       "      <td>0.661290</td>\n",
       "      <td>0.723630</td>\n",
       "      <td>0.057244</td>\n",
       "      <td>4855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.031445</td>\n",
       "      <td>0.001912</td>\n",
       "      <td>0.009800</td>\n",
       "      <td>0.001109</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>...</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.760599</td>\n",
       "      <td>0.045057</td>\n",
       "      <td>4835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.034447</td>\n",
       "      <td>0.002939</td>\n",
       "      <td>0.010506</td>\n",
       "      <td>0.001006</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>...</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.760625</td>\n",
       "      <td>0.047805</td>\n",
       "      <td>4834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4855</th>\n",
       "      <td>0.039993</td>\n",
       "      <td>0.000829</td>\n",
       "      <td>0.007979</td>\n",
       "      <td>0.000446</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.20</td>\n",
       "      <td>4</td>\n",
       "      <td>40</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.887097</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.850589</td>\n",
       "      <td>0.041824</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4856</th>\n",
       "      <td>0.057798</td>\n",
       "      <td>0.044078</td>\n",
       "      <td>0.008179</td>\n",
       "      <td>0.002352</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.20</td>\n",
       "      <td>4</td>\n",
       "      <td>40</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.823349</td>\n",
       "      <td>0.036404</td>\n",
       "      <td>3249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4857</th>\n",
       "      <td>0.065325</td>\n",
       "      <td>0.017959</td>\n",
       "      <td>0.008279</td>\n",
       "      <td>0.000779</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.20</td>\n",
       "      <td>4</td>\n",
       "      <td>50</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.834434</td>\n",
       "      <td>0.055885</td>\n",
       "      <td>1740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4858</th>\n",
       "      <td>0.067819</td>\n",
       "      <td>0.006180</td>\n",
       "      <td>0.008378</td>\n",
       "      <td>0.001196</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.20</td>\n",
       "      <td>4</td>\n",
       "      <td>50</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.837737</td>\n",
       "      <td>0.042732</td>\n",
       "      <td>1033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4859</th>\n",
       "      <td>0.055651</td>\n",
       "      <td>0.002176</td>\n",
       "      <td>0.007880</td>\n",
       "      <td>0.001042</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.20</td>\n",
       "      <td>4</td>\n",
       "      <td>50</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.828111</td>\n",
       "      <td>0.042532</td>\n",
       "      <td>2692</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4860 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0          0.021696      0.004852         0.009495        0.002555   \n",
       "1          0.023734      0.003344         0.010269        0.002012   \n",
       "2          0.021329      0.002649         0.009234        0.001687   \n",
       "3          0.031445      0.001912         0.009800        0.001109   \n",
       "4          0.034447      0.002939         0.010506        0.001006   \n",
       "...             ...           ...              ...             ...   \n",
       "4855       0.039993      0.000829         0.007979        0.000446   \n",
       "4856       0.057798      0.044078         0.008179        0.002352   \n",
       "4857       0.065325      0.017959         0.008279        0.000779   \n",
       "4858       0.067819      0.006180         0.008378        0.001196   \n",
       "4859       0.055651      0.002176         0.007880        0.001042   \n",
       "\n",
       "      param_colsample_bylevel  param_colsample_bytree  param_gamma  \\\n",
       "0                         0.2                     0.4          0.0   \n",
       "1                         0.2                     0.4          0.0   \n",
       "2                         0.2                     0.4          0.0   \n",
       "3                         0.2                     0.4          0.0   \n",
       "4                         0.2                     0.4          0.0   \n",
       "...                       ...                     ...          ...   \n",
       "4855                      0.4                     0.9          1.0   \n",
       "4856                      0.4                     0.9          1.0   \n",
       "4857                      0.4                     0.9          1.0   \n",
       "4858                      0.4                     0.9          1.0   \n",
       "4859                      0.4                     0.9          1.0   \n",
       "\n",
       "      param_learning_rate  param_max_depth  param_n_estimators  ...  \\\n",
       "0                    0.05                2                  10  ...   \n",
       "1                    0.05                2                  10  ...   \n",
       "2                    0.05                2                  10  ...   \n",
       "3                    0.05                2                  20  ...   \n",
       "4                    0.05                2                  20  ...   \n",
       "...                   ...              ...                 ...  ...   \n",
       "4855                 0.20                4                  40  ...   \n",
       "4856                 0.20                4                  40  ...   \n",
       "4857                 0.20                4                  50  ...   \n",
       "4858                 0.20                4                  50  ...   \n",
       "4859                 0.20                4                  50  ...   \n",
       "\n",
       "      split3_test_score split4_test_score  split5_test_score  \\\n",
       "0              0.741935          0.661290           0.758065   \n",
       "1              0.774194          0.677419           0.758065   \n",
       "2              0.741935          0.709677           0.774194   \n",
       "3              0.774194          0.741935           0.790323   \n",
       "4              0.806452          0.725806           0.790323   \n",
       "...                 ...               ...                ...   \n",
       "4855           0.870968          0.822581           0.854839   \n",
       "4856           0.854839          0.822581           0.806452   \n",
       "4857           0.838710          0.822581           0.790323   \n",
       "4858           0.838710          0.822581           0.822581   \n",
       "4859           0.870968          0.822581           0.790323   \n",
       "\n",
       "      split6_test_score  split7_test_score  split8_test_score  \\\n",
       "0              0.725806           0.661290           0.661290   \n",
       "1              0.693548           0.661290           0.629032   \n",
       "2              0.709677           0.645161           0.645161   \n",
       "3              0.758065           0.693548           0.709677   \n",
       "4              0.774194           0.693548           0.693548   \n",
       "...                 ...                ...                ...   \n",
       "4855           0.887097           0.838710           0.741935   \n",
       "4856           0.854839           0.822581           0.725806   \n",
       "4857           0.854839           0.838710           0.693548   \n",
       "4858           0.870968           0.838710           0.725806   \n",
       "4859           0.854839           0.806452           0.725806   \n",
       "\n",
       "      split9_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0              0.661290         0.720430        0.052226             4858  \n",
       "1              0.661290         0.720405        0.060569             4860  \n",
       "2              0.661290         0.723630        0.057244             4855  \n",
       "3              0.709677         0.760599        0.045057             4835  \n",
       "4              0.709677         0.760625        0.047805             4834  \n",
       "...                 ...              ...             ...              ...  \n",
       "4855           0.854839         0.850589        0.041824               18  \n",
       "4856           0.822581         0.823349        0.036404             3249  \n",
       "4857           0.854839         0.834434        0.055885             1740  \n",
       "4858           0.854839         0.837737        0.042732             1033  \n",
       "4859           0.838710         0.828111        0.042532             2692  \n",
       "\n",
       "[4860 rows x 25 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score is 0.856989 with params {'colsample_bylevel': 0.4, 'colsample_bytree': 0.4, 'gamma': 1, 'learning_rate': 0.15, 'max_depth': 4, 'n_estimators': 30, 'subsample': 0.9}\n"
     ]
    }
   ],
   "source": [
    "# read single parts of round 3, concatenate and update index and rank_test_score\n",
    "\n",
    "df2 = pd.read_csv(\"data\\\\xgb_results_full_2_learning=0.05_r3_20221124.csv\")\n",
    "df2.drop(df2.columns[0], axis=1, inplace=True)\n",
    "\n",
    "df4 = pd.read_csv(\"data\\\\xgb_results_full_4_learning=0.1_r3_20221124.csv\")\n",
    "df4.drop(df4.columns[0], axis=1, inplace=True)\n",
    "\n",
    "df5 = pd.read_csv(\"data\\\\xgb_results_full_5_learning=0.15_r3_20221124.csv\")\n",
    "df5.drop(df5.columns[0], axis=1, inplace=True)\n",
    "\n",
    "df6 = pd.read_csv(\"data\\\\xgb_results_full_6_learning=0.2_r3_20221124.csv\")\n",
    "df6.drop(df6.columns[0], axis=1, inplace=True)\n",
    "\n",
    "df_full = pd.concat([df2,df4,df5,df6])\n",
    "\n",
    "#assign correct rank\n",
    "df_full = df_full.sort_values(by='mean_test_score', ascending=False)\n",
    "df_full['rank_test_score'] = range(1, len(df_full)+1)\n",
    "\n",
    "#get correct order and set new index\n",
    "df_full = df_full.sort_values(by=['param_colsample_bylevel', 'param_colsample_bytree', 'param_gamma', 'param_learning_rate', 'param_max_depth', 'param_n_estimators', 'param_subsample'])\n",
    "xgb_grid_search_results_round4 = df_full.set_index(np.array(range(len(df_full))))\n",
    "display(xgb_grid_search_results_round4)\n",
    "\n",
    "print(\"best score is 0.856989 with params {'colsample_bylevel': 0.4, 'colsample_bytree': 0.4, 'gamma': 1, 'learning_rate': 0.15, 'max_depth': 4, 'n_estimators': 30, 'subsample': 0.9}\")\n",
    "\n",
    "# save dataframe\n",
    "from datetime import datetime\n",
    "date = str(datetime.now().date()).replace(\"-\", \"\")\n",
    "xgb_grid_search_results_round4.to_csv(f\"results/xgb_results_round4_{date}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "db0eebb7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "expression expected after dictionary key and ':' (2098851133.py, line 12)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn [54], line 12\u001b[1;36m\u001b[0m\n\u001b[1;33m    , 'learning_rate': [0.05 0.1, 0.15, 0.2]\u001b[0m\n\u001b[1;37m                     ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m expression expected after dictionary key and ':'\n"
     ]
    }
   ],
   "source": [
    "# Third Attempt\n",
    "\n",
    "random.seed(10)\n",
    "\n",
    "xgb = XGBClassifier()\n",
    "\n",
    "xgb_parameters = {'max_depth': [2,3,4]\n",
    "                   , 'subsample': [0.6, 0.8, 0.9]\n",
    "                   , 'gamma': [0, 0.5, 1]\n",
    "                   , 'colsample_bytree': [0.4, 0.5, 0.9]\n",
    "                   , 'colsample_bylevel': [0.2, 0.3, 0.4]\n",
    "                   , 'learning_rate': [0.05, 0.1, 0.15, 0.2]\n",
    "                   , 'n_estimators': [10, 20, 30, 40, 50]}\n",
    "\n",
    "stratified_10_fold_cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "xgb_grid_search = GridSearchCV(xgb, xgb_parameters, scoring='accuracy', cv=stratified_10_fold_cv)\n",
    "\n",
    "xgb_grid_search.fit(X_train, y_train)\n",
    "\n",
    "xgb_grid_search_results_round4 = pd.DataFrame(xgb_grid_search.cv_results_)\n",
    "display(xgb_grid_search_results_round4)\n",
    "\n",
    "# print the best parameter setting\n",
    "print(\"best score is {} with params {}\".format(xgb_grid_search.best_score_, xgb_grid_search.best_params_))\n",
    "#best score is 0.856989 with params {'colsample_bylevel': 0.4, 'colsample_bytree': 0.4, 'gamma': 1, 'learning_rate': 0.15, 'max_depth': 4, 'n_estimators': 30, 'subsample': 0.9}\n",
    "\n",
    "# save dataframe\n",
    "from datetime import datetime\n",
    "date = str(datetime.now().date()).replace(\"-\", \"\")\n",
    "xgb_grid_search_results_round4.to_csv(f\"results/xgb_results_round4_{date}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ecd39336",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_subsample</th>\n",
       "      <th>param_colsample_bylevel</th>\n",
       "      <th>param_colsample_bytree</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_gamma</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3728</th>\n",
       "      <td>4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.15</td>\n",
       "      <td>30</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.856989</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3714</th>\n",
       "      <td>3</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.15</td>\n",
       "      <td>40</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.853840</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1401</th>\n",
       "      <td>2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.20</td>\n",
       "      <td>30</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.852253</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1551</th>\n",
       "      <td>3</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.15</td>\n",
       "      <td>30</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.852227</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1596</th>\n",
       "      <td>3</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.20</td>\n",
       "      <td>30</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.852202</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.05</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.722043</td>\n",
       "      <td>4856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.05</td>\n",
       "      <td>10</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.720430</td>\n",
       "      <td>4857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.05</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.720430</td>\n",
       "      <td>4858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>2</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.05</td>\n",
       "      <td>10</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.720405</td>\n",
       "      <td>4859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.05</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.720405</td>\n",
       "      <td>4860</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4860 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      param_max_depth  param_subsample  param_colsample_bylevel  \\\n",
       "3728                4              0.9                      0.4   \n",
       "3714                3              0.6                      0.4   \n",
       "1401                2              0.6                      0.2   \n",
       "1551                3              0.6                      0.2   \n",
       "1596                3              0.6                      0.2   \n",
       "...               ...              ...                      ...   \n",
       "360                 2              0.6                      0.2   \n",
       "180                 2              0.6                      0.2   \n",
       "0                   2              0.6                      0.2   \n",
       "181                 2              0.8                      0.2   \n",
       "1                   2              0.8                      0.2   \n",
       "\n",
       "      param_colsample_bytree  param_learning_rate  param_n_estimators  \\\n",
       "3728                     0.4                 0.15                  30   \n",
       "3714                     0.4                 0.15                  40   \n",
       "1401                     0.9                 0.20                  30   \n",
       "1551                     0.9                 0.15                  30   \n",
       "1596                     0.9                 0.20                  30   \n",
       "...                      ...                  ...                 ...   \n",
       "360                      0.4                 0.05                  10   \n",
       "180                      0.4                 0.05                  10   \n",
       "0                        0.4                 0.05                  10   \n",
       "181                      0.4                 0.05                  10   \n",
       "1                        0.4                 0.05                  10   \n",
       "\n",
       "      param_gamma  mean_test_score  rank_test_score  \n",
       "3728          1.0         0.856989                1  \n",
       "3714          1.0         0.853840                2  \n",
       "1401          0.5         0.852253                3  \n",
       "1551          1.0         0.852227                4  \n",
       "1596          1.0         0.852202                5  \n",
       "...           ...              ...              ...  \n",
       "360           1.0         0.722043             4856  \n",
       "180           0.5         0.720430             4857  \n",
       "0             0.0         0.720430             4858  \n",
       "181           0.5         0.720405             4859  \n",
       "1             0.0         0.720405             4860  \n",
       "\n",
       "[4860 rows x 9 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# store relevant columns and sort by rank_test_score\n",
    "cols_round4 = ['param_max_depth', 'param_subsample', 'param_colsample_bylevel', 'param_colsample_bytree', 'param_learning_rate', 'param_n_estimators', 'param_gamma', 'mean_test_score', 'rank_test_score']\n",
    "xgb_results_round4_sorted = xgb_grid_search_results_round4[cols_round4]\n",
    "xgb_results_round4_sorted = xgb_results_round4_sorted.sort_values(by='rank_test_score')\n",
    "display(xgb_results_round4_sorted)\n",
    "\n",
    "# save dataframe\n",
    "from datetime import datetime\n",
    "date = str(datetime.now().date()).replace(\"-\", \"\")\n",
    "xgb_results_round4_sorted.to_csv(f\"results/xgb_results_round4_sorted_{date}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4deb5e3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.8283582089552238\n",
      "F1 Score = 0.7788461538461539\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.90      0.86       157\n",
      "           1       0.84      0.73      0.78       111\n",
      "\n",
      "    accuracy                           0.83       268\n",
      "   macro avg       0.83      0.81      0.82       268\n",
      "weighted avg       0.83      0.83      0.83       268\n",
      "\n",
      "Confusion Matrix:\n",
      "[[141  16]\n",
      " [ 30  81]]\n"
     ]
    }
   ],
   "source": [
    "# Fit and evaluate best model\n",
    "\n",
    "xgb_best = XGBClassifier(max_depth = 4, subsample = 0.9, colsample_bylevel = 0.4, colsample_bytree = 0.4, learning_rate = 0.15, n_estimators = 30, gamma = 1)\n",
    "xgb_best.fit(X_train, y_train)\n",
    "xgb_best_pred = xgb_best.predict(X_test)\n",
    "\n",
    "xgb_best_acc = accuracy_score(y_test, xgb_best_pred)\n",
    "print(\"Accuracy =\", xgb_best_acc) #0.8283582089552238\n",
    "\n",
    "xgb_best_f1 = f1_score(y_test, xgb_best_pred)\n",
    "print(\"F1 Score =\", xgb_best_f1) #0.7788461538461539\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, xgb_best_pred))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, xgb_best_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a1510f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc5a5c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "41362cd1",
   "metadata": {},
   "source": [
    "#### ausfÃ¼hrlich"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "74ca2db4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_colsample_bylevel</th>\n",
       "      <th>param_colsample_bytree</th>\n",
       "      <th>param_gamma</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>...</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.021696</td>\n",
       "      <td>0.004852</td>\n",
       "      <td>0.009495</td>\n",
       "      <td>0.002555</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.661290</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.661290</td>\n",
       "      <td>0.661290</td>\n",
       "      <td>0.661290</td>\n",
       "      <td>0.720430</td>\n",
       "      <td>0.052226</td>\n",
       "      <td>1212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.023734</td>\n",
       "      <td>0.003344</td>\n",
       "      <td>0.010269</td>\n",
       "      <td>0.002012</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.661290</td>\n",
       "      <td>0.629032</td>\n",
       "      <td>0.661290</td>\n",
       "      <td>0.720405</td>\n",
       "      <td>0.060569</td>\n",
       "      <td>1214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.021329</td>\n",
       "      <td>0.002649</td>\n",
       "      <td>0.009234</td>\n",
       "      <td>0.001687</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.645161</td>\n",
       "      <td>0.645161</td>\n",
       "      <td>0.661290</td>\n",
       "      <td>0.723630</td>\n",
       "      <td>0.057244</td>\n",
       "      <td>1208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.031445</td>\n",
       "      <td>0.001912</td>\n",
       "      <td>0.009800</td>\n",
       "      <td>0.001109</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>...</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.760599</td>\n",
       "      <td>0.045057</td>\n",
       "      <td>1204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.034447</td>\n",
       "      <td>0.002939</td>\n",
       "      <td>0.010506</td>\n",
       "      <td>0.001006</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>...</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.760625</td>\n",
       "      <td>0.047805</td>\n",
       "      <td>1203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1210</th>\n",
       "      <td>0.064949</td>\n",
       "      <td>0.005643</td>\n",
       "      <td>0.010790</td>\n",
       "      <td>0.002114</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>4</td>\n",
       "      <td>40</td>\n",
       "      <td>...</td>\n",
       "      <td>0.903226</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.829647</td>\n",
       "      <td>0.056432</td>\n",
       "      <td>337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1211</th>\n",
       "      <td>0.059376</td>\n",
       "      <td>0.006451</td>\n",
       "      <td>0.009179</td>\n",
       "      <td>0.002418</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>4</td>\n",
       "      <td>40</td>\n",
       "      <td>...</td>\n",
       "      <td>0.887097</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.824936</td>\n",
       "      <td>0.053006</td>\n",
       "      <td>496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1212</th>\n",
       "      <td>0.072250</td>\n",
       "      <td>0.006942</td>\n",
       "      <td>0.010528</td>\n",
       "      <td>0.001857</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>4</td>\n",
       "      <td>50</td>\n",
       "      <td>...</td>\n",
       "      <td>0.887097</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.834511</td>\n",
       "      <td>0.054857</td>\n",
       "      <td>156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1213</th>\n",
       "      <td>0.075180</td>\n",
       "      <td>0.004525</td>\n",
       "      <td>0.011624</td>\n",
       "      <td>0.001827</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>4</td>\n",
       "      <td>50</td>\n",
       "      <td>...</td>\n",
       "      <td>0.903226</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.837686</td>\n",
       "      <td>0.053661</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1214</th>\n",
       "      <td>0.071844</td>\n",
       "      <td>0.005366</td>\n",
       "      <td>0.010349</td>\n",
       "      <td>0.001572</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>4</td>\n",
       "      <td>50</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.821633</td>\n",
       "      <td>0.045313</td>\n",
       "      <td>643</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1215 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0          0.021696      0.004852         0.009495        0.002555   \n",
       "1          0.023734      0.003344         0.010269        0.002012   \n",
       "2          0.021329      0.002649         0.009234        0.001687   \n",
       "3          0.031445      0.001912         0.009800        0.001109   \n",
       "4          0.034447      0.002939         0.010506        0.001006   \n",
       "...             ...           ...              ...             ...   \n",
       "1210       0.064949      0.005643         0.010790        0.002114   \n",
       "1211       0.059376      0.006451         0.009179        0.002418   \n",
       "1212       0.072250      0.006942         0.010528        0.001857   \n",
       "1213       0.075180      0.004525         0.011624        0.001827   \n",
       "1214       0.071844      0.005366         0.010349        0.001572   \n",
       "\n",
       "      param_colsample_bylevel  param_colsample_bytree  param_gamma  \\\n",
       "0                         0.2                     0.4          0.0   \n",
       "1                         0.2                     0.4          0.0   \n",
       "2                         0.2                     0.4          0.0   \n",
       "3                         0.2                     0.4          0.0   \n",
       "4                         0.2                     0.4          0.0   \n",
       "...                       ...                     ...          ...   \n",
       "1210                      0.4                     0.9          1.0   \n",
       "1211                      0.4                     0.9          1.0   \n",
       "1212                      0.4                     0.9          1.0   \n",
       "1213                      0.4                     0.9          1.0   \n",
       "1214                      0.4                     0.9          1.0   \n",
       "\n",
       "      param_learning_rate  param_max_depth  param_n_estimators  ...  \\\n",
       "0                    0.05                2                  10  ...   \n",
       "1                    0.05                2                  10  ...   \n",
       "2                    0.05                2                  10  ...   \n",
       "3                    0.05                2                  20  ...   \n",
       "4                    0.05                2                  20  ...   \n",
       "...                   ...              ...                 ...  ...   \n",
       "1210                 0.05                4                  40  ...   \n",
       "1211                 0.05                4                  40  ...   \n",
       "1212                 0.05                4                  50  ...   \n",
       "1213                 0.05                4                  50  ...   \n",
       "1214                 0.05                4                  50  ...   \n",
       "\n",
       "      split3_test_score split4_test_score  split5_test_score  \\\n",
       "0              0.741935          0.661290           0.758065   \n",
       "1              0.774194          0.677419           0.758065   \n",
       "2              0.741935          0.709677           0.774194   \n",
       "3              0.774194          0.741935           0.790323   \n",
       "4              0.806452          0.725806           0.790323   \n",
       "...                 ...               ...                ...   \n",
       "1210           0.903226          0.806452           0.822581   \n",
       "1211           0.887097          0.822581           0.870968   \n",
       "1212           0.887097          0.822581           0.870968   \n",
       "1213           0.903226          0.822581           0.838710   \n",
       "1214           0.838710          0.822581           0.822581   \n",
       "\n",
       "      split6_test_score  split7_test_score  split8_test_score  \\\n",
       "0              0.725806           0.661290           0.661290   \n",
       "1              0.693548           0.661290           0.629032   \n",
       "2              0.709677           0.645161           0.645161   \n",
       "3              0.758065           0.693548           0.709677   \n",
       "4              0.774194           0.693548           0.693548   \n",
       "...                 ...                ...                ...   \n",
       "1210           0.822581           0.790323           0.693548   \n",
       "1211           0.822581           0.774194           0.693548   \n",
       "1212           0.822581           0.790323           0.693548   \n",
       "1213           0.822581           0.790323           0.709677   \n",
       "1214           0.822581           0.774194           0.709677   \n",
       "\n",
       "      split9_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0              0.661290         0.720430        0.052226             1212  \n",
       "1              0.661290         0.720405        0.060569             1214  \n",
       "2              0.661290         0.723630        0.057244             1208  \n",
       "3              0.709677         0.760599        0.045057             1204  \n",
       "4              0.709677         0.760625        0.047805             1203  \n",
       "...                 ...              ...             ...              ...  \n",
       "1210           0.838710         0.829647        0.056432              337  \n",
       "1211           0.838710         0.824936        0.053006              496  \n",
       "1212           0.854839         0.834511        0.054857              156  \n",
       "1213           0.854839         0.837686        0.053661               90  \n",
       "1214           0.838710         0.821633        0.045313              643  \n",
       "\n",
       "[1215 rows x 25 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score is 0.8457501280081926 with params {'colsample_bylevel': 0.3, 'colsample_bytree': 0.9, 'gamma': 0.5, 'learning_rate': 0.05, 'max_depth': 4, 'n_estimators': 40, 'subsample': 0.6}\n"
     ]
    }
   ],
   "source": [
    "df2 = pd.read_csv(\"data\\\\xgb_results_full_2_learning=0.05_r3_20221124.csv\")\n",
    "df2.drop(df2.columns[0], axis=1, inplace=True)\n",
    "display(df2)\n",
    "print(\"best score is 0.8457501280081926 with params {'colsample_bylevel': 0.3, 'colsample_bytree': 0.9, 'gamma': 0.5, 'learning_rate': 0.05, 'max_depth': 4, 'n_estimators': 40, 'subsample': 0.6}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "55456590",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_colsample_bylevel</th>\n",
       "      <th>param_colsample_bytree</th>\n",
       "      <th>param_gamma</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>...</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.021696</td>\n",
       "      <td>0.004852</td>\n",
       "      <td>0.009495</td>\n",
       "      <td>0.002555</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.661290</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.661290</td>\n",
       "      <td>0.661290</td>\n",
       "      <td>0.661290</td>\n",
       "      <td>0.720430</td>\n",
       "      <td>0.052226</td>\n",
       "      <td>1212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.023734</td>\n",
       "      <td>0.003344</td>\n",
       "      <td>0.010269</td>\n",
       "      <td>0.002012</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.661290</td>\n",
       "      <td>0.629032</td>\n",
       "      <td>0.661290</td>\n",
       "      <td>0.720405</td>\n",
       "      <td>0.060569</td>\n",
       "      <td>1214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.021329</td>\n",
       "      <td>0.002649</td>\n",
       "      <td>0.009234</td>\n",
       "      <td>0.001687</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.645161</td>\n",
       "      <td>0.645161</td>\n",
       "      <td>0.661290</td>\n",
       "      <td>0.723630</td>\n",
       "      <td>0.057244</td>\n",
       "      <td>1208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.031445</td>\n",
       "      <td>0.001912</td>\n",
       "      <td>0.009800</td>\n",
       "      <td>0.001109</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>...</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.760599</td>\n",
       "      <td>0.045057</td>\n",
       "      <td>1204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.034447</td>\n",
       "      <td>0.002939</td>\n",
       "      <td>0.010506</td>\n",
       "      <td>0.001006</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>...</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.760625</td>\n",
       "      <td>0.047805</td>\n",
       "      <td>1203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1210</th>\n",
       "      <td>0.064949</td>\n",
       "      <td>0.005643</td>\n",
       "      <td>0.010790</td>\n",
       "      <td>0.002114</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.05</td>\n",
       "      <td>4</td>\n",
       "      <td>40</td>\n",
       "      <td>...</td>\n",
       "      <td>0.903226</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.829647</td>\n",
       "      <td>0.056432</td>\n",
       "      <td>337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1211</th>\n",
       "      <td>0.059376</td>\n",
       "      <td>0.006451</td>\n",
       "      <td>0.009179</td>\n",
       "      <td>0.002418</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.05</td>\n",
       "      <td>4</td>\n",
       "      <td>40</td>\n",
       "      <td>...</td>\n",
       "      <td>0.887097</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.824936</td>\n",
       "      <td>0.053006</td>\n",
       "      <td>496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1212</th>\n",
       "      <td>0.072250</td>\n",
       "      <td>0.006942</td>\n",
       "      <td>0.010528</td>\n",
       "      <td>0.001857</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.05</td>\n",
       "      <td>4</td>\n",
       "      <td>50</td>\n",
       "      <td>...</td>\n",
       "      <td>0.887097</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.834511</td>\n",
       "      <td>0.054857</td>\n",
       "      <td>156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1213</th>\n",
       "      <td>0.075180</td>\n",
       "      <td>0.004525</td>\n",
       "      <td>0.011624</td>\n",
       "      <td>0.001827</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.05</td>\n",
       "      <td>4</td>\n",
       "      <td>50</td>\n",
       "      <td>...</td>\n",
       "      <td>0.903226</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.837686</td>\n",
       "      <td>0.053661</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1214</th>\n",
       "      <td>0.071844</td>\n",
       "      <td>0.005366</td>\n",
       "      <td>0.010349</td>\n",
       "      <td>0.001572</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.05</td>\n",
       "      <td>4</td>\n",
       "      <td>50</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.821633</td>\n",
       "      <td>0.045313</td>\n",
       "      <td>643</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1215 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0          0.021696      0.004852         0.009495        0.002555   \n",
       "1          0.023734      0.003344         0.010269        0.002012   \n",
       "2          0.021329      0.002649         0.009234        0.001687   \n",
       "3          0.031445      0.001912         0.009800        0.001109   \n",
       "4          0.034447      0.002939         0.010506        0.001006   \n",
       "...             ...           ...              ...             ...   \n",
       "1210       0.064949      0.005643         0.010790        0.002114   \n",
       "1211       0.059376      0.006451         0.009179        0.002418   \n",
       "1212       0.072250      0.006942         0.010528        0.001857   \n",
       "1213       0.075180      0.004525         0.011624        0.001827   \n",
       "1214       0.071844      0.005366         0.010349        0.001572   \n",
       "\n",
       "     param_colsample_bylevel param_colsample_bytree param_gamma  \\\n",
       "0                        0.2                    0.4           0   \n",
       "1                        0.2                    0.4           0   \n",
       "2                        0.2                    0.4           0   \n",
       "3                        0.2                    0.4           0   \n",
       "4                        0.2                    0.4           0   \n",
       "...                      ...                    ...         ...   \n",
       "1210                     0.4                    0.9           1   \n",
       "1211                     0.4                    0.9           1   \n",
       "1212                     0.4                    0.9           1   \n",
       "1213                     0.4                    0.9           1   \n",
       "1214                     0.4                    0.9           1   \n",
       "\n",
       "     param_learning_rate param_max_depth param_n_estimators  ...  \\\n",
       "0                   0.05               2                 10  ...   \n",
       "1                   0.05               2                 10  ...   \n",
       "2                   0.05               2                 10  ...   \n",
       "3                   0.05               2                 20  ...   \n",
       "4                   0.05               2                 20  ...   \n",
       "...                  ...             ...                ...  ...   \n",
       "1210                0.05               4                 40  ...   \n",
       "1211                0.05               4                 40  ...   \n",
       "1212                0.05               4                 50  ...   \n",
       "1213                0.05               4                 50  ...   \n",
       "1214                0.05               4                 50  ...   \n",
       "\n",
       "     split3_test_score split4_test_score  split5_test_score  \\\n",
       "0             0.741935          0.661290           0.758065   \n",
       "1             0.774194          0.677419           0.758065   \n",
       "2             0.741935          0.709677           0.774194   \n",
       "3             0.774194          0.741935           0.790323   \n",
       "4             0.806452          0.725806           0.790323   \n",
       "...                ...               ...                ...   \n",
       "1210          0.903226          0.806452           0.822581   \n",
       "1211          0.887097          0.822581           0.870968   \n",
       "1212          0.887097          0.822581           0.870968   \n",
       "1213          0.903226          0.822581           0.838710   \n",
       "1214          0.838710          0.822581           0.822581   \n",
       "\n",
       "      split6_test_score  split7_test_score  split8_test_score  \\\n",
       "0              0.725806           0.661290           0.661290   \n",
       "1              0.693548           0.661290           0.629032   \n",
       "2              0.709677           0.645161           0.645161   \n",
       "3              0.758065           0.693548           0.709677   \n",
       "4              0.774194           0.693548           0.693548   \n",
       "...                 ...                ...                ...   \n",
       "1210           0.822581           0.790323           0.693548   \n",
       "1211           0.822581           0.774194           0.693548   \n",
       "1212           0.822581           0.790323           0.693548   \n",
       "1213           0.822581           0.790323           0.709677   \n",
       "1214           0.822581           0.774194           0.709677   \n",
       "\n",
       "      split9_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0              0.661290         0.720430        0.052226             1212  \n",
       "1              0.661290         0.720405        0.060569             1214  \n",
       "2              0.661290         0.723630        0.057244             1208  \n",
       "3              0.709677         0.760599        0.045057             1204  \n",
       "4              0.709677         0.760625        0.047805             1203  \n",
       "...                 ...              ...             ...              ...  \n",
       "1210           0.838710         0.829647        0.056432              337  \n",
       "1211           0.838710         0.824936        0.053006              496  \n",
       "1212           0.854839         0.834511        0.054857              156  \n",
       "1213           0.854839         0.837686        0.053661               90  \n",
       "1214           0.838710         0.821633        0.045313              643  \n",
       "\n",
       "[1215 rows x 25 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score is 0.8457501280081926 with params {'colsample_bylevel': 0.3, 'colsample_bytree': 0.9, 'gamma': 0.5, 'learning_rate': 0.05, 'max_depth': 4, 'n_estimators': 40, 'subsample': 0.6}\n"
     ]
    }
   ],
   "source": [
    "# Full Tuning - Part 2\n",
    "random.seed(10)\n",
    "\n",
    "xgb = XGBClassifier()\n",
    "\n",
    "xgb_parameters = {'max_depth': [2,3,4]\n",
    "                   , 'subsample': [0.6, 0.8, 0.9]\n",
    "                   , 'gamma': [0, 0.5, 1]\n",
    "                   , 'colsample_bytree': [0.4, 0.5, 0.9]\n",
    "                   , 'colsample_bylevel': [0.2, 0.3, 0.4]\n",
    "                   , 'learning_rate': [0.05]\n",
    "                   , 'n_estimators': [10, 20, 30, 40, 50]}\n",
    "\n",
    "stratified_10_fold_cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "xgb_grid_search = GridSearchCV(xgb, xgb_parameters, scoring='accuracy', cv=stratified_10_fold_cv)\n",
    "\n",
    "xgb_grid_search.fit(X_train, y_train)\n",
    "\n",
    "xgb_grid_search_results_full_2 = pd.DataFrame(xgb_grid_search.cv_results_)\n",
    "display(xgb_grid_search_results_full_2)\n",
    "\n",
    "print(\"best score is {} with params {}\".format(xgb_grid_search.best_score_, xgb_grid_search.best_params_))\n",
    "#best score is 0.8457501280081926 with params\n",
    "#{'colsample_bylevel': 0.3, 'colsample_bytree': 0.9, 'gamma': 0.5, 'learning_rate': 0.05, 'max_depth': 4, 'n_estimators': 40, 'subsample': 0.6}\n",
    "\n",
    "# save dataframe\n",
    "from datetime import datetime\n",
    "date = str(datetime.now().date()).replace(\"-\", \"\")\n",
    "xgb_grid_search_results_full_2.to_csv(f\"results/xgb_results_full_round4_2_learning=0.05_r3_{date}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "56f26de1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_colsample_bylevel</th>\n",
       "      <th>param_colsample_bytree</th>\n",
       "      <th>param_gamma</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>...</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.023281</td>\n",
       "      <td>0.003346</td>\n",
       "      <td>0.010147</td>\n",
       "      <td>0.001151</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.645161</td>\n",
       "      <td>0.661290</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.738095</td>\n",
       "      <td>0.056816</td>\n",
       "      <td>1210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.021142</td>\n",
       "      <td>0.004710</td>\n",
       "      <td>0.008830</td>\n",
       "      <td>0.001959</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.629032</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.741321</td>\n",
       "      <td>0.059607</td>\n",
       "      <td>1207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.017339</td>\n",
       "      <td>0.001338</td>\n",
       "      <td>0.007330</td>\n",
       "      <td>0.000460</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.661290</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.734869</td>\n",
       "      <td>0.053170</td>\n",
       "      <td>1215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.029686</td>\n",
       "      <td>0.004877</td>\n",
       "      <td>0.010679</td>\n",
       "      <td>0.006277</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>...</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.776728</td>\n",
       "      <td>0.041775</td>\n",
       "      <td>1197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.028296</td>\n",
       "      <td>0.005223</td>\n",
       "      <td>0.008654</td>\n",
       "      <td>0.001540</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>...</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.778341</td>\n",
       "      <td>0.046040</td>\n",
       "      <td>1192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1210</th>\n",
       "      <td>0.046617</td>\n",
       "      <td>0.003638</td>\n",
       "      <td>0.006846</td>\n",
       "      <td>0.000652</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4</td>\n",
       "      <td>40</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.831285</td>\n",
       "      <td>0.053063</td>\n",
       "      <td>569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1211</th>\n",
       "      <td>0.046081</td>\n",
       "      <td>0.002453</td>\n",
       "      <td>0.007303</td>\n",
       "      <td>0.000902</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4</td>\n",
       "      <td>40</td>\n",
       "      <td>...</td>\n",
       "      <td>0.903226</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.834511</td>\n",
       "      <td>0.055329</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1212</th>\n",
       "      <td>0.054877</td>\n",
       "      <td>0.003162</td>\n",
       "      <td>0.007232</td>\n",
       "      <td>0.000972</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4</td>\n",
       "      <td>50</td>\n",
       "      <td>...</td>\n",
       "      <td>0.903226</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.836098</td>\n",
       "      <td>0.055697</td>\n",
       "      <td>330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1213</th>\n",
       "      <td>0.048312</td>\n",
       "      <td>0.001028</td>\n",
       "      <td>0.005916</td>\n",
       "      <td>0.000878</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4</td>\n",
       "      <td>50</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.832898</td>\n",
       "      <td>0.049449</td>\n",
       "      <td>480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1214</th>\n",
       "      <td>0.051567</td>\n",
       "      <td>0.004369</td>\n",
       "      <td>0.006275</td>\n",
       "      <td>0.001148</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4</td>\n",
       "      <td>50</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.831336</td>\n",
       "      <td>0.046681</td>\n",
       "      <td>524</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1215 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0          0.023281      0.003346         0.010147        0.001151   \n",
       "1          0.021142      0.004710         0.008830        0.001959   \n",
       "2          0.017339      0.001338         0.007330        0.000460   \n",
       "3          0.029686      0.004877         0.010679        0.006277   \n",
       "4          0.028296      0.005223         0.008654        0.001540   \n",
       "...             ...           ...              ...             ...   \n",
       "1210       0.046617      0.003638         0.006846        0.000652   \n",
       "1211       0.046081      0.002453         0.007303        0.000902   \n",
       "1212       0.054877      0.003162         0.007232        0.000972   \n",
       "1213       0.048312      0.001028         0.005916        0.000878   \n",
       "1214       0.051567      0.004369         0.006275        0.001148   \n",
       "\n",
       "      param_colsample_bylevel  param_colsample_bytree  param_gamma  \\\n",
       "0                         0.2                     0.4          0.0   \n",
       "1                         0.2                     0.4          0.0   \n",
       "2                         0.2                     0.4          0.0   \n",
       "3                         0.2                     0.4          0.0   \n",
       "4                         0.2                     0.4          0.0   \n",
       "...                       ...                     ...          ...   \n",
       "1210                      0.4                     0.9          1.0   \n",
       "1211                      0.4                     0.9          1.0   \n",
       "1212                      0.4                     0.9          1.0   \n",
       "1213                      0.4                     0.9          1.0   \n",
       "1214                      0.4                     0.9          1.0   \n",
       "\n",
       "      param_learning_rate  param_max_depth  param_n_estimators  ...  \\\n",
       "0                     0.1                2                  10  ...   \n",
       "1                     0.1                2                  10  ...   \n",
       "2                     0.1                2                  10  ...   \n",
       "3                     0.1                2                  20  ...   \n",
       "4                     0.1                2                  20  ...   \n",
       "...                   ...              ...                 ...  ...   \n",
       "1210                  0.1                4                  40  ...   \n",
       "1211                  0.1                4                  40  ...   \n",
       "1212                  0.1                4                  50  ...   \n",
       "1213                  0.1                4                  50  ...   \n",
       "1214                  0.1                4                  50  ...   \n",
       "\n",
       "      split3_test_score split4_test_score  split5_test_score  \\\n",
       "0              0.790323          0.693548           0.774194   \n",
       "1              0.806452          0.693548           0.774194   \n",
       "2              0.758065          0.693548           0.774194   \n",
       "3              0.806452          0.758065           0.806452   \n",
       "4              0.790323          0.758065           0.838710   \n",
       "...                 ...               ...                ...   \n",
       "1210           0.870968          0.822581           0.790323   \n",
       "1211           0.903226          0.822581           0.806452   \n",
       "1212           0.903226          0.806452           0.822581   \n",
       "1213           0.870968          0.838710           0.790323   \n",
       "1214           0.870968          0.838710           0.806452   \n",
       "\n",
       "      split6_test_score  split7_test_score  split8_test_score  \\\n",
       "0              0.725806           0.645161           0.661290   \n",
       "1              0.741935           0.677419           0.629032   \n",
       "2              0.725806           0.677419           0.661290   \n",
       "3              0.790323           0.693548           0.709677   \n",
       "4              0.790323           0.693548           0.709677   \n",
       "...                 ...                ...                ...   \n",
       "1210           0.838710           0.822581           0.693548   \n",
       "1211           0.854839           0.806452           0.693548   \n",
       "1212           0.838710           0.822581           0.693548   \n",
       "1213           0.822581           0.822581           0.709677   \n",
       "1214           0.870968           0.806452           0.709677   \n",
       "\n",
       "      split9_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0              0.709677         0.738095        0.056816             1210  \n",
       "1              0.709677         0.741321        0.059607             1207  \n",
       "2              0.677419         0.734869        0.053170             1215  \n",
       "3              0.774194         0.776728        0.041775             1197  \n",
       "4              0.774194         0.778341        0.046040             1192  \n",
       "...                 ...              ...             ...              ...  \n",
       "1210           0.870968         0.831285        0.053063              569  \n",
       "1211           0.854839         0.834511        0.055329              400  \n",
       "1212           0.854839         0.836098        0.055697              330  \n",
       "1213           0.870968         0.832898        0.049449              480  \n",
       "1214           0.838710         0.831336        0.046681              524  \n",
       "\n",
       "[1215 rows x 25 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score is 0.8489759344598055 with params {'colsample_bylevel': 0.2, 'colsample_bytree': 0.9, 'gamma': 1, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 40, 'subsample': 0.6}\n"
     ]
    }
   ],
   "source": [
    "df4 = pd.read_csv(\"data\\\\xgb_results_full_4_learning=0.1_r3_20221124.csv\")\n",
    "df4.drop(df4.columns[0], axis=1, inplace=True)\n",
    "display(df4)\n",
    "print(\"best score is 0.8489759344598055 with params {'colsample_bylevel': 0.2, 'colsample_bytree': 0.9, 'gamma': 1, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 40, 'subsample': 0.6}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "38267cf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_colsample_bylevel</th>\n",
       "      <th>param_colsample_bytree</th>\n",
       "      <th>param_gamma</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>...</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.023281</td>\n",
       "      <td>0.003346</td>\n",
       "      <td>0.010147</td>\n",
       "      <td>0.001151</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.645161</td>\n",
       "      <td>0.661290</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.738095</td>\n",
       "      <td>0.056816</td>\n",
       "      <td>1210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.021142</td>\n",
       "      <td>0.004710</td>\n",
       "      <td>0.008830</td>\n",
       "      <td>0.001959</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.629032</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.741321</td>\n",
       "      <td>0.059607</td>\n",
       "      <td>1207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.017339</td>\n",
       "      <td>0.001338</td>\n",
       "      <td>0.007330</td>\n",
       "      <td>0.000460</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.661290</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.734869</td>\n",
       "      <td>0.053170</td>\n",
       "      <td>1215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.029686</td>\n",
       "      <td>0.004877</td>\n",
       "      <td>0.010679</td>\n",
       "      <td>0.006277</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>...</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.776728</td>\n",
       "      <td>0.041775</td>\n",
       "      <td>1197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.028296</td>\n",
       "      <td>0.005223</td>\n",
       "      <td>0.008654</td>\n",
       "      <td>0.001540</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>...</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.778341</td>\n",
       "      <td>0.046040</td>\n",
       "      <td>1192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1210</th>\n",
       "      <td>0.046617</td>\n",
       "      <td>0.003638</td>\n",
       "      <td>0.006846</td>\n",
       "      <td>0.000652</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4</td>\n",
       "      <td>40</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.831285</td>\n",
       "      <td>0.053063</td>\n",
       "      <td>569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1211</th>\n",
       "      <td>0.046081</td>\n",
       "      <td>0.002453</td>\n",
       "      <td>0.007303</td>\n",
       "      <td>0.000902</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4</td>\n",
       "      <td>40</td>\n",
       "      <td>...</td>\n",
       "      <td>0.903226</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.834511</td>\n",
       "      <td>0.055329</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1212</th>\n",
       "      <td>0.054877</td>\n",
       "      <td>0.003162</td>\n",
       "      <td>0.007232</td>\n",
       "      <td>0.000972</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4</td>\n",
       "      <td>50</td>\n",
       "      <td>...</td>\n",
       "      <td>0.903226</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.836098</td>\n",
       "      <td>0.055697</td>\n",
       "      <td>330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1213</th>\n",
       "      <td>0.048312</td>\n",
       "      <td>0.001028</td>\n",
       "      <td>0.005916</td>\n",
       "      <td>0.000878</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4</td>\n",
       "      <td>50</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.832898</td>\n",
       "      <td>0.049449</td>\n",
       "      <td>480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1214</th>\n",
       "      <td>0.051567</td>\n",
       "      <td>0.004369</td>\n",
       "      <td>0.006275</td>\n",
       "      <td>0.001148</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4</td>\n",
       "      <td>50</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.831336</td>\n",
       "      <td>0.046681</td>\n",
       "      <td>524</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1215 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0          0.023281      0.003346         0.010147        0.001151   \n",
       "1          0.021142      0.004710         0.008830        0.001959   \n",
       "2          0.017339      0.001338         0.007330        0.000460   \n",
       "3          0.029686      0.004877         0.010679        0.006277   \n",
       "4          0.028296      0.005223         0.008654        0.001540   \n",
       "...             ...           ...              ...             ...   \n",
       "1210       0.046617      0.003638         0.006846        0.000652   \n",
       "1211       0.046081      0.002453         0.007303        0.000902   \n",
       "1212       0.054877      0.003162         0.007232        0.000972   \n",
       "1213       0.048312      0.001028         0.005916        0.000878   \n",
       "1214       0.051567      0.004369         0.006275        0.001148   \n",
       "\n",
       "     param_colsample_bylevel param_colsample_bytree param_gamma  \\\n",
       "0                        0.2                    0.4           0   \n",
       "1                        0.2                    0.4           0   \n",
       "2                        0.2                    0.4           0   \n",
       "3                        0.2                    0.4           0   \n",
       "4                        0.2                    0.4           0   \n",
       "...                      ...                    ...         ...   \n",
       "1210                     0.4                    0.9           1   \n",
       "1211                     0.4                    0.9           1   \n",
       "1212                     0.4                    0.9           1   \n",
       "1213                     0.4                    0.9           1   \n",
       "1214                     0.4                    0.9           1   \n",
       "\n",
       "     param_learning_rate param_max_depth param_n_estimators  ...  \\\n",
       "0                    0.1               2                 10  ...   \n",
       "1                    0.1               2                 10  ...   \n",
       "2                    0.1               2                 10  ...   \n",
       "3                    0.1               2                 20  ...   \n",
       "4                    0.1               2                 20  ...   \n",
       "...                  ...             ...                ...  ...   \n",
       "1210                 0.1               4                 40  ...   \n",
       "1211                 0.1               4                 40  ...   \n",
       "1212                 0.1               4                 50  ...   \n",
       "1213                 0.1               4                 50  ...   \n",
       "1214                 0.1               4                 50  ...   \n",
       "\n",
       "     split3_test_score split4_test_score  split5_test_score  \\\n",
       "0             0.790323          0.693548           0.774194   \n",
       "1             0.806452          0.693548           0.774194   \n",
       "2             0.758065          0.693548           0.774194   \n",
       "3             0.806452          0.758065           0.806452   \n",
       "4             0.790323          0.758065           0.838710   \n",
       "...                ...               ...                ...   \n",
       "1210          0.870968          0.822581           0.790323   \n",
       "1211          0.903226          0.822581           0.806452   \n",
       "1212          0.903226          0.806452           0.822581   \n",
       "1213          0.870968          0.838710           0.790323   \n",
       "1214          0.870968          0.838710           0.806452   \n",
       "\n",
       "      split6_test_score  split7_test_score  split8_test_score  \\\n",
       "0              0.725806           0.645161           0.661290   \n",
       "1              0.741935           0.677419           0.629032   \n",
       "2              0.725806           0.677419           0.661290   \n",
       "3              0.790323           0.693548           0.709677   \n",
       "4              0.790323           0.693548           0.709677   \n",
       "...                 ...                ...                ...   \n",
       "1210           0.838710           0.822581           0.693548   \n",
       "1211           0.854839           0.806452           0.693548   \n",
       "1212           0.838710           0.822581           0.693548   \n",
       "1213           0.822581           0.822581           0.709677   \n",
       "1214           0.870968           0.806452           0.709677   \n",
       "\n",
       "      split9_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0              0.709677         0.738095        0.056816             1210  \n",
       "1              0.709677         0.741321        0.059607             1207  \n",
       "2              0.677419         0.734869        0.053170             1215  \n",
       "3              0.774194         0.776728        0.041775             1197  \n",
       "4              0.774194         0.778341        0.046040             1192  \n",
       "...                 ...              ...             ...              ...  \n",
       "1210           0.870968         0.831285        0.053063              569  \n",
       "1211           0.854839         0.834511        0.055329              400  \n",
       "1212           0.854839         0.836098        0.055697              330  \n",
       "1213           0.870968         0.832898        0.049449              480  \n",
       "1214           0.838710         0.831336        0.046681              524  \n",
       "\n",
       "[1215 rows x 25 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score is 0.8489759344598055 with params {'colsample_bylevel': 0.2, 'colsample_bytree': 0.9, 'gamma': 1, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 40, 'subsample': 0.6}\n"
     ]
    }
   ],
   "source": [
    "# Full Tuning - Part 4\n",
    "random.seed(10)\n",
    "\n",
    "xgb = XGBClassifier()\n",
    "\n",
    "xgb_parameters = {'max_depth': [2,3,4]\n",
    "                   , 'subsample': [0.6, 0.8, 0.9]\n",
    "                   , 'gamma': [0, 0.5, 1]\n",
    "                   , 'colsample_bytree': [0.4, 0.5, 0.9]\n",
    "                   , 'colsample_bylevel': [0.2, 0.3, 0.4]\n",
    "                   , 'learning_rate': [0.1]\n",
    "                   , 'n_estimators': [10, 20, 30, 40, 50]}\n",
    "\n",
    "stratified_10_fold_cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "xgb_grid_search = GridSearchCV(xgb, xgb_parameters, scoring='accuracy', cv=stratified_10_fold_cv)\n",
    "\n",
    "xgb_grid_search.fit(X_train, y_train)\n",
    "\n",
    "xgb_grid_search_results_full_4 = pd.DataFrame(xgb_grid_search.cv_results_)\n",
    "display(xgb_grid_search_results_full_4)\n",
    "\n",
    "print(\"best score is {} with params {}\".format(xgb_grid_search.best_score_, xgb_grid_search.best_params_))\n",
    "#best score is 0.8489759344598055 with params\n",
    "#{'colsample_bylevel': 0.2, 'colsample_bytree': 0.9, 'gamma': 1, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 40, 'subsample': 0.6}\n",
    "\n",
    "# save dataframe\n",
    "from datetime import datetime\n",
    "date = str(datetime.now().date()).replace(\"-\", \"\")\n",
    "xgb_grid_search_results_full_4.to_csv(f\"results/xgb_results_full_round4_4_learning=0.1_r3_{date}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4039a71d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_colsample_bylevel</th>\n",
       "      <th>param_colsample_bytree</th>\n",
       "      <th>param_gamma</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>...</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.016554</td>\n",
       "      <td>0.002537</td>\n",
       "      <td>0.007182</td>\n",
       "      <td>0.000959</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.15</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.757424</td>\n",
       "      <td>0.050947</td>\n",
       "      <td>1215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.016427</td>\n",
       "      <td>0.001717</td>\n",
       "      <td>0.007107</td>\n",
       "      <td>0.001197</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.15</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.757450</td>\n",
       "      <td>0.053333</td>\n",
       "      <td>1214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.016237</td>\n",
       "      <td>0.001671</td>\n",
       "      <td>0.006752</td>\n",
       "      <td>0.001091</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.15</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.760676</td>\n",
       "      <td>0.044198</td>\n",
       "      <td>1209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.021693</td>\n",
       "      <td>0.001708</td>\n",
       "      <td>0.006730</td>\n",
       "      <td>0.000781</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.15</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>...</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.786380</td>\n",
       "      <td>0.041426</td>\n",
       "      <td>1198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.022707</td>\n",
       "      <td>0.001195</td>\n",
       "      <td>0.006760</td>\n",
       "      <td>0.001250</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.15</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.887097</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.788070</td>\n",
       "      <td>0.060361</td>\n",
       "      <td>1193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1210</th>\n",
       "      <td>0.042887</td>\n",
       "      <td>0.006616</td>\n",
       "      <td>0.007578</td>\n",
       "      <td>0.000661</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.15</td>\n",
       "      <td>4</td>\n",
       "      <td>40</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.840937</td>\n",
       "      <td>0.052094</td>\n",
       "      <td>216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1211</th>\n",
       "      <td>0.040591</td>\n",
       "      <td>0.002564</td>\n",
       "      <td>0.007381</td>\n",
       "      <td>0.000488</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.15</td>\n",
       "      <td>4</td>\n",
       "      <td>40</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.826498</td>\n",
       "      <td>0.044226</td>\n",
       "      <td>844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1212</th>\n",
       "      <td>0.047273</td>\n",
       "      <td>0.000661</td>\n",
       "      <td>0.007281</td>\n",
       "      <td>0.000457</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.15</td>\n",
       "      <td>4</td>\n",
       "      <td>50</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.836047</td>\n",
       "      <td>0.049856</td>\n",
       "      <td>522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1213</th>\n",
       "      <td>0.046974</td>\n",
       "      <td>0.001218</td>\n",
       "      <td>0.007380</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.15</td>\n",
       "      <td>4</td>\n",
       "      <td>50</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.837711</td>\n",
       "      <td>0.051631</td>\n",
       "      <td>393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1214</th>\n",
       "      <td>0.046675</td>\n",
       "      <td>0.001163</td>\n",
       "      <td>0.007381</td>\n",
       "      <td>0.000488</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.15</td>\n",
       "      <td>4</td>\n",
       "      <td>50</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.826523</td>\n",
       "      <td>0.043519</td>\n",
       "      <td>838</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1215 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0          0.016554      0.002537         0.007182        0.000959   \n",
       "1          0.016427      0.001717         0.007107        0.001197   \n",
       "2          0.016237      0.001671         0.006752        0.001091   \n",
       "3          0.021693      0.001708         0.006730        0.000781   \n",
       "4          0.022707      0.001195         0.006760        0.001250   \n",
       "...             ...           ...              ...             ...   \n",
       "1210       0.042887      0.006616         0.007578        0.000661   \n",
       "1211       0.040591      0.002564         0.007381        0.000488   \n",
       "1212       0.047273      0.000661         0.007281        0.000457   \n",
       "1213       0.046974      0.001218         0.007380        0.000489   \n",
       "1214       0.046675      0.001163         0.007381        0.000488   \n",
       "\n",
       "      param_colsample_bylevel  param_colsample_bytree  param_gamma  \\\n",
       "0                         0.2                     0.4          0.0   \n",
       "1                         0.2                     0.4          0.0   \n",
       "2                         0.2                     0.4          0.0   \n",
       "3                         0.2                     0.4          0.0   \n",
       "4                         0.2                     0.4          0.0   \n",
       "...                       ...                     ...          ...   \n",
       "1210                      0.4                     0.9          1.0   \n",
       "1211                      0.4                     0.9          1.0   \n",
       "1212                      0.4                     0.9          1.0   \n",
       "1213                      0.4                     0.9          1.0   \n",
       "1214                      0.4                     0.9          1.0   \n",
       "\n",
       "      param_learning_rate  param_max_depth  param_n_estimators  ...  \\\n",
       "0                    0.15                2                  10  ...   \n",
       "1                    0.15                2                  10  ...   \n",
       "2                    0.15                2                  10  ...   \n",
       "3                    0.15                2                  20  ...   \n",
       "4                    0.15                2                  20  ...   \n",
       "...                   ...              ...                 ...  ...   \n",
       "1210                 0.15                4                  40  ...   \n",
       "1211                 0.15                4                  40  ...   \n",
       "1212                 0.15                4                  50  ...   \n",
       "1213                 0.15                4                  50  ...   \n",
       "1214                 0.15                4                  50  ...   \n",
       "\n",
       "      split3_test_score split4_test_score  split5_test_score  \\\n",
       "0              0.822581          0.677419           0.774194   \n",
       "1              0.822581          0.693548           0.774194   \n",
       "2              0.806452          0.693548           0.774194   \n",
       "3              0.806452          0.790323           0.822581   \n",
       "4              0.854839          0.790323           0.887097   \n",
       "...                 ...               ...                ...   \n",
       "1210           0.854839          0.822581           0.854839   \n",
       "1211           0.854839          0.822581           0.790323   \n",
       "1212           0.838710          0.822581           0.806452   \n",
       "1213           0.854839          0.838710           0.838710   \n",
       "1214           0.854839          0.822581           0.806452   \n",
       "\n",
       "      split6_test_score  split7_test_score  split8_test_score  \\\n",
       "0              0.758065           0.677419           0.709677   \n",
       "1              0.790323           0.677419           0.677419   \n",
       "2              0.774194           0.693548           0.709677   \n",
       "3              0.806452           0.693548           0.725806   \n",
       "4              0.806452           0.709677           0.677419   \n",
       "...                 ...                ...                ...   \n",
       "1210           0.854839           0.838710           0.693548   \n",
       "1211           0.854839           0.822581           0.709677   \n",
       "1212           0.838710           0.838710           0.709677   \n",
       "1213           0.870968           0.822581           0.693548   \n",
       "1214           0.838710           0.822581           0.709677   \n",
       "\n",
       "      split9_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0              0.758065         0.757424        0.050947             1215  \n",
       "1              0.758065         0.757450        0.053333             1214  \n",
       "2              0.774194         0.760676        0.044198             1209  \n",
       "3              0.774194         0.786380        0.041426             1198  \n",
       "4              0.758065         0.788070        0.060361             1193  \n",
       "...                 ...              ...             ...              ...  \n",
       "1210           0.870968         0.840937        0.052094              216  \n",
       "1211           0.838710         0.826498        0.044226              844  \n",
       "1212           0.854839         0.836047        0.049856              522  \n",
       "1213           0.838710         0.837711        0.051631              393  \n",
       "1214           0.854839         0.826523        0.043519              838  \n",
       "\n",
       "[1215 rows x 25 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score is 0.856989247311828 with params {'colsample_bylevel': 0.4, 'colsample_bytree': 0.4, 'gamma': 1, 'learning_rate': 0.15, 'max_depth': 4, 'n_estimators': 30, 'subsample': 0.9}\n"
     ]
    }
   ],
   "source": [
    "df5 = pd.read_csv(\"data\\\\xgb_results_full_5_learning=0.15_r3_20221124.csv\")\n",
    "df5.drop(df5.columns[0], axis=1, inplace=True)\n",
    "display(df5)\n",
    "print(\"best score is 0.856989247311828 with params {'colsample_bylevel': 0.4, 'colsample_bytree': 0.4, 'gamma': 1, 'learning_rate': 0.15, 'max_depth': 4, 'n_estimators': 30, 'subsample': 0.9}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "47aa628f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_colsample_bylevel</th>\n",
       "      <th>param_colsample_bytree</th>\n",
       "      <th>param_gamma</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>...</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.016554</td>\n",
       "      <td>0.002537</td>\n",
       "      <td>0.007182</td>\n",
       "      <td>0.000959</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.15</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.757424</td>\n",
       "      <td>0.050947</td>\n",
       "      <td>1215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.016427</td>\n",
       "      <td>0.001717</td>\n",
       "      <td>0.007107</td>\n",
       "      <td>0.001197</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.15</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.757450</td>\n",
       "      <td>0.053333</td>\n",
       "      <td>1214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.016237</td>\n",
       "      <td>0.001671</td>\n",
       "      <td>0.006752</td>\n",
       "      <td>0.001091</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.15</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.760676</td>\n",
       "      <td>0.044198</td>\n",
       "      <td>1209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.021693</td>\n",
       "      <td>0.001708</td>\n",
       "      <td>0.006730</td>\n",
       "      <td>0.000781</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.15</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>...</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.786380</td>\n",
       "      <td>0.041426</td>\n",
       "      <td>1198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.022707</td>\n",
       "      <td>0.001195</td>\n",
       "      <td>0.006760</td>\n",
       "      <td>0.001250</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.15</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.887097</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.788070</td>\n",
       "      <td>0.060361</td>\n",
       "      <td>1193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1210</th>\n",
       "      <td>0.042887</td>\n",
       "      <td>0.006616</td>\n",
       "      <td>0.007578</td>\n",
       "      <td>0.000661</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.15</td>\n",
       "      <td>4</td>\n",
       "      <td>40</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.840937</td>\n",
       "      <td>0.052094</td>\n",
       "      <td>216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1211</th>\n",
       "      <td>0.040591</td>\n",
       "      <td>0.002564</td>\n",
       "      <td>0.007381</td>\n",
       "      <td>0.000488</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.15</td>\n",
       "      <td>4</td>\n",
       "      <td>40</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.826498</td>\n",
       "      <td>0.044226</td>\n",
       "      <td>844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1212</th>\n",
       "      <td>0.047273</td>\n",
       "      <td>0.000661</td>\n",
       "      <td>0.007281</td>\n",
       "      <td>0.000457</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.15</td>\n",
       "      <td>4</td>\n",
       "      <td>50</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.836047</td>\n",
       "      <td>0.049856</td>\n",
       "      <td>522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1213</th>\n",
       "      <td>0.046974</td>\n",
       "      <td>0.001218</td>\n",
       "      <td>0.007380</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.15</td>\n",
       "      <td>4</td>\n",
       "      <td>50</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.837711</td>\n",
       "      <td>0.051631</td>\n",
       "      <td>393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1214</th>\n",
       "      <td>0.046675</td>\n",
       "      <td>0.001163</td>\n",
       "      <td>0.007381</td>\n",
       "      <td>0.000488</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.15</td>\n",
       "      <td>4</td>\n",
       "      <td>50</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.826523</td>\n",
       "      <td>0.043519</td>\n",
       "      <td>838</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1215 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0          0.016554      0.002537         0.007182        0.000959   \n",
       "1          0.016427      0.001717         0.007107        0.001197   \n",
       "2          0.016237      0.001671         0.006752        0.001091   \n",
       "3          0.021693      0.001708         0.006730        0.000781   \n",
       "4          0.022707      0.001195         0.006760        0.001250   \n",
       "...             ...           ...              ...             ...   \n",
       "1210       0.042887      0.006616         0.007578        0.000661   \n",
       "1211       0.040591      0.002564         0.007381        0.000488   \n",
       "1212       0.047273      0.000661         0.007281        0.000457   \n",
       "1213       0.046974      0.001218         0.007380        0.000489   \n",
       "1214       0.046675      0.001163         0.007381        0.000488   \n",
       "\n",
       "     param_colsample_bylevel param_colsample_bytree param_gamma  \\\n",
       "0                        0.2                    0.4           0   \n",
       "1                        0.2                    0.4           0   \n",
       "2                        0.2                    0.4           0   \n",
       "3                        0.2                    0.4           0   \n",
       "4                        0.2                    0.4           0   \n",
       "...                      ...                    ...         ...   \n",
       "1210                     0.4                    0.9           1   \n",
       "1211                     0.4                    0.9           1   \n",
       "1212                     0.4                    0.9           1   \n",
       "1213                     0.4                    0.9           1   \n",
       "1214                     0.4                    0.9           1   \n",
       "\n",
       "     param_learning_rate param_max_depth param_n_estimators  ...  \\\n",
       "0                   0.15               2                 10  ...   \n",
       "1                   0.15               2                 10  ...   \n",
       "2                   0.15               2                 10  ...   \n",
       "3                   0.15               2                 20  ...   \n",
       "4                   0.15               2                 20  ...   \n",
       "...                  ...             ...                ...  ...   \n",
       "1210                0.15               4                 40  ...   \n",
       "1211                0.15               4                 40  ...   \n",
       "1212                0.15               4                 50  ...   \n",
       "1213                0.15               4                 50  ...   \n",
       "1214                0.15               4                 50  ...   \n",
       "\n",
       "     split3_test_score split4_test_score  split5_test_score  \\\n",
       "0             0.822581          0.677419           0.774194   \n",
       "1             0.822581          0.693548           0.774194   \n",
       "2             0.806452          0.693548           0.774194   \n",
       "3             0.806452          0.790323           0.822581   \n",
       "4             0.854839          0.790323           0.887097   \n",
       "...                ...               ...                ...   \n",
       "1210          0.854839          0.822581           0.854839   \n",
       "1211          0.854839          0.822581           0.790323   \n",
       "1212          0.838710          0.822581           0.806452   \n",
       "1213          0.854839          0.838710           0.838710   \n",
       "1214          0.854839          0.822581           0.806452   \n",
       "\n",
       "      split6_test_score  split7_test_score  split8_test_score  \\\n",
       "0              0.758065           0.677419           0.709677   \n",
       "1              0.790323           0.677419           0.677419   \n",
       "2              0.774194           0.693548           0.709677   \n",
       "3              0.806452           0.693548           0.725806   \n",
       "4              0.806452           0.709677           0.677419   \n",
       "...                 ...                ...                ...   \n",
       "1210           0.854839           0.838710           0.693548   \n",
       "1211           0.854839           0.822581           0.709677   \n",
       "1212           0.838710           0.838710           0.709677   \n",
       "1213           0.870968           0.822581           0.693548   \n",
       "1214           0.838710           0.822581           0.709677   \n",
       "\n",
       "      split9_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0              0.758065         0.757424        0.050947             1215  \n",
       "1              0.758065         0.757450        0.053333             1214  \n",
       "2              0.774194         0.760676        0.044198             1209  \n",
       "3              0.774194         0.786380        0.041426             1198  \n",
       "4              0.758065         0.788070        0.060361             1193  \n",
       "...                 ...              ...             ...              ...  \n",
       "1210           0.870968         0.840937        0.052094              216  \n",
       "1211           0.838710         0.826498        0.044226              844  \n",
       "1212           0.854839         0.836047        0.049856              522  \n",
       "1213           0.838710         0.837711        0.051631              393  \n",
       "1214           0.854839         0.826523        0.043519              838  \n",
       "\n",
       "[1215 rows x 25 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score is 0.856989247311828 with params {'colsample_bylevel': 0.4, 'colsample_bytree': 0.4, 'gamma': 1, 'learning_rate': 0.15, 'max_depth': 4, 'n_estimators': 30, 'subsample': 0.9}\n"
     ]
    }
   ],
   "source": [
    "# Full Tuning - Part 5\n",
    "random.seed(10)\n",
    "\n",
    "xgb = XGBClassifier()\n",
    "\n",
    "xgb_parameters = {'max_depth': [2,3,4]\n",
    "                   , 'subsample': [0.6, 0.8, 0.9]\n",
    "                   , 'gamma': [0, 0.5, 1]\n",
    "                   , 'colsample_bytree': [0.4, 0.5, 0.9]\n",
    "                   , 'colsample_bylevel': [0.2, 0.3, 0.4]\n",
    "                   , 'learning_rate': [0.15]\n",
    "                   , 'n_estimators': [10, 20, 30, 40, 50]}\n",
    "\n",
    "stratified_10_fold_cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "xgb_grid_search = GridSearchCV(xgb, xgb_parameters, scoring='accuracy', cv=stratified_10_fold_cv)\n",
    "\n",
    "xgb_grid_search.fit(X_train, y_train)\n",
    "\n",
    "xgb_grid_search_results_full_5 = pd.DataFrame(xgb_grid_search.cv_results_)\n",
    "display(xgb_grid_search_results_full_5)\n",
    "\n",
    "print(\"best score is {} with params {}\".format(xgb_grid_search.best_score_, xgb_grid_search.best_params_))\n",
    "#best score is 0.856989247311828 with params\n",
    "#{'colsample_bylevel': 0.4, 'colsample_bytree': 0.4, 'gamma': 1, 'learning_rate': 0.15, 'max_depth': 4, 'n_estimators': 30, 'subsample': 0.9}\n",
    "\n",
    "# save dataframe\n",
    "from datetime import datetime\n",
    "date = str(datetime.now().date()).replace(\"-\", \"\")\n",
    "xgb_grid_search_results_full_5.to_csv(f\"results/xgb_results_full_round4_5_learning=0.15_r3_{date}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6660d344",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_colsample_bylevel</th>\n",
       "      <th>param_colsample_bytree</th>\n",
       "      <th>param_gamma</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>...</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.017553</td>\n",
       "      <td>0.003160</td>\n",
       "      <td>0.006982</td>\n",
       "      <td>0.000446</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.661290</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.661290</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.763850</td>\n",
       "      <td>0.060953</td>\n",
       "      <td>1214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.014960</td>\n",
       "      <td>0.000446</td>\n",
       "      <td>0.007181</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.768689</td>\n",
       "      <td>0.054639</td>\n",
       "      <td>1210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.014760</td>\n",
       "      <td>0.001323</td>\n",
       "      <td>0.006583</td>\n",
       "      <td>0.000798</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.765515</td>\n",
       "      <td>0.050031</td>\n",
       "      <td>1211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.020445</td>\n",
       "      <td>0.002610</td>\n",
       "      <td>0.005785</td>\n",
       "      <td>0.000870</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.800768</td>\n",
       "      <td>0.050666</td>\n",
       "      <td>1196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.022241</td>\n",
       "      <td>0.002404</td>\n",
       "      <td>0.006483</td>\n",
       "      <td>0.000499</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.903226</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.805658</td>\n",
       "      <td>0.055483</td>\n",
       "      <td>1176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1210</th>\n",
       "      <td>0.039993</td>\n",
       "      <td>0.000829</td>\n",
       "      <td>0.007979</td>\n",
       "      <td>0.000446</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>4</td>\n",
       "      <td>40</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.887097</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.850589</td>\n",
       "      <td>0.041824</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1211</th>\n",
       "      <td>0.057798</td>\n",
       "      <td>0.044078</td>\n",
       "      <td>0.008179</td>\n",
       "      <td>0.002352</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>4</td>\n",
       "      <td>40</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.823349</td>\n",
       "      <td>0.036404</td>\n",
       "      <td>966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1212</th>\n",
       "      <td>0.065325</td>\n",
       "      <td>0.017959</td>\n",
       "      <td>0.008279</td>\n",
       "      <td>0.000779</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>4</td>\n",
       "      <td>50</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.834434</td>\n",
       "      <td>0.055885</td>\n",
       "      <td>546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1213</th>\n",
       "      <td>0.067819</td>\n",
       "      <td>0.006180</td>\n",
       "      <td>0.008378</td>\n",
       "      <td>0.001196</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>4</td>\n",
       "      <td>50</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.837737</td>\n",
       "      <td>0.042732</td>\n",
       "      <td>317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1214</th>\n",
       "      <td>0.055651</td>\n",
       "      <td>0.002176</td>\n",
       "      <td>0.007880</td>\n",
       "      <td>0.001042</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>4</td>\n",
       "      <td>50</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.828111</td>\n",
       "      <td>0.042532</td>\n",
       "      <td>829</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1215 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0          0.017553      0.003160         0.006982        0.000446   \n",
       "1          0.014960      0.000446         0.007181        0.000399   \n",
       "2          0.014760      0.001323         0.006583        0.000798   \n",
       "3          0.020445      0.002610         0.005785        0.000870   \n",
       "4          0.022241      0.002404         0.006483        0.000499   \n",
       "...             ...           ...              ...             ...   \n",
       "1210       0.039993      0.000829         0.007979        0.000446   \n",
       "1211       0.057798      0.044078         0.008179        0.002352   \n",
       "1212       0.065325      0.017959         0.008279        0.000779   \n",
       "1213       0.067819      0.006180         0.008378        0.001196   \n",
       "1214       0.055651      0.002176         0.007880        0.001042   \n",
       "\n",
       "      param_colsample_bylevel  param_colsample_bytree  param_gamma  \\\n",
       "0                         0.2                     0.4          0.0   \n",
       "1                         0.2                     0.4          0.0   \n",
       "2                         0.2                     0.4          0.0   \n",
       "3                         0.2                     0.4          0.0   \n",
       "4                         0.2                     0.4          0.0   \n",
       "...                       ...                     ...          ...   \n",
       "1210                      0.4                     0.9          1.0   \n",
       "1211                      0.4                     0.9          1.0   \n",
       "1212                      0.4                     0.9          1.0   \n",
       "1213                      0.4                     0.9          1.0   \n",
       "1214                      0.4                     0.9          1.0   \n",
       "\n",
       "      param_learning_rate  param_max_depth  param_n_estimators  ...  \\\n",
       "0                     0.2                2                  10  ...   \n",
       "1                     0.2                2                  10  ...   \n",
       "2                     0.2                2                  10  ...   \n",
       "3                     0.2                2                  20  ...   \n",
       "4                     0.2                2                  20  ...   \n",
       "...                   ...              ...                 ...  ...   \n",
       "1210                  0.2                4                  40  ...   \n",
       "1211                  0.2                4                  40  ...   \n",
       "1212                  0.2                4                  50  ...   \n",
       "1213                  0.2                4                  50  ...   \n",
       "1214                  0.2                4                  50  ...   \n",
       "\n",
       "      split3_test_score split4_test_score  split5_test_score  \\\n",
       "0              0.838710          0.661290           0.790323   \n",
       "1              0.854839          0.693548           0.790323   \n",
       "2              0.838710          0.725806           0.790323   \n",
       "3              0.838710          0.774194           0.838710   \n",
       "4              0.838710          0.774194           0.903226   \n",
       "...                 ...               ...                ...   \n",
       "1210           0.870968          0.822581           0.854839   \n",
       "1211           0.854839          0.822581           0.806452   \n",
       "1212           0.838710          0.822581           0.790323   \n",
       "1213           0.838710          0.822581           0.822581   \n",
       "1214           0.870968          0.822581           0.790323   \n",
       "\n",
       "      split6_test_score  split7_test_score  split8_test_score  \\\n",
       "0              0.774194           0.661290           0.709677   \n",
       "1              0.774194           0.693548           0.693548   \n",
       "2              0.774194           0.677419           0.693548   \n",
       "3              0.806452           0.709677           0.709677   \n",
       "4              0.806452           0.741935           0.693548   \n",
       "...                 ...                ...                ...   \n",
       "1210           0.887097           0.838710           0.741935   \n",
       "1211           0.854839           0.822581           0.725806   \n",
       "1212           0.854839           0.838710           0.693548   \n",
       "1213           0.870968           0.838710           0.725806   \n",
       "1214           0.854839           0.806452           0.725806   \n",
       "\n",
       "      split9_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0              0.790323         0.763850        0.060953             1214  \n",
       "1              0.774194         0.768689        0.054639             1210  \n",
       "2              0.774194         0.765515        0.050031             1211  \n",
       "3              0.806452         0.800768        0.050666             1196  \n",
       "4              0.806452         0.805658        0.055483             1176  \n",
       "...                 ...              ...             ...              ...  \n",
       "1210           0.854839         0.850589        0.041824                6  \n",
       "1211           0.822581         0.823349        0.036404              966  \n",
       "1212           0.854839         0.834434        0.055885              546  \n",
       "1213           0.854839         0.837737        0.042732              317  \n",
       "1214           0.838710         0.828111        0.042532              829  \n",
       "\n",
       "[1215 rows x 25 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score is 0.8522529441884281 with params {'colsample_bylevel': 0.2, 'colsample_bytree': 0.9, 'gamma': 0.5, 'learning_rate': 0.2, 'max_depth': 2, 'n_estimators': 30, 'subsample': 0.6}\n"
     ]
    }
   ],
   "source": [
    "df6 = pd.read_csv(\"data\\\\xgb_results_full_6_learning=0.2_r3_20221124.csv\")\n",
    "df6.drop(df6.columns[0], axis=1, inplace=True)\n",
    "display(df6)\n",
    "print(\"best score is 0.8522529441884281 with params {'colsample_bylevel': 0.2, 'colsample_bytree': 0.9, 'gamma': 0.5, 'learning_rate': 0.2, 'max_depth': 2, 'n_estimators': 30, 'subsample': 0.6}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "10ee410e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_colsample_bylevel</th>\n",
       "      <th>param_colsample_bytree</th>\n",
       "      <th>param_gamma</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>...</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.017553</td>\n",
       "      <td>0.003160</td>\n",
       "      <td>0.006982</td>\n",
       "      <td>0.000446</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.661290</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.661290</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.763850</td>\n",
       "      <td>0.060953</td>\n",
       "      <td>1214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.014960</td>\n",
       "      <td>0.000446</td>\n",
       "      <td>0.007181</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.768689</td>\n",
       "      <td>0.054639</td>\n",
       "      <td>1210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.014760</td>\n",
       "      <td>0.001323</td>\n",
       "      <td>0.006583</td>\n",
       "      <td>0.000798</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.765515</td>\n",
       "      <td>0.050031</td>\n",
       "      <td>1211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.020445</td>\n",
       "      <td>0.002610</td>\n",
       "      <td>0.005785</td>\n",
       "      <td>0.000870</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.800768</td>\n",
       "      <td>0.050666</td>\n",
       "      <td>1196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.022241</td>\n",
       "      <td>0.002404</td>\n",
       "      <td>0.006483</td>\n",
       "      <td>0.000499</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.903226</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.805658</td>\n",
       "      <td>0.055483</td>\n",
       "      <td>1176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1210</th>\n",
       "      <td>0.039993</td>\n",
       "      <td>0.000829</td>\n",
       "      <td>0.007979</td>\n",
       "      <td>0.000446</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>4</td>\n",
       "      <td>40</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.887097</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.850589</td>\n",
       "      <td>0.041824</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1211</th>\n",
       "      <td>0.057798</td>\n",
       "      <td>0.044078</td>\n",
       "      <td>0.008179</td>\n",
       "      <td>0.002352</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>4</td>\n",
       "      <td>40</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.823349</td>\n",
       "      <td>0.036404</td>\n",
       "      <td>966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1212</th>\n",
       "      <td>0.065325</td>\n",
       "      <td>0.017959</td>\n",
       "      <td>0.008279</td>\n",
       "      <td>0.000779</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>4</td>\n",
       "      <td>50</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.834434</td>\n",
       "      <td>0.055885</td>\n",
       "      <td>546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1213</th>\n",
       "      <td>0.067819</td>\n",
       "      <td>0.006180</td>\n",
       "      <td>0.008378</td>\n",
       "      <td>0.001196</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>4</td>\n",
       "      <td>50</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.837737</td>\n",
       "      <td>0.042732</td>\n",
       "      <td>317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1214</th>\n",
       "      <td>0.055651</td>\n",
       "      <td>0.002176</td>\n",
       "      <td>0.007880</td>\n",
       "      <td>0.001042</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>4</td>\n",
       "      <td>50</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.828111</td>\n",
       "      <td>0.042532</td>\n",
       "      <td>829</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1215 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0          0.017553      0.003160         0.006982        0.000446   \n",
       "1          0.014960      0.000446         0.007181        0.000399   \n",
       "2          0.014760      0.001323         0.006583        0.000798   \n",
       "3          0.020445      0.002610         0.005785        0.000870   \n",
       "4          0.022241      0.002404         0.006483        0.000499   \n",
       "...             ...           ...              ...             ...   \n",
       "1210       0.039993      0.000829         0.007979        0.000446   \n",
       "1211       0.057798      0.044078         0.008179        0.002352   \n",
       "1212       0.065325      0.017959         0.008279        0.000779   \n",
       "1213       0.067819      0.006180         0.008378        0.001196   \n",
       "1214       0.055651      0.002176         0.007880        0.001042   \n",
       "\n",
       "     param_colsample_bylevel param_colsample_bytree param_gamma  \\\n",
       "0                        0.2                    0.4           0   \n",
       "1                        0.2                    0.4           0   \n",
       "2                        0.2                    0.4           0   \n",
       "3                        0.2                    0.4           0   \n",
       "4                        0.2                    0.4           0   \n",
       "...                      ...                    ...         ...   \n",
       "1210                     0.4                    0.9           1   \n",
       "1211                     0.4                    0.9           1   \n",
       "1212                     0.4                    0.9           1   \n",
       "1213                     0.4                    0.9           1   \n",
       "1214                     0.4                    0.9           1   \n",
       "\n",
       "     param_learning_rate param_max_depth param_n_estimators  ...  \\\n",
       "0                    0.2               2                 10  ...   \n",
       "1                    0.2               2                 10  ...   \n",
       "2                    0.2               2                 10  ...   \n",
       "3                    0.2               2                 20  ...   \n",
       "4                    0.2               2                 20  ...   \n",
       "...                  ...             ...                ...  ...   \n",
       "1210                 0.2               4                 40  ...   \n",
       "1211                 0.2               4                 40  ...   \n",
       "1212                 0.2               4                 50  ...   \n",
       "1213                 0.2               4                 50  ...   \n",
       "1214                 0.2               4                 50  ...   \n",
       "\n",
       "     split3_test_score split4_test_score  split5_test_score  \\\n",
       "0             0.838710          0.661290           0.790323   \n",
       "1             0.854839          0.693548           0.790323   \n",
       "2             0.838710          0.725806           0.790323   \n",
       "3             0.838710          0.774194           0.838710   \n",
       "4             0.838710          0.774194           0.903226   \n",
       "...                ...               ...                ...   \n",
       "1210          0.870968          0.822581           0.854839   \n",
       "1211          0.854839          0.822581           0.806452   \n",
       "1212          0.838710          0.822581           0.790323   \n",
       "1213          0.838710          0.822581           0.822581   \n",
       "1214          0.870968          0.822581           0.790323   \n",
       "\n",
       "      split6_test_score  split7_test_score  split8_test_score  \\\n",
       "0              0.774194           0.661290           0.709677   \n",
       "1              0.774194           0.693548           0.693548   \n",
       "2              0.774194           0.677419           0.693548   \n",
       "3              0.806452           0.709677           0.709677   \n",
       "4              0.806452           0.741935           0.693548   \n",
       "...                 ...                ...                ...   \n",
       "1210           0.887097           0.838710           0.741935   \n",
       "1211           0.854839           0.822581           0.725806   \n",
       "1212           0.854839           0.838710           0.693548   \n",
       "1213           0.870968           0.838710           0.725806   \n",
       "1214           0.854839           0.806452           0.725806   \n",
       "\n",
       "      split9_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0              0.790323         0.763850        0.060953             1214  \n",
       "1              0.774194         0.768689        0.054639             1210  \n",
       "2              0.774194         0.765515        0.050031             1211  \n",
       "3              0.806452         0.800768        0.050666             1196  \n",
       "4              0.806452         0.805658        0.055483             1176  \n",
       "...                 ...              ...             ...              ...  \n",
       "1210           0.854839         0.850589        0.041824                6  \n",
       "1211           0.822581         0.823349        0.036404              966  \n",
       "1212           0.854839         0.834434        0.055885              546  \n",
       "1213           0.854839         0.837737        0.042732              317  \n",
       "1214           0.838710         0.828111        0.042532              829  \n",
       "\n",
       "[1215 rows x 25 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score is 0.8522529441884281 with params {'colsample_bylevel': 0.2, 'colsample_bytree': 0.9, 'gamma': 0.5, 'learning_rate': 0.2, 'max_depth': 2, 'n_estimators': 30, 'subsample': 0.6}\n"
     ]
    }
   ],
   "source": [
    "# Full Tuning - Part 6\n",
    "random.seed(10)\n",
    "\n",
    "xgb = XGBClassifier()\n",
    "\n",
    "xgb_parameters = {'max_depth': [2,3,4]\n",
    "                   , 'subsample': [0.6, 0.8, 0.9]\n",
    "                   , 'gamma': [0, 0.5, 1]\n",
    "                   , 'colsample_bytree': [0.4, 0.5, 0.9]\n",
    "                   , 'colsample_bylevel': [0.2, 0.3, 0.4]\n",
    "                   , 'learning_rate': [0.2]\n",
    "                   , 'n_estimators': [10, 20, 30, 40, 50]}\n",
    "\n",
    "stratified_10_fold_cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "xgb_grid_search = GridSearchCV(xgb, xgb_parameters, scoring='accuracy', cv=stratified_10_fold_cv)\n",
    "\n",
    "xgb_grid_search.fit(X_train, y_train)\n",
    "\n",
    "xgb_grid_search_results_full_6 = pd.DataFrame(xgb_grid_search.cv_results_)\n",
    "display(xgb_grid_search_results_full_6)\n",
    "\n",
    "print(\"best score is {} with params {}\".format(xgb_grid_search.best_score_, xgb_grid_search.best_params_))\n",
    "#best score is 0.8522529441884281 with params\n",
    "#{'colsample_bylevel': 0.2, 'colsample_bytree': 0.9, 'gamma': 0.5, 'learning_rate': 0.2, 'max_depth': 2, 'n_estimators': 30, 'subsample': 0.6}\n",
    "\n",
    "# save dataframe\n",
    "from datetime import datetime\n",
    "date = str(datetime.now().date()).replace(\"-\", \"\")\n",
    "xgb_grid_search_results_full_6.to_csv(f\"results/xgb_results_full_round4_6_learning=0.2_r3_{date}.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57b04632",
   "metadata": {},
   "source": [
    "Combine single hyper parameter tuning to find best values for hyper parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9a382288",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_colsample_bylevel</th>\n",
       "      <th>param_colsample_bytree</th>\n",
       "      <th>param_gamma</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>...</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.021696</td>\n",
       "      <td>0.004852</td>\n",
       "      <td>0.009495</td>\n",
       "      <td>0.002555</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.661290</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.661290</td>\n",
       "      <td>0.661290</td>\n",
       "      <td>0.661290</td>\n",
       "      <td>0.720430</td>\n",
       "      <td>0.052226</td>\n",
       "      <td>4858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.023734</td>\n",
       "      <td>0.003344</td>\n",
       "      <td>0.010269</td>\n",
       "      <td>0.002012</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.661290</td>\n",
       "      <td>0.629032</td>\n",
       "      <td>0.661290</td>\n",
       "      <td>0.720405</td>\n",
       "      <td>0.060569</td>\n",
       "      <td>4860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.021329</td>\n",
       "      <td>0.002649</td>\n",
       "      <td>0.009234</td>\n",
       "      <td>0.001687</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.645161</td>\n",
       "      <td>0.645161</td>\n",
       "      <td>0.661290</td>\n",
       "      <td>0.723630</td>\n",
       "      <td>0.057244</td>\n",
       "      <td>4855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.031445</td>\n",
       "      <td>0.001912</td>\n",
       "      <td>0.009800</td>\n",
       "      <td>0.001109</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>...</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.760599</td>\n",
       "      <td>0.045057</td>\n",
       "      <td>4835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.034447</td>\n",
       "      <td>0.002939</td>\n",
       "      <td>0.010506</td>\n",
       "      <td>0.001006</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>...</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.760625</td>\n",
       "      <td>0.047805</td>\n",
       "      <td>4834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4855</th>\n",
       "      <td>0.039993</td>\n",
       "      <td>0.000829</td>\n",
       "      <td>0.007979</td>\n",
       "      <td>0.000446</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.20</td>\n",
       "      <td>4</td>\n",
       "      <td>40</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.887097</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.850589</td>\n",
       "      <td>0.041824</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4856</th>\n",
       "      <td>0.057798</td>\n",
       "      <td>0.044078</td>\n",
       "      <td>0.008179</td>\n",
       "      <td>0.002352</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.20</td>\n",
       "      <td>4</td>\n",
       "      <td>40</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.823349</td>\n",
       "      <td>0.036404</td>\n",
       "      <td>3249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4857</th>\n",
       "      <td>0.065325</td>\n",
       "      <td>0.017959</td>\n",
       "      <td>0.008279</td>\n",
       "      <td>0.000779</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.20</td>\n",
       "      <td>4</td>\n",
       "      <td>50</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.834434</td>\n",
       "      <td>0.055885</td>\n",
       "      <td>1740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4858</th>\n",
       "      <td>0.067819</td>\n",
       "      <td>0.006180</td>\n",
       "      <td>0.008378</td>\n",
       "      <td>0.001196</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.20</td>\n",
       "      <td>4</td>\n",
       "      <td>50</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.837737</td>\n",
       "      <td>0.042732</td>\n",
       "      <td>1033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4859</th>\n",
       "      <td>0.055651</td>\n",
       "      <td>0.002176</td>\n",
       "      <td>0.007880</td>\n",
       "      <td>0.001042</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.20</td>\n",
       "      <td>4</td>\n",
       "      <td>50</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.828111</td>\n",
       "      <td>0.042532</td>\n",
       "      <td>2692</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4860 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0          0.021696      0.004852         0.009495        0.002555   \n",
       "1          0.023734      0.003344         0.010269        0.002012   \n",
       "2          0.021329      0.002649         0.009234        0.001687   \n",
       "3          0.031445      0.001912         0.009800        0.001109   \n",
       "4          0.034447      0.002939         0.010506        0.001006   \n",
       "...             ...           ...              ...             ...   \n",
       "4855       0.039993      0.000829         0.007979        0.000446   \n",
       "4856       0.057798      0.044078         0.008179        0.002352   \n",
       "4857       0.065325      0.017959         0.008279        0.000779   \n",
       "4858       0.067819      0.006180         0.008378        0.001196   \n",
       "4859       0.055651      0.002176         0.007880        0.001042   \n",
       "\n",
       "      param_colsample_bylevel  param_colsample_bytree  param_gamma  \\\n",
       "0                         0.2                     0.4          0.0   \n",
       "1                         0.2                     0.4          0.0   \n",
       "2                         0.2                     0.4          0.0   \n",
       "3                         0.2                     0.4          0.0   \n",
       "4                         0.2                     0.4          0.0   \n",
       "...                       ...                     ...          ...   \n",
       "4855                      0.4                     0.9          1.0   \n",
       "4856                      0.4                     0.9          1.0   \n",
       "4857                      0.4                     0.9          1.0   \n",
       "4858                      0.4                     0.9          1.0   \n",
       "4859                      0.4                     0.9          1.0   \n",
       "\n",
       "      param_learning_rate  param_max_depth  param_n_estimators  ...  \\\n",
       "0                    0.05                2                  10  ...   \n",
       "1                    0.05                2                  10  ...   \n",
       "2                    0.05                2                  10  ...   \n",
       "3                    0.05                2                  20  ...   \n",
       "4                    0.05                2                  20  ...   \n",
       "...                   ...              ...                 ...  ...   \n",
       "4855                 0.20                4                  40  ...   \n",
       "4856                 0.20                4                  40  ...   \n",
       "4857                 0.20                4                  50  ...   \n",
       "4858                 0.20                4                  50  ...   \n",
       "4859                 0.20                4                  50  ...   \n",
       "\n",
       "      split3_test_score split4_test_score  split5_test_score  \\\n",
       "0              0.741935          0.661290           0.758065   \n",
       "1              0.774194          0.677419           0.758065   \n",
       "2              0.741935          0.709677           0.774194   \n",
       "3              0.774194          0.741935           0.790323   \n",
       "4              0.806452          0.725806           0.790323   \n",
       "...                 ...               ...                ...   \n",
       "4855           0.870968          0.822581           0.854839   \n",
       "4856           0.854839          0.822581           0.806452   \n",
       "4857           0.838710          0.822581           0.790323   \n",
       "4858           0.838710          0.822581           0.822581   \n",
       "4859           0.870968          0.822581           0.790323   \n",
       "\n",
       "      split6_test_score  split7_test_score  split8_test_score  \\\n",
       "0              0.725806           0.661290           0.661290   \n",
       "1              0.693548           0.661290           0.629032   \n",
       "2              0.709677           0.645161           0.645161   \n",
       "3              0.758065           0.693548           0.709677   \n",
       "4              0.774194           0.693548           0.693548   \n",
       "...                 ...                ...                ...   \n",
       "4855           0.887097           0.838710           0.741935   \n",
       "4856           0.854839           0.822581           0.725806   \n",
       "4857           0.854839           0.838710           0.693548   \n",
       "4858           0.870968           0.838710           0.725806   \n",
       "4859           0.854839           0.806452           0.725806   \n",
       "\n",
       "      split9_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0              0.661290         0.720430        0.052226             4858  \n",
       "1              0.661290         0.720405        0.060569             4860  \n",
       "2              0.661290         0.723630        0.057244             4855  \n",
       "3              0.709677         0.760599        0.045057             4835  \n",
       "4              0.709677         0.760625        0.047805             4834  \n",
       "...                 ...              ...             ...              ...  \n",
       "4855           0.854839         0.850589        0.041824               18  \n",
       "4856           0.822581         0.823349        0.036404             3249  \n",
       "4857           0.854839         0.834434        0.055885             1740  \n",
       "4858           0.854839         0.837737        0.042732             1033  \n",
       "4859           0.838710         0.828111        0.042532             2692  \n",
       "\n",
       "[4860 rows x 25 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score is 0.856989 with params {'colsample_bylevel': 0.4, 'colsample_bytree': 0.4, 'gamma': 1, 'learning_rate': 0.15, 'max_depth': 4, 'n_estimators': 30, 'subsample': 0.9}\n"
     ]
    }
   ],
   "source": [
    "# read single parts of round 3, concatenate and update index and rank_test_score\n",
    "\n",
    "df2 = pd.read_csv(\"data\\\\xgb_results_full_2_learning=0.05_r3_20221124.csv\")\n",
    "df2.drop(df2.columns[0], axis=1, inplace=True)\n",
    "\n",
    "df4 = pd.read_csv(\"data\\\\xgb_results_full_4_learning=0.1_r3_20221124.csv\")\n",
    "df4.drop(df4.columns[0], axis=1, inplace=True)\n",
    "\n",
    "df5 = pd.read_csv(\"data\\\\xgb_results_full_5_learning=0.15_r3_20221124.csv\")\n",
    "df5.drop(df5.columns[0], axis=1, inplace=True)\n",
    "\n",
    "df6 = pd.read_csv(\"data\\\\xgb_results_full_6_learning=0.2_r3_20221124.csv\")\n",
    "df6.drop(df6.columns[0], axis=1, inplace=True)\n",
    "\n",
    "df_full = pd.concat([df2,df4,df5,df6])\n",
    "\n",
    "#assign correct rank\n",
    "df_full = df_full.sort_values(by='mean_test_score', ascending=False)\n",
    "df_full['rank_test_score'] = range(1, len(df_full)+1)\n",
    "\n",
    "#get correct order and set new index\n",
    "df_full = df_full.sort_values(by=['param_colsample_bylevel', 'param_colsample_bytree', 'param_gamma', 'param_learning_rate', 'param_max_depth', 'param_n_estimators', 'param_subsample'])\n",
    "xgb_grid_search_results_round4 = df_full.set_index(np.array(range(len(df_full))))\n",
    "display(xgb_grid_search_results_round4)\n",
    "\n",
    "print(\"best score is 0.856989 with params {'colsample_bylevel': 0.4, 'colsample_bytree': 0.4, 'gamma': 1, 'learning_rate': 0.15, 'max_depth': 4, 'n_estimators': 30, 'subsample': 0.9}\")\n",
    "\n",
    "# save dataframe\n",
    "from datetime import datetime\n",
    "date = str(datetime.now().date()).replace(\"-\", \"\")\n",
    "xgb_grid_search_results_round4.to_csv(f\"results/xgb_results_round4_{date}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "137cdd22",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_subsample</th>\n",
       "      <th>param_colsample_bylevel</th>\n",
       "      <th>param_colsample_bytree</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_gamma</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3728</th>\n",
       "      <td>4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.15</td>\n",
       "      <td>30</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.856989</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3714</th>\n",
       "      <td>3</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.15</td>\n",
       "      <td>40</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.853840</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1401</th>\n",
       "      <td>2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.20</td>\n",
       "      <td>30</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.852253</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1551</th>\n",
       "      <td>3</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.15</td>\n",
       "      <td>30</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.852227</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1596</th>\n",
       "      <td>3</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.20</td>\n",
       "      <td>30</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.852202</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.05</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.722043</td>\n",
       "      <td>4856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.05</td>\n",
       "      <td>10</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.720430</td>\n",
       "      <td>4857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.05</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.720430</td>\n",
       "      <td>4858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>2</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.05</td>\n",
       "      <td>10</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.720405</td>\n",
       "      <td>4859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.05</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.720405</td>\n",
       "      <td>4860</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4860 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      param_max_depth  param_subsample  param_colsample_bylevel  \\\n",
       "3728                4              0.9                      0.4   \n",
       "3714                3              0.6                      0.4   \n",
       "1401                2              0.6                      0.2   \n",
       "1551                3              0.6                      0.2   \n",
       "1596                3              0.6                      0.2   \n",
       "...               ...              ...                      ...   \n",
       "360                 2              0.6                      0.2   \n",
       "180                 2              0.6                      0.2   \n",
       "0                   2              0.6                      0.2   \n",
       "181                 2              0.8                      0.2   \n",
       "1                   2              0.8                      0.2   \n",
       "\n",
       "      param_colsample_bytree  param_learning_rate  param_n_estimators  \\\n",
       "3728                     0.4                 0.15                  30   \n",
       "3714                     0.4                 0.15                  40   \n",
       "1401                     0.9                 0.20                  30   \n",
       "1551                     0.9                 0.15                  30   \n",
       "1596                     0.9                 0.20                  30   \n",
       "...                      ...                  ...                 ...   \n",
       "360                      0.4                 0.05                  10   \n",
       "180                      0.4                 0.05                  10   \n",
       "0                        0.4                 0.05                  10   \n",
       "181                      0.4                 0.05                  10   \n",
       "1                        0.4                 0.05                  10   \n",
       "\n",
       "      param_gamma  mean_test_score  rank_test_score  \n",
       "3728          1.0         0.856989                1  \n",
       "3714          1.0         0.853840                2  \n",
       "1401          0.5         0.852253                3  \n",
       "1551          1.0         0.852227                4  \n",
       "1596          1.0         0.852202                5  \n",
       "...           ...              ...              ...  \n",
       "360           1.0         0.722043             4856  \n",
       "180           0.5         0.720430             4857  \n",
       "0             0.0         0.720430             4858  \n",
       "181           0.5         0.720405             4859  \n",
       "1             0.0         0.720405             4860  \n",
       "\n",
       "[4860 rows x 9 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# store relevant columns and sort by rank_test_score\n",
    "cols_round4 = ['param_max_depth', 'param_subsample', 'param_colsample_bylevel', 'param_colsample_bytree', 'param_learning_rate', 'param_n_estimators', 'param_gamma', 'mean_test_score', 'rank_test_score']\n",
    "xgb_results_round4_sorted = xgb_grid_search_results_round4[cols_round4]\n",
    "xgb_results_round4_sorted = xgb_results_round4_sorted.sort_values(by='rank_test_score')\n",
    "display(xgb_results_round4_sorted)\n",
    "\n",
    "# save dataframe\n",
    "from datetime import datetime\n",
    "date = str(datetime.now().date()).replace(\"-\", \"\")\n",
    "xgb_results_round4_sorted.to_csv(f\"results/xgb_results_round4_sorted_{date}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f31aba85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.8283582089552238\n",
      "F1 Score = 0.7788461538461539\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.90      0.86       157\n",
      "           1       0.84      0.73      0.78       111\n",
      "\n",
      "    accuracy                           0.83       268\n",
      "   macro avg       0.83      0.81      0.82       268\n",
      "weighted avg       0.83      0.83      0.83       268\n",
      "\n",
      "Confusion Matrix:\n",
      "[[141  16]\n",
      " [ 30  81]]\n"
     ]
    }
   ],
   "source": [
    "# Fit and evaluate best model\n",
    "\n",
    "xgb_best = XGBClassifier(max_depth = 4, subsample = 0.9, colsample_bylevel = 0.4, colsample_bytree = 0.4, learning_rate = 0.15, n_estimators = 30, gamma = 1)\n",
    "xgb_best.fit(X_train, y_train)\n",
    "xgb_best_pred = xgb_best.predict(X_test)\n",
    "\n",
    "xgb_best_acc = accuracy_score(y_test, xgb_best_pred)\n",
    "print(\"Accuracy =\", xgb_best_acc) #0.8283582089552238\n",
    "\n",
    "xgb_best_f1 = f1_score(y_test, xgb_best_pred)\n",
    "print(\"F1 Score =\", xgb_best_f1) #0.7788461538461539\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, xgb_best_pred))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, xgb_best_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10317046",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba1a3507",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9882d10e",
   "metadata": {},
   "source": [
    "## Best Model by trying out some combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "48d4a5b2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.8171641791044776\n",
      "F1 Score = 0.780269058295964\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.84      0.84       157\n",
      "           1       0.78      0.78      0.78       111\n",
      "\n",
      "    accuracy                           0.82       268\n",
      "   macro avg       0.81      0.81      0.81       268\n",
      "weighted avg       0.82      0.82      0.82       268\n",
      "\n",
      "Confusion Matrix:\n",
      "[[132  25]\n",
      " [ 24  87]]\n"
     ]
    }
   ],
   "source": [
    "# Fit and evaluate best model\n",
    "\n",
    "xgb_best = XGBClassifier(max_depth = 3, subsample = 0.6, colsample_bylevel = 0.2, colsample_bytree = 0.9, learning_rate = 0.7, n_estimators = 100, gamma = 0)\n",
    "\n",
    "xgb_best.fit(X_train, y_train)\n",
    "xgb_best_pred = xgb_best.predict(X_test)\n",
    "\n",
    "xgb_best_acc = accuracy_score(y_test, xgb_best_pred)\n",
    "print(\"Accuracy =\", xgb_best_acc) #0.8470149253731343\n",
    "\n",
    "xgb_best_f1 = f1_score(y_test, xgb_best_pred)\n",
    "print(\"F1 Score =\", xgb_best_f1) #0.8038277511961723\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, xgb_best_pred))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, xgb_best_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "318e6206",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 19 artists>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "feature_importance = xgb_best.feature_importances_\n",
    "feature_names = list(X_train.columns)\n",
    "plt.barh(feature_names, feature_importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8973f17f",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance = final_xgb.feature_importances_\n",
    "feature_names = list(X_train.columns)\n",
    "\n",
    "plt.barh(feature_names, feature_importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51407377",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# plot feature importance\n",
    "plot_importance(model)\n",
    "pyplot.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
