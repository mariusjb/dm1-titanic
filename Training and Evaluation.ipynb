{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7104d2ce",
   "metadata": {},
   "source": [
    "# Training and Evaluation of different Machine Learning Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "202391f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load required packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ce61838",
   "metadata": {},
   "source": [
    "## Train and Test Data\n",
    "We load the train and the test data which we splitted in _preprocessing.ipynb_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "de0a10cb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Age_true</th>\n",
       "      <th>AgeGroup</th>\n",
       "      <th>FareGroup</th>\n",
       "      <th>CabinLvl</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "      <th>Title_Master</th>\n",
       "      <th>Title_Mr</th>\n",
       "      <th>Title_Mrs</th>\n",
       "      <th>Title_Ms</th>\n",
       "      <th>Title_Noble</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pclass  SibSp  Parch  Age_true  AgeGroup  FareGroup  CabinLvl  Embarked_C  \\\n",
       "0       1      0      2         1         0          4         7           0   \n",
       "1       3      0      0         0         3          1         0           0   \n",
       "2       3      1      1         1         0          2         0           0   \n",
       "3       2      1      2         1         4          3         0           0   \n",
       "4       2      1      1         1         4          3         0           0   \n",
       "\n",
       "   Embarked_Q  Embarked_S  Title_Master  Title_Mr  Title_Mrs  Title_Ms  \\\n",
       "0           0           1             1         0          0         0   \n",
       "1           0           1             0         1          0         0   \n",
       "2           0           1             0         0          0         1   \n",
       "3           0           1             0         1          0         0   \n",
       "4           0           1             0         1          0         0   \n",
       "\n",
       "   Title_Noble  Survived  \n",
       "0            0         1  \n",
       "1            0         0  \n",
       "2            0         1  \n",
       "3            0         0  \n",
       "4            0         0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Age_true</th>\n",
       "      <th>AgeGroup</th>\n",
       "      <th>FareGroup</th>\n",
       "      <th>CabinLvl</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "      <th>Title_Master</th>\n",
       "      <th>Title_Mr</th>\n",
       "      <th>Title_Mrs</th>\n",
       "      <th>Title_Ms</th>\n",
       "      <th>Title_Noble</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pclass  SibSp  Parch  Age_true  AgeGroup  FareGroup  CabinLvl  Embarked_C  \\\n",
       "0       3      1      1         0         0          2         0           1   \n",
       "1       2      0      0         1         3          1         0           0   \n",
       "2       3      0      0         1         2          1         0           0   \n",
       "3       2      0      1         1         0          3         0           0   \n",
       "4       3      1      0         1         1          2         0           1   \n",
       "\n",
       "   Embarked_Q  Embarked_S  Title_Master  Title_Mr  Title_Mrs  Title_Ms  \\\n",
       "0           0           0             1         0          0         0   \n",
       "1           0           1             0         1          0         0   \n",
       "2           0           1             0         1          0         0   \n",
       "3           0           1             0         0          0         1   \n",
       "4           0           0             0         0          0         1   \n",
       "\n",
       "   Title_Noble  Survived  \n",
       "0            0         1  \n",
       "1            0         0  \n",
       "2            0         0  \n",
       "3            0         1  \n",
       "4            0         1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# read train and test data\n",
    "\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "# train_data\n",
    "train_data_files = sorted([f for f in os.listdir(\"data\") if (f.endswith(\".csv\") and (f.startswith(\"train_data_\")))], reverse=True)\n",
    "latest_train_data = train_data_files[0]\n",
    "train_data = pd.read_csv(f\"data/{latest_train_data}\")\n",
    "\n",
    "# drop new generated index column\n",
    "train_data.drop(train_data.columns[0], axis=1, inplace=True)\n",
    "display(train_data.head())\n",
    "\n",
    "# split train_data for models\n",
    "y_train = train_data['Survived']\n",
    "X_train = train_data.drop('Survived', axis=1)\n",
    "\n",
    "\n",
    "# test_data\n",
    "test_data_files = sorted([f for f in os.listdir(\"data\") if (f.endswith(\".csv\") and (f.startswith(\"test_data_\")))], reverse=True)\n",
    "latest_test_data = test_data_files[0]\n",
    "test_data = pd.read_csv(f\"data/{latest_test_data}\")\n",
    "\n",
    "#drop new generated index column\n",
    "test_data.drop(test_data.columns[0], axis=1, inplace=True)\n",
    "display(test_data.head())\n",
    "\n",
    "# split test_data for models\n",
    "y_test = test_data['Survived']\n",
    "X_test = test_data.drop('Survived', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72de1a37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "675b47e0",
   "metadata": {},
   "source": [
    "## Model 1: Baseline Model\n",
    "\n",
    "Option A: Our baseline model predicts \"No Survival\" (Class 0) for all passengers since 0 is the most common value of variable 'Survived' in the train data. This results in an accuracy of 58.58% and a f1 score of 0% on the test data.  \n",
    "Option B: Our baseline model predicts \"Survival\" (Class 1) for first-class passengers and \"No Survival\" (Class 0) if a passenger has ticket class 2 or 3. We determined those values by taking the most common value of the variable 'Survived' for each 'Pclass' in the train data. This results in an accuracy of 69.40% and a f1 score of 56.38% on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "149eba15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.585820895522388\n",
      "F1 Score = 0.0\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      1.00      0.74       157\n",
      "           1       0.00      0.00      0.00       111\n",
      "\n",
      "    accuracy                           0.59       268\n",
      "   macro avg       0.29      0.50      0.37       268\n",
      "weighted avg       0.34      0.59      0.43       268\n",
      "\n",
      "Confusion Matrix:\n",
      "[[157   0]\n",
      " [111   0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kikip\\anaconda3\\envs\\dm1_hws22\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\kikip\\anaconda3\\envs\\dm1_hws22\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\kikip\\anaconda3\\envs\\dm1_hws22\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Option A - predict \"No Survival\" for all passengers\n",
    "train_data.groupby('Survived').size()\n",
    "\n",
    "baseline_pred_A = pd.Series(np.zeros(len(y_test)))\n",
    "\n",
    "baseline_acc_A = accuracy_score(y_test, baseline_pred_A)\n",
    "print(\"Accuracy =\", baseline_acc_A) #0.585820895522388\n",
    "\n",
    "baseline_f1_A = f1_score(y_test, baseline_pred_A)\n",
    "print(\"F1 Score =\", baseline_f1_A) #0.0\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, baseline_pred_A))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, baseline_pred_A))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "62b13d8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pclass  Survived\n",
      "1       0            56\n",
      "        1            83\n",
      "2       0            69\n",
      "        1            63\n",
      "3       0           267\n",
      "        1            85\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Option B - predict \"Survival\" or \"No Survival\" based on 'Pclass'\n",
    "\n",
    "# for each 'PClass' find number of passengers that survived and did not survive\n",
    "print(train_data.groupby(['Pclass', 'Survived']).size())\n",
    "# if 'Pclass'==1, we predict 'Survived'=1, else we predict 'Survived'=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3a04d4b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.6940298507462687\n",
      "F1 Score = 0.5638297872340425\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.85      0.76       157\n",
      "           1       0.69      0.48      0.56       111\n",
      "\n",
      "    accuracy                           0.69       268\n",
      "   macro avg       0.69      0.66      0.66       268\n",
      "weighted avg       0.69      0.69      0.68       268\n",
      "\n",
      "Confusion Matrix:\n",
      "[[133  24]\n",
      " [ 58  53]]\n"
     ]
    }
   ],
   "source": [
    "# make prediction\n",
    "X_test['baseline_pred_B'] = 0\n",
    "X_test.loc[X_test['Pclass'] == 1, 'baseline_pred_B'] = 1\n",
    "baseline_pred_B = X_test.baseline_pred_B\n",
    "X_test.drop('baseline_pred_B', axis=1, inplace=True)\n",
    "\n",
    "# print performance measures\n",
    "baseline_acc_B = accuracy_score(y_test, baseline_pred_B)\n",
    "print(\"Accuracy =\", baseline_acc_B) #0.6940298507462687\n",
    "\n",
    "baseline_f1_B = f1_score(y_test, baseline_pred_B)\n",
    "print(\"F1 Score =\", baseline_f1_B) #0.5638297872340425\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, baseline_pred_B))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, baseline_pred_B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b87fee6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "41d03a15",
   "metadata": {},
   "source": [
    "## Model 2: XGBoost\n",
    "We train the _XGBClassifier_ from the _xgboost_-module. First, we train a simple model with the default parameters and then we perform grid search to determine the best hyper parameter combination for our data set.\n",
    "\n",
    "https://www.datacamp.com/tutorial/xgboost-in-python  \n",
    "https://thinkingneuron.com/how-to-create-a-classification-model-using-xgboost-in-python/  \n",
    "https://towardsdatascience.com/a-guide-to-xgboost-hyperparameters-87980c7f44a9 (Hyperparameter Cheatsheet)  \n",
    "https://towardsdatascience.com/beyond-grid-search-hypercharge-hyperparameter-tuning-for-xgboost-7c78f7a2929d (Step by Step Tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "556c7c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "949742ca",
   "metadata": {},
   "source": [
    "### Simple XGB-Classifier with default parameters\n",
    "As a baseline for the xgboost Classifier we train it with the default parameters which results in an accuracy of 79.10% and a f1 score of 73.08%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0a53a8be",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.8097014925373134\n",
      "F1 Score = 0.7536231884057971\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.89      0.84       157\n",
      "           1       0.81      0.70      0.75       111\n",
      "\n",
      "    accuracy                           0.81       268\n",
      "   macro avg       0.81      0.79      0.80       268\n",
      "weighted avg       0.81      0.81      0.81       268\n",
      "\n",
      "Confusion Matrix:\n",
      "[[139  18]\n",
      " [ 33  78]]\n"
     ]
    }
   ],
   "source": [
    "# simple XGB-Classifier with default parameters\n",
    "\n",
    "random.seed(10)\n",
    "\n",
    "xgb_simple = XGBClassifier()\n",
    "xgb_simple.fit(X_train, y_train)\n",
    "xgb_simple_pred = xgb_simple.predict(X_test)\n",
    "\n",
    "xgb_simple_acc = accuracy_score(y_test, xgb_simple_pred)\n",
    "print(\"Accuracy =\", xgb_simple_acc) #0.7910447761194029\n",
    "\n",
    "xgb_simple_f1 = f1_score(y_test, xgb_simple_pred)\n",
    "print(\"F1 Score =\", xgb_simple_f1) #0.7307692307692308\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, xgb_simple_pred))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, xgb_simple_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "079b5fd7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9fb5892c",
   "metadata": {},
   "source": [
    "### Hyper parameter-Tuning for best hyper parameter setting\n",
    "\n",
    "We perform grid search to find the best hyper parameter setting using the following hyper parameters:\n",
    "- _max_depth_\n",
    "- _subsample_\n",
    "- _gamma_\n",
    "- _colsample_bytree_\n",
    "- _colsample_bylevel_\n",
    "- _learning_rate_\n",
    "- _n _estimators_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "387ab105",
   "metadata": {},
   "source": [
    "#### First Attempt\n",
    "We start by tuning on a small grid, i.e., we only use two possible values for each hyper parameter. The best combination of hyper parameters for this grid search is: {'colsample_bylevel': 0.3, 'colsample_bytree': 0.3, 'learning_rate': 0.3, 'max_depth': 3, 'n_estimators': 50, 'subsample': 0.8}. Then, we train the XGBoost Classifier with this hyper parameter setting on the whole train data which results in an accuracy of 82.09% and a f1 score of 77.36%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "48dc982a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_colsample_bylevel</th>\n",
       "      <th>param_colsample_bytree</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_subsample</th>\n",
       "      <th>...</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.038495</td>\n",
       "      <td>0.003062</td>\n",
       "      <td>0.006681</td>\n",
       "      <td>0.000456</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>3</td>\n",
       "      <td>50</td>\n",
       "      <td>0.3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.818433</td>\n",
       "      <td>0.049987</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.036502</td>\n",
       "      <td>0.000662</td>\n",
       "      <td>0.006683</td>\n",
       "      <td>0.000457</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>3</td>\n",
       "      <td>50</td>\n",
       "      <td>0.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.824885</td>\n",
       "      <td>0.055524</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.068317</td>\n",
       "      <td>0.003433</td>\n",
       "      <td>0.006682</td>\n",
       "      <td>0.000639</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>0.3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.834485</td>\n",
       "      <td>0.040747</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.069015</td>\n",
       "      <td>0.006352</td>\n",
       "      <td>0.007181</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>0.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.887097</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.836073</td>\n",
       "      <td>0.052347</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.046675</td>\n",
       "      <td>0.004501</td>\n",
       "      <td>0.007482</td>\n",
       "      <td>0.000807</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "      <td>0.3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.818433</td>\n",
       "      <td>0.052027</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>0.092054</td>\n",
       "      <td>0.012248</td>\n",
       "      <td>0.007182</td>\n",
       "      <td>0.001244</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.7</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>0.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.823067</td>\n",
       "      <td>0.065056</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>0.049867</td>\n",
       "      <td>0.003569</td>\n",
       "      <td>0.006881</td>\n",
       "      <td>0.000699</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.7</td>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "      <td>0.3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.794470</td>\n",
       "      <td>0.050498</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>0.058244</td>\n",
       "      <td>0.007180</td>\n",
       "      <td>0.006883</td>\n",
       "      <td>0.001218</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.7</td>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "      <td>0.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.816846</td>\n",
       "      <td>0.053297</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>0.091609</td>\n",
       "      <td>0.011597</td>\n",
       "      <td>0.007080</td>\n",
       "      <td>0.000829</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.7</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>0.3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.803917</td>\n",
       "      <td>0.053965</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>0.106566</td>\n",
       "      <td>0.015866</td>\n",
       "      <td>0.008079</td>\n",
       "      <td>0.001574</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.7</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>0.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.812033</td>\n",
       "      <td>0.046151</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>64 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0        0.038495      0.003062         0.006681        0.000456   \n",
       "1        0.036502      0.000662         0.006683        0.000457   \n",
       "2        0.068317      0.003433         0.006682        0.000639   \n",
       "3        0.069015      0.006352         0.007181        0.000399   \n",
       "4        0.046675      0.004501         0.007482        0.000807   \n",
       "..            ...           ...              ...             ...   \n",
       "59       0.092054      0.012248         0.007182        0.001244   \n",
       "60       0.049867      0.003569         0.006881        0.000699   \n",
       "61       0.058244      0.007180         0.006883        0.001218   \n",
       "62       0.091609      0.011597         0.007080        0.000829   \n",
       "63       0.106566      0.015866         0.008079        0.001574   \n",
       "\n",
       "   param_colsample_bylevel param_colsample_bytree param_learning_rate  \\\n",
       "0                      0.3                    0.3                 0.3   \n",
       "1                      0.3                    0.3                 0.3   \n",
       "2                      0.3                    0.3                 0.3   \n",
       "3                      0.3                    0.3                 0.3   \n",
       "4                      0.3                    0.3                 0.3   \n",
       "..                     ...                    ...                 ...   \n",
       "59                     0.8                    0.8                 0.7   \n",
       "60                     0.8                    0.8                 0.7   \n",
       "61                     0.8                    0.8                 0.7   \n",
       "62                     0.8                    0.8                 0.7   \n",
       "63                     0.8                    0.8                 0.7   \n",
       "\n",
       "   param_max_depth param_n_estimators param_subsample  ... split3_test_score  \\\n",
       "0                3                 50             0.3  ...          0.854839   \n",
       "1                3                 50             0.8  ...          0.854839   \n",
       "2                3                100             0.3  ...          0.854839   \n",
       "3                3                100             0.8  ...          0.838710   \n",
       "4                5                 50             0.3  ...          0.854839   \n",
       "..             ...                ...             ...  ...               ...   \n",
       "59               3                100             0.8  ...          0.854839   \n",
       "60               5                 50             0.3  ...          0.838710   \n",
       "61               5                 50             0.8  ...          0.854839   \n",
       "62               5                100             0.3  ...          0.806452   \n",
       "63               5                100             0.8  ...          0.854839   \n",
       "\n",
       "    split4_test_score  split5_test_score  split6_test_score  \\\n",
       "0            0.790323           0.806452           0.790323   \n",
       "1            0.806452           0.870968           0.790323   \n",
       "2            0.822581           0.854839           0.790323   \n",
       "3            0.806452           0.887097           0.806452   \n",
       "4            0.774194           0.806452           0.806452   \n",
       "..                ...                ...                ...   \n",
       "59           0.790323           0.806452           0.822581   \n",
       "60           0.741935           0.741935           0.790323   \n",
       "61           0.790323           0.774194           0.822581   \n",
       "62           0.741935           0.741935           0.838710   \n",
       "63           0.790323           0.790323           0.854839   \n",
       "\n",
       "    split7_test_score  split8_test_score  split9_test_score  mean_test_score  \\\n",
       "0            0.822581           0.693548           0.854839         0.818433   \n",
       "1            0.822581           0.677419           0.854839         0.824885   \n",
       "2            0.822581           0.741935           0.838710         0.834485   \n",
       "3            0.822581           0.709677           0.854839         0.836073   \n",
       "4            0.806452           0.693548           0.870968         0.818433   \n",
       "..                ...                ...                ...              ...   \n",
       "59           0.758065           0.693548           0.806452         0.823067   \n",
       "60           0.838710           0.709677           0.854839         0.794470   \n",
       "61           0.822581           0.709677           0.838710         0.816846   \n",
       "62           0.774194           0.725806           0.838710         0.803917   \n",
       "63           0.774194           0.709677           0.806452         0.812033   \n",
       "\n",
       "    std_test_score  rank_test_score  \n",
       "0         0.049987               41  \n",
       "1         0.055524               23  \n",
       "2         0.040747                3  \n",
       "3         0.052347                2  \n",
       "4         0.052027               41  \n",
       "..             ...              ...  \n",
       "59        0.065056               33  \n",
       "60        0.050498               63  \n",
       "61        0.053297               50  \n",
       "62        0.053965               59  \n",
       "63        0.046151               53  \n",
       "\n",
       "[64 rows x 24 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score is 0.8360983102918587 with params {'colsample_bylevel': 0.3, 'colsample_bytree': 0.3, 'learning_rate': 0.7, 'max_depth': 3, 'n_estimators': 50, 'subsample': 0.8}\n"
     ]
    }
   ],
   "source": [
    "# First Attempt\n",
    "\n",
    "random.seed(10)\n",
    "\n",
    "# create an estimator\n",
    "xgb = XGBClassifier()\n",
    "\n",
    "# specify the parameter grid\n",
    "xgb_parameters = {\n",
    "    'max_depth': [3, 5]\n",
    "    , 'subsample': [0.3, 0.8]\n",
    "    , 'colsample_bytree': [0.3, 0.8]\n",
    "    , 'colsample_bylevel': [0.3, 0.8]\n",
    "    , 'learning_rate': [0.3, 0.7]\n",
    "    , 'n_estimators': [50, 100]\n",
    "    #, 'gamma': [0.5, 1, 3]\n",
    "}\n",
    "\n",
    "# specify the cross validation\n",
    "stratified_10_fold_cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "# create grid search instance\n",
    "xgb_grid_search = GridSearchCV(xgb, xgb_parameters, scoring='accuracy', cv=stratified_10_fold_cv)\n",
    "\n",
    "# run the grid search\n",
    "xgb_grid_search.fit(X_train, y_train)\n",
    "\n",
    "# print the results of all hyper parameter combinations\n",
    "xgb_grid_search_results_round1 = pd.DataFrame(xgb_grid_search.cv_results_)\n",
    "display(xgb_grid_search_results_round1)\n",
    "\n",
    "# print the best parameter setting\n",
    "print(\"best score is {} with params {}\".format(xgb_grid_search.best_score_, xgb_grid_search.best_params_))\n",
    "#best score is 0.8409114183307732 with params\n",
    "#{'colsample_bylevel': 0.3, 'colsample_bytree': 0.3, 'learning_rate': 0.3, 'max_depth': 3, 'n_estimators': 50, 'subsample': 0.8}\n",
    "\n",
    "# save dataframe\n",
    "from datetime import datetime\n",
    "date = str(datetime.now().date()).replace(\"-\", \"\")\n",
    "xgb_grid_search_results_round1.to_csv(f\"results/xgb_results_round1_{date}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4abbd5a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_subsample</th>\n",
       "      <th>param_colsample_bylevel</th>\n",
       "      <th>param_colsample_bytree</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>50</td>\n",
       "      <td>0.840911</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>100</td>\n",
       "      <td>0.840911</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.7</td>\n",
       "      <td>100</td>\n",
       "      <td>0.839247</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>5</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.3</td>\n",
       "      <td>50</td>\n",
       "      <td>0.836175</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>3</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.3</td>\n",
       "      <td>50</td>\n",
       "      <td>0.836098</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.7</td>\n",
       "      <td>50</td>\n",
       "      <td>0.797491</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.7</td>\n",
       "      <td>100</td>\n",
       "      <td>0.797491</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.7</td>\n",
       "      <td>100</td>\n",
       "      <td>0.795955</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.7</td>\n",
       "      <td>50</td>\n",
       "      <td>0.792857</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.7</td>\n",
       "      <td>50</td>\n",
       "      <td>0.784869</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>64 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   param_max_depth param_subsample param_colsample_bylevel  \\\n",
       "1                3             0.8                     0.3   \n",
       "3                3             0.8                     0.3   \n",
       "11               3             0.8                     0.3   \n",
       "21               5             0.8                     0.3   \n",
       "17               3             0.8                     0.3   \n",
       "..             ...             ...                     ...   \n",
       "28               5             0.3                     0.3   \n",
       "46               5             0.3                     0.8   \n",
       "30               5             0.3                     0.3   \n",
       "44               5             0.3                     0.8   \n",
       "60               5             0.3                     0.8   \n",
       "\n",
       "   param_colsample_bytree param_learning_rate param_n_estimators  \\\n",
       "1                     0.3                 0.3                 50   \n",
       "3                     0.3                 0.3                100   \n",
       "11                    0.3                 0.7                100   \n",
       "21                    0.8                 0.3                 50   \n",
       "17                    0.8                 0.3                 50   \n",
       "..                    ...                 ...                ...   \n",
       "28                    0.8                 0.7                 50   \n",
       "46                    0.3                 0.7                100   \n",
       "30                    0.8                 0.7                100   \n",
       "44                    0.3                 0.7                 50   \n",
       "60                    0.8                 0.7                 50   \n",
       "\n",
       "    mean_test_score  rank_test_score  \n",
       "1          0.840911                1  \n",
       "3          0.840911                1  \n",
       "11         0.839247                3  \n",
       "21         0.836175                4  \n",
       "17         0.836098                5  \n",
       "..              ...              ...  \n",
       "28         0.797491               60  \n",
       "46         0.797491               61  \n",
       "30         0.795955               62  \n",
       "44         0.792857               63  \n",
       "60         0.784869               64  \n",
       "\n",
       "[64 rows x 8 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# store relevant columns and sort by rank_test_score\n",
    "cols_round1 = ['param_max_depth', 'param_subsample', 'param_colsample_bylevel', 'param_colsample_bytree', 'param_learning_rate', 'param_n_estimators', 'mean_test_score', 'rank_test_score']\n",
    "xgb_results_round1_sorted = xgb_grid_search_results_round1[cols_round1]\n",
    "xgb_results_round1_sorted = xgb_results_round1_sorted.sort_values(by='rank_test_score')\n",
    "display(xgb_results_round1_sorted)\n",
    "\n",
    "# save dataframe\n",
    "from datetime import datetime\n",
    "date = str(datetime.now().date()).replace(\"-\", \"\")\n",
    "xgb_results_round1_sorted.to_csv(f\"results/xgb_results_round1_sorted_{date}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aec0ba87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.8208955223880597\n",
      "F1 Score = 0.7735849056603774\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.88      0.85       157\n",
      "           1       0.81      0.74      0.77       111\n",
      "\n",
      "    accuracy                           0.82       268\n",
      "   macro avg       0.82      0.81      0.81       268\n",
      "weighted avg       0.82      0.82      0.82       268\n",
      "\n",
      "Confusion Matrix:\n",
      "[[138  19]\n",
      " [ 29  82]]\n"
     ]
    }
   ],
   "source": [
    "# Fit and evaluate best model\n",
    "\n",
    "xgb_best = XGBClassifier(max_depth = 3, subsample = 0.8, colsample_bylevel = 0.3, colsample_bytree = 0.3, learning_rate = 0.3, n_estimators = 50)\n",
    "xgb_best.fit(X_train, y_train)\n",
    "xgb_best_pred = xgb_best.predict(X_test)\n",
    "\n",
    "xgb_best_acc = accuracy_score(y_test, xgb_best_pred)\n",
    "print(\"Accuracy =\", xgb_best_acc) #0.8208955223880597\n",
    "\n",
    "xgb_best_f1 = f1_score(y_test, xgb_best_pred)\n",
    "print(\"F1 Score =\", xgb_best_f1) #0.7735849056603774\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, xgb_best_pred))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, xgb_best_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "940748c1",
   "metadata": {},
   "source": [
    "#### Second Attempt\n",
    "We perform a hyper parameter tuning using the following parameters and values:  \n",
    "\n",
    "{'max_depth': [2,3,4,5]  \n",
    ", 'subsample': [0.5, 0.6, 0.7, 0.8, 0.9]  \n",
    ", 'colsample_bytree': [0.3, 0.4, 0.5, 0.6, 0.9]  \n",
    ", 'colsample_bylevel': [0.1, 0.2, 0.3, 0.4, 0.6, 0.7]  \n",
    ", 'learning_rate': [0.1, 0.15, 0.2, 0.25, 0.3, 0.4]  \n",
    ", 'n_estimators': [100, 150, 200, 250, 300]}  \n",
    "\n",
    "The best hyper parameter setting results to be {'colsample_bylevel': 0.4, 'colsample_bytree': 0.5, 'learning_rate': 0.15, 'max_depth': 2, 'n_estimators': 100, 'subsample': 0.7} which leads to an accuracy of 82.84% and a f1 score of 77.88% on the test data (after training the classifier on the whole train data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f96d3ba4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_colsample_bylevel</th>\n",
       "      <th>param_colsample_bytree</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_subsample</th>\n",
       "      <th>...</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.064527</td>\n",
       "      <td>0.004136</td>\n",
       "      <td>0.005885</td>\n",
       "      <td>0.000538</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.820020</td>\n",
       "      <td>0.048275</td>\n",
       "      <td>15186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.064327</td>\n",
       "      <td>0.002493</td>\n",
       "      <td>0.005885</td>\n",
       "      <td>0.000537</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.661290</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.823221</td>\n",
       "      <td>0.059057</td>\n",
       "      <td>12810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.063231</td>\n",
       "      <td>0.001954</td>\n",
       "      <td>0.005785</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.824782</td>\n",
       "      <td>0.057512</td>\n",
       "      <td>12084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.062235</td>\n",
       "      <td>0.001017</td>\n",
       "      <td>0.006082</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.661290</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.824834</td>\n",
       "      <td>0.059251</td>\n",
       "      <td>11402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.062333</td>\n",
       "      <td>0.002285</td>\n",
       "      <td>0.005784</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.828059</td>\n",
       "      <td>0.053977</td>\n",
       "      <td>8256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17995</th>\n",
       "      <td>0.228489</td>\n",
       "      <td>0.002462</td>\n",
       "      <td>0.007480</td>\n",
       "      <td>0.000499</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.802355</td>\n",
       "      <td>0.049888</td>\n",
       "      <td>17998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17996</th>\n",
       "      <td>0.228688</td>\n",
       "      <td>0.002142</td>\n",
       "      <td>0.007281</td>\n",
       "      <td>0.000457</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.800768</td>\n",
       "      <td>0.052893</td>\n",
       "      <td>17999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17997</th>\n",
       "      <td>0.228987</td>\n",
       "      <td>0.001197</td>\n",
       "      <td>0.007580</td>\n",
       "      <td>0.000488</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.810317</td>\n",
       "      <td>0.057193</td>\n",
       "      <td>17871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17998</th>\n",
       "      <td>0.228788</td>\n",
       "      <td>0.001620</td>\n",
       "      <td>0.007181</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.816692</td>\n",
       "      <td>0.055624</td>\n",
       "      <td>17108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17999</th>\n",
       "      <td>0.226893</td>\n",
       "      <td>0.002150</td>\n",
       "      <td>0.007381</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.818382</td>\n",
       "      <td>0.053516</td>\n",
       "      <td>16381</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18000 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0           0.064527      0.004136         0.005885        0.000538   \n",
       "1           0.064327      0.002493         0.005885        0.000537   \n",
       "2           0.063231      0.001954         0.005785        0.000399   \n",
       "3           0.062235      0.001017         0.006082        0.000300   \n",
       "4           0.062333      0.002285         0.005784        0.000399   \n",
       "...              ...           ...              ...             ...   \n",
       "17995       0.228489      0.002462         0.007480        0.000499   \n",
       "17996       0.228688      0.002142         0.007281        0.000457   \n",
       "17997       0.228987      0.001197         0.007580        0.000488   \n",
       "17998       0.228788      0.001620         0.007181        0.000399   \n",
       "17999       0.226893      0.002150         0.007381        0.000489   \n",
       "\n",
       "       param_colsample_bylevel  param_colsample_bytree  param_learning_rate  \\\n",
       "0                          0.1                     0.3                  0.1   \n",
       "1                          0.1                     0.3                  0.1   \n",
       "2                          0.1                     0.3                  0.1   \n",
       "3                          0.1                     0.3                  0.1   \n",
       "4                          0.1                     0.3                  0.1   \n",
       "...                        ...                     ...                  ...   \n",
       "17995                      0.7                     0.9                  0.4   \n",
       "17996                      0.7                     0.9                  0.4   \n",
       "17997                      0.7                     0.9                  0.4   \n",
       "17998                      0.7                     0.9                  0.4   \n",
       "17999                      0.7                     0.9                  0.4   \n",
       "\n",
       "       param_max_depth  param_n_estimators  param_subsample  ...  \\\n",
       "0                    2                 100              0.5  ...   \n",
       "1                    2                 100              0.6  ...   \n",
       "2                    2                 100              0.7  ...   \n",
       "3                    2                 100              0.8  ...   \n",
       "4                    2                 100              0.9  ...   \n",
       "...                ...                 ...              ...  ...   \n",
       "17995                5                 300              0.5  ...   \n",
       "17996                5                 300              0.6  ...   \n",
       "17997                5                 300              0.7  ...   \n",
       "17998                5                 300              0.8  ...   \n",
       "17999                5                 300              0.9  ...   \n",
       "\n",
       "      split3_test_score  split4_test_score  split5_test_score  \\\n",
       "0              0.822581           0.822581           0.806452   \n",
       "1              0.838710           0.822581           0.806452   \n",
       "2              0.838710           0.806452           0.806452   \n",
       "3              0.854839           0.822581           0.806452   \n",
       "4              0.854839           0.822581           0.838710   \n",
       "...                 ...                ...                ...   \n",
       "17995          0.822581           0.774194           0.806452   \n",
       "17996          0.822581           0.774194           0.790323   \n",
       "17997          0.870968           0.774194           0.774194   \n",
       "17998          0.822581           0.790323           0.774194   \n",
       "17999          0.806452           0.790323           0.774194   \n",
       "\n",
       "       split6_test_score  split7_test_score  split8_test_score  \\\n",
       "0               0.822581           0.806452           0.693548   \n",
       "1               0.838710           0.806452           0.661290   \n",
       "2               0.838710           0.806452           0.677419   \n",
       "3               0.854839           0.806452           0.661290   \n",
       "4               0.838710           0.806452           0.677419   \n",
       "...                  ...                ...                ...   \n",
       "17995           0.822581           0.774194           0.709677   \n",
       "17996           0.822581           0.790323           0.693548   \n",
       "17997           0.790323           0.790323           0.709677   \n",
       "17998           0.822581           0.790323           0.709677   \n",
       "17999           0.854839           0.790323           0.709677   \n",
       "\n",
       "       split9_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0               0.838710         0.820020        0.048275            15186  \n",
       "1               0.854839         0.823221        0.059057            12810  \n",
       "2               0.838710         0.824782        0.057512            12084  \n",
       "3               0.838710         0.824834        0.059251            11402  \n",
       "4               0.838710         0.828059        0.053977             8256  \n",
       "...                  ...              ...             ...              ...  \n",
       "17995           0.774194         0.802355        0.049888            17998  \n",
       "17996           0.790323         0.800768        0.052893            17999  \n",
       "17997           0.790323         0.810317        0.057193            17871  \n",
       "17998           0.806452         0.816692        0.055624            17108  \n",
       "17999           0.854839         0.818382        0.053516            16381  \n",
       "\n",
       "[18000 rows x 24 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score is 0.850563 with params {'colsample_bylevel': 0.4, 'colsample_bytree': 0.5, 'learning_rate': 0.15, 'max_depth': 2, 'n_estimators': 100, 'subsample': 0.7}\n"
     ]
    }
   ],
   "source": [
    "# read single parts of round 2, concatenate and update index and rank_test_score\n",
    "\n",
    "df1 = pd.read_csv(\"data\\\\xgb_results_full_1_bylevel=0.1_20221123.csv\")\n",
    "df1.drop(df1.columns[0], axis=1, inplace=True)\n",
    "\n",
    "df2 = pd.read_csv(\"data\\\\xgb_results_full_2_bylevel=0.2_20221123.csv\")\n",
    "df2.drop(df2.columns[0], axis=1, inplace=True)\n",
    "\n",
    "df3 = pd.read_csv(\"data\\\\xgb_results_full_3_bylevel=0.3_20221123.csv\")\n",
    "df3.drop(df3.columns[0], axis=1, inplace=True)\n",
    "\n",
    "df4 = pd.read_csv(\"data\\\\xgb_results_full_4_bylevel=0.4_20221123.csv\")\n",
    "df4.drop(df4.columns[0], axis=1, inplace=True)\n",
    "\n",
    "df5 = pd.read_csv(\"data\\\\xgb_results_full_5_bylevel=0.6_20221123.csv\")\n",
    "df5.drop(df5.columns[0], axis=1, inplace=True)\n",
    "\n",
    "df6 = pd.read_csv(\"data\\\\xgb_results_full_6_bylevel=0.7_20221123.csv\")\n",
    "df6.drop(df6.columns[0], axis=1, inplace=True)\n",
    "\n",
    "df_full = pd.concat([df1,df2,df3,df4,df5,df6])\n",
    "\n",
    "#assign correct rank\n",
    "df_full = df_full.sort_values(by='mean_test_score', ascending=False)\n",
    "df_full['rank_test_score'] = range(1, len(df_full)+1)\n",
    "\n",
    "#get correct order and set new index\n",
    "df_full = df_full.sort_values(by=['param_colsample_bylevel', 'param_colsample_bytree', 'param_learning_rate', 'param_max_depth', 'param_n_estimators', 'param_subsample'])\n",
    "xgb_grid_search_results_round2 = df_full.set_index(np.array(range(len(df_full))))\n",
    "display(xgb_grid_search_results_round2)\n",
    "\n",
    "print(\"best score is 0.850563 with params {'colsample_bylevel': 0.4, 'colsample_bytree': 0.5, 'learning_rate': 0.15, 'max_depth': 2, 'n_estimators': 100, 'subsample': 0.7}\")\n",
    "\n",
    "# save dataframe\n",
    "from datetime import datetime\n",
    "date = str(datetime.now().date()).replace(\"-\", \"\")\n",
    "xgb_grid_search_results_round2.to_csv(f\"results/xgb_results_round2_{date}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "435465f2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_colsample_bylevel</th>\n",
       "      <th>param_colsample_bytree</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_subsample</th>\n",
       "      <th>...</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.064527</td>\n",
       "      <td>0.004136</td>\n",
       "      <td>0.005885</td>\n",
       "      <td>0.000538</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.820020</td>\n",
       "      <td>0.048275</td>\n",
       "      <td>2840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.064327</td>\n",
       "      <td>0.002493</td>\n",
       "      <td>0.005885</td>\n",
       "      <td>0.000537</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.661290</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.823221</td>\n",
       "      <td>0.059057</td>\n",
       "      <td>5179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.063231</td>\n",
       "      <td>0.001954</td>\n",
       "      <td>0.005785</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.824782</td>\n",
       "      <td>0.057512</td>\n",
       "      <td>5860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.062235</td>\n",
       "      <td>0.001017</td>\n",
       "      <td>0.006082</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.661290</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.824834</td>\n",
       "      <td>0.059251</td>\n",
       "      <td>6715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.062333</td>\n",
       "      <td>0.002285</td>\n",
       "      <td>0.005784</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.828059</td>\n",
       "      <td>0.053977</td>\n",
       "      <td>9897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17995</th>\n",
       "      <td>0.228489</td>\n",
       "      <td>0.002462</td>\n",
       "      <td>0.007480</td>\n",
       "      <td>0.000499</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.802355</td>\n",
       "      <td>0.049888</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17996</th>\n",
       "      <td>0.228688</td>\n",
       "      <td>0.002142</td>\n",
       "      <td>0.007281</td>\n",
       "      <td>0.000457</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.800768</td>\n",
       "      <td>0.052893</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17997</th>\n",
       "      <td>0.228987</td>\n",
       "      <td>0.001197</td>\n",
       "      <td>0.007580</td>\n",
       "      <td>0.000488</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.810317</td>\n",
       "      <td>0.057193</td>\n",
       "      <td>139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17998</th>\n",
       "      <td>0.228788</td>\n",
       "      <td>0.001620</td>\n",
       "      <td>0.007181</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.816692</td>\n",
       "      <td>0.055624</td>\n",
       "      <td>893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17999</th>\n",
       "      <td>0.226893</td>\n",
       "      <td>0.002150</td>\n",
       "      <td>0.007381</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.818382</td>\n",
       "      <td>0.053516</td>\n",
       "      <td>1646</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18000 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0           0.064527      0.004136         0.005885        0.000538   \n",
       "1           0.064327      0.002493         0.005885        0.000537   \n",
       "2           0.063231      0.001954         0.005785        0.000399   \n",
       "3           0.062235      0.001017         0.006082        0.000300   \n",
       "4           0.062333      0.002285         0.005784        0.000399   \n",
       "...              ...           ...              ...             ...   \n",
       "17995       0.228489      0.002462         0.007480        0.000499   \n",
       "17996       0.228688      0.002142         0.007281        0.000457   \n",
       "17997       0.228987      0.001197         0.007580        0.000488   \n",
       "17998       0.228788      0.001620         0.007181        0.000399   \n",
       "17999       0.226893      0.002150         0.007381        0.000489   \n",
       "\n",
       "       param_colsample_bylevel  param_colsample_bytree  param_learning_rate  \\\n",
       "0                          0.1                     0.3                  0.1   \n",
       "1                          0.1                     0.3                  0.1   \n",
       "2                          0.1                     0.3                  0.1   \n",
       "3                          0.1                     0.3                  0.1   \n",
       "4                          0.1                     0.3                  0.1   \n",
       "...                        ...                     ...                  ...   \n",
       "17995                      0.7                     0.9                  0.4   \n",
       "17996                      0.7                     0.9                  0.4   \n",
       "17997                      0.7                     0.9                  0.4   \n",
       "17998                      0.7                     0.9                  0.4   \n",
       "17999                      0.7                     0.9                  0.4   \n",
       "\n",
       "       param_max_depth  param_n_estimators  param_subsample  ...  \\\n",
       "0                    2                 100              0.5  ...   \n",
       "1                    2                 100              0.6  ...   \n",
       "2                    2                 100              0.7  ...   \n",
       "3                    2                 100              0.8  ...   \n",
       "4                    2                 100              0.9  ...   \n",
       "...                ...                 ...              ...  ...   \n",
       "17995                5                 300              0.5  ...   \n",
       "17996                5                 300              0.6  ...   \n",
       "17997                5                 300              0.7  ...   \n",
       "17998                5                 300              0.8  ...   \n",
       "17999                5                 300              0.9  ...   \n",
       "\n",
       "      split3_test_score  split4_test_score  split5_test_score  \\\n",
       "0              0.822581           0.822581           0.806452   \n",
       "1              0.838710           0.822581           0.806452   \n",
       "2              0.838710           0.806452           0.806452   \n",
       "3              0.854839           0.822581           0.806452   \n",
       "4              0.854839           0.822581           0.838710   \n",
       "...                 ...                ...                ...   \n",
       "17995          0.822581           0.774194           0.806452   \n",
       "17996          0.822581           0.774194           0.790323   \n",
       "17997          0.870968           0.774194           0.774194   \n",
       "17998          0.822581           0.790323           0.774194   \n",
       "17999          0.806452           0.790323           0.774194   \n",
       "\n",
       "       split6_test_score  split7_test_score  split8_test_score  \\\n",
       "0               0.822581           0.806452           0.693548   \n",
       "1               0.838710           0.806452           0.661290   \n",
       "2               0.838710           0.806452           0.677419   \n",
       "3               0.854839           0.806452           0.661290   \n",
       "4               0.838710           0.806452           0.677419   \n",
       "...                  ...                ...                ...   \n",
       "17995           0.822581           0.774194           0.709677   \n",
       "17996           0.822581           0.790323           0.693548   \n",
       "17997           0.790323           0.790323           0.709677   \n",
       "17998           0.822581           0.790323           0.709677   \n",
       "17999           0.854839           0.790323           0.709677   \n",
       "\n",
       "       split9_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0               0.838710         0.820020        0.048275             2840  \n",
       "1               0.854839         0.823221        0.059057             5179  \n",
       "2               0.838710         0.824782        0.057512             5860  \n",
       "3               0.838710         0.824834        0.059251             6715  \n",
       "4               0.838710         0.828059        0.053977             9897  \n",
       "...                  ...              ...             ...              ...  \n",
       "17995           0.774194         0.802355        0.049888                3  \n",
       "17996           0.790323         0.800768        0.052893                2  \n",
       "17997           0.790323         0.810317        0.057193              139  \n",
       "17998           0.806452         0.816692        0.055624              893  \n",
       "17999           0.854839         0.818382        0.053516             1646  \n",
       "\n",
       "[18000 rows x 24 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Second Attempt\n",
    "\n",
    "random.seed(10)\n",
    "\n",
    "xgb = XGBClassifier()\n",
    "\n",
    "xgb_parameters = {'max_depth': [2,3,4,5]\n",
    "                , 'subsample': [0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "                , 'colsample_bytree': [0.3, 0.4, 0.5, 0.6, 0.9]\n",
    "                , 'colsample_bylevel': [0.1, 0.2, 0.3, 0.4, 0.6, 0.7]\n",
    "                , 'learning_rate': [0.1, 0.15, 0.2, 0.25, 0.3, 0.4]\n",
    "                , 'n_estimators': [100, 150, 200, 250, 300]}\n",
    "\n",
    "stratified_10_fold_cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "xgb_grid_search = GridSearchCV(xgb, xgb_parameters, scoring='accuracy', cv=stratified_10_fold_cv)\n",
    "\n",
    "xgb_grid_search.fit(X_train, y_train)\n",
    "\n",
    "xgb_grid_search_results_round2 = pd.DataFrame(xgb_grid_search.cv_results_)\n",
    "display(xgb_grid_search_results_round2)\n",
    "\n",
    "# print the best parameter setting\n",
    "print(\"best score is {} with params {}\".format(xgb_grid_search.best_score_, xgb_grid_search.best_params_))\n",
    "#best score is 0.850563 with params\n",
    "#{'colsample_bylevel': 0.4, 'colsample_bytree': 0.5, 'learning_rate': 0.15, 'max_depth': 2, 'n_estimators': 100, 'subsample': 0.7}\n",
    "\n",
    "# save dataframe\n",
    "from datetime import datetime\n",
    "date = str(datetime.now().date()).replace(\"-\", \"\")\n",
    "xgb_grid_search_results_round2.to_csv(f\"results/xgb_results_round2_{date}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e682b560",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_subsample</th>\n",
       "      <th>param_colsample_bylevel</th>\n",
       "      <th>param_colsample_bytree</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10302</th>\n",
       "      <td>2</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.15</td>\n",
       "      <td>100</td>\n",
       "      <td>0.850563</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7302</th>\n",
       "      <td>2</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.15</td>\n",
       "      <td>100</td>\n",
       "      <td>0.850563</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4976</th>\n",
       "      <td>5</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.15</td>\n",
       "      <td>100</td>\n",
       "      <td>0.850538</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1976</th>\n",
       "      <td>5</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.15</td>\n",
       "      <td>100</td>\n",
       "      <td>0.850538</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5419</th>\n",
       "      <td>2</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.10</td>\n",
       "      <td>250</td>\n",
       "      <td>0.849002</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7745</th>\n",
       "      <td>3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.40</td>\n",
       "      <td>300</td>\n",
       "      <td>0.803943</td>\n",
       "      <td>17996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13171</th>\n",
       "      <td>4</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.40</td>\n",
       "      <td>300</td>\n",
       "      <td>0.803917</td>\n",
       "      <td>17997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17995</th>\n",
       "      <td>5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.40</td>\n",
       "      <td>300</td>\n",
       "      <td>0.802355</td>\n",
       "      <td>17998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17996</th>\n",
       "      <td>5</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.40</td>\n",
       "      <td>300</td>\n",
       "      <td>0.800768</td>\n",
       "      <td>17999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17940</th>\n",
       "      <td>3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.40</td>\n",
       "      <td>250</td>\n",
       "      <td>0.800742</td>\n",
       "      <td>18000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18000 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       param_max_depth  param_subsample  param_colsample_bylevel  \\\n",
       "10302                2              0.7                      0.4   \n",
       "7302                 2              0.7                      0.3   \n",
       "4976                 5              0.6                      0.2   \n",
       "1976                 5              0.6                      0.1   \n",
       "5419                 2              0.9                      0.2   \n",
       "...                ...              ...                      ...   \n",
       "7745                 3              0.5                      0.3   \n",
       "13171                4              0.6                      0.6   \n",
       "17995                5              0.5                      0.7   \n",
       "17996                5              0.6                      0.7   \n",
       "17940                3              0.5                      0.7   \n",
       "\n",
       "       param_colsample_bytree  param_learning_rate  param_n_estimators  \\\n",
       "10302                     0.5                 0.15                 100   \n",
       "7302                      0.5                 0.15                 100   \n",
       "4976                      0.6                 0.15                 100   \n",
       "1976                      0.6                 0.15                 100   \n",
       "5419                      0.9                 0.10                 250   \n",
       "...                       ...                  ...                 ...   \n",
       "7745                      0.5                 0.40                 300   \n",
       "13171                     0.4                 0.40                 300   \n",
       "17995                     0.9                 0.40                 300   \n",
       "17996                     0.9                 0.40                 300   \n",
       "17940                     0.9                 0.40                 250   \n",
       "\n",
       "       mean_test_score  rank_test_score  \n",
       "10302         0.850563                1  \n",
       "7302          0.850563                2  \n",
       "4976          0.850538                3  \n",
       "1976          0.850538                4  \n",
       "5419          0.849002                5  \n",
       "...                ...              ...  \n",
       "7745          0.803943            17996  \n",
       "13171         0.803917            17997  \n",
       "17995         0.802355            17998  \n",
       "17996         0.800768            17999  \n",
       "17940         0.800742            18000  \n",
       "\n",
       "[18000 rows x 8 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# store relevant columns and sort by rank_test_score\n",
    "cols_round2 = ['param_max_depth', 'param_subsample', 'param_colsample_bylevel', 'param_colsample_bytree', 'param_learning_rate', 'param_n_estimators', 'mean_test_score', 'rank_test_score']\n",
    "xgb_results_round2_sorted = xgb_grid_search_results_round2[cols_round2]\n",
    "xgb_results_round2_sorted = xgb_results_round2_sorted.sort_values(by='rank_test_score')\n",
    "display(xgb_results_round2_sorted)\n",
    "\n",
    "# save dataframe\n",
    "from datetime import datetime\n",
    "date = str(datetime.now().date()).replace(\"-\", \"\")\n",
    "xgb_results_round2_sorted.to_csv(f\"results/xgb_results_round2_sorted_{date}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fc655747",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.8283582089552238\n",
      "F1 Score = 0.7788461538461539\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.90      0.86       157\n",
      "           1       0.84      0.73      0.78       111\n",
      "\n",
      "    accuracy                           0.83       268\n",
      "   macro avg       0.83      0.81      0.82       268\n",
      "weighted avg       0.83      0.83      0.83       268\n",
      "\n",
      "Confusion Matrix:\n",
      "[[141  16]\n",
      " [ 30  81]]\n"
     ]
    }
   ],
   "source": [
    "# Fit and evaluate best model\n",
    "\n",
    "xgb_best = XGBClassifier(max_depth = 2, subsample = 0.7, colsample_bylevel = 0.4, colsample_bytree = 0.5, learning_rate = 0.15, n_estimators = 100)\n",
    "xgb_best.fit(X_train, y_train)\n",
    "xgb_best_pred = xgb_best.predict(X_test)\n",
    "\n",
    "xgb_best_acc = accuracy_score(y_test, xgb_best_pred)\n",
    "print(\"Accuracy =\", xgb_best_acc) #0.8283582089552238\n",
    "\n",
    "xgb_best_f1 = f1_score(y_test, xgb_best_pred)\n",
    "print(\"F1 Score =\", xgb_best_f1) #0.7788461538461539\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, xgb_best_pred))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, xgb_best_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "250c3acb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d82f44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "66e8dc94",
   "metadata": {},
   "source": [
    "#### ausführlich"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1dfcf6bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_colsample_bylevel</th>\n",
       "      <th>param_colsample_bytree</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_subsample</th>\n",
       "      <th>...</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.064527</td>\n",
       "      <td>0.004136</td>\n",
       "      <td>0.005885</td>\n",
       "      <td>5.376236e-04</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.820020</td>\n",
       "      <td>0.048275</td>\n",
       "      <td>2651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.064327</td>\n",
       "      <td>0.002493</td>\n",
       "      <td>0.005885</td>\n",
       "      <td>5.374151e-04</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.661290</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.823221</td>\n",
       "      <td>0.059057</td>\n",
       "      <td>2358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.063231</td>\n",
       "      <td>0.001954</td>\n",
       "      <td>0.005785</td>\n",
       "      <td>3.990535e-04</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.824782</td>\n",
       "      <td>0.057512</td>\n",
       "      <td>2252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.062235</td>\n",
       "      <td>0.001017</td>\n",
       "      <td>0.006082</td>\n",
       "      <td>3.001655e-04</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.661290</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.824834</td>\n",
       "      <td>0.059251</td>\n",
       "      <td>2175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.062333</td>\n",
       "      <td>0.002285</td>\n",
       "      <td>0.005784</td>\n",
       "      <td>3.991850e-04</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.828059</td>\n",
       "      <td>0.053977</td>\n",
       "      <td>1747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2995</th>\n",
       "      <td>0.180018</td>\n",
       "      <td>0.001496</td>\n",
       "      <td>0.007081</td>\n",
       "      <td>2.993507e-04</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.887097</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.828085</td>\n",
       "      <td>0.048801</td>\n",
       "      <td>1701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2996</th>\n",
       "      <td>0.182212</td>\n",
       "      <td>0.003339</td>\n",
       "      <td>0.006982</td>\n",
       "      <td>4.460618e-04</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.826421</td>\n",
       "      <td>0.052840</td>\n",
       "      <td>1992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2997</th>\n",
       "      <td>0.181813</td>\n",
       "      <td>0.001548</td>\n",
       "      <td>0.007082</td>\n",
       "      <td>2.990570e-04</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.824808</td>\n",
       "      <td>0.053239</td>\n",
       "      <td>2204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998</th>\n",
       "      <td>0.181666</td>\n",
       "      <td>0.001723</td>\n",
       "      <td>0.006982</td>\n",
       "      <td>4.529953e-07</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.823272</td>\n",
       "      <td>0.043729</td>\n",
       "      <td>2305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999</th>\n",
       "      <td>0.182113</td>\n",
       "      <td>0.002005</td>\n",
       "      <td>0.007081</td>\n",
       "      <td>2.993824e-04</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.823169</td>\n",
       "      <td>0.050024</td>\n",
       "      <td>2460</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0          0.064527      0.004136         0.005885    5.376236e-04   \n",
       "1          0.064327      0.002493         0.005885    5.374151e-04   \n",
       "2          0.063231      0.001954         0.005785    3.990535e-04   \n",
       "3          0.062235      0.001017         0.006082    3.001655e-04   \n",
       "4          0.062333      0.002285         0.005784    3.991850e-04   \n",
       "...             ...           ...              ...             ...   \n",
       "2995       0.180018      0.001496         0.007081    2.993507e-04   \n",
       "2996       0.182212      0.003339         0.006982    4.460618e-04   \n",
       "2997       0.181813      0.001548         0.007082    2.990570e-04   \n",
       "2998       0.181666      0.001723         0.006982    4.529953e-07   \n",
       "2999       0.182113      0.002005         0.007081    2.993824e-04   \n",
       "\n",
       "      param_colsample_bylevel  param_colsample_bytree  param_learning_rate  \\\n",
       "0                         0.1                     0.3                  0.1   \n",
       "1                         0.1                     0.3                  0.1   \n",
       "2                         0.1                     0.3                  0.1   \n",
       "3                         0.1                     0.3                  0.1   \n",
       "4                         0.1                     0.3                  0.1   \n",
       "...                       ...                     ...                  ...   \n",
       "2995                      0.1                     0.9                  0.4   \n",
       "2996                      0.1                     0.9                  0.4   \n",
       "2997                      0.1                     0.9                  0.4   \n",
       "2998                      0.1                     0.9                  0.4   \n",
       "2999                      0.1                     0.9                  0.4   \n",
       "\n",
       "      param_max_depth  param_n_estimators  param_subsample  ...  \\\n",
       "0                   2                 100              0.5  ...   \n",
       "1                   2                 100              0.6  ...   \n",
       "2                   2                 100              0.7  ...   \n",
       "3                   2                 100              0.8  ...   \n",
       "4                   2                 100              0.9  ...   \n",
       "...               ...                 ...              ...  ...   \n",
       "2995                5                 300              0.5  ...   \n",
       "2996                5                 300              0.6  ...   \n",
       "2997                5                 300              0.7  ...   \n",
       "2998                5                 300              0.8  ...   \n",
       "2999                5                 300              0.9  ...   \n",
       "\n",
       "     split3_test_score  split4_test_score  split5_test_score  \\\n",
       "0             0.822581           0.822581           0.806452   \n",
       "1             0.838710           0.822581           0.806452   \n",
       "2             0.838710           0.806452           0.806452   \n",
       "3             0.854839           0.822581           0.806452   \n",
       "4             0.854839           0.822581           0.838710   \n",
       "...                ...                ...                ...   \n",
       "2995          0.887097           0.806452           0.774194   \n",
       "2996          0.870968           0.774194           0.758065   \n",
       "2997          0.870968           0.790323           0.790323   \n",
       "2998          0.870968           0.790323           0.774194   \n",
       "2999          0.854839           0.806452           0.774194   \n",
       "\n",
       "      split6_test_score  split7_test_score  split8_test_score  \\\n",
       "0              0.822581           0.806452           0.693548   \n",
       "1              0.838710           0.806452           0.661290   \n",
       "2              0.838710           0.806452           0.677419   \n",
       "3              0.854839           0.806452           0.661290   \n",
       "4              0.838710           0.806452           0.677419   \n",
       "...                 ...                ...                ...   \n",
       "2995           0.822581           0.822581           0.725806   \n",
       "2996           0.806452           0.838710           0.741935   \n",
       "2997           0.790323           0.854839           0.709677   \n",
       "2998           0.806452           0.854839           0.741935   \n",
       "2999           0.806452           0.822581           0.725806   \n",
       "\n",
       "      split9_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0              0.838710         0.820020        0.048275             2651  \n",
       "1              0.854839         0.823221        0.059057             2358  \n",
       "2              0.838710         0.824782        0.057512             2252  \n",
       "3              0.838710         0.824834        0.059251             2175  \n",
       "4              0.838710         0.828059        0.053977             1747  \n",
       "...                 ...              ...             ...              ...  \n",
       "2995           0.854839         0.828085        0.048801             1701  \n",
       "2996           0.854839         0.826421        0.052840             1992  \n",
       "2997           0.822581         0.824808        0.053239             2204  \n",
       "2998           0.822581         0.823272        0.043729             2305  \n",
       "2999           0.806452         0.823169        0.050024             2460  \n",
       "\n",
       "[3000 rows x 24 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score is 0.8505376344086022 with params {'colsample_bylevel': 0.1, 'colsample_bytree': 0.6, 'learning_rate': 0.15, 'max_depth': 5, 'n_estimators': 100, 'subsample': 0.6}\n"
     ]
    }
   ],
   "source": [
    "df1 = pd.read_csv(\"data\\\\xgb_results_full_1_bylevel=0.1_20221123.csv\")\n",
    "df1.drop(df1.columns[0], axis=1, inplace=True)\n",
    "display(df1)\n",
    "print(\"best score is 0.8505376344086022 with params {'colsample_bylevel': 0.1, 'colsample_bytree': 0.6, 'learning_rate': 0.15, 'max_depth': 5, 'n_estimators': 100, 'subsample': 0.6}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "714bfa65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_colsample_bylevel</th>\n",
       "      <th>param_colsample_bytree</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_subsample</th>\n",
       "      <th>...</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.064527</td>\n",
       "      <td>0.004136</td>\n",
       "      <td>0.005885</td>\n",
       "      <td>5.376236e-04</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.820020</td>\n",
       "      <td>0.048275</td>\n",
       "      <td>2651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.064327</td>\n",
       "      <td>0.002493</td>\n",
       "      <td>0.005885</td>\n",
       "      <td>5.374151e-04</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.661290</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.823221</td>\n",
       "      <td>0.059057</td>\n",
       "      <td>2358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.063231</td>\n",
       "      <td>0.001954</td>\n",
       "      <td>0.005785</td>\n",
       "      <td>3.990535e-04</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.824782</td>\n",
       "      <td>0.057512</td>\n",
       "      <td>2252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.062235</td>\n",
       "      <td>0.001017</td>\n",
       "      <td>0.006082</td>\n",
       "      <td>3.001655e-04</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.661290</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.824834</td>\n",
       "      <td>0.059251</td>\n",
       "      <td>2175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.062333</td>\n",
       "      <td>0.002285</td>\n",
       "      <td>0.005784</td>\n",
       "      <td>3.991850e-04</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.828059</td>\n",
       "      <td>0.053977</td>\n",
       "      <td>1747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2995</th>\n",
       "      <td>0.180018</td>\n",
       "      <td>0.001496</td>\n",
       "      <td>0.007081</td>\n",
       "      <td>2.993507e-04</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.887097</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.828085</td>\n",
       "      <td>0.048801</td>\n",
       "      <td>1701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2996</th>\n",
       "      <td>0.182212</td>\n",
       "      <td>0.003339</td>\n",
       "      <td>0.006982</td>\n",
       "      <td>4.460618e-04</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.826421</td>\n",
       "      <td>0.052840</td>\n",
       "      <td>1992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2997</th>\n",
       "      <td>0.181813</td>\n",
       "      <td>0.001548</td>\n",
       "      <td>0.007082</td>\n",
       "      <td>2.990570e-04</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.824808</td>\n",
       "      <td>0.053239</td>\n",
       "      <td>2204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998</th>\n",
       "      <td>0.181666</td>\n",
       "      <td>0.001723</td>\n",
       "      <td>0.006982</td>\n",
       "      <td>4.529953e-07</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.823272</td>\n",
       "      <td>0.043729</td>\n",
       "      <td>2305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999</th>\n",
       "      <td>0.182113</td>\n",
       "      <td>0.002005</td>\n",
       "      <td>0.007081</td>\n",
       "      <td>2.993824e-04</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.823169</td>\n",
       "      <td>0.050024</td>\n",
       "      <td>2460</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0          0.064527      0.004136         0.005885    5.376236e-04   \n",
       "1          0.064327      0.002493         0.005885    5.374151e-04   \n",
       "2          0.063231      0.001954         0.005785    3.990535e-04   \n",
       "3          0.062235      0.001017         0.006082    3.001655e-04   \n",
       "4          0.062333      0.002285         0.005784    3.991850e-04   \n",
       "...             ...           ...              ...             ...   \n",
       "2995       0.180018      0.001496         0.007081    2.993507e-04   \n",
       "2996       0.182212      0.003339         0.006982    4.460618e-04   \n",
       "2997       0.181813      0.001548         0.007082    2.990570e-04   \n",
       "2998       0.181666      0.001723         0.006982    4.529953e-07   \n",
       "2999       0.182113      0.002005         0.007081    2.993824e-04   \n",
       "\n",
       "     param_colsample_bylevel param_colsample_bytree param_learning_rate  \\\n",
       "0                        0.1                    0.3                 0.1   \n",
       "1                        0.1                    0.3                 0.1   \n",
       "2                        0.1                    0.3                 0.1   \n",
       "3                        0.1                    0.3                 0.1   \n",
       "4                        0.1                    0.3                 0.1   \n",
       "...                      ...                    ...                 ...   \n",
       "2995                     0.1                    0.9                 0.4   \n",
       "2996                     0.1                    0.9                 0.4   \n",
       "2997                     0.1                    0.9                 0.4   \n",
       "2998                     0.1                    0.9                 0.4   \n",
       "2999                     0.1                    0.9                 0.4   \n",
       "\n",
       "     param_max_depth param_n_estimators param_subsample  ...  \\\n",
       "0                  2                100             0.5  ...   \n",
       "1                  2                100             0.6  ...   \n",
       "2                  2                100             0.7  ...   \n",
       "3                  2                100             0.8  ...   \n",
       "4                  2                100             0.9  ...   \n",
       "...              ...                ...             ...  ...   \n",
       "2995               5                300             0.5  ...   \n",
       "2996               5                300             0.6  ...   \n",
       "2997               5                300             0.7  ...   \n",
       "2998               5                300             0.8  ...   \n",
       "2999               5                300             0.9  ...   \n",
       "\n",
       "     split3_test_score  split4_test_score  split5_test_score  \\\n",
       "0             0.822581           0.822581           0.806452   \n",
       "1             0.838710           0.822581           0.806452   \n",
       "2             0.838710           0.806452           0.806452   \n",
       "3             0.854839           0.822581           0.806452   \n",
       "4             0.854839           0.822581           0.838710   \n",
       "...                ...                ...                ...   \n",
       "2995          0.887097           0.806452           0.774194   \n",
       "2996          0.870968           0.774194           0.758065   \n",
       "2997          0.870968           0.790323           0.790323   \n",
       "2998          0.870968           0.790323           0.774194   \n",
       "2999          0.854839           0.806452           0.774194   \n",
       "\n",
       "      split6_test_score  split7_test_score  split8_test_score  \\\n",
       "0              0.822581           0.806452           0.693548   \n",
       "1              0.838710           0.806452           0.661290   \n",
       "2              0.838710           0.806452           0.677419   \n",
       "3              0.854839           0.806452           0.661290   \n",
       "4              0.838710           0.806452           0.677419   \n",
       "...                 ...                ...                ...   \n",
       "2995           0.822581           0.822581           0.725806   \n",
       "2996           0.806452           0.838710           0.741935   \n",
       "2997           0.790323           0.854839           0.709677   \n",
       "2998           0.806452           0.854839           0.741935   \n",
       "2999           0.806452           0.822581           0.725806   \n",
       "\n",
       "      split9_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0              0.838710         0.820020        0.048275             2651  \n",
       "1              0.854839         0.823221        0.059057             2358  \n",
       "2              0.838710         0.824782        0.057512             2252  \n",
       "3              0.838710         0.824834        0.059251             2175  \n",
       "4              0.838710         0.828059        0.053977             1747  \n",
       "...                 ...              ...             ...              ...  \n",
       "2995           0.854839         0.828085        0.048801             1701  \n",
       "2996           0.854839         0.826421        0.052840             1992  \n",
       "2997           0.822581         0.824808        0.053239             2204  \n",
       "2998           0.822581         0.823272        0.043729             2305  \n",
       "2999           0.806452         0.823169        0.050024             2460  \n",
       "\n",
       "[3000 rows x 24 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score is 0.8505376344086022 with params {'colsample_bylevel': 0.1, 'colsample_bytree': 0.6, 'learning_rate': 0.15, 'max_depth': 5, 'n_estimators': 100, 'subsample': 0.6}\n"
     ]
    }
   ],
   "source": [
    "# Full Tuning - Part 1\n",
    "random.seed(10)\n",
    "\n",
    "xgb = XGBClassifier()\n",
    "\n",
    "xgb_parameters = {'max_depth': [2,3,4,5]\n",
    "                   , 'subsample': [0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "                   , 'colsample_bytree': [0.3, 0.4, 0.5, 0.6, 0.9]\n",
    "                   , 'colsample_bylevel': [0.1]\n",
    "                   , 'learning_rate': [0.1, 0.15, 0.2, 0.25, 0.3, 0.4]\n",
    "                   , 'n_estimators': [100, 150, 200, 250, 300]}\n",
    "\n",
    "stratified_10_fold_cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "xgb_grid_search = GridSearchCV(xgb, xgb_parameters, scoring='accuracy', cv=stratified_10_fold_cv)\n",
    "\n",
    "xgb_grid_search.fit(X_train, y_train)\n",
    "\n",
    "xgb_grid_search_results_full_1 = pd.DataFrame(xgb_grid_search.cv_results_)\n",
    "display(xgb_grid_search_results_full_1)\n",
    "\n",
    "print(\"best score is {} with params {}\".format(xgb_grid_search.best_score_, xgb_grid_search.best_params_))\n",
    "\n",
    "# best values for\n",
    "\n",
    "# save dataframe\n",
    "from datetime import datetime\n",
    "date = str(datetime.now().date()).replace(\"-\", \"\")\n",
    "xgb_grid_search_results_full_1.to_csv(f\"results/xgb_results_full_round2_1_bylevel=0.1_{date}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a821b1df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_colsample_bylevel</th>\n",
       "      <th>param_colsample_bytree</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_subsample</th>\n",
       "      <th>...</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.062133</td>\n",
       "      <td>0.002485</td>\n",
       "      <td>0.006284</td>\n",
       "      <td>0.000639</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.820020</td>\n",
       "      <td>0.048275</td>\n",
       "      <td>2663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.063131</td>\n",
       "      <td>0.003027</td>\n",
       "      <td>0.006683</td>\n",
       "      <td>0.000457</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.661290</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.823221</td>\n",
       "      <td>0.059057</td>\n",
       "      <td>2338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.060438</td>\n",
       "      <td>0.000798</td>\n",
       "      <td>0.006782</td>\n",
       "      <td>0.000398</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.824782</td>\n",
       "      <td>0.057512</td>\n",
       "      <td>2222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.059541</td>\n",
       "      <td>0.000779</td>\n",
       "      <td>0.006682</td>\n",
       "      <td>0.000457</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.661290</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.824834</td>\n",
       "      <td>0.059251</td>\n",
       "      <td>2132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.059840</td>\n",
       "      <td>0.001092</td>\n",
       "      <td>0.006782</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.828059</td>\n",
       "      <td>0.053977</td>\n",
       "      <td>1661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2995</th>\n",
       "      <td>0.195577</td>\n",
       "      <td>0.001636</td>\n",
       "      <td>0.017653</td>\n",
       "      <td>0.031683</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.819918</td>\n",
       "      <td>0.052433</td>\n",
       "      <td>2744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2996</th>\n",
       "      <td>0.221308</td>\n",
       "      <td>0.011234</td>\n",
       "      <td>0.006782</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.819995</td>\n",
       "      <td>0.058351</td>\n",
       "      <td>2693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2997</th>\n",
       "      <td>0.226194</td>\n",
       "      <td>0.002309</td>\n",
       "      <td>0.007082</td>\n",
       "      <td>0.000299</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.821582</td>\n",
       "      <td>0.054587</td>\n",
       "      <td>2581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998</th>\n",
       "      <td>0.199167</td>\n",
       "      <td>0.006213</td>\n",
       "      <td>0.007381</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.823195</td>\n",
       "      <td>0.052389</td>\n",
       "      <td>2389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999</th>\n",
       "      <td>0.196574</td>\n",
       "      <td>0.001133</td>\n",
       "      <td>0.007480</td>\n",
       "      <td>0.000499</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.826395</td>\n",
       "      <td>0.049816</td>\n",
       "      <td>2002</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0          0.062133      0.002485         0.006284        0.000639   \n",
       "1          0.063131      0.003027         0.006683        0.000457   \n",
       "2          0.060438      0.000798         0.006782        0.000398   \n",
       "3          0.059541      0.000779         0.006682        0.000457   \n",
       "4          0.059840      0.001092         0.006782        0.000399   \n",
       "...             ...           ...              ...             ...   \n",
       "2995       0.195577      0.001636         0.017653        0.031683   \n",
       "2996       0.221308      0.011234         0.006782        0.000399   \n",
       "2997       0.226194      0.002309         0.007082        0.000299   \n",
       "2998       0.199167      0.006213         0.007381        0.000489   \n",
       "2999       0.196574      0.001133         0.007480        0.000499   \n",
       "\n",
       "      param_colsample_bylevel  param_colsample_bytree  param_learning_rate  \\\n",
       "0                         0.2                     0.3                  0.1   \n",
       "1                         0.2                     0.3                  0.1   \n",
       "2                         0.2                     0.3                  0.1   \n",
       "3                         0.2                     0.3                  0.1   \n",
       "4                         0.2                     0.3                  0.1   \n",
       "...                       ...                     ...                  ...   \n",
       "2995                      0.2                     0.9                  0.4   \n",
       "2996                      0.2                     0.9                  0.4   \n",
       "2997                      0.2                     0.9                  0.4   \n",
       "2998                      0.2                     0.9                  0.4   \n",
       "2999                      0.2                     0.9                  0.4   \n",
       "\n",
       "      param_max_depth  param_n_estimators  param_subsample  ...  \\\n",
       "0                   2                 100              0.5  ...   \n",
       "1                   2                 100              0.6  ...   \n",
       "2                   2                 100              0.7  ...   \n",
       "3                   2                 100              0.8  ...   \n",
       "4                   2                 100              0.9  ...   \n",
       "...               ...                 ...              ...  ...   \n",
       "2995                5                 300              0.5  ...   \n",
       "2996                5                 300              0.6  ...   \n",
       "2997                5                 300              0.7  ...   \n",
       "2998                5                 300              0.8  ...   \n",
       "2999                5                 300              0.9  ...   \n",
       "\n",
       "     split3_test_score  split4_test_score  split5_test_score  \\\n",
       "0             0.822581           0.822581           0.806452   \n",
       "1             0.838710           0.822581           0.806452   \n",
       "2             0.838710           0.806452           0.806452   \n",
       "3             0.854839           0.822581           0.806452   \n",
       "4             0.854839           0.822581           0.838710   \n",
       "...                ...                ...                ...   \n",
       "2995          0.822581           0.806452           0.774194   \n",
       "2996          0.838710           0.806452           0.774194   \n",
       "2997          0.838710           0.790323           0.758065   \n",
       "2998          0.838710           0.822581           0.774194   \n",
       "2999          0.838710           0.806452           0.790323   \n",
       "\n",
       "      split6_test_score  split7_test_score  split8_test_score  \\\n",
       "0              0.822581           0.806452           0.693548   \n",
       "1              0.838710           0.806452           0.661290   \n",
       "2              0.838710           0.806452           0.677419   \n",
       "3              0.854839           0.806452           0.661290   \n",
       "4              0.838710           0.806452           0.677419   \n",
       "...                 ...                ...                ...   \n",
       "2995           0.790323           0.790323           0.741935   \n",
       "2996           0.822581           0.838710           0.693548   \n",
       "2997           0.806452           0.854839           0.725806   \n",
       "2998           0.838710           0.822581           0.725806   \n",
       "2999           0.838710           0.822581           0.725806   \n",
       "\n",
       "      split9_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0              0.838710         0.820020        0.048275             2663  \n",
       "1              0.854839         0.823221        0.059057             2338  \n",
       "2              0.838710         0.824782        0.057512             2222  \n",
       "3              0.838710         0.824834        0.059251             2132  \n",
       "4              0.838710         0.828059        0.053977             1661  \n",
       "...                 ...              ...             ...              ...  \n",
       "2995           0.822581         0.819918        0.052433             2744  \n",
       "2996           0.822581         0.819995        0.058351             2693  \n",
       "2997           0.822581         0.821582        0.054587             2581  \n",
       "2998           0.790323         0.823195        0.052389             2389  \n",
       "2999           0.806452         0.826395        0.049816             2002  \n",
       "\n",
       "[3000 rows x 24 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score is 0.8505376344086022 with params {'colsample_bylevel': 0.2, 'colsample_bytree': 0.6, 'learning_rate': 0.15, 'max_depth': 5, 'n_estimators': 100, 'subsample': 0.6}\n"
     ]
    }
   ],
   "source": [
    "df2 = pd.read_csv(\"data\\\\xgb_results_full_2_bylevel=0.2_20221123.csv\")\n",
    "df2.drop(df2.columns[0], axis=1, inplace=True)\n",
    "display(df2)\n",
    "print(\"best score is 0.8505376344086022 with params {'colsample_bylevel': 0.2, 'colsample_bytree': 0.6, 'learning_rate': 0.15, 'max_depth': 5, 'n_estimators': 100, 'subsample': 0.6}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cf6243bd",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_colsample_bylevel</th>\n",
       "      <th>param_colsample_bytree</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_subsample</th>\n",
       "      <th>...</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.062133</td>\n",
       "      <td>0.002485</td>\n",
       "      <td>0.006284</td>\n",
       "      <td>0.000639</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.820020</td>\n",
       "      <td>0.048275</td>\n",
       "      <td>2663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.063131</td>\n",
       "      <td>0.003027</td>\n",
       "      <td>0.006683</td>\n",
       "      <td>0.000457</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.661290</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.823221</td>\n",
       "      <td>0.059057</td>\n",
       "      <td>2338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.060438</td>\n",
       "      <td>0.000798</td>\n",
       "      <td>0.006782</td>\n",
       "      <td>0.000398</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.824782</td>\n",
       "      <td>0.057512</td>\n",
       "      <td>2222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.059541</td>\n",
       "      <td>0.000779</td>\n",
       "      <td>0.006682</td>\n",
       "      <td>0.000457</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.661290</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.824834</td>\n",
       "      <td>0.059251</td>\n",
       "      <td>2132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.059840</td>\n",
       "      <td>0.001092</td>\n",
       "      <td>0.006782</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.828059</td>\n",
       "      <td>0.053977</td>\n",
       "      <td>1661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2995</th>\n",
       "      <td>0.195577</td>\n",
       "      <td>0.001636</td>\n",
       "      <td>0.017653</td>\n",
       "      <td>0.031683</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.819918</td>\n",
       "      <td>0.052433</td>\n",
       "      <td>2744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2996</th>\n",
       "      <td>0.221308</td>\n",
       "      <td>0.011234</td>\n",
       "      <td>0.006782</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.819995</td>\n",
       "      <td>0.058351</td>\n",
       "      <td>2693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2997</th>\n",
       "      <td>0.226194</td>\n",
       "      <td>0.002309</td>\n",
       "      <td>0.007082</td>\n",
       "      <td>0.000299</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.821582</td>\n",
       "      <td>0.054587</td>\n",
       "      <td>2581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998</th>\n",
       "      <td>0.199167</td>\n",
       "      <td>0.006213</td>\n",
       "      <td>0.007381</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.823195</td>\n",
       "      <td>0.052389</td>\n",
       "      <td>2389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999</th>\n",
       "      <td>0.196574</td>\n",
       "      <td>0.001133</td>\n",
       "      <td>0.007480</td>\n",
       "      <td>0.000499</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.826395</td>\n",
       "      <td>0.049816</td>\n",
       "      <td>2002</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0          0.062133      0.002485         0.006284        0.000639   \n",
       "1          0.063131      0.003027         0.006683        0.000457   \n",
       "2          0.060438      0.000798         0.006782        0.000398   \n",
       "3          0.059541      0.000779         0.006682        0.000457   \n",
       "4          0.059840      0.001092         0.006782        0.000399   \n",
       "...             ...           ...              ...             ...   \n",
       "2995       0.195577      0.001636         0.017653        0.031683   \n",
       "2996       0.221308      0.011234         0.006782        0.000399   \n",
       "2997       0.226194      0.002309         0.007082        0.000299   \n",
       "2998       0.199167      0.006213         0.007381        0.000489   \n",
       "2999       0.196574      0.001133         0.007480        0.000499   \n",
       "\n",
       "     param_colsample_bylevel param_colsample_bytree param_learning_rate  \\\n",
       "0                        0.2                    0.3                 0.1   \n",
       "1                        0.2                    0.3                 0.1   \n",
       "2                        0.2                    0.3                 0.1   \n",
       "3                        0.2                    0.3                 0.1   \n",
       "4                        0.2                    0.3                 0.1   \n",
       "...                      ...                    ...                 ...   \n",
       "2995                     0.2                    0.9                 0.4   \n",
       "2996                     0.2                    0.9                 0.4   \n",
       "2997                     0.2                    0.9                 0.4   \n",
       "2998                     0.2                    0.9                 0.4   \n",
       "2999                     0.2                    0.9                 0.4   \n",
       "\n",
       "     param_max_depth param_n_estimators param_subsample  ...  \\\n",
       "0                  2                100             0.5  ...   \n",
       "1                  2                100             0.6  ...   \n",
       "2                  2                100             0.7  ...   \n",
       "3                  2                100             0.8  ...   \n",
       "4                  2                100             0.9  ...   \n",
       "...              ...                ...             ...  ...   \n",
       "2995               5                300             0.5  ...   \n",
       "2996               5                300             0.6  ...   \n",
       "2997               5                300             0.7  ...   \n",
       "2998               5                300             0.8  ...   \n",
       "2999               5                300             0.9  ...   \n",
       "\n",
       "     split3_test_score  split4_test_score  split5_test_score  \\\n",
       "0             0.822581           0.822581           0.806452   \n",
       "1             0.838710           0.822581           0.806452   \n",
       "2             0.838710           0.806452           0.806452   \n",
       "3             0.854839           0.822581           0.806452   \n",
       "4             0.854839           0.822581           0.838710   \n",
       "...                ...                ...                ...   \n",
       "2995          0.822581           0.806452           0.774194   \n",
       "2996          0.838710           0.806452           0.774194   \n",
       "2997          0.838710           0.790323           0.758065   \n",
       "2998          0.838710           0.822581           0.774194   \n",
       "2999          0.838710           0.806452           0.790323   \n",
       "\n",
       "      split6_test_score  split7_test_score  split8_test_score  \\\n",
       "0              0.822581           0.806452           0.693548   \n",
       "1              0.838710           0.806452           0.661290   \n",
       "2              0.838710           0.806452           0.677419   \n",
       "3              0.854839           0.806452           0.661290   \n",
       "4              0.838710           0.806452           0.677419   \n",
       "...                 ...                ...                ...   \n",
       "2995           0.790323           0.790323           0.741935   \n",
       "2996           0.822581           0.838710           0.693548   \n",
       "2997           0.806452           0.854839           0.725806   \n",
       "2998           0.838710           0.822581           0.725806   \n",
       "2999           0.838710           0.822581           0.725806   \n",
       "\n",
       "      split9_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0              0.838710         0.820020        0.048275             2663  \n",
       "1              0.854839         0.823221        0.059057             2338  \n",
       "2              0.838710         0.824782        0.057512             2222  \n",
       "3              0.838710         0.824834        0.059251             2132  \n",
       "4              0.838710         0.828059        0.053977             1661  \n",
       "...                 ...              ...             ...              ...  \n",
       "2995           0.822581         0.819918        0.052433             2744  \n",
       "2996           0.822581         0.819995        0.058351             2693  \n",
       "2997           0.822581         0.821582        0.054587             2581  \n",
       "2998           0.790323         0.823195        0.052389             2389  \n",
       "2999           0.806452         0.826395        0.049816             2002  \n",
       "\n",
       "[3000 rows x 24 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score is 0.8505376344086022 with params {'colsample_bylevel': 0.2, 'colsample_bytree': 0.6, 'learning_rate': 0.15, 'max_depth': 5, 'n_estimators': 100, 'subsample': 0.6}\n"
     ]
    }
   ],
   "source": [
    "# Full Tuning - Part 2\n",
    "random.seed(10)\n",
    "\n",
    "xgb = XGBClassifier()\n",
    "\n",
    "xgb_parameters = {'max_depth': [2,3,4,5]\n",
    "                   , 'subsample': [0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "                   , 'colsample_bytree': [0.3, 0.4, 0.5, 0.6, 0.9]\n",
    "                   , 'colsample_bylevel': [0.2]\n",
    "                   , 'learning_rate': [0.1, 0.15, 0.2, 0.25, 0.3, 0.4]\n",
    "                   , 'n_estimators': [100, 150, 200, 250, 300]}\n",
    "\n",
    "stratified_10_fold_cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "xgb_grid_search = GridSearchCV(xgb, xgb_parameters, scoring='accuracy', cv=stratified_10_fold_cv)\n",
    "\n",
    "xgb_grid_search.fit(X_train, y_train)\n",
    "\n",
    "xgb_grid_search_results_full_2 = pd.DataFrame(xgb_grid_search.cv_results_)\n",
    "display(xgb_grid_search_results_full_2)\n",
    "\n",
    "print(\"best score is {} with params {}\".format(xgb_grid_search.best_score_, xgb_grid_search.best_params_))\n",
    "#best score is 0.8505376344086022 with params\n",
    "#{'colsample_bylevel': 0.2, 'colsample_bytree': 0.6, 'learning_rate': 0.15, 'max_depth': 5, 'n_estimators': 100, 'subsample': 0.6}\n",
    "\n",
    "# save dataframe\n",
    "from datetime import datetime\n",
    "date = str(datetime.now().date()).replace(\"-\", \"\")\n",
    "xgb_grid_search_results_full_2.to_csv(f\"results/xgb_results_full_round2_2_bylevel=0.2_{date}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9c3c4e54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_colsample_bylevel</th>\n",
       "      <th>param_colsample_bytree</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_subsample</th>\n",
       "      <th>...</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.062034</td>\n",
       "      <td>0.001596</td>\n",
       "      <td>0.006882</td>\n",
       "      <td>0.000537</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.820020</td>\n",
       "      <td>0.048275</td>\n",
       "      <td>2509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.068327</td>\n",
       "      <td>0.005910</td>\n",
       "      <td>0.006573</td>\n",
       "      <td>0.000502</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.661290</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.823221</td>\n",
       "      <td>0.059057</td>\n",
       "      <td>2140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.065225</td>\n",
       "      <td>0.003191</td>\n",
       "      <td>0.006683</td>\n",
       "      <td>0.000457</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.824782</td>\n",
       "      <td>0.057512</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.063630</td>\n",
       "      <td>0.001596</td>\n",
       "      <td>0.006483</td>\n",
       "      <td>0.000499</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.661290</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.824834</td>\n",
       "      <td>0.059251</td>\n",
       "      <td>1898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.061435</td>\n",
       "      <td>0.001493</td>\n",
       "      <td>0.006483</td>\n",
       "      <td>0.000498</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.828059</td>\n",
       "      <td>0.053977</td>\n",
       "      <td>1394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2995</th>\n",
       "      <td>0.206226</td>\n",
       "      <td>0.002782</td>\n",
       "      <td>0.007182</td>\n",
       "      <td>0.000598</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.813646</td>\n",
       "      <td>0.044452</td>\n",
       "      <td>2900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2996</th>\n",
       "      <td>0.207998</td>\n",
       "      <td>0.002457</td>\n",
       "      <td>0.007280</td>\n",
       "      <td>0.000457</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.818459</td>\n",
       "      <td>0.053856</td>\n",
       "      <td>2648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2997</th>\n",
       "      <td>0.207744</td>\n",
       "      <td>0.000898</td>\n",
       "      <td>0.007480</td>\n",
       "      <td>0.000499</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.813594</td>\n",
       "      <td>0.056215</td>\n",
       "      <td>2908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998</th>\n",
       "      <td>0.208343</td>\n",
       "      <td>0.001863</td>\n",
       "      <td>0.007280</td>\n",
       "      <td>0.000457</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.815207</td>\n",
       "      <td>0.053961</td>\n",
       "      <td>2850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999</th>\n",
       "      <td>0.207644</td>\n",
       "      <td>0.001882</td>\n",
       "      <td>0.007381</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.820020</td>\n",
       "      <td>0.055129</td>\n",
       "      <td>2509</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0          0.062034      0.001596         0.006882        0.000537   \n",
       "1          0.068327      0.005910         0.006573        0.000502   \n",
       "2          0.065225      0.003191         0.006683        0.000457   \n",
       "3          0.063630      0.001596         0.006483        0.000499   \n",
       "4          0.061435      0.001493         0.006483        0.000498   \n",
       "...             ...           ...              ...             ...   \n",
       "2995       0.206226      0.002782         0.007182        0.000598   \n",
       "2996       0.207998      0.002457         0.007280        0.000457   \n",
       "2997       0.207744      0.000898         0.007480        0.000499   \n",
       "2998       0.208343      0.001863         0.007280        0.000457   \n",
       "2999       0.207644      0.001882         0.007381        0.000489   \n",
       "\n",
       "      param_colsample_bylevel  param_colsample_bytree  param_learning_rate  \\\n",
       "0                         0.3                     0.3                  0.1   \n",
       "1                         0.3                     0.3                  0.1   \n",
       "2                         0.3                     0.3                  0.1   \n",
       "3                         0.3                     0.3                  0.1   \n",
       "4                         0.3                     0.3                  0.1   \n",
       "...                       ...                     ...                  ...   \n",
       "2995                      0.3                     0.9                  0.4   \n",
       "2996                      0.3                     0.9                  0.4   \n",
       "2997                      0.3                     0.9                  0.4   \n",
       "2998                      0.3                     0.9                  0.4   \n",
       "2999                      0.3                     0.9                  0.4   \n",
       "\n",
       "      param_max_depth  param_n_estimators  param_subsample  ...  \\\n",
       "0                   2                 100              0.5  ...   \n",
       "1                   2                 100              0.6  ...   \n",
       "2                   2                 100              0.7  ...   \n",
       "3                   2                 100              0.8  ...   \n",
       "4                   2                 100              0.9  ...   \n",
       "...               ...                 ...              ...  ...   \n",
       "2995                5                 300              0.5  ...   \n",
       "2996                5                 300              0.6  ...   \n",
       "2997                5                 300              0.7  ...   \n",
       "2998                5                 300              0.8  ...   \n",
       "2999                5                 300              0.9  ...   \n",
       "\n",
       "     split3_test_score  split4_test_score  split5_test_score  \\\n",
       "0             0.822581           0.822581           0.806452   \n",
       "1             0.838710           0.822581           0.806452   \n",
       "2             0.838710           0.806452           0.806452   \n",
       "3             0.854839           0.822581           0.806452   \n",
       "4             0.854839           0.822581           0.838710   \n",
       "...                ...                ...                ...   \n",
       "2995          0.838710           0.790323           0.774194   \n",
       "2996          0.854839           0.774194           0.790323   \n",
       "2997          0.854839           0.790323           0.758065   \n",
       "2998          0.854839           0.790323           0.790323   \n",
       "2999          0.822581           0.790323           0.774194   \n",
       "\n",
       "      split6_test_score  split7_test_score  split8_test_score  \\\n",
       "0              0.822581           0.806452           0.693548   \n",
       "1              0.838710           0.806452           0.661290   \n",
       "2              0.838710           0.806452           0.677419   \n",
       "3              0.854839           0.806452           0.661290   \n",
       "4              0.838710           0.806452           0.677419   \n",
       "...                 ...                ...                ...   \n",
       "2995           0.838710           0.822581           0.709677   \n",
       "2996           0.854839           0.806452           0.693548   \n",
       "2997           0.822581           0.806452           0.709677   \n",
       "2998           0.822581           0.806452           0.693548   \n",
       "2999           0.854839           0.806452           0.709677   \n",
       "\n",
       "      split9_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0              0.838710         0.820020        0.048275             2509  \n",
       "1              0.854839         0.823221        0.059057             2140  \n",
       "2              0.838710         0.824782        0.057512             2021  \n",
       "3              0.838710         0.824834        0.059251             1898  \n",
       "4              0.838710         0.828059        0.053977             1394  \n",
       "...                 ...              ...             ...              ...  \n",
       "2995           0.822581         0.813646        0.044452             2900  \n",
       "2996           0.854839         0.818459        0.053856             2648  \n",
       "2997           0.822581         0.813594        0.056215             2908  \n",
       "2998           0.822581         0.815207        0.053961             2850  \n",
       "2999           0.854839         0.820020        0.055129             2509  \n",
       "\n",
       "[3000 rows x 24 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score is 0.850563236047107 with params {'colsample_bylevel': 0.3, 'colsample_bytree': 0.5, 'learning_rate': 0.15, 'max_depth': 2, 'n_estimators': 100, 'subsample': 0.7}\n"
     ]
    }
   ],
   "source": [
    "df3 = pd.read_csv(\"data\\\\xgb_results_full_3_bylevel=0.3_20221123.csv\")\n",
    "df3.drop(df3.columns[0], axis=1, inplace=True)\n",
    "display(df3)\n",
    "print(\"best score is 0.850563236047107 with params {'colsample_bylevel': 0.3, 'colsample_bytree': 0.5, 'learning_rate': 0.15, 'max_depth': 2, 'n_estimators': 100, 'subsample': 0.7}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "96404602",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_colsample_bylevel</th>\n",
       "      <th>param_colsample_bytree</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_subsample</th>\n",
       "      <th>...</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.062034</td>\n",
       "      <td>0.001596</td>\n",
       "      <td>0.006882</td>\n",
       "      <td>0.000537</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.820020</td>\n",
       "      <td>0.048275</td>\n",
       "      <td>2509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.068327</td>\n",
       "      <td>0.005910</td>\n",
       "      <td>0.006573</td>\n",
       "      <td>0.000502</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.661290</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.823221</td>\n",
       "      <td>0.059057</td>\n",
       "      <td>2140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.065225</td>\n",
       "      <td>0.003191</td>\n",
       "      <td>0.006683</td>\n",
       "      <td>0.000457</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.824782</td>\n",
       "      <td>0.057512</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.063630</td>\n",
       "      <td>0.001596</td>\n",
       "      <td>0.006483</td>\n",
       "      <td>0.000499</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.661290</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.824834</td>\n",
       "      <td>0.059251</td>\n",
       "      <td>1898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.061435</td>\n",
       "      <td>0.001493</td>\n",
       "      <td>0.006483</td>\n",
       "      <td>0.000498</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.828059</td>\n",
       "      <td>0.053977</td>\n",
       "      <td>1394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2995</th>\n",
       "      <td>0.206226</td>\n",
       "      <td>0.002782</td>\n",
       "      <td>0.007182</td>\n",
       "      <td>0.000598</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.813646</td>\n",
       "      <td>0.044452</td>\n",
       "      <td>2900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2996</th>\n",
       "      <td>0.207998</td>\n",
       "      <td>0.002457</td>\n",
       "      <td>0.007280</td>\n",
       "      <td>0.000457</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.818459</td>\n",
       "      <td>0.053856</td>\n",
       "      <td>2648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2997</th>\n",
       "      <td>0.207744</td>\n",
       "      <td>0.000898</td>\n",
       "      <td>0.007480</td>\n",
       "      <td>0.000499</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.813594</td>\n",
       "      <td>0.056215</td>\n",
       "      <td>2908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998</th>\n",
       "      <td>0.208343</td>\n",
       "      <td>0.001863</td>\n",
       "      <td>0.007280</td>\n",
       "      <td>0.000457</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.815207</td>\n",
       "      <td>0.053961</td>\n",
       "      <td>2850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999</th>\n",
       "      <td>0.207644</td>\n",
       "      <td>0.001882</td>\n",
       "      <td>0.007381</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.820020</td>\n",
       "      <td>0.055129</td>\n",
       "      <td>2509</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0          0.062034      0.001596         0.006882        0.000537   \n",
       "1          0.068327      0.005910         0.006573        0.000502   \n",
       "2          0.065225      0.003191         0.006683        0.000457   \n",
       "3          0.063630      0.001596         0.006483        0.000499   \n",
       "4          0.061435      0.001493         0.006483        0.000498   \n",
       "...             ...           ...              ...             ...   \n",
       "2995       0.206226      0.002782         0.007182        0.000598   \n",
       "2996       0.207998      0.002457         0.007280        0.000457   \n",
       "2997       0.207744      0.000898         0.007480        0.000499   \n",
       "2998       0.208343      0.001863         0.007280        0.000457   \n",
       "2999       0.207644      0.001882         0.007381        0.000489   \n",
       "\n",
       "     param_colsample_bylevel param_colsample_bytree param_learning_rate  \\\n",
       "0                        0.3                    0.3                 0.1   \n",
       "1                        0.3                    0.3                 0.1   \n",
       "2                        0.3                    0.3                 0.1   \n",
       "3                        0.3                    0.3                 0.1   \n",
       "4                        0.3                    0.3                 0.1   \n",
       "...                      ...                    ...                 ...   \n",
       "2995                     0.3                    0.9                 0.4   \n",
       "2996                     0.3                    0.9                 0.4   \n",
       "2997                     0.3                    0.9                 0.4   \n",
       "2998                     0.3                    0.9                 0.4   \n",
       "2999                     0.3                    0.9                 0.4   \n",
       "\n",
       "     param_max_depth param_n_estimators param_subsample  ...  \\\n",
       "0                  2                100             0.5  ...   \n",
       "1                  2                100             0.6  ...   \n",
       "2                  2                100             0.7  ...   \n",
       "3                  2                100             0.8  ...   \n",
       "4                  2                100             0.9  ...   \n",
       "...              ...                ...             ...  ...   \n",
       "2995               5                300             0.5  ...   \n",
       "2996               5                300             0.6  ...   \n",
       "2997               5                300             0.7  ...   \n",
       "2998               5                300             0.8  ...   \n",
       "2999               5                300             0.9  ...   \n",
       "\n",
       "     split3_test_score  split4_test_score  split5_test_score  \\\n",
       "0             0.822581           0.822581           0.806452   \n",
       "1             0.838710           0.822581           0.806452   \n",
       "2             0.838710           0.806452           0.806452   \n",
       "3             0.854839           0.822581           0.806452   \n",
       "4             0.854839           0.822581           0.838710   \n",
       "...                ...                ...                ...   \n",
       "2995          0.838710           0.790323           0.774194   \n",
       "2996          0.854839           0.774194           0.790323   \n",
       "2997          0.854839           0.790323           0.758065   \n",
       "2998          0.854839           0.790323           0.790323   \n",
       "2999          0.822581           0.790323           0.774194   \n",
       "\n",
       "      split6_test_score  split7_test_score  split8_test_score  \\\n",
       "0              0.822581           0.806452           0.693548   \n",
       "1              0.838710           0.806452           0.661290   \n",
       "2              0.838710           0.806452           0.677419   \n",
       "3              0.854839           0.806452           0.661290   \n",
       "4              0.838710           0.806452           0.677419   \n",
       "...                 ...                ...                ...   \n",
       "2995           0.838710           0.822581           0.709677   \n",
       "2996           0.854839           0.806452           0.693548   \n",
       "2997           0.822581           0.806452           0.709677   \n",
       "2998           0.822581           0.806452           0.693548   \n",
       "2999           0.854839           0.806452           0.709677   \n",
       "\n",
       "      split9_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0              0.838710         0.820020        0.048275             2509  \n",
       "1              0.854839         0.823221        0.059057             2140  \n",
       "2              0.838710         0.824782        0.057512             2021  \n",
       "3              0.838710         0.824834        0.059251             1898  \n",
       "4              0.838710         0.828059        0.053977             1394  \n",
       "...                 ...              ...             ...              ...  \n",
       "2995           0.822581         0.813646        0.044452             2900  \n",
       "2996           0.854839         0.818459        0.053856             2648  \n",
       "2997           0.822581         0.813594        0.056215             2908  \n",
       "2998           0.822581         0.815207        0.053961             2850  \n",
       "2999           0.854839         0.820020        0.055129             2509  \n",
       "\n",
       "[3000 rows x 24 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score is 0.850563236047107 with params {'colsample_bylevel': 0.3, 'colsample_bytree': 0.5, 'learning_rate': 0.15, 'max_depth': 2, 'n_estimators': 100, 'subsample': 0.7}\n"
     ]
    }
   ],
   "source": [
    "# Full Tuning - Part 3\n",
    "random.seed(10)\n",
    "\n",
    "xgb = XGBClassifier()\n",
    "\n",
    "xgb_parameters = {'max_depth': [2,3,4,5]\n",
    "                   , 'subsample': [0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "                   , 'colsample_bytree': [0.3, 0.4, 0.5, 0.6, 0.9]\n",
    "                   , 'colsample_bylevel': [0.3]\n",
    "                   , 'learning_rate': [0.1, 0.15, 0.2, 0.25, 0.3, 0.4]\n",
    "                   , 'n_estimators': [100, 150, 200, 250, 300]}\n",
    "\n",
    "stratified_10_fold_cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "xgb_grid_search = GridSearchCV(xgb, xgb_parameters, scoring='accuracy', cv=stratified_10_fold_cv)\n",
    "\n",
    "xgb_grid_search.fit(X_train, y_train)\n",
    "\n",
    "xgb_grid_search_results_full_3 = pd.DataFrame(xgb_grid_search.cv_results_)\n",
    "display(xgb_grid_search_results_full_3)\n",
    "\n",
    "print(\"best score is {} with params {}\".format(xgb_grid_search.best_score_, xgb_grid_search.best_params_))\n",
    "#best score is 0.850563236047107 with params\n",
    "#{'colsample_bylevel': 0.3, 'colsample_bytree': 0.5, 'learning_rate': 0.15, 'max_depth': 2, 'n_estimators': 100, 'subsample': 0.7}\n",
    "\n",
    "# save dataframe\n",
    "from datetime import datetime\n",
    "date = str(datetime.now().date()).replace(\"-\", \"\")\n",
    "xgb_grid_search_results_full_3.to_csv(f\"results/xgb_results_full_round2_3_bylevel=0.3_{date}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1205514d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_colsample_bylevel</th>\n",
       "      <th>param_colsample_bytree</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_subsample</th>\n",
       "      <th>...</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.061735</td>\n",
       "      <td>0.001296</td>\n",
       "      <td>0.006482</td>\n",
       "      <td>0.000669</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.820020</td>\n",
       "      <td>0.048275</td>\n",
       "      <td>2502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.063031</td>\n",
       "      <td>0.002778</td>\n",
       "      <td>0.006483</td>\n",
       "      <td>0.000669</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.661290</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.823221</td>\n",
       "      <td>0.059057</td>\n",
       "      <td>2077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.060638</td>\n",
       "      <td>0.000746</td>\n",
       "      <td>0.006782</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.824782</td>\n",
       "      <td>0.057512</td>\n",
       "      <td>1941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.060339</td>\n",
       "      <td>0.000919</td>\n",
       "      <td>0.006483</td>\n",
       "      <td>0.000499</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.661290</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.824834</td>\n",
       "      <td>0.059251</td>\n",
       "      <td>1818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.059840</td>\n",
       "      <td>0.001180</td>\n",
       "      <td>0.006682</td>\n",
       "      <td>0.000457</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.828059</td>\n",
       "      <td>0.053977</td>\n",
       "      <td>1289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2995</th>\n",
       "      <td>0.218216</td>\n",
       "      <td>0.004179</td>\n",
       "      <td>0.007181</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.808807</td>\n",
       "      <td>0.046180</td>\n",
       "      <td>2975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2996</th>\n",
       "      <td>0.221009</td>\n",
       "      <td>0.003402</td>\n",
       "      <td>0.007480</td>\n",
       "      <td>0.000499</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.812007</td>\n",
       "      <td>0.049754</td>\n",
       "      <td>2922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2997</th>\n",
       "      <td>0.221308</td>\n",
       "      <td>0.004515</td>\n",
       "      <td>0.007380</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.816795</td>\n",
       "      <td>0.050406</td>\n",
       "      <td>2770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998</th>\n",
       "      <td>0.219213</td>\n",
       "      <td>0.003908</td>\n",
       "      <td>0.007194</td>\n",
       "      <td>0.000425</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.816820</td>\n",
       "      <td>0.047212</td>\n",
       "      <td>2763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999</th>\n",
       "      <td>0.216122</td>\n",
       "      <td>0.003092</td>\n",
       "      <td>0.007381</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.818382</td>\n",
       "      <td>0.050014</td>\n",
       "      <td>2693</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0          0.061735      0.001296         0.006482        0.000669   \n",
       "1          0.063031      0.002778         0.006483        0.000669   \n",
       "2          0.060638      0.000746         0.006782        0.000399   \n",
       "3          0.060339      0.000919         0.006483        0.000499   \n",
       "4          0.059840      0.001180         0.006682        0.000457   \n",
       "...             ...           ...              ...             ...   \n",
       "2995       0.218216      0.004179         0.007181        0.000399   \n",
       "2996       0.221009      0.003402         0.007480        0.000499   \n",
       "2997       0.221308      0.004515         0.007380        0.000489   \n",
       "2998       0.219213      0.003908         0.007194        0.000425   \n",
       "2999       0.216122      0.003092         0.007381        0.000489   \n",
       "\n",
       "      param_colsample_bylevel  param_colsample_bytree  param_learning_rate  \\\n",
       "0                         0.4                     0.3                  0.1   \n",
       "1                         0.4                     0.3                  0.1   \n",
       "2                         0.4                     0.3                  0.1   \n",
       "3                         0.4                     0.3                  0.1   \n",
       "4                         0.4                     0.3                  0.1   \n",
       "...                       ...                     ...                  ...   \n",
       "2995                      0.4                     0.9                  0.4   \n",
       "2996                      0.4                     0.9                  0.4   \n",
       "2997                      0.4                     0.9                  0.4   \n",
       "2998                      0.4                     0.9                  0.4   \n",
       "2999                      0.4                     0.9                  0.4   \n",
       "\n",
       "      param_max_depth  param_n_estimators  param_subsample  ...  \\\n",
       "0                   2                 100              0.5  ...   \n",
       "1                   2                 100              0.6  ...   \n",
       "2                   2                 100              0.7  ...   \n",
       "3                   2                 100              0.8  ...   \n",
       "4                   2                 100              0.9  ...   \n",
       "...               ...                 ...              ...  ...   \n",
       "2995                5                 300              0.5  ...   \n",
       "2996                5                 300              0.6  ...   \n",
       "2997                5                 300              0.7  ...   \n",
       "2998                5                 300              0.8  ...   \n",
       "2999                5                 300              0.9  ...   \n",
       "\n",
       "     split3_test_score  split4_test_score  split5_test_score  \\\n",
       "0             0.822581           0.822581           0.806452   \n",
       "1             0.838710           0.822581           0.806452   \n",
       "2             0.838710           0.806452           0.806452   \n",
       "3             0.854839           0.822581           0.806452   \n",
       "4             0.854839           0.822581           0.838710   \n",
       "...                ...                ...                ...   \n",
       "2995          0.838710           0.758065           0.790323   \n",
       "2996          0.838710           0.790323           0.806452   \n",
       "2997          0.838710           0.790323           0.790323   \n",
       "2998          0.838710           0.790323           0.806452   \n",
       "2999          0.822581           0.774194           0.774194   \n",
       "\n",
       "      split6_test_score  split7_test_score  split8_test_score  \\\n",
       "0              0.822581           0.806452           0.693548   \n",
       "1              0.838710           0.806452           0.661290   \n",
       "2              0.838710           0.806452           0.677419   \n",
       "3              0.854839           0.806452           0.661290   \n",
       "4              0.838710           0.806452           0.677419   \n",
       "...                 ...                ...                ...   \n",
       "2995           0.806452           0.790323           0.741935   \n",
       "2996           0.838710           0.774194           0.725806   \n",
       "2997           0.790323           0.822581           0.725806   \n",
       "2998           0.838710           0.790323           0.725806   \n",
       "2999           0.854839           0.790323           0.725806   \n",
       "\n",
       "      split9_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0              0.838710         0.820020        0.048275             2502  \n",
       "1              0.854839         0.823221        0.059057             2077  \n",
       "2              0.838710         0.824782        0.057512             1941  \n",
       "3              0.838710         0.824834        0.059251             1818  \n",
       "4              0.838710         0.828059        0.053977             1289  \n",
       "...                 ...              ...             ...              ...  \n",
       "2995           0.822581         0.808807        0.046180             2975  \n",
       "2996           0.790323         0.812007        0.049754             2922  \n",
       "2997           0.822581         0.816795        0.050406             2770  \n",
       "2998           0.806452         0.816820        0.047212             2763  \n",
       "2999           0.838710         0.818382        0.050014             2693  \n",
       "\n",
       "[3000 rows x 24 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score is 0.850563236047107 with params {'colsample_bylevel': 0.4, 'colsample_bytree': 0.5, 'learning_rate': 0.15, 'max_depth': 2, 'n_estimators': 100, 'subsample': 0.7}\n"
     ]
    }
   ],
   "source": [
    "df4 = pd.read_csv(\"data\\\\xgb_results_full_4_bylevel=0.4_20221123.csv\")\n",
    "df4.drop(df4.columns[0], axis=1, inplace=True)\n",
    "display(df4)\n",
    "print(\"best score is 0.850563236047107 with params {'colsample_bylevel': 0.4, 'colsample_bytree': 0.5, 'learning_rate': 0.15, 'max_depth': 2, 'n_estimators': 100, 'subsample': 0.7}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b8606396",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_colsample_bylevel</th>\n",
       "      <th>param_colsample_bytree</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_subsample</th>\n",
       "      <th>...</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.061735</td>\n",
       "      <td>0.001296</td>\n",
       "      <td>0.006482</td>\n",
       "      <td>0.000669</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.820020</td>\n",
       "      <td>0.048275</td>\n",
       "      <td>2502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.063031</td>\n",
       "      <td>0.002778</td>\n",
       "      <td>0.006483</td>\n",
       "      <td>0.000669</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.661290</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.823221</td>\n",
       "      <td>0.059057</td>\n",
       "      <td>2077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.060638</td>\n",
       "      <td>0.000746</td>\n",
       "      <td>0.006782</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.824782</td>\n",
       "      <td>0.057512</td>\n",
       "      <td>1941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.060339</td>\n",
       "      <td>0.000919</td>\n",
       "      <td>0.006483</td>\n",
       "      <td>0.000499</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.661290</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.824834</td>\n",
       "      <td>0.059251</td>\n",
       "      <td>1818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.059840</td>\n",
       "      <td>0.001180</td>\n",
       "      <td>0.006682</td>\n",
       "      <td>0.000457</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.828059</td>\n",
       "      <td>0.053977</td>\n",
       "      <td>1289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2995</th>\n",
       "      <td>0.218216</td>\n",
       "      <td>0.004179</td>\n",
       "      <td>0.007181</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.808807</td>\n",
       "      <td>0.046180</td>\n",
       "      <td>2975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2996</th>\n",
       "      <td>0.221009</td>\n",
       "      <td>0.003402</td>\n",
       "      <td>0.007480</td>\n",
       "      <td>0.000499</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.812007</td>\n",
       "      <td>0.049754</td>\n",
       "      <td>2922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2997</th>\n",
       "      <td>0.221308</td>\n",
       "      <td>0.004515</td>\n",
       "      <td>0.007380</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.816795</td>\n",
       "      <td>0.050406</td>\n",
       "      <td>2770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998</th>\n",
       "      <td>0.219213</td>\n",
       "      <td>0.003908</td>\n",
       "      <td>0.007194</td>\n",
       "      <td>0.000425</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.816820</td>\n",
       "      <td>0.047212</td>\n",
       "      <td>2763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999</th>\n",
       "      <td>0.216122</td>\n",
       "      <td>0.003092</td>\n",
       "      <td>0.007381</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.818382</td>\n",
       "      <td>0.050014</td>\n",
       "      <td>2693</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0          0.061735      0.001296         0.006482        0.000669   \n",
       "1          0.063031      0.002778         0.006483        0.000669   \n",
       "2          0.060638      0.000746         0.006782        0.000399   \n",
       "3          0.060339      0.000919         0.006483        0.000499   \n",
       "4          0.059840      0.001180         0.006682        0.000457   \n",
       "...             ...           ...              ...             ...   \n",
       "2995       0.218216      0.004179         0.007181        0.000399   \n",
       "2996       0.221009      0.003402         0.007480        0.000499   \n",
       "2997       0.221308      0.004515         0.007380        0.000489   \n",
       "2998       0.219213      0.003908         0.007194        0.000425   \n",
       "2999       0.216122      0.003092         0.007381        0.000489   \n",
       "\n",
       "     param_colsample_bylevel param_colsample_bytree param_learning_rate  \\\n",
       "0                        0.4                    0.3                 0.1   \n",
       "1                        0.4                    0.3                 0.1   \n",
       "2                        0.4                    0.3                 0.1   \n",
       "3                        0.4                    0.3                 0.1   \n",
       "4                        0.4                    0.3                 0.1   \n",
       "...                      ...                    ...                 ...   \n",
       "2995                     0.4                    0.9                 0.4   \n",
       "2996                     0.4                    0.9                 0.4   \n",
       "2997                     0.4                    0.9                 0.4   \n",
       "2998                     0.4                    0.9                 0.4   \n",
       "2999                     0.4                    0.9                 0.4   \n",
       "\n",
       "     param_max_depth param_n_estimators param_subsample  ...  \\\n",
       "0                  2                100             0.5  ...   \n",
       "1                  2                100             0.6  ...   \n",
       "2                  2                100             0.7  ...   \n",
       "3                  2                100             0.8  ...   \n",
       "4                  2                100             0.9  ...   \n",
       "...              ...                ...             ...  ...   \n",
       "2995               5                300             0.5  ...   \n",
       "2996               5                300             0.6  ...   \n",
       "2997               5                300             0.7  ...   \n",
       "2998               5                300             0.8  ...   \n",
       "2999               5                300             0.9  ...   \n",
       "\n",
       "     split3_test_score  split4_test_score  split5_test_score  \\\n",
       "0             0.822581           0.822581           0.806452   \n",
       "1             0.838710           0.822581           0.806452   \n",
       "2             0.838710           0.806452           0.806452   \n",
       "3             0.854839           0.822581           0.806452   \n",
       "4             0.854839           0.822581           0.838710   \n",
       "...                ...                ...                ...   \n",
       "2995          0.838710           0.758065           0.790323   \n",
       "2996          0.838710           0.790323           0.806452   \n",
       "2997          0.838710           0.790323           0.790323   \n",
       "2998          0.838710           0.790323           0.806452   \n",
       "2999          0.822581           0.774194           0.774194   \n",
       "\n",
       "      split6_test_score  split7_test_score  split8_test_score  \\\n",
       "0              0.822581           0.806452           0.693548   \n",
       "1              0.838710           0.806452           0.661290   \n",
       "2              0.838710           0.806452           0.677419   \n",
       "3              0.854839           0.806452           0.661290   \n",
       "4              0.838710           0.806452           0.677419   \n",
       "...                 ...                ...                ...   \n",
       "2995           0.806452           0.790323           0.741935   \n",
       "2996           0.838710           0.774194           0.725806   \n",
       "2997           0.790323           0.822581           0.725806   \n",
       "2998           0.838710           0.790323           0.725806   \n",
       "2999           0.854839           0.790323           0.725806   \n",
       "\n",
       "      split9_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0              0.838710         0.820020        0.048275             2502  \n",
       "1              0.854839         0.823221        0.059057             2077  \n",
       "2              0.838710         0.824782        0.057512             1941  \n",
       "3              0.838710         0.824834        0.059251             1818  \n",
       "4              0.838710         0.828059        0.053977             1289  \n",
       "...                 ...              ...             ...              ...  \n",
       "2995           0.822581         0.808807        0.046180             2975  \n",
       "2996           0.790323         0.812007        0.049754             2922  \n",
       "2997           0.822581         0.816795        0.050406             2770  \n",
       "2998           0.806452         0.816820        0.047212             2763  \n",
       "2999           0.838710         0.818382        0.050014             2693  \n",
       "\n",
       "[3000 rows x 24 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score is 0.850563236047107 with params {'colsample_bylevel': 0.4, 'colsample_bytree': 0.5, 'learning_rate': 0.15, 'max_depth': 2, 'n_estimators': 100, 'subsample': 0.7}\n"
     ]
    }
   ],
   "source": [
    "# Full Tuning - Part 4\n",
    "random.seed(10)\n",
    "\n",
    "xgb = XGBClassifier()\n",
    "\n",
    "xgb_parameters = {'max_depth': [2,3,4,5]\n",
    "                   , 'subsample': [0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "                   , 'colsample_bytree': [0.3, 0.4, 0.5, 0.6, 0.9]\n",
    "                   , 'colsample_bylevel': [0.4]\n",
    "                   , 'learning_rate': [0.1, 0.15, 0.2, 0.25, 0.3, 0.4]\n",
    "                   , 'n_estimators': [100, 150, 200, 250, 300]}\n",
    "\n",
    "stratified_10_fold_cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "xgb_grid_search = GridSearchCV(xgb, xgb_parameters, scoring='accuracy', cv=stratified_10_fold_cv)\n",
    "\n",
    "xgb_grid_search.fit(X_train, y_train)\n",
    "\n",
    "xgb_grid_search_results_full_4 = pd.DataFrame(xgb_grid_search.cv_results_)\n",
    "display(xgb_grid_search_results_full_4)\n",
    "\n",
    "print(\"best score is {} with params {}\".format(xgb_grid_search.best_score_, xgb_grid_search.best_params_))\n",
    "#best score is 0.850563236047107 with params\n",
    "#{'colsample_bylevel': 0.4, 'colsample_bytree': 0.5, 'learning_rate': 0.15, 'max_depth': 2, 'n_estimators': 100, 'subsample': 0.7}\n",
    "\n",
    "# save dataframe\n",
    "from datetime import datetime\n",
    "date = str(datetime.now().date()).replace(\"-\", \"\")\n",
    "xgb_grid_search_results_full_4.to_csv(f\"results/xgb_results_full_round2_4_bylevel=0.4_{date}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9153372b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_colsample_bylevel</th>\n",
       "      <th>param_colsample_bytree</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_subsample</th>\n",
       "      <th>...</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.063530</td>\n",
       "      <td>0.002446</td>\n",
       "      <td>0.006383</td>\n",
       "      <td>0.000662</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.834537</td>\n",
       "      <td>0.044892</td>\n",
       "      <td>215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.065725</td>\n",
       "      <td>0.003351</td>\n",
       "      <td>0.006882</td>\n",
       "      <td>0.000299</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.832949</td>\n",
       "      <td>0.048291</td>\n",
       "      <td>320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.062236</td>\n",
       "      <td>0.001196</td>\n",
       "      <td>0.006780</td>\n",
       "      <td>0.000398</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.887097</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.842601</td>\n",
       "      <td>0.046342</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.061335</td>\n",
       "      <td>0.001798</td>\n",
       "      <td>0.006583</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.834562</td>\n",
       "      <td>0.050284</td>\n",
       "      <td>208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.060937</td>\n",
       "      <td>0.000698</td>\n",
       "      <td>0.006483</td>\n",
       "      <td>0.000669</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.887097</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.832924</td>\n",
       "      <td>0.057218</td>\n",
       "      <td>327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2995</th>\n",
       "      <td>0.219613</td>\n",
       "      <td>0.001532</td>\n",
       "      <td>0.007380</td>\n",
       "      <td>0.000488</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.805504</td>\n",
       "      <td>0.051226</td>\n",
       "      <td>2997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2996</th>\n",
       "      <td>0.222105</td>\n",
       "      <td>0.001787</td>\n",
       "      <td>0.006882</td>\n",
       "      <td>0.000698</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.810317</td>\n",
       "      <td>0.059764</td>\n",
       "      <td>2968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2997</th>\n",
       "      <td>0.221906</td>\n",
       "      <td>0.002534</td>\n",
       "      <td>0.007281</td>\n",
       "      <td>0.000457</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.818331</td>\n",
       "      <td>0.051641</td>\n",
       "      <td>2706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998</th>\n",
       "      <td>0.224599</td>\n",
       "      <td>0.011023</td>\n",
       "      <td>0.007380</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.816718</td>\n",
       "      <td>0.054669</td>\n",
       "      <td>2825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999</th>\n",
       "      <td>0.219812</td>\n",
       "      <td>0.002609</td>\n",
       "      <td>0.007381</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.807220</td>\n",
       "      <td>0.045482</td>\n",
       "      <td>2983</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0          0.063530      0.002446         0.006383        0.000662   \n",
       "1          0.065725      0.003351         0.006882        0.000299   \n",
       "2          0.062236      0.001196         0.006780        0.000398   \n",
       "3          0.061335      0.001798         0.006583        0.000489   \n",
       "4          0.060937      0.000698         0.006483        0.000669   \n",
       "...             ...           ...              ...             ...   \n",
       "2995       0.219613      0.001532         0.007380        0.000488   \n",
       "2996       0.222105      0.001787         0.006882        0.000698   \n",
       "2997       0.221906      0.002534         0.007281        0.000457   \n",
       "2998       0.224599      0.011023         0.007380        0.000489   \n",
       "2999       0.219812      0.002609         0.007381        0.000489   \n",
       "\n",
       "      param_colsample_bylevel  param_colsample_bytree  param_learning_rate  \\\n",
       "0                         0.6                     0.3                  0.1   \n",
       "1                         0.6                     0.3                  0.1   \n",
       "2                         0.6                     0.3                  0.1   \n",
       "3                         0.6                     0.3                  0.1   \n",
       "4                         0.6                     0.3                  0.1   \n",
       "...                       ...                     ...                  ...   \n",
       "2995                      0.6                     0.9                  0.4   \n",
       "2996                      0.6                     0.9                  0.4   \n",
       "2997                      0.6                     0.9                  0.4   \n",
       "2998                      0.6                     0.9                  0.4   \n",
       "2999                      0.6                     0.9                  0.4   \n",
       "\n",
       "      param_max_depth  param_n_estimators  param_subsample  ...  \\\n",
       "0                   2                 100              0.5  ...   \n",
       "1                   2                 100              0.6  ...   \n",
       "2                   2                 100              0.7  ...   \n",
       "3                   2                 100              0.8  ...   \n",
       "4                   2                 100              0.9  ...   \n",
       "...               ...                 ...              ...  ...   \n",
       "2995                5                 300              0.5  ...   \n",
       "2996                5                 300              0.6  ...   \n",
       "2997                5                 300              0.7  ...   \n",
       "2998                5                 300              0.8  ...   \n",
       "2999                5                 300              0.9  ...   \n",
       "\n",
       "     split3_test_score  split4_test_score  split5_test_score  \\\n",
       "0             0.870968           0.822581           0.838710   \n",
       "1             0.854839           0.822581           0.854839   \n",
       "2             0.887097           0.838710           0.854839   \n",
       "3             0.870968           0.822581           0.870968   \n",
       "4             0.870968           0.822581           0.887097   \n",
       "...                ...                ...                ...   \n",
       "2995          0.806452           0.741935           0.774194   \n",
       "2996          0.854839           0.790323           0.758065   \n",
       "2997          0.838710           0.774194           0.790323   \n",
       "2998          0.838710           0.790323           0.758065   \n",
       "2999          0.822581           0.790323           0.758065   \n",
       "\n",
       "      split6_test_score  split7_test_score  split8_test_score  \\\n",
       "0              0.854839           0.822581           0.709677   \n",
       "1              0.854839           0.822581           0.693548   \n",
       "2              0.854839           0.838710           0.709677   \n",
       "3              0.838710           0.822581           0.693548   \n",
       "4              0.822581           0.806452           0.677419   \n",
       "...                 ...                ...                ...   \n",
       "2995           0.806452           0.790323           0.741935   \n",
       "2996           0.822581           0.741935           0.725806   \n",
       "2997           0.822581           0.774194           0.725806   \n",
       "2998           0.822581           0.806452           0.709677   \n",
       "2999           0.838710           0.806452           0.709677   \n",
       "\n",
       "      split9_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0              0.838710         0.834537        0.044892              215  \n",
       "1              0.854839         0.832949        0.048291              320  \n",
       "2              0.854839         0.842601        0.046342               17  \n",
       "3              0.854839         0.834562        0.050284              208  \n",
       "4              0.854839         0.832924        0.057218              327  \n",
       "...                 ...              ...             ...              ...  \n",
       "2995           0.806452         0.805504        0.051226             2997  \n",
       "2996           0.806452         0.810317        0.059764             2968  \n",
       "2997           0.822581         0.818331        0.051641             2706  \n",
       "2998           0.806452         0.816718        0.054669             2825  \n",
       "2999           0.822581         0.807220        0.045482             2983  \n",
       "\n",
       "[3000 rows x 24 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score is 0.8458269329237071 with params {'colsample_bylevel': 0.6, 'colsample_bytree': 0.4, 'learning_rate': 0.1, 'max_depth': 2, 'n_estimators': 100, 'subsample': 0.8}\n"
     ]
    }
   ],
   "source": [
    "df5 = pd.read_csv(\"data\\\\xgb_results_full_5_bylevel=0.6_20221123.csv\")\n",
    "df5.drop(df5.columns[0], axis=1, inplace=True)\n",
    "display(df5)\n",
    "print(\"best score is 0.8458269329237071 with params {'colsample_bylevel': 0.6, 'colsample_bytree': 0.4, 'learning_rate': 0.1, 'max_depth': 2, 'n_estimators': 100, 'subsample': 0.8}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "04f9734e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_colsample_bylevel</th>\n",
       "      <th>param_colsample_bytree</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_subsample</th>\n",
       "      <th>...</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.063530</td>\n",
       "      <td>0.002446</td>\n",
       "      <td>0.006383</td>\n",
       "      <td>0.000662</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.834537</td>\n",
       "      <td>0.044892</td>\n",
       "      <td>215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.065725</td>\n",
       "      <td>0.003351</td>\n",
       "      <td>0.006882</td>\n",
       "      <td>0.000299</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.832949</td>\n",
       "      <td>0.048291</td>\n",
       "      <td>320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.062236</td>\n",
       "      <td>0.001196</td>\n",
       "      <td>0.006780</td>\n",
       "      <td>0.000398</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.887097</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.842601</td>\n",
       "      <td>0.046342</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.061335</td>\n",
       "      <td>0.001798</td>\n",
       "      <td>0.006583</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.834562</td>\n",
       "      <td>0.050284</td>\n",
       "      <td>208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.060937</td>\n",
       "      <td>0.000698</td>\n",
       "      <td>0.006483</td>\n",
       "      <td>0.000669</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.887097</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.832924</td>\n",
       "      <td>0.057218</td>\n",
       "      <td>327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2995</th>\n",
       "      <td>0.219613</td>\n",
       "      <td>0.001532</td>\n",
       "      <td>0.007380</td>\n",
       "      <td>0.000488</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.805504</td>\n",
       "      <td>0.051226</td>\n",
       "      <td>2997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2996</th>\n",
       "      <td>0.222105</td>\n",
       "      <td>0.001787</td>\n",
       "      <td>0.006882</td>\n",
       "      <td>0.000698</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.810317</td>\n",
       "      <td>0.059764</td>\n",
       "      <td>2968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2997</th>\n",
       "      <td>0.221906</td>\n",
       "      <td>0.002534</td>\n",
       "      <td>0.007281</td>\n",
       "      <td>0.000457</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.818331</td>\n",
       "      <td>0.051641</td>\n",
       "      <td>2706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998</th>\n",
       "      <td>0.224599</td>\n",
       "      <td>0.011023</td>\n",
       "      <td>0.007380</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.816718</td>\n",
       "      <td>0.054669</td>\n",
       "      <td>2825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999</th>\n",
       "      <td>0.219812</td>\n",
       "      <td>0.002609</td>\n",
       "      <td>0.007381</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.807220</td>\n",
       "      <td>0.045482</td>\n",
       "      <td>2983</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0          0.063530      0.002446         0.006383        0.000662   \n",
       "1          0.065725      0.003351         0.006882        0.000299   \n",
       "2          0.062236      0.001196         0.006780        0.000398   \n",
       "3          0.061335      0.001798         0.006583        0.000489   \n",
       "4          0.060937      0.000698         0.006483        0.000669   \n",
       "...             ...           ...              ...             ...   \n",
       "2995       0.219613      0.001532         0.007380        0.000488   \n",
       "2996       0.222105      0.001787         0.006882        0.000698   \n",
       "2997       0.221906      0.002534         0.007281        0.000457   \n",
       "2998       0.224599      0.011023         0.007380        0.000489   \n",
       "2999       0.219812      0.002609         0.007381        0.000489   \n",
       "\n",
       "     param_colsample_bylevel param_colsample_bytree param_learning_rate  \\\n",
       "0                        0.6                    0.3                 0.1   \n",
       "1                        0.6                    0.3                 0.1   \n",
       "2                        0.6                    0.3                 0.1   \n",
       "3                        0.6                    0.3                 0.1   \n",
       "4                        0.6                    0.3                 0.1   \n",
       "...                      ...                    ...                 ...   \n",
       "2995                     0.6                    0.9                 0.4   \n",
       "2996                     0.6                    0.9                 0.4   \n",
       "2997                     0.6                    0.9                 0.4   \n",
       "2998                     0.6                    0.9                 0.4   \n",
       "2999                     0.6                    0.9                 0.4   \n",
       "\n",
       "     param_max_depth param_n_estimators param_subsample  ...  \\\n",
       "0                  2                100             0.5  ...   \n",
       "1                  2                100             0.6  ...   \n",
       "2                  2                100             0.7  ...   \n",
       "3                  2                100             0.8  ...   \n",
       "4                  2                100             0.9  ...   \n",
       "...              ...                ...             ...  ...   \n",
       "2995               5                300             0.5  ...   \n",
       "2996               5                300             0.6  ...   \n",
       "2997               5                300             0.7  ...   \n",
       "2998               5                300             0.8  ...   \n",
       "2999               5                300             0.9  ...   \n",
       "\n",
       "     split3_test_score  split4_test_score  split5_test_score  \\\n",
       "0             0.870968           0.822581           0.838710   \n",
       "1             0.854839           0.822581           0.854839   \n",
       "2             0.887097           0.838710           0.854839   \n",
       "3             0.870968           0.822581           0.870968   \n",
       "4             0.870968           0.822581           0.887097   \n",
       "...                ...                ...                ...   \n",
       "2995          0.806452           0.741935           0.774194   \n",
       "2996          0.854839           0.790323           0.758065   \n",
       "2997          0.838710           0.774194           0.790323   \n",
       "2998          0.838710           0.790323           0.758065   \n",
       "2999          0.822581           0.790323           0.758065   \n",
       "\n",
       "      split6_test_score  split7_test_score  split8_test_score  \\\n",
       "0              0.854839           0.822581           0.709677   \n",
       "1              0.854839           0.822581           0.693548   \n",
       "2              0.854839           0.838710           0.709677   \n",
       "3              0.838710           0.822581           0.693548   \n",
       "4              0.822581           0.806452           0.677419   \n",
       "...                 ...                ...                ...   \n",
       "2995           0.806452           0.790323           0.741935   \n",
       "2996           0.822581           0.741935           0.725806   \n",
       "2997           0.822581           0.774194           0.725806   \n",
       "2998           0.822581           0.806452           0.709677   \n",
       "2999           0.838710           0.806452           0.709677   \n",
       "\n",
       "      split9_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0              0.838710         0.834537        0.044892              215  \n",
       "1              0.854839         0.832949        0.048291              320  \n",
       "2              0.854839         0.842601        0.046342               17  \n",
       "3              0.854839         0.834562        0.050284              208  \n",
       "4              0.854839         0.832924        0.057218              327  \n",
       "...                 ...              ...             ...              ...  \n",
       "2995           0.806452         0.805504        0.051226             2997  \n",
       "2996           0.806452         0.810317        0.059764             2968  \n",
       "2997           0.822581         0.818331        0.051641             2706  \n",
       "2998           0.806452         0.816718        0.054669             2825  \n",
       "2999           0.822581         0.807220        0.045482             2983  \n",
       "\n",
       "[3000 rows x 24 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score is 0.8458269329237071 with params {'colsample_bylevel': 0.6, 'colsample_bytree': 0.4, 'learning_rate': 0.1, 'max_depth': 2, 'n_estimators': 100, 'subsample': 0.8}\n"
     ]
    }
   ],
   "source": [
    "# Full Tuning - Part 5\n",
    "random.seed(10)\n",
    "\n",
    "xgb = XGBClassifier()\n",
    "\n",
    "xgb_parameters = {'max_depth': [2,3,4,5]\n",
    "                   , 'subsample': [0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "                   , 'colsample_bytree': [0.3, 0.4, 0.5, 0.6, 0.9]\n",
    "                   , 'colsample_bylevel': [0.6]\n",
    "                   , 'learning_rate': [0.1, 0.15, 0.2, 0.25, 0.3, 0.4]\n",
    "                   , 'n_estimators': [100, 150, 200, 250, 300]}\n",
    "\n",
    "stratified_10_fold_cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "xgb_grid_search = GridSearchCV(xgb, xgb_parameters, scoring='accuracy', cv=stratified_10_fold_cv)\n",
    "\n",
    "xgb_grid_search.fit(X_train, y_train)\n",
    "\n",
    "xgb_grid_search_results_full_5 = pd.DataFrame(xgb_grid_search.cv_results_)\n",
    "display(xgb_grid_search_results_full_5)\n",
    "\n",
    "print(\"best score is {} with params {}\".format(xgb_grid_search.best_score_, xgb_grid_search.best_params_))\n",
    "#best score is 0.8458269329237071 with params\n",
    "#{'colsample_bylevel': 0.6, 'colsample_bytree': 0.4, 'learning_rate': 0.1, 'max_depth': 2, 'n_estimators': 100, 'subsample': 0.8}\n",
    "\n",
    "# save dataframe\n",
    "from datetime import datetime\n",
    "date = str(datetime.now().date()).replace(\"-\", \"\")\n",
    "xgb_grid_search_results_full_5.to_csv(f\"results/xgb_results_full_round2_5_bylevel=0.6_{date}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b6962257",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_colsample_bylevel</th>\n",
       "      <th>param_colsample_bytree</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_subsample</th>\n",
       "      <th>...</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.063128</td>\n",
       "      <td>0.002527</td>\n",
       "      <td>0.006483</td>\n",
       "      <td>0.000669</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.834537</td>\n",
       "      <td>0.044892</td>\n",
       "      <td>218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.065325</td>\n",
       "      <td>0.003097</td>\n",
       "      <td>0.006882</td>\n",
       "      <td>0.000537</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.832949</td>\n",
       "      <td>0.048291</td>\n",
       "      <td>327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.061886</td>\n",
       "      <td>0.000566</td>\n",
       "      <td>0.006583</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.887097</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.842601</td>\n",
       "      <td>0.046342</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.061137</td>\n",
       "      <td>0.000638</td>\n",
       "      <td>0.006882</td>\n",
       "      <td>0.000299</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.834562</td>\n",
       "      <td>0.050284</td>\n",
       "      <td>210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.060537</td>\n",
       "      <td>0.000638</td>\n",
       "      <td>0.006682</td>\n",
       "      <td>0.000457</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.887097</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.832924</td>\n",
       "      <td>0.057218</td>\n",
       "      <td>333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2995</th>\n",
       "      <td>0.228489</td>\n",
       "      <td>0.002462</td>\n",
       "      <td>0.007480</td>\n",
       "      <td>0.000499</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.802355</td>\n",
       "      <td>0.049888</td>\n",
       "      <td>2998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2996</th>\n",
       "      <td>0.228688</td>\n",
       "      <td>0.002142</td>\n",
       "      <td>0.007281</td>\n",
       "      <td>0.000457</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.800768</td>\n",
       "      <td>0.052893</td>\n",
       "      <td>2999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2997</th>\n",
       "      <td>0.228987</td>\n",
       "      <td>0.001197</td>\n",
       "      <td>0.007580</td>\n",
       "      <td>0.000488</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.810317</td>\n",
       "      <td>0.057193</td>\n",
       "      <td>2964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998</th>\n",
       "      <td>0.228788</td>\n",
       "      <td>0.001620</td>\n",
       "      <td>0.007181</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.816692</td>\n",
       "      <td>0.055624</td>\n",
       "      <td>2812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999</th>\n",
       "      <td>0.226893</td>\n",
       "      <td>0.002150</td>\n",
       "      <td>0.007381</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.818382</td>\n",
       "      <td>0.053516</td>\n",
       "      <td>2629</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0          0.063128      0.002527         0.006483        0.000669   \n",
       "1          0.065325      0.003097         0.006882        0.000537   \n",
       "2          0.061886      0.000566         0.006583        0.000489   \n",
       "3          0.061137      0.000638         0.006882        0.000299   \n",
       "4          0.060537      0.000638         0.006682        0.000457   \n",
       "...             ...           ...              ...             ...   \n",
       "2995       0.228489      0.002462         0.007480        0.000499   \n",
       "2996       0.228688      0.002142         0.007281        0.000457   \n",
       "2997       0.228987      0.001197         0.007580        0.000488   \n",
       "2998       0.228788      0.001620         0.007181        0.000399   \n",
       "2999       0.226893      0.002150         0.007381        0.000489   \n",
       "\n",
       "      param_colsample_bylevel  param_colsample_bytree  param_learning_rate  \\\n",
       "0                         0.7                     0.3                  0.1   \n",
       "1                         0.7                     0.3                  0.1   \n",
       "2                         0.7                     0.3                  0.1   \n",
       "3                         0.7                     0.3                  0.1   \n",
       "4                         0.7                     0.3                  0.1   \n",
       "...                       ...                     ...                  ...   \n",
       "2995                      0.7                     0.9                  0.4   \n",
       "2996                      0.7                     0.9                  0.4   \n",
       "2997                      0.7                     0.9                  0.4   \n",
       "2998                      0.7                     0.9                  0.4   \n",
       "2999                      0.7                     0.9                  0.4   \n",
       "\n",
       "      param_max_depth  param_n_estimators  param_subsample  ...  \\\n",
       "0                   2                 100              0.5  ...   \n",
       "1                   2                 100              0.6  ...   \n",
       "2                   2                 100              0.7  ...   \n",
       "3                   2                 100              0.8  ...   \n",
       "4                   2                 100              0.9  ...   \n",
       "...               ...                 ...              ...  ...   \n",
       "2995                5                 300              0.5  ...   \n",
       "2996                5                 300              0.6  ...   \n",
       "2997                5                 300              0.7  ...   \n",
       "2998                5                 300              0.8  ...   \n",
       "2999                5                 300              0.9  ...   \n",
       "\n",
       "     split3_test_score  split4_test_score  split5_test_score  \\\n",
       "0             0.870968           0.822581           0.838710   \n",
       "1             0.854839           0.822581           0.854839   \n",
       "2             0.887097           0.838710           0.854839   \n",
       "3             0.870968           0.822581           0.870968   \n",
       "4             0.870968           0.822581           0.887097   \n",
       "...                ...                ...                ...   \n",
       "2995          0.822581           0.774194           0.806452   \n",
       "2996          0.822581           0.774194           0.790323   \n",
       "2997          0.870968           0.774194           0.774194   \n",
       "2998          0.822581           0.790323           0.774194   \n",
       "2999          0.806452           0.790323           0.774194   \n",
       "\n",
       "      split6_test_score  split7_test_score  split8_test_score  \\\n",
       "0              0.854839           0.822581           0.709677   \n",
       "1              0.854839           0.822581           0.693548   \n",
       "2              0.854839           0.838710           0.709677   \n",
       "3              0.838710           0.822581           0.693548   \n",
       "4              0.822581           0.806452           0.677419   \n",
       "...                 ...                ...                ...   \n",
       "2995           0.822581           0.774194           0.709677   \n",
       "2996           0.822581           0.790323           0.693548   \n",
       "2997           0.790323           0.790323           0.709677   \n",
       "2998           0.822581           0.790323           0.709677   \n",
       "2999           0.854839           0.790323           0.709677   \n",
       "\n",
       "      split9_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0              0.838710         0.834537        0.044892              218  \n",
       "1              0.854839         0.832949        0.048291              327  \n",
       "2              0.854839         0.842601        0.046342               16  \n",
       "3              0.854839         0.834562        0.050284              210  \n",
       "4              0.854839         0.832924        0.057218              333  \n",
       "...                 ...              ...             ...              ...  \n",
       "2995           0.774194         0.802355        0.049888             2998  \n",
       "2996           0.790323         0.800768        0.052893             2999  \n",
       "2997           0.790323         0.810317        0.057193             2964  \n",
       "2998           0.806452         0.816692        0.055624             2812  \n",
       "2999           0.854839         0.818382        0.053516             2629  \n",
       "\n",
       "[3000 rows x 24 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score is 0.8490015360983103 with params {'colsample_bylevel': 0.7, 'colsample_bytree': 0.4, 'learning_rate': 0.1, 'max_depth': 2, 'n_estimators': 150, 'subsample': 0.9}\n"
     ]
    }
   ],
   "source": [
    "df6 = pd.read_csv(\"data\\\\xgb_results_full_6_bylevel=0.7_20221123.csv\")\n",
    "df6.drop(df6.columns[0], axis=1, inplace=True)\n",
    "display(df6)\n",
    "print(\"best score is 0.8490015360983103 with params {'colsample_bylevel': 0.7, 'colsample_bytree': 0.4, 'learning_rate': 0.1, 'max_depth': 2, 'n_estimators': 150, 'subsample': 0.9}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dc96b622",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_colsample_bylevel</th>\n",
       "      <th>param_colsample_bytree</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_subsample</th>\n",
       "      <th>...</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.063128</td>\n",
       "      <td>0.002527</td>\n",
       "      <td>0.006483</td>\n",
       "      <td>0.000669</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.834537</td>\n",
       "      <td>0.044892</td>\n",
       "      <td>218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.065325</td>\n",
       "      <td>0.003097</td>\n",
       "      <td>0.006882</td>\n",
       "      <td>0.000537</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.832949</td>\n",
       "      <td>0.048291</td>\n",
       "      <td>327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.061886</td>\n",
       "      <td>0.000566</td>\n",
       "      <td>0.006583</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.887097</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.842601</td>\n",
       "      <td>0.046342</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.061137</td>\n",
       "      <td>0.000638</td>\n",
       "      <td>0.006882</td>\n",
       "      <td>0.000299</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.834562</td>\n",
       "      <td>0.050284</td>\n",
       "      <td>210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.060537</td>\n",
       "      <td>0.000638</td>\n",
       "      <td>0.006682</td>\n",
       "      <td>0.000457</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.887097</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.832924</td>\n",
       "      <td>0.057218</td>\n",
       "      <td>333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2995</th>\n",
       "      <td>0.228489</td>\n",
       "      <td>0.002462</td>\n",
       "      <td>0.007480</td>\n",
       "      <td>0.000499</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.802355</td>\n",
       "      <td>0.049888</td>\n",
       "      <td>2998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2996</th>\n",
       "      <td>0.228688</td>\n",
       "      <td>0.002142</td>\n",
       "      <td>0.007281</td>\n",
       "      <td>0.000457</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.800768</td>\n",
       "      <td>0.052893</td>\n",
       "      <td>2999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2997</th>\n",
       "      <td>0.228987</td>\n",
       "      <td>0.001197</td>\n",
       "      <td>0.007580</td>\n",
       "      <td>0.000488</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.810317</td>\n",
       "      <td>0.057193</td>\n",
       "      <td>2964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998</th>\n",
       "      <td>0.228788</td>\n",
       "      <td>0.001620</td>\n",
       "      <td>0.007181</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.816692</td>\n",
       "      <td>0.055624</td>\n",
       "      <td>2812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999</th>\n",
       "      <td>0.226893</td>\n",
       "      <td>0.002150</td>\n",
       "      <td>0.007381</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.818382</td>\n",
       "      <td>0.053516</td>\n",
       "      <td>2629</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0          0.063128      0.002527         0.006483        0.000669   \n",
       "1          0.065325      0.003097         0.006882        0.000537   \n",
       "2          0.061886      0.000566         0.006583        0.000489   \n",
       "3          0.061137      0.000638         0.006882        0.000299   \n",
       "4          0.060537      0.000638         0.006682        0.000457   \n",
       "...             ...           ...              ...             ...   \n",
       "2995       0.228489      0.002462         0.007480        0.000499   \n",
       "2996       0.228688      0.002142         0.007281        0.000457   \n",
       "2997       0.228987      0.001197         0.007580        0.000488   \n",
       "2998       0.228788      0.001620         0.007181        0.000399   \n",
       "2999       0.226893      0.002150         0.007381        0.000489   \n",
       "\n",
       "     param_colsample_bylevel param_colsample_bytree param_learning_rate  \\\n",
       "0                        0.7                    0.3                 0.1   \n",
       "1                        0.7                    0.3                 0.1   \n",
       "2                        0.7                    0.3                 0.1   \n",
       "3                        0.7                    0.3                 0.1   \n",
       "4                        0.7                    0.3                 0.1   \n",
       "...                      ...                    ...                 ...   \n",
       "2995                     0.7                    0.9                 0.4   \n",
       "2996                     0.7                    0.9                 0.4   \n",
       "2997                     0.7                    0.9                 0.4   \n",
       "2998                     0.7                    0.9                 0.4   \n",
       "2999                     0.7                    0.9                 0.4   \n",
       "\n",
       "     param_max_depth param_n_estimators param_subsample  ...  \\\n",
       "0                  2                100             0.5  ...   \n",
       "1                  2                100             0.6  ...   \n",
       "2                  2                100             0.7  ...   \n",
       "3                  2                100             0.8  ...   \n",
       "4                  2                100             0.9  ...   \n",
       "...              ...                ...             ...  ...   \n",
       "2995               5                300             0.5  ...   \n",
       "2996               5                300             0.6  ...   \n",
       "2997               5                300             0.7  ...   \n",
       "2998               5                300             0.8  ...   \n",
       "2999               5                300             0.9  ...   \n",
       "\n",
       "     split3_test_score  split4_test_score  split5_test_score  \\\n",
       "0             0.870968           0.822581           0.838710   \n",
       "1             0.854839           0.822581           0.854839   \n",
       "2             0.887097           0.838710           0.854839   \n",
       "3             0.870968           0.822581           0.870968   \n",
       "4             0.870968           0.822581           0.887097   \n",
       "...                ...                ...                ...   \n",
       "2995          0.822581           0.774194           0.806452   \n",
       "2996          0.822581           0.774194           0.790323   \n",
       "2997          0.870968           0.774194           0.774194   \n",
       "2998          0.822581           0.790323           0.774194   \n",
       "2999          0.806452           0.790323           0.774194   \n",
       "\n",
       "      split6_test_score  split7_test_score  split8_test_score  \\\n",
       "0              0.854839           0.822581           0.709677   \n",
       "1              0.854839           0.822581           0.693548   \n",
       "2              0.854839           0.838710           0.709677   \n",
       "3              0.838710           0.822581           0.693548   \n",
       "4              0.822581           0.806452           0.677419   \n",
       "...                 ...                ...                ...   \n",
       "2995           0.822581           0.774194           0.709677   \n",
       "2996           0.822581           0.790323           0.693548   \n",
       "2997           0.790323           0.790323           0.709677   \n",
       "2998           0.822581           0.790323           0.709677   \n",
       "2999           0.854839           0.790323           0.709677   \n",
       "\n",
       "      split9_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0              0.838710         0.834537        0.044892              218  \n",
       "1              0.854839         0.832949        0.048291              327  \n",
       "2              0.854839         0.842601        0.046342               16  \n",
       "3              0.854839         0.834562        0.050284              210  \n",
       "4              0.854839         0.832924        0.057218              333  \n",
       "...                 ...              ...             ...              ...  \n",
       "2995           0.774194         0.802355        0.049888             2998  \n",
       "2996           0.790323         0.800768        0.052893             2999  \n",
       "2997           0.790323         0.810317        0.057193             2964  \n",
       "2998           0.806452         0.816692        0.055624             2812  \n",
       "2999           0.854839         0.818382        0.053516             2629  \n",
       "\n",
       "[3000 rows x 24 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score is 0.8490015360983103 with params {'colsample_bylevel': 0.7, 'colsample_bytree': 0.4, 'learning_rate': 0.1, 'max_depth': 2, 'n_estimators': 150, 'subsample': 0.9}\n"
     ]
    }
   ],
   "source": [
    "# Full Tuning - Part 6\n",
    "random.seed(10)\n",
    "\n",
    "xgb = XGBClassifier()\n",
    "\n",
    "xgb_parameters = {'max_depth': [2,3,4,5]\n",
    "                   , 'subsample': [0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "                   , 'colsample_bytree': [0.3, 0.4, 0.5, 0.6, 0.9]\n",
    "                   , 'colsample_bylevel': [0.7]\n",
    "                   , 'learning_rate': [0.1, 0.15, 0.2, 0.25, 0.3, 0.4]\n",
    "                   , 'n_estimators': [100, 150, 200, 250, 300]}\n",
    "\n",
    "stratified_10_fold_cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "xgb_grid_search = GridSearchCV(xgb, xgb_parameters, scoring='accuracy', cv=stratified_10_fold_cv)\n",
    "\n",
    "xgb_grid_search.fit(X_train, y_train)\n",
    "\n",
    "xgb_grid_search_results_full_6 = pd.DataFrame(xgb_grid_search.cv_results_)\n",
    "display(xgb_grid_search_results_full_6)\n",
    "\n",
    "print(\"best score is {} with params {}\".format(xgb_grid_search.best_score_, xgb_grid_search.best_params_))\n",
    "#best score is 0.8490015360983103 with params\n",
    "#{'colsample_bylevel': 0.7, 'colsample_bytree': 0.4, 'learning_rate': 0.1, 'max_depth': 2, 'n_estimators': 150, 'subsample': 0.9}\n",
    "\n",
    "# save dataframe\n",
    "from datetime import datetime\n",
    "date = str(datetime.now().date()).replace(\"-\", \"\")\n",
    "xgb_grid_search_results_full_6.to_csv(f\"results/xgb_results_full_round2_6_bylevel=0.7_{date}.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd55526d",
   "metadata": {},
   "source": [
    "Combine single hyper parameter tuning to find best values for hyper parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9b22556b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_colsample_bylevel</th>\n",
       "      <th>param_colsample_bytree</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_subsample</th>\n",
       "      <th>...</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.064527</td>\n",
       "      <td>0.004136</td>\n",
       "      <td>0.005885</td>\n",
       "      <td>0.000538</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.820020</td>\n",
       "      <td>0.048275</td>\n",
       "      <td>15186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.064327</td>\n",
       "      <td>0.002493</td>\n",
       "      <td>0.005885</td>\n",
       "      <td>0.000537</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.661290</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.823221</td>\n",
       "      <td>0.059057</td>\n",
       "      <td>12810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.063231</td>\n",
       "      <td>0.001954</td>\n",
       "      <td>0.005785</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.824782</td>\n",
       "      <td>0.057512</td>\n",
       "      <td>12084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.062235</td>\n",
       "      <td>0.001017</td>\n",
       "      <td>0.006082</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.661290</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.824834</td>\n",
       "      <td>0.059251</td>\n",
       "      <td>11402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.062333</td>\n",
       "      <td>0.002285</td>\n",
       "      <td>0.005784</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.828059</td>\n",
       "      <td>0.053977</td>\n",
       "      <td>8256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17995</th>\n",
       "      <td>0.228489</td>\n",
       "      <td>0.002462</td>\n",
       "      <td>0.007480</td>\n",
       "      <td>0.000499</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.802355</td>\n",
       "      <td>0.049888</td>\n",
       "      <td>17998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17996</th>\n",
       "      <td>0.228688</td>\n",
       "      <td>0.002142</td>\n",
       "      <td>0.007281</td>\n",
       "      <td>0.000457</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.800768</td>\n",
       "      <td>0.052893</td>\n",
       "      <td>17999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17997</th>\n",
       "      <td>0.228987</td>\n",
       "      <td>0.001197</td>\n",
       "      <td>0.007580</td>\n",
       "      <td>0.000488</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.810317</td>\n",
       "      <td>0.057193</td>\n",
       "      <td>17871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17998</th>\n",
       "      <td>0.228788</td>\n",
       "      <td>0.001620</td>\n",
       "      <td>0.007181</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.816692</td>\n",
       "      <td>0.055624</td>\n",
       "      <td>17108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17999</th>\n",
       "      <td>0.226893</td>\n",
       "      <td>0.002150</td>\n",
       "      <td>0.007381</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.818382</td>\n",
       "      <td>0.053516</td>\n",
       "      <td>16381</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18000 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0           0.064527      0.004136         0.005885        0.000538   \n",
       "1           0.064327      0.002493         0.005885        0.000537   \n",
       "2           0.063231      0.001954         0.005785        0.000399   \n",
       "3           0.062235      0.001017         0.006082        0.000300   \n",
       "4           0.062333      0.002285         0.005784        0.000399   \n",
       "...              ...           ...              ...             ...   \n",
       "17995       0.228489      0.002462         0.007480        0.000499   \n",
       "17996       0.228688      0.002142         0.007281        0.000457   \n",
       "17997       0.228987      0.001197         0.007580        0.000488   \n",
       "17998       0.228788      0.001620         0.007181        0.000399   \n",
       "17999       0.226893      0.002150         0.007381        0.000489   \n",
       "\n",
       "       param_colsample_bylevel  param_colsample_bytree  param_learning_rate  \\\n",
       "0                          0.1                     0.3                  0.1   \n",
       "1                          0.1                     0.3                  0.1   \n",
       "2                          0.1                     0.3                  0.1   \n",
       "3                          0.1                     0.3                  0.1   \n",
       "4                          0.1                     0.3                  0.1   \n",
       "...                        ...                     ...                  ...   \n",
       "17995                      0.7                     0.9                  0.4   \n",
       "17996                      0.7                     0.9                  0.4   \n",
       "17997                      0.7                     0.9                  0.4   \n",
       "17998                      0.7                     0.9                  0.4   \n",
       "17999                      0.7                     0.9                  0.4   \n",
       "\n",
       "       param_max_depth  param_n_estimators  param_subsample  ...  \\\n",
       "0                    2                 100              0.5  ...   \n",
       "1                    2                 100              0.6  ...   \n",
       "2                    2                 100              0.7  ...   \n",
       "3                    2                 100              0.8  ...   \n",
       "4                    2                 100              0.9  ...   \n",
       "...                ...                 ...              ...  ...   \n",
       "17995                5                 300              0.5  ...   \n",
       "17996                5                 300              0.6  ...   \n",
       "17997                5                 300              0.7  ...   \n",
       "17998                5                 300              0.8  ...   \n",
       "17999                5                 300              0.9  ...   \n",
       "\n",
       "      split3_test_score  split4_test_score  split5_test_score  \\\n",
       "0              0.822581           0.822581           0.806452   \n",
       "1              0.838710           0.822581           0.806452   \n",
       "2              0.838710           0.806452           0.806452   \n",
       "3              0.854839           0.822581           0.806452   \n",
       "4              0.854839           0.822581           0.838710   \n",
       "...                 ...                ...                ...   \n",
       "17995          0.822581           0.774194           0.806452   \n",
       "17996          0.822581           0.774194           0.790323   \n",
       "17997          0.870968           0.774194           0.774194   \n",
       "17998          0.822581           0.790323           0.774194   \n",
       "17999          0.806452           0.790323           0.774194   \n",
       "\n",
       "       split6_test_score  split7_test_score  split8_test_score  \\\n",
       "0               0.822581           0.806452           0.693548   \n",
       "1               0.838710           0.806452           0.661290   \n",
       "2               0.838710           0.806452           0.677419   \n",
       "3               0.854839           0.806452           0.661290   \n",
       "4               0.838710           0.806452           0.677419   \n",
       "...                  ...                ...                ...   \n",
       "17995           0.822581           0.774194           0.709677   \n",
       "17996           0.822581           0.790323           0.693548   \n",
       "17997           0.790323           0.790323           0.709677   \n",
       "17998           0.822581           0.790323           0.709677   \n",
       "17999           0.854839           0.790323           0.709677   \n",
       "\n",
       "       split9_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0               0.838710         0.820020        0.048275            15186  \n",
       "1               0.854839         0.823221        0.059057            12810  \n",
       "2               0.838710         0.824782        0.057512            12084  \n",
       "3               0.838710         0.824834        0.059251            11402  \n",
       "4               0.838710         0.828059        0.053977             8256  \n",
       "...                  ...              ...             ...              ...  \n",
       "17995           0.774194         0.802355        0.049888            17998  \n",
       "17996           0.790323         0.800768        0.052893            17999  \n",
       "17997           0.790323         0.810317        0.057193            17871  \n",
       "17998           0.806452         0.816692        0.055624            17108  \n",
       "17999           0.854839         0.818382        0.053516            16381  \n",
       "\n",
       "[18000 rows x 24 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score is 0.850563 with params {'colsample_bylevel': 0.4, 'colsample_bytree': 0.5, 'learning_rate': 0.15, 'max_depth': 2, 'n_estimators': 100, 'subsample': 0.7}\n"
     ]
    }
   ],
   "source": [
    "# read single parts of round 2, concatenate and update index and rank_test_score\n",
    "\n",
    "df1 = pd.read_csv(\"data\\\\xgb_results_full_1_bylevel=0.1_20221123.csv\")\n",
    "df1.drop(df1.columns[0], axis=1, inplace=True)\n",
    "\n",
    "df2 = pd.read_csv(\"data\\\\xgb_results_full_2_bylevel=0.2_20221123.csv\")\n",
    "df2.drop(df2.columns[0], axis=1, inplace=True)\n",
    "\n",
    "df3 = pd.read_csv(\"data\\\\xgb_results_full_3_bylevel=0.3_20221123.csv\")\n",
    "df3.drop(df3.columns[0], axis=1, inplace=True)\n",
    "\n",
    "df4 = pd.read_csv(\"data\\\\xgb_results_full_4_bylevel=0.4_20221123.csv\")\n",
    "df4.drop(df4.columns[0], axis=1, inplace=True)\n",
    "\n",
    "df5 = pd.read_csv(\"data\\\\xgb_results_full_5_bylevel=0.6_20221123.csv\")\n",
    "df5.drop(df5.columns[0], axis=1, inplace=True)\n",
    "\n",
    "df6 = pd.read_csv(\"data\\\\xgb_results_full_6_bylevel=0.7_20221123.csv\")\n",
    "df6.drop(df6.columns[0], axis=1, inplace=True)\n",
    "\n",
    "df_full = pd.concat([df1,df2,df3,df4,df5,df6])\n",
    "\n",
    "#assign correct rank\n",
    "df_full = df_full.sort_values(by='mean_test_score', ascending=False)\n",
    "df_full['rank_test_score'] = range(1, len(df_full)+1)\n",
    "\n",
    "#get correct order and set new index\n",
    "df_full = df_full.sort_values(by=['param_colsample_bylevel', 'param_colsample_bytree', 'param_learning_rate', 'param_max_depth', 'param_n_estimators', 'param_subsample'])\n",
    "xgb_grid_search_results_round2 = df_full.set_index(np.array(range(len(df_full))))\n",
    "display(xgb_grid_search_results_round2)\n",
    "\n",
    "print(\"best score is 0.850563 with params {'colsample_bylevel': 0.4, 'colsample_bytree': 0.5, 'learning_rate': 0.15, 'max_depth': 2, 'n_estimators': 100, 'subsample': 0.7}\")\n",
    "\n",
    "# save dataframe\n",
    "from datetime import datetime\n",
    "date = str(datetime.now().date()).replace(\"-\", \"\")\n",
    "xgb_grid_search_results_round2.to_csv(f\"results/xgb_results_round2_{date}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "22eaf083",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_subsample</th>\n",
       "      <th>param_colsample_bylevel</th>\n",
       "      <th>param_colsample_bytree</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10302</th>\n",
       "      <td>2</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.15</td>\n",
       "      <td>100</td>\n",
       "      <td>0.850563</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7302</th>\n",
       "      <td>2</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.15</td>\n",
       "      <td>100</td>\n",
       "      <td>0.850563</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4976</th>\n",
       "      <td>5</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.15</td>\n",
       "      <td>100</td>\n",
       "      <td>0.850538</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1976</th>\n",
       "      <td>5</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.15</td>\n",
       "      <td>100</td>\n",
       "      <td>0.850538</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5419</th>\n",
       "      <td>2</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.10</td>\n",
       "      <td>250</td>\n",
       "      <td>0.849002</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7745</th>\n",
       "      <td>3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.40</td>\n",
       "      <td>300</td>\n",
       "      <td>0.803943</td>\n",
       "      <td>17996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13171</th>\n",
       "      <td>4</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.40</td>\n",
       "      <td>300</td>\n",
       "      <td>0.803917</td>\n",
       "      <td>17997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17995</th>\n",
       "      <td>5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.40</td>\n",
       "      <td>300</td>\n",
       "      <td>0.802355</td>\n",
       "      <td>17998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17996</th>\n",
       "      <td>5</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.40</td>\n",
       "      <td>300</td>\n",
       "      <td>0.800768</td>\n",
       "      <td>17999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17940</th>\n",
       "      <td>3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.40</td>\n",
       "      <td>250</td>\n",
       "      <td>0.800742</td>\n",
       "      <td>18000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18000 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       param_max_depth  param_subsample  param_colsample_bylevel  \\\n",
       "10302                2              0.7                      0.4   \n",
       "7302                 2              0.7                      0.3   \n",
       "4976                 5              0.6                      0.2   \n",
       "1976                 5              0.6                      0.1   \n",
       "5419                 2              0.9                      0.2   \n",
       "...                ...              ...                      ...   \n",
       "7745                 3              0.5                      0.3   \n",
       "13171                4              0.6                      0.6   \n",
       "17995                5              0.5                      0.7   \n",
       "17996                5              0.6                      0.7   \n",
       "17940                3              0.5                      0.7   \n",
       "\n",
       "       param_colsample_bytree  param_learning_rate  param_n_estimators  \\\n",
       "10302                     0.5                 0.15                 100   \n",
       "7302                      0.5                 0.15                 100   \n",
       "4976                      0.6                 0.15                 100   \n",
       "1976                      0.6                 0.15                 100   \n",
       "5419                      0.9                 0.10                 250   \n",
       "...                       ...                  ...                 ...   \n",
       "7745                      0.5                 0.40                 300   \n",
       "13171                     0.4                 0.40                 300   \n",
       "17995                     0.9                 0.40                 300   \n",
       "17996                     0.9                 0.40                 300   \n",
       "17940                     0.9                 0.40                 250   \n",
       "\n",
       "       mean_test_score  rank_test_score  \n",
       "10302         0.850563                1  \n",
       "7302          0.850563                2  \n",
       "4976          0.850538                3  \n",
       "1976          0.850538                4  \n",
       "5419          0.849002                5  \n",
       "...                ...              ...  \n",
       "7745          0.803943            17996  \n",
       "13171         0.803917            17997  \n",
       "17995         0.802355            17998  \n",
       "17996         0.800768            17999  \n",
       "17940         0.800742            18000  \n",
       "\n",
       "[18000 rows x 8 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# store relevant columns and sort by rank_test_score\n",
    "cols_full = ['param_max_depth', 'param_subsample', 'param_colsample_bylevel', 'param_colsample_bytree', 'param_learning_rate', 'param_n_estimators', 'mean_test_score', 'rank_test_score']\n",
    "xgb_results_round2_sorted = xgb_grid_search_results_round2[cols_full]\n",
    "xgb_results_round2_sorted = xgb_results_round2_sorted.sort_values(by='rank_test_score')\n",
    "display(xgb_results_round2_sorted)\n",
    "\n",
    "# save dataframe\n",
    "from datetime import datetime\n",
    "date = str(datetime.now().date()).replace(\"-\", \"\")\n",
    "xgb_results_round2_sorted.to_csv(f\"results/xgb_results_round2_sorted_{date}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "31aeddd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.8283582089552238\n",
      "F1 Score = 0.7788461538461539\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.90      0.86       157\n",
      "           1       0.84      0.73      0.78       111\n",
      "\n",
      "    accuracy                           0.83       268\n",
      "   macro avg       0.83      0.81      0.82       268\n",
      "weighted avg       0.83      0.83      0.83       268\n",
      "\n",
      "Confusion Matrix:\n",
      "[[141  16]\n",
      " [ 30  81]]\n"
     ]
    }
   ],
   "source": [
    "# Fit and evaluate best model\n",
    "\n",
    "xgb_best = XGBClassifier(max_depth = 2, subsample = 0.7, colsample_bylevel = 0.4, colsample_bytree = 0.5, learning_rate = 0.15, n_estimators = 100)\n",
    "xgb_best.fit(X_train, y_train)\n",
    "xgb_best_pred = xgb_best.predict(X_test)\n",
    "\n",
    "xgb_best_acc = accuracy_score(y_test, xgb_best_pred)\n",
    "print(\"Accuracy =\", xgb_best_acc) #0.8283582089552238\n",
    "\n",
    "xgb_best_f1 = f1_score(y_test, xgb_best_pred)\n",
    "print(\"F1 Score =\", xgb_best_f1) #0.7788461538461539\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, xgb_best_pred))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, xgb_best_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56268403",
   "metadata": {},
   "source": [
    "beim nächsten Tuning:  \n",
    "- param_subsample ungleich 0.5\n",
    "- param_colsample_bytree ungleich 0.3\n",
    "- param_colsample_bylevel ungleich 0.6\n",
    "- param_learning_rate kleiner gleich 0.2\n",
    "- param_n_estimators ungleich 200 und ungleich 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f05c0475",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc874cb6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af95c214",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2f3a4dda",
   "metadata": {},
   "source": [
    "#### Third Attempt\n",
    "We perform a second hyper parameter tuning, adjusting the parameter grid according to the results of round 2. We use the following parameters and values:  \n",
    "\n",
    "{'max_depth': [2,3,4,5]  \n",
    ", 'subsample': [0.6, 0.7, 0.8, 0.9]  \n",
    ", 'gamma': [0, 1, 10]  \n",
    ", 'colsample_bytree': [0.4, 0.5, 0.6, 0.9]  \n",
    ", 'colsample_bylevel': [0.1, 0.2, 0.3, 0.4]  \n",
    ", 'learning_rate': [0.01, 0.05, 0.08, 0.1, 0.15, 0.2]  \n",
    ", 'n_estimators': [30, 50, 80, 100, 150, 200]}  \n",
    "\n",
    "The best hyper parameter setting results to be xxx which leads to an accuracy of xxx% and a f1 score of xxx% on the test data (after training the classifier on the whole train data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dfb85f37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_colsample_bylevel</th>\n",
       "      <th>param_colsample_bytree</th>\n",
       "      <th>param_gamma</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>...</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.028623</td>\n",
       "      <td>0.002525</td>\n",
       "      <td>0.007181</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.741295</td>\n",
       "      <td>0.048078</td>\n",
       "      <td>27618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.027127</td>\n",
       "      <td>0.000598</td>\n",
       "      <td>0.007082</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.742908</td>\n",
       "      <td>0.049390</td>\n",
       "      <td>27616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.027028</td>\n",
       "      <td>0.000698</td>\n",
       "      <td>0.007580</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.752586</td>\n",
       "      <td>0.048690</td>\n",
       "      <td>27568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.027427</td>\n",
       "      <td>0.000920</td>\n",
       "      <td>0.007381</td>\n",
       "      <td>0.000662</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.742960</td>\n",
       "      <td>0.043040</td>\n",
       "      <td>27614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.040093</td>\n",
       "      <td>0.001465</td>\n",
       "      <td>0.007082</td>\n",
       "      <td>0.000536</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>...</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.765463</td>\n",
       "      <td>0.037846</td>\n",
       "      <td>27462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27643</th>\n",
       "      <td>0.129354</td>\n",
       "      <td>0.001184</td>\n",
       "      <td>0.007281</td>\n",
       "      <td>0.000457</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.20</td>\n",
       "      <td>5</td>\n",
       "      <td>150</td>\n",
       "      <td>...</td>\n",
       "      <td>0.887097</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.919355</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.826600</td>\n",
       "      <td>0.059814</td>\n",
       "      <td>14497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27644</th>\n",
       "      <td>0.168948</td>\n",
       "      <td>0.001739</td>\n",
       "      <td>0.007581</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.20</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.919355</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.828187</td>\n",
       "      <td>0.060472</td>\n",
       "      <td>13496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27645</th>\n",
       "      <td>0.170344</td>\n",
       "      <td>0.002515</td>\n",
       "      <td>0.007481</td>\n",
       "      <td>0.000498</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.20</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.887097</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.824936</td>\n",
       "      <td>0.057195</td>\n",
       "      <td>15641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27646</th>\n",
       "      <td>0.169896</td>\n",
       "      <td>0.002405</td>\n",
       "      <td>0.007281</td>\n",
       "      <td>0.000457</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.20</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.824910</td>\n",
       "      <td>0.045101</td>\n",
       "      <td>15655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27647</th>\n",
       "      <td>0.169047</td>\n",
       "      <td>0.001201</td>\n",
       "      <td>0.007281</td>\n",
       "      <td>0.000457</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.20</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.887097</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.919355</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.826600</td>\n",
       "      <td>0.059814</td>\n",
       "      <td>14482</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27648 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0           0.028623      0.002525         0.007181        0.000399   \n",
       "1           0.027127      0.000598         0.007082        0.000300   \n",
       "2           0.027028      0.000698         0.007580        0.000489   \n",
       "3           0.027427      0.000920         0.007381        0.000662   \n",
       "4           0.040093      0.001465         0.007082        0.000536   \n",
       "...              ...           ...              ...             ...   \n",
       "27643       0.129354      0.001184         0.007281        0.000457   \n",
       "27644       0.168948      0.001739         0.007581        0.000489   \n",
       "27645       0.170344      0.002515         0.007481        0.000498   \n",
       "27646       0.169896      0.002405         0.007281        0.000457   \n",
       "27647       0.169047      0.001201         0.007281        0.000457   \n",
       "\n",
       "       param_colsample_bylevel  param_colsample_bytree  param_gamma  \\\n",
       "0                          0.1                     0.4            0   \n",
       "1                          0.1                     0.4            0   \n",
       "2                          0.1                     0.4            0   \n",
       "3                          0.1                     0.4            0   \n",
       "4                          0.1                     0.4            0   \n",
       "...                        ...                     ...          ...   \n",
       "27643                      0.4                     0.9           10   \n",
       "27644                      0.4                     0.9           10   \n",
       "27645                      0.4                     0.9           10   \n",
       "27646                      0.4                     0.9           10   \n",
       "27647                      0.4                     0.9           10   \n",
       "\n",
       "       param_learning_rate  param_max_depth  param_n_estimators  ...  \\\n",
       "0                     0.01                2                  30  ...   \n",
       "1                     0.01                2                  30  ...   \n",
       "2                     0.01                2                  30  ...   \n",
       "3                     0.01                2                  30  ...   \n",
       "4                     0.01                2                  50  ...   \n",
       "...                    ...              ...                 ...  ...   \n",
       "27643                 0.20                5                 150  ...   \n",
       "27644                 0.20                5                 200  ...   \n",
       "27645                 0.20                5                 200  ...   \n",
       "27646                 0.20                5                 200  ...   \n",
       "27647                 0.20                5                 200  ...   \n",
       "\n",
       "       split3_test_score split4_test_score  split5_test_score  \\\n",
       "0               0.758065          0.741935           0.741935   \n",
       "1               0.774194          0.741935           0.741935   \n",
       "2               0.774194          0.758065           0.774194   \n",
       "3               0.790323          0.725806           0.709677   \n",
       "4               0.790323          0.774194           0.774194   \n",
       "...                  ...               ...                ...   \n",
       "27643           0.887097          0.806452           0.919355   \n",
       "27644           0.919355          0.838710           0.870968   \n",
       "27645           0.870968          0.806452           0.887097   \n",
       "27646           0.870968          0.806452           0.854839   \n",
       "27647           0.887097          0.806452           0.919355   \n",
       "\n",
       "       split6_test_score  split7_test_score  split8_test_score  \\\n",
       "0               0.725806           0.677419           0.693548   \n",
       "1               0.725806           0.677419           0.677419   \n",
       "2               0.741935           0.693548           0.677419   \n",
       "3               0.741935           0.709677           0.709677   \n",
       "4               0.725806           0.693548           0.725806   \n",
       "...                  ...                ...                ...   \n",
       "27643           0.822581           0.806452           0.693548   \n",
       "27644           0.806452           0.806452           0.677419   \n",
       "27645           0.806452           0.822581           0.677419   \n",
       "27646           0.822581           0.806452           0.709677   \n",
       "27647           0.822581           0.806452           0.693548   \n",
       "\n",
       "       split9_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0               0.677419         0.741295        0.048078            27618  \n",
       "1               0.693548         0.742908        0.049390            27616  \n",
       "2               0.709677         0.752586        0.048690            27568  \n",
       "3               0.677419         0.742960        0.043040            27614  \n",
       "4               0.758065         0.765463        0.037846            27462  \n",
       "...                  ...              ...             ...              ...  \n",
       "27643           0.822581         0.826600        0.059814            14497  \n",
       "27644           0.838710         0.828187        0.060472            13496  \n",
       "27645           0.838710         0.824936        0.057195            15641  \n",
       "27646           0.822581         0.824910        0.045101            15655  \n",
       "27647           0.822581         0.826600        0.059814            14482  \n",
       "\n",
       "[27648 rows x 25 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score is 0.850563 with params {'colsample_bylevel': 0.4, 'colsample_bytree': 0.4, 'gamma': 1, 'learning_rate': 0.15, 'max_depth': 4, 'n_estimators': 30, 'subsample': 0.9}\n"
     ]
    }
   ],
   "source": [
    "# read single parts of round 3, concatenate and update index and rank_test_score\n",
    "\n",
    "df1 = pd.read_csv(\"data\\\\xgb_results_full_1_learning=0.01_20221124.csv\")\n",
    "df1.drop(df1.columns[0], axis=1, inplace=True)\n",
    "\n",
    "df2 = pd.read_csv(\"data\\\\xgb_results_full_2_learning=0.05_20221124.csv\")\n",
    "df2.drop(df2.columns[0], axis=1, inplace=True)\n",
    "\n",
    "df3 = pd.read_csv(\"data\\\\xgb_results_full_3_learning=0.08_20221124.csv\")\n",
    "df3.drop(df3.columns[0], axis=1, inplace=True)\n",
    "\n",
    "df4 = pd.read_csv(\"data\\\\xgb_results_full_4_learning=0.1_20221124.csv\")\n",
    "df4.drop(df4.columns[0], axis=1, inplace=True)\n",
    "\n",
    "df5 = pd.read_csv(\"data\\\\xgb_results_full_5_learning=0.15_20221124.csv\")\n",
    "df5.drop(df5.columns[0], axis=1, inplace=True)\n",
    "\n",
    "df6 = pd.read_csv(\"data\\\\xgb_results_full_6_learning=0.2_20221124.csv\")\n",
    "df6.drop(df6.columns[0], axis=1, inplace=True)\n",
    "\n",
    "df_full = pd.concat([df1,df2,df3,df4,df5,df6])\n",
    "\n",
    "#assign correct rank\n",
    "df_full = df_full.sort_values(by='mean_test_score', ascending=False)\n",
    "df_full['rank_test_score'] = range(1, len(df_full)+1)\n",
    "\n",
    "#get correct order and set new index\n",
    "df_full = df_full.sort_values(by=['param_colsample_bylevel', 'param_colsample_bytree', 'param_gamma', 'param_learning_rate', 'param_max_depth', 'param_n_estimators', 'param_subsample'])\n",
    "xgb_grid_search_results_round3 = df_full.set_index(np.array(range(len(df_full))))\n",
    "display(xgb_grid_search_results_round3)\n",
    "\n",
    "print(\"best score is 0.850563 with params {'colsample_bylevel': 0.4, 'colsample_bytree': 0.4, 'gamma': 1, 'learning_rate': 0.15, 'max_depth': 4, 'n_estimators': 30, 'subsample': 0.9}\")\n",
    "\n",
    "# save dataframe\n",
    "from datetime import datetime\n",
    "date = str(datetime.now().date()).replace(\"-\", \"\")\n",
    "xgb_grid_search_results_round3.to_csv(f\"results/xgb_results_round3_{date}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ef1cdad4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_colsample_bylevel</th>\n",
       "      <th>param_colsample_bytree</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_subsample</th>\n",
       "      <th>...</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.064527</td>\n",
       "      <td>0.004136</td>\n",
       "      <td>0.005885</td>\n",
       "      <td>0.000538</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.820020</td>\n",
       "      <td>0.048275</td>\n",
       "      <td>2840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.064327</td>\n",
       "      <td>0.002493</td>\n",
       "      <td>0.005885</td>\n",
       "      <td>0.000537</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.661290</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.823221</td>\n",
       "      <td>0.059057</td>\n",
       "      <td>5179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.063231</td>\n",
       "      <td>0.001954</td>\n",
       "      <td>0.005785</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.824782</td>\n",
       "      <td>0.057512</td>\n",
       "      <td>5860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.062235</td>\n",
       "      <td>0.001017</td>\n",
       "      <td>0.006082</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.661290</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.824834</td>\n",
       "      <td>0.059251</td>\n",
       "      <td>6715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.062333</td>\n",
       "      <td>0.002285</td>\n",
       "      <td>0.005784</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.828059</td>\n",
       "      <td>0.053977</td>\n",
       "      <td>9897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17995</th>\n",
       "      <td>0.228489</td>\n",
       "      <td>0.002462</td>\n",
       "      <td>0.007480</td>\n",
       "      <td>0.000499</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.802355</td>\n",
       "      <td>0.049888</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17996</th>\n",
       "      <td>0.228688</td>\n",
       "      <td>0.002142</td>\n",
       "      <td>0.007281</td>\n",
       "      <td>0.000457</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.800768</td>\n",
       "      <td>0.052893</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17997</th>\n",
       "      <td>0.228987</td>\n",
       "      <td>0.001197</td>\n",
       "      <td>0.007580</td>\n",
       "      <td>0.000488</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.810317</td>\n",
       "      <td>0.057193</td>\n",
       "      <td>139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17998</th>\n",
       "      <td>0.228788</td>\n",
       "      <td>0.001620</td>\n",
       "      <td>0.007181</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.816692</td>\n",
       "      <td>0.055624</td>\n",
       "      <td>893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17999</th>\n",
       "      <td>0.226893</td>\n",
       "      <td>0.002150</td>\n",
       "      <td>0.007381</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.818382</td>\n",
       "      <td>0.053516</td>\n",
       "      <td>1646</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18000 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0           0.064527      0.004136         0.005885        0.000538   \n",
       "1           0.064327      0.002493         0.005885        0.000537   \n",
       "2           0.063231      0.001954         0.005785        0.000399   \n",
       "3           0.062235      0.001017         0.006082        0.000300   \n",
       "4           0.062333      0.002285         0.005784        0.000399   \n",
       "...              ...           ...              ...             ...   \n",
       "17995       0.228489      0.002462         0.007480        0.000499   \n",
       "17996       0.228688      0.002142         0.007281        0.000457   \n",
       "17997       0.228987      0.001197         0.007580        0.000488   \n",
       "17998       0.228788      0.001620         0.007181        0.000399   \n",
       "17999       0.226893      0.002150         0.007381        0.000489   \n",
       "\n",
       "       param_colsample_bylevel  param_colsample_bytree  param_learning_rate  \\\n",
       "0                          0.1                     0.3                  0.1   \n",
       "1                          0.1                     0.3                  0.1   \n",
       "2                          0.1                     0.3                  0.1   \n",
       "3                          0.1                     0.3                  0.1   \n",
       "4                          0.1                     0.3                  0.1   \n",
       "...                        ...                     ...                  ...   \n",
       "17995                      0.7                     0.9                  0.4   \n",
       "17996                      0.7                     0.9                  0.4   \n",
       "17997                      0.7                     0.9                  0.4   \n",
       "17998                      0.7                     0.9                  0.4   \n",
       "17999                      0.7                     0.9                  0.4   \n",
       "\n",
       "       param_max_depth  param_n_estimators  param_subsample  ...  \\\n",
       "0                    2                 100              0.5  ...   \n",
       "1                    2                 100              0.6  ...   \n",
       "2                    2                 100              0.7  ...   \n",
       "3                    2                 100              0.8  ...   \n",
       "4                    2                 100              0.9  ...   \n",
       "...                ...                 ...              ...  ...   \n",
       "17995                5                 300              0.5  ...   \n",
       "17996                5                 300              0.6  ...   \n",
       "17997                5                 300              0.7  ...   \n",
       "17998                5                 300              0.8  ...   \n",
       "17999                5                 300              0.9  ...   \n",
       "\n",
       "      split3_test_score  split4_test_score  split5_test_score  \\\n",
       "0              0.822581           0.822581           0.806452   \n",
       "1              0.838710           0.822581           0.806452   \n",
       "2              0.838710           0.806452           0.806452   \n",
       "3              0.854839           0.822581           0.806452   \n",
       "4              0.854839           0.822581           0.838710   \n",
       "...                 ...                ...                ...   \n",
       "17995          0.822581           0.774194           0.806452   \n",
       "17996          0.822581           0.774194           0.790323   \n",
       "17997          0.870968           0.774194           0.774194   \n",
       "17998          0.822581           0.790323           0.774194   \n",
       "17999          0.806452           0.790323           0.774194   \n",
       "\n",
       "       split6_test_score  split7_test_score  split8_test_score  \\\n",
       "0               0.822581           0.806452           0.693548   \n",
       "1               0.838710           0.806452           0.661290   \n",
       "2               0.838710           0.806452           0.677419   \n",
       "3               0.854839           0.806452           0.661290   \n",
       "4               0.838710           0.806452           0.677419   \n",
       "...                  ...                ...                ...   \n",
       "17995           0.822581           0.774194           0.709677   \n",
       "17996           0.822581           0.790323           0.693548   \n",
       "17997           0.790323           0.790323           0.709677   \n",
       "17998           0.822581           0.790323           0.709677   \n",
       "17999           0.854839           0.790323           0.709677   \n",
       "\n",
       "       split9_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0               0.838710         0.820020        0.048275             2840  \n",
       "1               0.854839         0.823221        0.059057             5179  \n",
       "2               0.838710         0.824782        0.057512             5860  \n",
       "3               0.838710         0.824834        0.059251             6715  \n",
       "4               0.838710         0.828059        0.053977             9897  \n",
       "...                  ...              ...             ...              ...  \n",
       "17995           0.774194         0.802355        0.049888                3  \n",
       "17996           0.790323         0.800768        0.052893                2  \n",
       "17997           0.790323         0.810317        0.057193              139  \n",
       "17998           0.806452         0.816692        0.055624              893  \n",
       "17999           0.854839         0.818382        0.053516             1646  \n",
       "\n",
       "[18000 rows x 24 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Third Attempt\n",
    "\n",
    "random.seed(10)\n",
    "\n",
    "xgb = XGBClassifier()\n",
    "\n",
    "xgb_parameters = {'max_depth': [2,3,4,5]\n",
    "                   , 'subsample': [0.6, 0.7, 0.8, 0.9]\n",
    "                   , 'gamma': [0, 1, 10]\n",
    "                   , 'colsample_bytree': [0.4, 0.5, 0.6, 0.9]\n",
    "                   , 'colsample_bylevel': [0.1, 0.2, 0.3, 0.4]\n",
    "                   , 'learning_rate': [0.01, 0.05, 0.08, 0.1, 0.15, 0.2]\n",
    "                   , 'n_estimators': [30, 50, 80, 100, 150, 200]}\n",
    "\n",
    "stratified_10_fold_cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "xgb_grid_search = GridSearchCV(xgb, xgb_parameters, scoring='accuracy', cv=stratified_10_fold_cv)\n",
    "\n",
    "xgb_grid_search.fit(X_train, y_train)\n",
    "\n",
    "xgb_grid_search_results_round3 = pd.DataFrame(xgb_grid_search.cv_results_)\n",
    "display(xgb_grid_search_results_round3)\n",
    "\n",
    "# print the best parameter setting\n",
    "print(\"best score is {} with params {}\".format(xgb_grid_search.best_score_, xgb_grid_search.best_params_))\n",
    "#best score is 0.850563 with params {'colsample_bylevel': 0.4, 'colsample_bytree': 0.4, 'gamma': 1, 'learning_rate': 0.15, 'max_depth': 4, 'n_estimators': 30, 'subsample': 0.9}\n",
    "\n",
    "# save dataframe\n",
    "from datetime import datetime\n",
    "date = str(datetime.now().date()).replace(\"-\", \"\")\n",
    "xgb_grid_search_results_round3.to_csv(f\"results/xgb_results_round3_{date}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0acf7bf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_subsample</th>\n",
       "      <th>param_colsample_bylevel</th>\n",
       "      <th>param_colsample_bytree</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_gamma</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21747</th>\n",
       "      <td>4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.15</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>0.856989</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13080</th>\n",
       "      <td>3</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.15</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>0.852227</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13176</th>\n",
       "      <td>3</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.20</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>0.852202</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21720</th>\n",
       "      <td>3</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.15</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>0.852202</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23470</th>\n",
       "      <td>3</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.15</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>0.852151</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6340</th>\n",
       "      <td>2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.01</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>0.718920</td>\n",
       "      <td>27644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6339</th>\n",
       "      <td>2</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.01</td>\n",
       "      <td>30</td>\n",
       "      <td>10</td>\n",
       "      <td>0.709217</td>\n",
       "      <td>27645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6338</th>\n",
       "      <td>2</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.01</td>\n",
       "      <td>30</td>\n",
       "      <td>10</td>\n",
       "      <td>0.705991</td>\n",
       "      <td>27646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6336</th>\n",
       "      <td>2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.01</td>\n",
       "      <td>30</td>\n",
       "      <td>10</td>\n",
       "      <td>0.704403</td>\n",
       "      <td>27647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6337</th>\n",
       "      <td>2</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.01</td>\n",
       "      <td>30</td>\n",
       "      <td>10</td>\n",
       "      <td>0.702765</td>\n",
       "      <td>27648</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27648 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       param_max_depth  param_subsample  param_colsample_bylevel  \\\n",
       "21747                4              0.9                      0.4   \n",
       "13080                3              0.6                      0.2   \n",
       "13176                3              0.6                      0.2   \n",
       "21720                3              0.6                      0.4   \n",
       "23470                3              0.8                      0.4   \n",
       "...                ...              ...                      ...   \n",
       "6340                 2              0.6                      0.1   \n",
       "6339                 2              0.9                      0.1   \n",
       "6338                 2              0.8                      0.1   \n",
       "6336                 2              0.6                      0.1   \n",
       "6337                 2              0.7                      0.1   \n",
       "\n",
       "       param_colsample_bytree  param_learning_rate  param_n_estimators  \\\n",
       "21747                     0.4                 0.15                  30   \n",
       "13080                     0.9                 0.15                  30   \n",
       "13176                     0.9                 0.20                  30   \n",
       "21720                     0.4                 0.15                  30   \n",
       "23470                     0.5                 0.15                 200   \n",
       "...                       ...                  ...                 ...   \n",
       "6340                      0.9                 0.01                  50   \n",
       "6339                      0.9                 0.01                  30   \n",
       "6338                      0.9                 0.01                  30   \n",
       "6336                      0.9                 0.01                  30   \n",
       "6337                      0.9                 0.01                  30   \n",
       "\n",
       "       param_gamma  mean_test_score  rank_test_score  \n",
       "21747            1         0.856989                1  \n",
       "13080            1         0.852227                2  \n",
       "13176            1         0.852202                3  \n",
       "21720            1         0.852202                4  \n",
       "23470            1         0.852151                5  \n",
       "...            ...              ...              ...  \n",
       "6340            10         0.718920            27644  \n",
       "6339            10         0.709217            27645  \n",
       "6338            10         0.705991            27646  \n",
       "6336            10         0.704403            27647  \n",
       "6337            10         0.702765            27648  \n",
       "\n",
       "[27648 rows x 9 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# store relevant columns and sort by rank_test_score\n",
    "cols_round3 = ['param_max_depth', 'param_subsample', 'param_colsample_bylevel', 'param_colsample_bytree', 'param_learning_rate', 'param_n_estimators', 'param_gamma', 'mean_test_score', 'rank_test_score']\n",
    "xgb_results_round3_sorted = xgb_grid_search_results_round3[cols_round3]\n",
    "xgb_results_round3_sorted = xgb_results_round3_sorted.sort_values(by='rank_test_score')\n",
    "display(xgb_results_round3_sorted)\n",
    "\n",
    "# save dataframe\n",
    "from datetime import datetime\n",
    "date = str(datetime.now().date()).replace(\"-\", \"\")\n",
    "xgb_results_round3_sorted.to_csv(f\"results/xgb_results_round3_sorted_{date}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "11f0488a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.8283582089552238\n",
      "F1 Score = 0.7788461538461539\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.90      0.86       157\n",
      "           1       0.84      0.73      0.78       111\n",
      "\n",
      "    accuracy                           0.83       268\n",
      "   macro avg       0.83      0.81      0.82       268\n",
      "weighted avg       0.83      0.83      0.83       268\n",
      "\n",
      "Confusion Matrix:\n",
      "[[141  16]\n",
      " [ 30  81]]\n"
     ]
    }
   ],
   "source": [
    "# Fit and evaluate best model\n",
    "\n",
    "xgb_best = XGBClassifier(max_depth = 4, subsample = 0.9, colsample_bylevel = 0.4, colsample_bytree = 0.4, learning_rate = 0.15, n_estimators = 30, gamma = 1)\n",
    "xgb_best.fit(X_train, y_train)\n",
    "xgb_best_pred = xgb_best.predict(X_test)\n",
    "\n",
    "xgb_best_acc = accuracy_score(y_test, xgb_best_pred)\n",
    "print(\"Accuracy =\", xgb_best_acc) #0.8283582089552238\n",
    "\n",
    "xgb_best_f1 = f1_score(y_test, xgb_best_pred)\n",
    "print(\"F1 Score =\", xgb_best_f1) #0.7788461538461539\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, xgb_best_pred))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, xgb_best_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "871fce0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ec32490",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b5d3a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "486b0ff9",
   "metadata": {},
   "source": [
    "#### ausführlich"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ea249e06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_colsample_bylevel</th>\n",
       "      <th>param_colsample_bytree</th>\n",
       "      <th>param_gamma</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>...</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.028623</td>\n",
       "      <td>0.002525</td>\n",
       "      <td>0.007181</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.741295</td>\n",
       "      <td>0.048078</td>\n",
       "      <td>4578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.027127</td>\n",
       "      <td>0.000598</td>\n",
       "      <td>0.007082</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.742908</td>\n",
       "      <td>0.049390</td>\n",
       "      <td>4575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.027028</td>\n",
       "      <td>0.000698</td>\n",
       "      <td>0.007580</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.752586</td>\n",
       "      <td>0.048690</td>\n",
       "      <td>4530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.027427</td>\n",
       "      <td>0.000920</td>\n",
       "      <td>0.007381</td>\n",
       "      <td>0.000662</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.742960</td>\n",
       "      <td>0.043040</td>\n",
       "      <td>4573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.040093</td>\n",
       "      <td>0.001465</td>\n",
       "      <td>0.007082</td>\n",
       "      <td>0.000536</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>...</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.765463</td>\n",
       "      <td>0.037846</td>\n",
       "      <td>4434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4603</th>\n",
       "      <td>0.129553</td>\n",
       "      <td>0.002379</td>\n",
       "      <td>0.007381</td>\n",
       "      <td>0.000488</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.01</td>\n",
       "      <td>5</td>\n",
       "      <td>150</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.813774</td>\n",
       "      <td>0.047909</td>\n",
       "      <td>2050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4604</th>\n",
       "      <td>0.169746</td>\n",
       "      <td>0.002475</td>\n",
       "      <td>0.007680</td>\n",
       "      <td>0.000457</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.01</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.816948</td>\n",
       "      <td>0.046448</td>\n",
       "      <td>1787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4605</th>\n",
       "      <td>0.169550</td>\n",
       "      <td>0.002185</td>\n",
       "      <td>0.007381</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.01</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.815335</td>\n",
       "      <td>0.050783</td>\n",
       "      <td>1939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4606</th>\n",
       "      <td>0.170743</td>\n",
       "      <td>0.003753</td>\n",
       "      <td>0.007481</td>\n",
       "      <td>0.000499</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.01</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.812186</td>\n",
       "      <td>0.050956</td>\n",
       "      <td>2153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4607</th>\n",
       "      <td>0.168649</td>\n",
       "      <td>0.001371</td>\n",
       "      <td>0.007380</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.01</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.813774</td>\n",
       "      <td>0.047909</td>\n",
       "      <td>2050</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4608 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0          0.028623      0.002525         0.007181        0.000399   \n",
       "1          0.027127      0.000598         0.007082        0.000300   \n",
       "2          0.027028      0.000698         0.007580        0.000489   \n",
       "3          0.027427      0.000920         0.007381        0.000662   \n",
       "4          0.040093      0.001465         0.007082        0.000536   \n",
       "...             ...           ...              ...             ...   \n",
       "4603       0.129553      0.002379         0.007381        0.000488   \n",
       "4604       0.169746      0.002475         0.007680        0.000457   \n",
       "4605       0.169550      0.002185         0.007381        0.000489   \n",
       "4606       0.170743      0.003753         0.007481        0.000499   \n",
       "4607       0.168649      0.001371         0.007380        0.000489   \n",
       "\n",
       "      param_colsample_bylevel  param_colsample_bytree  param_gamma  \\\n",
       "0                         0.1                     0.4            0   \n",
       "1                         0.1                     0.4            0   \n",
       "2                         0.1                     0.4            0   \n",
       "3                         0.1                     0.4            0   \n",
       "4                         0.1                     0.4            0   \n",
       "...                       ...                     ...          ...   \n",
       "4603                      0.4                     0.9           10   \n",
       "4604                      0.4                     0.9           10   \n",
       "4605                      0.4                     0.9           10   \n",
       "4606                      0.4                     0.9           10   \n",
       "4607                      0.4                     0.9           10   \n",
       "\n",
       "      param_learning_rate  param_max_depth  param_n_estimators  ...  \\\n",
       "0                    0.01                2                  30  ...   \n",
       "1                    0.01                2                  30  ...   \n",
       "2                    0.01                2                  30  ...   \n",
       "3                    0.01                2                  30  ...   \n",
       "4                    0.01                2                  50  ...   \n",
       "...                   ...              ...                 ...  ...   \n",
       "4603                 0.01                5                 150  ...   \n",
       "4604                 0.01                5                 200  ...   \n",
       "4605                 0.01                5                 200  ...   \n",
       "4606                 0.01                5                 200  ...   \n",
       "4607                 0.01                5                 200  ...   \n",
       "\n",
       "      split3_test_score split4_test_score  split5_test_score  \\\n",
       "0              0.758065          0.741935           0.741935   \n",
       "1              0.774194          0.741935           0.741935   \n",
       "2              0.774194          0.758065           0.774194   \n",
       "3              0.790323          0.725806           0.709677   \n",
       "4              0.790323          0.774194           0.774194   \n",
       "...                 ...               ...                ...   \n",
       "4603           0.838710          0.822581           0.870968   \n",
       "4604           0.838710          0.822581           0.870968   \n",
       "4605           0.838710          0.822581           0.870968   \n",
       "4606           0.838710          0.822581           0.870968   \n",
       "4607           0.838710          0.822581           0.870968   \n",
       "\n",
       "      split6_test_score  split7_test_score  split8_test_score  \\\n",
       "0              0.725806           0.677419           0.693548   \n",
       "1              0.725806           0.677419           0.677419   \n",
       "2              0.741935           0.693548           0.677419   \n",
       "3              0.741935           0.709677           0.709677   \n",
       "4              0.725806           0.693548           0.725806   \n",
       "...                 ...                ...                ...   \n",
       "4603           0.822581           0.806452           0.693548   \n",
       "4604           0.822581           0.806452           0.693548   \n",
       "4605           0.822581           0.806452           0.677419   \n",
       "4606           0.822581           0.822581           0.677419   \n",
       "4607           0.822581           0.806452           0.693548   \n",
       "\n",
       "      split9_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0              0.677419         0.741295        0.048078             4578  \n",
       "1              0.693548         0.742908        0.049390             4575  \n",
       "2              0.709677         0.752586        0.048690             4530  \n",
       "3              0.677419         0.742960        0.043040             4573  \n",
       "4              0.758065         0.765463        0.037846             4434  \n",
       "...                 ...              ...             ...              ...  \n",
       "4603           0.822581         0.813774        0.047909             2050  \n",
       "4604           0.822581         0.816948        0.046448             1787  \n",
       "4605           0.822581         0.815335        0.050783             1939  \n",
       "4606           0.822581         0.812186        0.050956             2153  \n",
       "4607           0.822581         0.813774        0.047909             2050  \n",
       "\n",
       "[4608 rows x 25 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score is 0.8505376344086022 with params {'colsample_bylevel': 0.1, 'colsample_bytree': 0.6, 'learning_rate': 0.15, 'max_depth': 5, 'n_estimators': 100, 'subsample': 0.6}\n"
     ]
    }
   ],
   "source": [
    "df1 = pd.read_csv(\"data\\\\xgb_results_full_1_learning=0.01_20221124.csv\")\n",
    "df1.drop(df1.columns[0], axis=1, inplace=True)\n",
    "display(df1)\n",
    "print(\"best score is 0.8505376344086022 with params {'colsample_bylevel': 0.1, 'colsample_bytree': 0.6, 'learning_rate': 0.15, 'max_depth': 5, 'n_estimators': 100, 'subsample': 0.6}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "042c4de6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_colsample_bylevel</th>\n",
       "      <th>param_colsample_bytree</th>\n",
       "      <th>param_gamma</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>...</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.028623</td>\n",
       "      <td>0.002525</td>\n",
       "      <td>0.007181</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.741295</td>\n",
       "      <td>0.048078</td>\n",
       "      <td>4578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.027127</td>\n",
       "      <td>0.000598</td>\n",
       "      <td>0.007082</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.742908</td>\n",
       "      <td>0.049390</td>\n",
       "      <td>4575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.027028</td>\n",
       "      <td>0.000698</td>\n",
       "      <td>0.007580</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.752586</td>\n",
       "      <td>0.048690</td>\n",
       "      <td>4530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.027427</td>\n",
       "      <td>0.000920</td>\n",
       "      <td>0.007381</td>\n",
       "      <td>0.000662</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.742960</td>\n",
       "      <td>0.043040</td>\n",
       "      <td>4573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.040093</td>\n",
       "      <td>0.001465</td>\n",
       "      <td>0.007082</td>\n",
       "      <td>0.000536</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>...</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.765463</td>\n",
       "      <td>0.037846</td>\n",
       "      <td>4434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4603</th>\n",
       "      <td>0.129553</td>\n",
       "      <td>0.002379</td>\n",
       "      <td>0.007381</td>\n",
       "      <td>0.000488</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.01</td>\n",
       "      <td>5</td>\n",
       "      <td>150</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.813774</td>\n",
       "      <td>0.047909</td>\n",
       "      <td>2050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4604</th>\n",
       "      <td>0.169746</td>\n",
       "      <td>0.002475</td>\n",
       "      <td>0.007680</td>\n",
       "      <td>0.000457</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.01</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.816948</td>\n",
       "      <td>0.046448</td>\n",
       "      <td>1787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4605</th>\n",
       "      <td>0.169550</td>\n",
       "      <td>0.002185</td>\n",
       "      <td>0.007381</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.01</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.815335</td>\n",
       "      <td>0.050783</td>\n",
       "      <td>1939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4606</th>\n",
       "      <td>0.170743</td>\n",
       "      <td>0.003753</td>\n",
       "      <td>0.007481</td>\n",
       "      <td>0.000499</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.01</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.812186</td>\n",
       "      <td>0.050956</td>\n",
       "      <td>2153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4607</th>\n",
       "      <td>0.168649</td>\n",
       "      <td>0.001371</td>\n",
       "      <td>0.007380</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.01</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.813774</td>\n",
       "      <td>0.047909</td>\n",
       "      <td>2050</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4608 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0          0.028623      0.002525         0.007181        0.000399   \n",
       "1          0.027127      0.000598         0.007082        0.000300   \n",
       "2          0.027028      0.000698         0.007580        0.000489   \n",
       "3          0.027427      0.000920         0.007381        0.000662   \n",
       "4          0.040093      0.001465         0.007082        0.000536   \n",
       "...             ...           ...              ...             ...   \n",
       "4603       0.129553      0.002379         0.007381        0.000488   \n",
       "4604       0.169746      0.002475         0.007680        0.000457   \n",
       "4605       0.169550      0.002185         0.007381        0.000489   \n",
       "4606       0.170743      0.003753         0.007481        0.000499   \n",
       "4607       0.168649      0.001371         0.007380        0.000489   \n",
       "\n",
       "     param_colsample_bylevel param_colsample_bytree param_gamma  \\\n",
       "0                        0.1                    0.4           0   \n",
       "1                        0.1                    0.4           0   \n",
       "2                        0.1                    0.4           0   \n",
       "3                        0.1                    0.4           0   \n",
       "4                        0.1                    0.4           0   \n",
       "...                      ...                    ...         ...   \n",
       "4603                     0.4                    0.9          10   \n",
       "4604                     0.4                    0.9          10   \n",
       "4605                     0.4                    0.9          10   \n",
       "4606                     0.4                    0.9          10   \n",
       "4607                     0.4                    0.9          10   \n",
       "\n",
       "     param_learning_rate param_max_depth param_n_estimators  ...  \\\n",
       "0                   0.01               2                 30  ...   \n",
       "1                   0.01               2                 30  ...   \n",
       "2                   0.01               2                 30  ...   \n",
       "3                   0.01               2                 30  ...   \n",
       "4                   0.01               2                 50  ...   \n",
       "...                  ...             ...                ...  ...   \n",
       "4603                0.01               5                150  ...   \n",
       "4604                0.01               5                200  ...   \n",
       "4605                0.01               5                200  ...   \n",
       "4606                0.01               5                200  ...   \n",
       "4607                0.01               5                200  ...   \n",
       "\n",
       "     split3_test_score split4_test_score  split5_test_score  \\\n",
       "0             0.758065          0.741935           0.741935   \n",
       "1             0.774194          0.741935           0.741935   \n",
       "2             0.774194          0.758065           0.774194   \n",
       "3             0.790323          0.725806           0.709677   \n",
       "4             0.790323          0.774194           0.774194   \n",
       "...                ...               ...                ...   \n",
       "4603          0.838710          0.822581           0.870968   \n",
       "4604          0.838710          0.822581           0.870968   \n",
       "4605          0.838710          0.822581           0.870968   \n",
       "4606          0.838710          0.822581           0.870968   \n",
       "4607          0.838710          0.822581           0.870968   \n",
       "\n",
       "      split6_test_score  split7_test_score  split8_test_score  \\\n",
       "0              0.725806           0.677419           0.693548   \n",
       "1              0.725806           0.677419           0.677419   \n",
       "2              0.741935           0.693548           0.677419   \n",
       "3              0.741935           0.709677           0.709677   \n",
       "4              0.725806           0.693548           0.725806   \n",
       "...                 ...                ...                ...   \n",
       "4603           0.822581           0.806452           0.693548   \n",
       "4604           0.822581           0.806452           0.693548   \n",
       "4605           0.822581           0.806452           0.677419   \n",
       "4606           0.822581           0.822581           0.677419   \n",
       "4607           0.822581           0.806452           0.693548   \n",
       "\n",
       "      split9_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0              0.677419         0.741295        0.048078             4578  \n",
       "1              0.693548         0.742908        0.049390             4575  \n",
       "2              0.709677         0.752586        0.048690             4530  \n",
       "3              0.677419         0.742960        0.043040             4573  \n",
       "4              0.758065         0.765463        0.037846             4434  \n",
       "...                 ...              ...             ...              ...  \n",
       "4603           0.822581         0.813774        0.047909             2050  \n",
       "4604           0.822581         0.816948        0.046448             1787  \n",
       "4605           0.822581         0.815335        0.050783             1939  \n",
       "4606           0.822581         0.812186        0.050956             2153  \n",
       "4607           0.822581         0.813774        0.047909             2050  \n",
       "\n",
       "[4608 rows x 25 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score is 0.844162826420891 with params {'colsample_bylevel': 0.3, 'colsample_bytree': 0.9, 'gamma': 1, 'learning_rate': 0.01, 'max_depth': 5, 'n_estimators': 200, 'subsample': 0.7}\n"
     ]
    }
   ],
   "source": [
    "# Full Tuning - Part 1\n",
    "random.seed(10)\n",
    "\n",
    "xgb = XGBClassifier()\n",
    "\n",
    "xgb_parameters = {'max_depth': [2,3,4,5]\n",
    "                   , 'subsample': [0.6, 0.7, 0.8, 0.9]\n",
    "                   , 'gamma': [0, 1, 10]\n",
    "                   , 'colsample_bytree': [0.4, 0.5, 0.6, 0.9]\n",
    "                   , 'colsample_bylevel': [0.1, 0.2, 0.3, 0.4]\n",
    "                   , 'learning_rate': [0.01]\n",
    "                   , 'n_estimators': [30, 50, 80, 100, 150, 200]}\n",
    "\n",
    "stratified_10_fold_cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "xgb_grid_search = GridSearchCV(xgb, xgb_parameters, scoring='accuracy', cv=stratified_10_fold_cv)\n",
    "\n",
    "xgb_grid_search.fit(X_train, y_train)\n",
    "\n",
    "xgb_grid_search_results_full_1 = pd.DataFrame(xgb_grid_search.cv_results_)\n",
    "display(xgb_grid_search_results_full_1)\n",
    "\n",
    "print(\"best score is {} with params {}\".format(xgb_grid_search.best_score_, xgb_grid_search.best_params_))\n",
    "#best score is 0.844162826420891 with params\n",
    "{'colsample_bylevel': 0.3, 'colsample_bytree': 0.9, 'gamma': 1, 'learning_rate': 0.01, 'max_depth': 5, 'n_estimators': 200, 'subsample': 0.7}\n",
    "\n",
    "# save dataframe\n",
    "from datetime import datetime\n",
    "date = str(datetime.now().date()).replace(\"-\", \"\")\n",
    "xgb_grid_search_results_full_1.to_csv(f\"results/xgb_results_full_round3_1_learning=0.01_{date}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c6d50dac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_colsample_bylevel</th>\n",
       "      <th>param_colsample_bytree</th>\n",
       "      <th>param_gamma</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>...</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.028523</td>\n",
       "      <td>0.001197</td>\n",
       "      <td>0.007181</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.775090</td>\n",
       "      <td>0.045213</td>\n",
       "      <td>4574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.027227</td>\n",
       "      <td>0.000779</td>\n",
       "      <td>0.006981</td>\n",
       "      <td>0.000772</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.765463</td>\n",
       "      <td>0.044700</td>\n",
       "      <td>4590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.030020</td>\n",
       "      <td>0.003261</td>\n",
       "      <td>0.007580</td>\n",
       "      <td>0.000662</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.775090</td>\n",
       "      <td>0.048492</td>\n",
       "      <td>4576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.027626</td>\n",
       "      <td>0.001097</td>\n",
       "      <td>0.007480</td>\n",
       "      <td>0.000499</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.776677</td>\n",
       "      <td>0.047735</td>\n",
       "      <td>4572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.039397</td>\n",
       "      <td>0.000667</td>\n",
       "      <td>0.007378</td>\n",
       "      <td>0.000491</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>...</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.799155</td>\n",
       "      <td>0.059192</td>\n",
       "      <td>4360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4603</th>\n",
       "      <td>0.130850</td>\n",
       "      <td>0.001882</td>\n",
       "      <td>0.007381</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.05</td>\n",
       "      <td>5</td>\n",
       "      <td>150</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.919355</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.816999</td>\n",
       "      <td>0.059810</td>\n",
       "      <td>3203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4604</th>\n",
       "      <td>0.171740</td>\n",
       "      <td>0.001773</td>\n",
       "      <td>0.007580</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.05</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.919355</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.818612</td>\n",
       "      <td>0.053929</td>\n",
       "      <td>2994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4605</th>\n",
       "      <td>0.171541</td>\n",
       "      <td>0.002318</td>\n",
       "      <td>0.007381</td>\n",
       "      <td>0.000488</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.05</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.919355</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.823400</td>\n",
       "      <td>0.053525</td>\n",
       "      <td>2604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4606</th>\n",
       "      <td>0.171951</td>\n",
       "      <td>0.002359</td>\n",
       "      <td>0.007469</td>\n",
       "      <td>0.000504</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.05</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.887097</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.816999</td>\n",
       "      <td>0.046733</td>\n",
       "      <td>3198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4607</th>\n",
       "      <td>0.170743</td>\n",
       "      <td>0.001773</td>\n",
       "      <td>0.007580</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.05</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.903226</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.815387</td>\n",
       "      <td>0.057189</td>\n",
       "      <td>3367</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4608 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0          0.028523      0.001197         0.007181        0.000399   \n",
       "1          0.027227      0.000779         0.006981        0.000772   \n",
       "2          0.030020      0.003261         0.007580        0.000662   \n",
       "3          0.027626      0.001097         0.007480        0.000499   \n",
       "4          0.039397      0.000667         0.007378        0.000491   \n",
       "...             ...           ...              ...             ...   \n",
       "4603       0.130850      0.001882         0.007381        0.000489   \n",
       "4604       0.171740      0.001773         0.007580        0.000489   \n",
       "4605       0.171541      0.002318         0.007381        0.000488   \n",
       "4606       0.171951      0.002359         0.007469        0.000504   \n",
       "4607       0.170743      0.001773         0.007580        0.000489   \n",
       "\n",
       "      param_colsample_bylevel  param_colsample_bytree  param_gamma  \\\n",
       "0                         0.1                     0.4            0   \n",
       "1                         0.1                     0.4            0   \n",
       "2                         0.1                     0.4            0   \n",
       "3                         0.1                     0.4            0   \n",
       "4                         0.1                     0.4            0   \n",
       "...                       ...                     ...          ...   \n",
       "4603                      0.4                     0.9           10   \n",
       "4604                      0.4                     0.9           10   \n",
       "4605                      0.4                     0.9           10   \n",
       "4606                      0.4                     0.9           10   \n",
       "4607                      0.4                     0.9           10   \n",
       "\n",
       "      param_learning_rate  param_max_depth  param_n_estimators  ...  \\\n",
       "0                    0.05                2                  30  ...   \n",
       "1                    0.05                2                  30  ...   \n",
       "2                    0.05                2                  30  ...   \n",
       "3                    0.05                2                  30  ...   \n",
       "4                    0.05                2                  50  ...   \n",
       "...                   ...              ...                 ...  ...   \n",
       "4603                 0.05                5                 150  ...   \n",
       "4604                 0.05                5                 200  ...   \n",
       "4605                 0.05                5                 200  ...   \n",
       "4606                 0.05                5                 200  ...   \n",
       "4607                 0.05                5                 200  ...   \n",
       "\n",
       "      split3_test_score split4_test_score  split5_test_score  \\\n",
       "0              0.774194          0.741935           0.806452   \n",
       "1              0.774194          0.741935           0.790323   \n",
       "2              0.806452          0.758065           0.806452   \n",
       "3              0.806452          0.741935           0.790323   \n",
       "4              0.806452          0.806452           0.870968   \n",
       "...                 ...               ...                ...   \n",
       "4603           0.838710          0.806452           0.919355   \n",
       "4604           0.838710          0.822581           0.919355   \n",
       "4605           0.838710          0.822581           0.919355   \n",
       "4606           0.838710          0.822581           0.887097   \n",
       "4607           0.838710          0.806452           0.903226   \n",
       "\n",
       "      split6_test_score  split7_test_score  split8_test_score  \\\n",
       "0              0.806452           0.677419           0.725806   \n",
       "1              0.790323           0.677419           0.709677   \n",
       "2              0.790323           0.677419           0.709677   \n",
       "3              0.806452           0.677419           0.725806   \n",
       "4              0.806452           0.693548           0.693548   \n",
       "...                 ...                ...                ...   \n",
       "4603           0.822581           0.790323           0.693548   \n",
       "4604           0.822581           0.806452           0.693548   \n",
       "4605           0.822581           0.822581           0.693548   \n",
       "4606           0.822581           0.806452           0.709677   \n",
       "4607           0.822581           0.790323           0.693548   \n",
       "\n",
       "      split9_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0              0.774194         0.775090        0.045213             4574  \n",
       "1              0.758065         0.765463        0.044700             4590  \n",
       "2              0.758065         0.775090        0.048492             4576  \n",
       "3              0.758065         0.776677        0.047735             4572  \n",
       "4              0.790323         0.799155        0.059192             4360  \n",
       "...                 ...              ...             ...              ...  \n",
       "4603           0.838710         0.816999        0.059810             3203  \n",
       "4604           0.822581         0.818612        0.053929             2994  \n",
       "4605           0.822581         0.823400        0.053525             2604  \n",
       "4606           0.822581         0.816999        0.046733             3198  \n",
       "4607           0.838710         0.815387        0.057189             3367  \n",
       "\n",
       "[4608 rows x 25 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score is 0.8506144393241168 with params {'colsample_bylevel': 0.2, 'colsample_bytree': 0.9, 'gamma': 1, 'learning_rate': 0.05, 'max_depth': 4, 'n_estimators': 100, 'subsample': 0.7}\n"
     ]
    }
   ],
   "source": [
    "df2 = pd.read_csv(\"data\\\\xgb_results_full_2_learning=0.05_20221124.csv\")\n",
    "df2.drop(df2.columns[0], axis=1, inplace=True)\n",
    "display(df2)\n",
    "print(\"best score is 0.8506144393241168 with params {'colsample_bylevel': 0.2, 'colsample_bytree': 0.9, 'gamma': 1, 'learning_rate': 0.05, 'max_depth': 4, 'n_estimators': 100, 'subsample': 0.7}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cecd42a5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_colsample_bylevel</th>\n",
       "      <th>param_colsample_bytree</th>\n",
       "      <th>param_gamma</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>...</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.028523</td>\n",
       "      <td>0.001197</td>\n",
       "      <td>0.007181</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.775090</td>\n",
       "      <td>0.045213</td>\n",
       "      <td>4574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.027227</td>\n",
       "      <td>0.000779</td>\n",
       "      <td>0.006981</td>\n",
       "      <td>0.000772</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.765463</td>\n",
       "      <td>0.044700</td>\n",
       "      <td>4590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.030020</td>\n",
       "      <td>0.003261</td>\n",
       "      <td>0.007580</td>\n",
       "      <td>0.000662</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.775090</td>\n",
       "      <td>0.048492</td>\n",
       "      <td>4576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.027626</td>\n",
       "      <td>0.001097</td>\n",
       "      <td>0.007480</td>\n",
       "      <td>0.000499</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.776677</td>\n",
       "      <td>0.047735</td>\n",
       "      <td>4572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.039397</td>\n",
       "      <td>0.000667</td>\n",
       "      <td>0.007378</td>\n",
       "      <td>0.000491</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>...</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.799155</td>\n",
       "      <td>0.059192</td>\n",
       "      <td>4360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4603</th>\n",
       "      <td>0.130850</td>\n",
       "      <td>0.001882</td>\n",
       "      <td>0.007381</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.05</td>\n",
       "      <td>5</td>\n",
       "      <td>150</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.919355</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.816999</td>\n",
       "      <td>0.059810</td>\n",
       "      <td>3203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4604</th>\n",
       "      <td>0.171740</td>\n",
       "      <td>0.001773</td>\n",
       "      <td>0.007580</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.05</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.919355</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.818612</td>\n",
       "      <td>0.053929</td>\n",
       "      <td>2994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4605</th>\n",
       "      <td>0.171541</td>\n",
       "      <td>0.002318</td>\n",
       "      <td>0.007381</td>\n",
       "      <td>0.000488</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.05</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.919355</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.823400</td>\n",
       "      <td>0.053525</td>\n",
       "      <td>2604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4606</th>\n",
       "      <td>0.171951</td>\n",
       "      <td>0.002359</td>\n",
       "      <td>0.007469</td>\n",
       "      <td>0.000504</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.05</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.887097</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.816999</td>\n",
       "      <td>0.046733</td>\n",
       "      <td>3198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4607</th>\n",
       "      <td>0.170743</td>\n",
       "      <td>0.001773</td>\n",
       "      <td>0.007580</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.05</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.903226</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.815387</td>\n",
       "      <td>0.057189</td>\n",
       "      <td>3367</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4608 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0          0.028523      0.001197         0.007181        0.000399   \n",
       "1          0.027227      0.000779         0.006981        0.000772   \n",
       "2          0.030020      0.003261         0.007580        0.000662   \n",
       "3          0.027626      0.001097         0.007480        0.000499   \n",
       "4          0.039397      0.000667         0.007378        0.000491   \n",
       "...             ...           ...              ...             ...   \n",
       "4603       0.130850      0.001882         0.007381        0.000489   \n",
       "4604       0.171740      0.001773         0.007580        0.000489   \n",
       "4605       0.171541      0.002318         0.007381        0.000488   \n",
       "4606       0.171951      0.002359         0.007469        0.000504   \n",
       "4607       0.170743      0.001773         0.007580        0.000489   \n",
       "\n",
       "     param_colsample_bylevel param_colsample_bytree param_gamma  \\\n",
       "0                        0.1                    0.4           0   \n",
       "1                        0.1                    0.4           0   \n",
       "2                        0.1                    0.4           0   \n",
       "3                        0.1                    0.4           0   \n",
       "4                        0.1                    0.4           0   \n",
       "...                      ...                    ...         ...   \n",
       "4603                     0.4                    0.9          10   \n",
       "4604                     0.4                    0.9          10   \n",
       "4605                     0.4                    0.9          10   \n",
       "4606                     0.4                    0.9          10   \n",
       "4607                     0.4                    0.9          10   \n",
       "\n",
       "     param_learning_rate param_max_depth param_n_estimators  ...  \\\n",
       "0                   0.05               2                 30  ...   \n",
       "1                   0.05               2                 30  ...   \n",
       "2                   0.05               2                 30  ...   \n",
       "3                   0.05               2                 30  ...   \n",
       "4                   0.05               2                 50  ...   \n",
       "...                  ...             ...                ...  ...   \n",
       "4603                0.05               5                150  ...   \n",
       "4604                0.05               5                200  ...   \n",
       "4605                0.05               5                200  ...   \n",
       "4606                0.05               5                200  ...   \n",
       "4607                0.05               5                200  ...   \n",
       "\n",
       "     split3_test_score split4_test_score  split5_test_score  \\\n",
       "0             0.774194          0.741935           0.806452   \n",
       "1             0.774194          0.741935           0.790323   \n",
       "2             0.806452          0.758065           0.806452   \n",
       "3             0.806452          0.741935           0.790323   \n",
       "4             0.806452          0.806452           0.870968   \n",
       "...                ...               ...                ...   \n",
       "4603          0.838710          0.806452           0.919355   \n",
       "4604          0.838710          0.822581           0.919355   \n",
       "4605          0.838710          0.822581           0.919355   \n",
       "4606          0.838710          0.822581           0.887097   \n",
       "4607          0.838710          0.806452           0.903226   \n",
       "\n",
       "      split6_test_score  split7_test_score  split8_test_score  \\\n",
       "0              0.806452           0.677419           0.725806   \n",
       "1              0.790323           0.677419           0.709677   \n",
       "2              0.790323           0.677419           0.709677   \n",
       "3              0.806452           0.677419           0.725806   \n",
       "4              0.806452           0.693548           0.693548   \n",
       "...                 ...                ...                ...   \n",
       "4603           0.822581           0.790323           0.693548   \n",
       "4604           0.822581           0.806452           0.693548   \n",
       "4605           0.822581           0.822581           0.693548   \n",
       "4606           0.822581           0.806452           0.709677   \n",
       "4607           0.822581           0.790323           0.693548   \n",
       "\n",
       "      split9_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0              0.774194         0.775090        0.045213             4574  \n",
       "1              0.758065         0.765463        0.044700             4590  \n",
       "2              0.758065         0.775090        0.048492             4576  \n",
       "3              0.758065         0.776677        0.047735             4572  \n",
       "4              0.790323         0.799155        0.059192             4360  \n",
       "...                 ...              ...             ...              ...  \n",
       "4603           0.838710         0.816999        0.059810             3203  \n",
       "4604           0.822581         0.818612        0.053929             2994  \n",
       "4605           0.822581         0.823400        0.053525             2604  \n",
       "4606           0.822581         0.816999        0.046733             3198  \n",
       "4607           0.838710         0.815387        0.057189             3367  \n",
       "\n",
       "[4608 rows x 25 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score is 0.8506144393241168 with params {'colsample_bylevel': 0.2, 'colsample_bytree': 0.9, 'gamma': 1, 'learning_rate': 0.05, 'max_depth': 4, 'n_estimators': 100, 'subsample': 0.7}\n"
     ]
    }
   ],
   "source": [
    "# Full Tuning - Part 2\n",
    "random.seed(10)\n",
    "\n",
    "xgb = XGBClassifier()\n",
    "\n",
    "xgb_parameters = {'max_depth': [2,3,4,5]\n",
    "                   , 'subsample': [0.6, 0.7, 0.8, 0.9]\n",
    "                   , 'gamma': [0, 1, 10]\n",
    "                   , 'colsample_bytree': [0.4, 0.5, 0.6, 0.9]\n",
    "                   , 'colsample_bylevel': [0.1, 0.2, 0.3, 0.4]\n",
    "                   , 'learning_rate': [0.05]\n",
    "                   , 'n_estimators': [30, 50, 80, 100, 150, 200]}\n",
    "\n",
    "stratified_10_fold_cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "xgb_grid_search = GridSearchCV(xgb, xgb_parameters, scoring='accuracy', cv=stratified_10_fold_cv)\n",
    "\n",
    "xgb_grid_search.fit(X_train, y_train)\n",
    "\n",
    "xgb_grid_search_results_full_2 = pd.DataFrame(xgb_grid_search.cv_results_)\n",
    "display(xgb_grid_search_results_full_2)\n",
    "\n",
    "print(\"best score is {} with params {}\".format(xgb_grid_search.best_score_, xgb_grid_search.best_params_))\n",
    "#best score is 0.8506144393241168 with params\n",
    "#{'colsample_bylevel': 0.2, 'colsample_bytree': 0.9, 'gamma': 1, 'learning_rate': 0.05, 'max_depth': 4, 'n_estimators': 100, 'subsample': 0.7}\n",
    "\n",
    "# save dataframe\n",
    "from datetime import datetime\n",
    "date = str(datetime.now().date()).replace(\"-\", \"\")\n",
    "xgb_grid_search_results_full_2.to_csv(f\"results/xgb_results_full_round3_2_learning=0.05_{date}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "de35f20c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_colsample_bylevel</th>\n",
       "      <th>param_colsample_bytree</th>\n",
       "      <th>param_gamma</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>...</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.028224</td>\n",
       "      <td>0.001548</td>\n",
       "      <td>0.007181</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.08</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.791193</td>\n",
       "      <td>0.044965</td>\n",
       "      <td>4563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.026928</td>\n",
       "      <td>0.000772</td>\n",
       "      <td>0.007181</td>\n",
       "      <td>0.000599</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.08</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.789555</td>\n",
       "      <td>0.044749</td>\n",
       "      <td>4576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.029339</td>\n",
       "      <td>0.001735</td>\n",
       "      <td>0.007479</td>\n",
       "      <td>0.000498</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.08</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.789580</td>\n",
       "      <td>0.046896</td>\n",
       "      <td>4572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.028622</td>\n",
       "      <td>0.001947</td>\n",
       "      <td>0.007481</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.08</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.792780</td>\n",
       "      <td>0.044102</td>\n",
       "      <td>4551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.039893</td>\n",
       "      <td>0.001261</td>\n",
       "      <td>0.007380</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.08</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.812007</td>\n",
       "      <td>0.056776</td>\n",
       "      <td>4032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4603</th>\n",
       "      <td>0.129553</td>\n",
       "      <td>0.001133</td>\n",
       "      <td>0.007580</td>\n",
       "      <td>0.000488</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.08</td>\n",
       "      <td>5</td>\n",
       "      <td>150</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.919355</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.824962</td>\n",
       "      <td>0.052356</td>\n",
       "      <td>2818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4604</th>\n",
       "      <td>0.170643</td>\n",
       "      <td>0.001863</td>\n",
       "      <td>0.007581</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.08</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.903226</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.820225</td>\n",
       "      <td>0.053767</td>\n",
       "      <td>3155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4605</th>\n",
       "      <td>0.170045</td>\n",
       "      <td>0.001561</td>\n",
       "      <td>0.007281</td>\n",
       "      <td>0.000457</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.08</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.887097</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.816974</td>\n",
       "      <td>0.048018</td>\n",
       "      <td>3490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4606</th>\n",
       "      <td>0.169746</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>0.007480</td>\n",
       "      <td>0.000499</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.08</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.903226</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.816999</td>\n",
       "      <td>0.050944</td>\n",
       "      <td>3455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4607</th>\n",
       "      <td>0.170444</td>\n",
       "      <td>0.002693</td>\n",
       "      <td>0.007181</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.08</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.919355</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.823374</td>\n",
       "      <td>0.053036</td>\n",
       "      <td>2921</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4608 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0          0.028224      0.001548         0.007181        0.000399   \n",
       "1          0.026928      0.000772         0.007181        0.000599   \n",
       "2          0.029339      0.001735         0.007479        0.000498   \n",
       "3          0.028622      0.001947         0.007481        0.000500   \n",
       "4          0.039893      0.001261         0.007380        0.000489   \n",
       "...             ...           ...              ...             ...   \n",
       "4603       0.129553      0.001133         0.007580        0.000488   \n",
       "4604       0.170643      0.001863         0.007581        0.000489   \n",
       "4605       0.170045      0.001561         0.007281        0.000457   \n",
       "4606       0.169746      0.000977         0.007480        0.000499   \n",
       "4607       0.170444      0.002693         0.007181        0.000399   \n",
       "\n",
       "      param_colsample_bylevel  param_colsample_bytree  param_gamma  \\\n",
       "0                         0.1                     0.4            0   \n",
       "1                         0.1                     0.4            0   \n",
       "2                         0.1                     0.4            0   \n",
       "3                         0.1                     0.4            0   \n",
       "4                         0.1                     0.4            0   \n",
       "...                       ...                     ...          ...   \n",
       "4603                      0.4                     0.9           10   \n",
       "4604                      0.4                     0.9           10   \n",
       "4605                      0.4                     0.9           10   \n",
       "4606                      0.4                     0.9           10   \n",
       "4607                      0.4                     0.9           10   \n",
       "\n",
       "      param_learning_rate  param_max_depth  param_n_estimators  ...  \\\n",
       "0                    0.08                2                  30  ...   \n",
       "1                    0.08                2                  30  ...   \n",
       "2                    0.08                2                  30  ...   \n",
       "3                    0.08                2                  30  ...   \n",
       "4                    0.08                2                  50  ...   \n",
       "...                   ...              ...                 ...  ...   \n",
       "4603                 0.08                5                 150  ...   \n",
       "4604                 0.08                5                 200  ...   \n",
       "4605                 0.08                5                 200  ...   \n",
       "4606                 0.08                5                 200  ...   \n",
       "4607                 0.08                5                 200  ...   \n",
       "\n",
       "      split3_test_score split4_test_score  split5_test_score  \\\n",
       "0              0.806452          0.774194           0.822581   \n",
       "1              0.806452          0.774194           0.822581   \n",
       "2              0.838710          0.774194           0.822581   \n",
       "3              0.838710          0.774194           0.822581   \n",
       "4              0.854839          0.790323           0.870968   \n",
       "...                 ...               ...                ...   \n",
       "4603           0.838710          0.806452           0.919355   \n",
       "4604           0.870968          0.806452           0.903226   \n",
       "4605           0.838710          0.822581           0.887097   \n",
       "4606           0.838710          0.806452           0.903226   \n",
       "4607           0.838710          0.806452           0.919355   \n",
       "\n",
       "      split6_test_score  split7_test_score  split8_test_score  \\\n",
       "0              0.822581           0.693548           0.725806   \n",
       "1              0.790323           0.709677           0.709677   \n",
       "2              0.790323           0.709677           0.709677   \n",
       "3              0.790323           0.725806           0.709677   \n",
       "4              0.806452           0.741935           0.693548   \n",
       "...                 ...                ...                ...   \n",
       "4603           0.822581           0.806452           0.709677   \n",
       "4604           0.822581           0.822581           0.693548   \n",
       "4605           0.822581           0.806452           0.693548   \n",
       "4606           0.822581           0.806452           0.709677   \n",
       "4607           0.822581           0.806452           0.709677   \n",
       "\n",
       "      split9_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0              0.806452         0.791193        0.044965             4563  \n",
       "1              0.806452         0.789555        0.044749             4576  \n",
       "2              0.790323         0.789580        0.046896             4572  \n",
       "3              0.790323         0.792780        0.044102             4551  \n",
       "4              0.806452         0.812007        0.056776             4032  \n",
       "...                 ...              ...             ...              ...  \n",
       "4603           0.822581         0.824962        0.052356             2818  \n",
       "4604           0.822581         0.820225        0.053767             3155  \n",
       "4605           0.822581         0.816974        0.048018             3490  \n",
       "4606           0.822581         0.816999        0.050944             3455  \n",
       "4607           0.822581         0.823374        0.053036             2921  \n",
       "\n",
       "[4608 rows x 25 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score is 0.8506400409626217 with params {'colsample_bylevel': 0.2, 'colsample_bytree': 0.5, 'gamma': 1, 'learning_rate': 0.08, 'max_depth': 2, 'n_estimators': 150, 'subsample': 0.8}\n"
     ]
    }
   ],
   "source": [
    "df3 = pd.read_csv(\"data\\\\xgb_results_full_3_learning=0.08_20221124.csv\")\n",
    "df3.drop(df3.columns[0], axis=1, inplace=True)\n",
    "display(df3)\n",
    "print(\"best score is 0.8506400409626217 with params {'colsample_bylevel': 0.2, 'colsample_bytree': 0.5, 'gamma': 1, 'learning_rate': 0.08, 'max_depth': 2, 'n_estimators': 150, 'subsample': 0.8}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3ae2939c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_colsample_bylevel</th>\n",
       "      <th>param_colsample_bytree</th>\n",
       "      <th>param_gamma</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>...</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.028224</td>\n",
       "      <td>0.001548</td>\n",
       "      <td>0.007181</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.08</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.791193</td>\n",
       "      <td>0.044965</td>\n",
       "      <td>4563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.026928</td>\n",
       "      <td>0.000772</td>\n",
       "      <td>0.007181</td>\n",
       "      <td>0.000599</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.08</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.789555</td>\n",
       "      <td>0.044749</td>\n",
       "      <td>4576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.029339</td>\n",
       "      <td>0.001735</td>\n",
       "      <td>0.007479</td>\n",
       "      <td>0.000498</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.08</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.789580</td>\n",
       "      <td>0.046896</td>\n",
       "      <td>4572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.028622</td>\n",
       "      <td>0.001947</td>\n",
       "      <td>0.007481</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.08</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.792780</td>\n",
       "      <td>0.044102</td>\n",
       "      <td>4551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.039893</td>\n",
       "      <td>0.001261</td>\n",
       "      <td>0.007380</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.08</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.812007</td>\n",
       "      <td>0.056776</td>\n",
       "      <td>4032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4603</th>\n",
       "      <td>0.129553</td>\n",
       "      <td>0.001133</td>\n",
       "      <td>0.007580</td>\n",
       "      <td>0.000488</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.08</td>\n",
       "      <td>5</td>\n",
       "      <td>150</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.919355</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.824962</td>\n",
       "      <td>0.052356</td>\n",
       "      <td>2818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4604</th>\n",
       "      <td>0.170643</td>\n",
       "      <td>0.001863</td>\n",
       "      <td>0.007581</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.08</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.903226</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.820225</td>\n",
       "      <td>0.053767</td>\n",
       "      <td>3155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4605</th>\n",
       "      <td>0.170045</td>\n",
       "      <td>0.001561</td>\n",
       "      <td>0.007281</td>\n",
       "      <td>0.000457</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.08</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.887097</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.816974</td>\n",
       "      <td>0.048018</td>\n",
       "      <td>3490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4606</th>\n",
       "      <td>0.169746</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>0.007480</td>\n",
       "      <td>0.000499</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.08</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.903226</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.816999</td>\n",
       "      <td>0.050944</td>\n",
       "      <td>3455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4607</th>\n",
       "      <td>0.170444</td>\n",
       "      <td>0.002693</td>\n",
       "      <td>0.007181</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.08</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.919355</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.823374</td>\n",
       "      <td>0.053036</td>\n",
       "      <td>2921</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4608 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0          0.028224      0.001548         0.007181        0.000399   \n",
       "1          0.026928      0.000772         0.007181        0.000599   \n",
       "2          0.029339      0.001735         0.007479        0.000498   \n",
       "3          0.028622      0.001947         0.007481        0.000500   \n",
       "4          0.039893      0.001261         0.007380        0.000489   \n",
       "...             ...           ...              ...             ...   \n",
       "4603       0.129553      0.001133         0.007580        0.000488   \n",
       "4604       0.170643      0.001863         0.007581        0.000489   \n",
       "4605       0.170045      0.001561         0.007281        0.000457   \n",
       "4606       0.169746      0.000977         0.007480        0.000499   \n",
       "4607       0.170444      0.002693         0.007181        0.000399   \n",
       "\n",
       "     param_colsample_bylevel param_colsample_bytree param_gamma  \\\n",
       "0                        0.1                    0.4           0   \n",
       "1                        0.1                    0.4           0   \n",
       "2                        0.1                    0.4           0   \n",
       "3                        0.1                    0.4           0   \n",
       "4                        0.1                    0.4           0   \n",
       "...                      ...                    ...         ...   \n",
       "4603                     0.4                    0.9          10   \n",
       "4604                     0.4                    0.9          10   \n",
       "4605                     0.4                    0.9          10   \n",
       "4606                     0.4                    0.9          10   \n",
       "4607                     0.4                    0.9          10   \n",
       "\n",
       "     param_learning_rate param_max_depth param_n_estimators  ...  \\\n",
       "0                   0.08               2                 30  ...   \n",
       "1                   0.08               2                 30  ...   \n",
       "2                   0.08               2                 30  ...   \n",
       "3                   0.08               2                 30  ...   \n",
       "4                   0.08               2                 50  ...   \n",
       "...                  ...             ...                ...  ...   \n",
       "4603                0.08               5                150  ...   \n",
       "4604                0.08               5                200  ...   \n",
       "4605                0.08               5                200  ...   \n",
       "4606                0.08               5                200  ...   \n",
       "4607                0.08               5                200  ...   \n",
       "\n",
       "     split3_test_score split4_test_score  split5_test_score  \\\n",
       "0             0.806452          0.774194           0.822581   \n",
       "1             0.806452          0.774194           0.822581   \n",
       "2             0.838710          0.774194           0.822581   \n",
       "3             0.838710          0.774194           0.822581   \n",
       "4             0.854839          0.790323           0.870968   \n",
       "...                ...               ...                ...   \n",
       "4603          0.838710          0.806452           0.919355   \n",
       "4604          0.870968          0.806452           0.903226   \n",
       "4605          0.838710          0.822581           0.887097   \n",
       "4606          0.838710          0.806452           0.903226   \n",
       "4607          0.838710          0.806452           0.919355   \n",
       "\n",
       "      split6_test_score  split7_test_score  split8_test_score  \\\n",
       "0              0.822581           0.693548           0.725806   \n",
       "1              0.790323           0.709677           0.709677   \n",
       "2              0.790323           0.709677           0.709677   \n",
       "3              0.790323           0.725806           0.709677   \n",
       "4              0.806452           0.741935           0.693548   \n",
       "...                 ...                ...                ...   \n",
       "4603           0.822581           0.806452           0.709677   \n",
       "4604           0.822581           0.822581           0.693548   \n",
       "4605           0.822581           0.806452           0.693548   \n",
       "4606           0.822581           0.806452           0.709677   \n",
       "4607           0.822581           0.806452           0.709677   \n",
       "\n",
       "      split9_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0              0.806452         0.791193        0.044965             4563  \n",
       "1              0.806452         0.789555        0.044749             4576  \n",
       "2              0.790323         0.789580        0.046896             4572  \n",
       "3              0.790323         0.792780        0.044102             4551  \n",
       "4              0.806452         0.812007        0.056776             4032  \n",
       "...                 ...              ...             ...              ...  \n",
       "4603           0.822581         0.824962        0.052356             2818  \n",
       "4604           0.822581         0.820225        0.053767             3155  \n",
       "4605           0.822581         0.816974        0.048018             3490  \n",
       "4606           0.822581         0.816999        0.050944             3455  \n",
       "4607           0.822581         0.823374        0.053036             2921  \n",
       "\n",
       "[4608 rows x 25 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score is 0.8506400409626217 with params {'colsample_bylevel': 0.2, 'colsample_bytree': 0.5, 'gamma': 1, 'learning_rate': 0.08, 'max_depth': 2, 'n_estimators': 150, 'subsample': 0.8}\n"
     ]
    }
   ],
   "source": [
    "# Full Tuning - Part 3\n",
    "random.seed(10)\n",
    "\n",
    "xgb = XGBClassifier()\n",
    "\n",
    "xgb_parameters = {'max_depth': [2,3,4,5]\n",
    "                   , 'subsample': [0.6, 0.7, 0.8, 0.9]\n",
    "                   , 'gamma': [0, 1, 10]\n",
    "                   , 'colsample_bytree': [0.4, 0.5, 0.6, 0.9]\n",
    "                   , 'colsample_bylevel': [0.1, 0.2, 0.3, 0.4]\n",
    "                   , 'learning_rate': [0.08]\n",
    "                   , 'n_estimators': [30, 50, 80, 100, 150, 200]}\n",
    "\n",
    "stratified_10_fold_cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "xgb_grid_search = GridSearchCV(xgb, xgb_parameters, scoring='accuracy', cv=stratified_10_fold_cv)\n",
    "\n",
    "xgb_grid_search.fit(X_train, y_train)\n",
    "\n",
    "xgb_grid_search_results_full_3 = pd.DataFrame(xgb_grid_search.cv_results_)\n",
    "display(xgb_grid_search_results_full_3)\n",
    "\n",
    "print(\"best score is {} with params {}\".format(xgb_grid_search.best_score_, xgb_grid_search.best_params_))\n",
    "#best score is 0.8506400409626217 with params\n",
    "#{'colsample_bylevel': 0.2, 'colsample_bytree': 0.5, 'gamma': 1, 'learning_rate': 0.08, 'max_depth': 2, 'n_estimators': 150, 'subsample': 0.8}\n",
    "\n",
    "# save dataframe\n",
    "from datetime import datetime\n",
    "date = str(datetime.now().date()).replace(\"-\", \"\")\n",
    "xgb_grid_search_results_full_3.to_csv(f\"results/xgb_results_full_round3_3_learning=0.08_{date}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9eef9359",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_colsample_bylevel</th>\n",
       "      <th>param_colsample_bytree</th>\n",
       "      <th>param_gamma</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>...</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.027726</td>\n",
       "      <td>0.001246</td>\n",
       "      <td>0.007381</td>\n",
       "      <td>0.000662</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.791219</td>\n",
       "      <td>0.043138</td>\n",
       "      <td>4572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.027127</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>0.007081</td>\n",
       "      <td>0.000698</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.797619</td>\n",
       "      <td>0.056310</td>\n",
       "      <td>4538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.027725</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>0.007582</td>\n",
       "      <td>0.000486</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.800819</td>\n",
       "      <td>0.053966</td>\n",
       "      <td>4506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.028225</td>\n",
       "      <td>0.001002</td>\n",
       "      <td>0.007579</td>\n",
       "      <td>0.000661</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.799232</td>\n",
       "      <td>0.049960</td>\n",
       "      <td>4523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.041589</td>\n",
       "      <td>0.000779</td>\n",
       "      <td>0.007481</td>\n",
       "      <td>0.000499</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.812007</td>\n",
       "      <td>0.054003</td>\n",
       "      <td>4127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4603</th>\n",
       "      <td>0.128755</td>\n",
       "      <td>0.000698</td>\n",
       "      <td>0.007581</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.1</td>\n",
       "      <td>5</td>\n",
       "      <td>150</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.919355</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.818587</td>\n",
       "      <td>0.059897</td>\n",
       "      <td>3439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4604</th>\n",
       "      <td>0.181969</td>\n",
       "      <td>0.018973</td>\n",
       "      <td>0.007281</td>\n",
       "      <td>0.000457</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.1</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.903226</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.818612</td>\n",
       "      <td>0.058941</td>\n",
       "      <td>3420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4605</th>\n",
       "      <td>0.176428</td>\n",
       "      <td>0.003770</td>\n",
       "      <td>0.007381</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.1</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.887097</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.815463</td>\n",
       "      <td>0.055569</td>\n",
       "      <td>3709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4606</th>\n",
       "      <td>0.171740</td>\n",
       "      <td>0.003450</td>\n",
       "      <td>0.007381</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.1</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.903226</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.812238</td>\n",
       "      <td>0.052148</td>\n",
       "      <td>4000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4607</th>\n",
       "      <td>0.170743</td>\n",
       "      <td>0.002706</td>\n",
       "      <td>0.007680</td>\n",
       "      <td>0.000457</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.1</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.919355</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.821761</td>\n",
       "      <td>0.060591</td>\n",
       "      <td>3170</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4608 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0          0.027726      0.001246         0.007381        0.000662   \n",
       "1          0.027127      0.000977         0.007081        0.000698   \n",
       "2          0.027725      0.000977         0.007582        0.000486   \n",
       "3          0.028225      0.001002         0.007579        0.000661   \n",
       "4          0.041589      0.000779         0.007481        0.000499   \n",
       "...             ...           ...              ...             ...   \n",
       "4603       0.128755      0.000698         0.007581        0.000489   \n",
       "4604       0.181969      0.018973         0.007281        0.000457   \n",
       "4605       0.176428      0.003770         0.007381        0.000489   \n",
       "4606       0.171740      0.003450         0.007381        0.000489   \n",
       "4607       0.170743      0.002706         0.007680        0.000457   \n",
       "\n",
       "      param_colsample_bylevel  param_colsample_bytree  param_gamma  \\\n",
       "0                         0.1                     0.4            0   \n",
       "1                         0.1                     0.4            0   \n",
       "2                         0.1                     0.4            0   \n",
       "3                         0.1                     0.4            0   \n",
       "4                         0.1                     0.4            0   \n",
       "...                       ...                     ...          ...   \n",
       "4603                      0.4                     0.9           10   \n",
       "4604                      0.4                     0.9           10   \n",
       "4605                      0.4                     0.9           10   \n",
       "4606                      0.4                     0.9           10   \n",
       "4607                      0.4                     0.9           10   \n",
       "\n",
       "      param_learning_rate  param_max_depth  param_n_estimators  ...  \\\n",
       "0                     0.1                2                  30  ...   \n",
       "1                     0.1                2                  30  ...   \n",
       "2                     0.1                2                  30  ...   \n",
       "3                     0.1                2                  30  ...   \n",
       "4                     0.1                2                  50  ...   \n",
       "...                   ...              ...                 ...  ...   \n",
       "4603                  0.1                5                 150  ...   \n",
       "4604                  0.1                5                 200  ...   \n",
       "4605                  0.1                5                 200  ...   \n",
       "4606                  0.1                5                 200  ...   \n",
       "4607                  0.1                5                 200  ...   \n",
       "\n",
       "      split3_test_score split4_test_score  split5_test_score  \\\n",
       "0              0.838710          0.790323           0.822581   \n",
       "1              0.838710          0.774194           0.870968   \n",
       "2              0.838710          0.774194           0.870968   \n",
       "3              0.838710          0.790323           0.854839   \n",
       "4              0.870968          0.790323           0.854839   \n",
       "...                 ...               ...                ...   \n",
       "4603           0.838710          0.806452           0.919355   \n",
       "4604           0.870968          0.806452           0.903226   \n",
       "4605           0.870968          0.822581           0.887097   \n",
       "4606           0.838710          0.806452           0.903226   \n",
       "4607           0.838710          0.806452           0.919355   \n",
       "\n",
       "      split6_test_score  split7_test_score  split8_test_score  \\\n",
       "0              0.790323           0.709677           0.709677   \n",
       "1              0.806452           0.725806           0.677419   \n",
       "2              0.806452           0.725806           0.693548   \n",
       "3              0.806452           0.725806           0.693548   \n",
       "4              0.806452           0.758065           0.693548   \n",
       "...                 ...                ...                ...   \n",
       "4603           0.822581           0.806452           0.677419   \n",
       "4604           0.822581           0.822581           0.677419   \n",
       "4605           0.822581           0.822581           0.693548   \n",
       "4606           0.822581           0.806452           0.709677   \n",
       "4607           0.822581           0.806452           0.677419   \n",
       "\n",
       "      split9_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0              0.806452         0.791219        0.043138             4572  \n",
       "1              0.806452         0.797619        0.056310             4538  \n",
       "2              0.806452         0.800819        0.053966             4506  \n",
       "3              0.806452         0.799232        0.049960             4523  \n",
       "4              0.790323         0.812007        0.054003             4127  \n",
       "...                 ...              ...             ...              ...  \n",
       "4603           0.838710         0.818587        0.059897             3439  \n",
       "4604           0.822581         0.818612        0.058941             3420  \n",
       "4605           0.822581         0.815463        0.055569             3709  \n",
       "4606           0.822581         0.812238        0.052148             4000  \n",
       "4607           0.838710         0.821761        0.060591             3170  \n",
       "\n",
       "[4608 rows x 25 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score is 0.8506400409626217 with params {'colsample_bylevel': 0.3, 'colsample_bytree': 0.5, 'gamma': 1, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 100, 'subsample': 0.8}\n"
     ]
    }
   ],
   "source": [
    "df4 = pd.read_csv(\"data\\\\xgb_results_full_4_learning=0.1_20221124.csv\")\n",
    "df4.drop(df4.columns[0], axis=1, inplace=True)\n",
    "display(df4)\n",
    "print(\"best score is 0.8506400409626217 with params {'colsample_bylevel': 0.3, 'colsample_bytree': 0.5, 'gamma': 1, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 100, 'subsample': 0.8}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "81c3993c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_colsample_bylevel</th>\n",
       "      <th>param_colsample_bytree</th>\n",
       "      <th>param_gamma</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>...</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.027726</td>\n",
       "      <td>0.001246</td>\n",
       "      <td>0.007381</td>\n",
       "      <td>0.000662</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.791219</td>\n",
       "      <td>0.043138</td>\n",
       "      <td>4572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.027127</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>0.007081</td>\n",
       "      <td>0.000698</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.797619</td>\n",
       "      <td>0.056310</td>\n",
       "      <td>4538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.027725</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>0.007582</td>\n",
       "      <td>0.000486</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.800819</td>\n",
       "      <td>0.053966</td>\n",
       "      <td>4506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.028225</td>\n",
       "      <td>0.001002</td>\n",
       "      <td>0.007579</td>\n",
       "      <td>0.000661</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.799232</td>\n",
       "      <td>0.049960</td>\n",
       "      <td>4523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.041589</td>\n",
       "      <td>0.000779</td>\n",
       "      <td>0.007481</td>\n",
       "      <td>0.000499</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.812007</td>\n",
       "      <td>0.054003</td>\n",
       "      <td>4127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4603</th>\n",
       "      <td>0.128755</td>\n",
       "      <td>0.000698</td>\n",
       "      <td>0.007581</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.1</td>\n",
       "      <td>5</td>\n",
       "      <td>150</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.919355</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.818587</td>\n",
       "      <td>0.059897</td>\n",
       "      <td>3439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4604</th>\n",
       "      <td>0.181969</td>\n",
       "      <td>0.018973</td>\n",
       "      <td>0.007281</td>\n",
       "      <td>0.000457</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.1</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.903226</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.818612</td>\n",
       "      <td>0.058941</td>\n",
       "      <td>3420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4605</th>\n",
       "      <td>0.176428</td>\n",
       "      <td>0.003770</td>\n",
       "      <td>0.007381</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.1</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.887097</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.815463</td>\n",
       "      <td>0.055569</td>\n",
       "      <td>3709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4606</th>\n",
       "      <td>0.171740</td>\n",
       "      <td>0.003450</td>\n",
       "      <td>0.007381</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.1</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.903226</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.812238</td>\n",
       "      <td>0.052148</td>\n",
       "      <td>4000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4607</th>\n",
       "      <td>0.170743</td>\n",
       "      <td>0.002706</td>\n",
       "      <td>0.007680</td>\n",
       "      <td>0.000457</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.1</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.919355</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.821761</td>\n",
       "      <td>0.060591</td>\n",
       "      <td>3170</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4608 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0          0.027726      0.001246         0.007381        0.000662   \n",
       "1          0.027127      0.000977         0.007081        0.000698   \n",
       "2          0.027725      0.000977         0.007582        0.000486   \n",
       "3          0.028225      0.001002         0.007579        0.000661   \n",
       "4          0.041589      0.000779         0.007481        0.000499   \n",
       "...             ...           ...              ...             ...   \n",
       "4603       0.128755      0.000698         0.007581        0.000489   \n",
       "4604       0.181969      0.018973         0.007281        0.000457   \n",
       "4605       0.176428      0.003770         0.007381        0.000489   \n",
       "4606       0.171740      0.003450         0.007381        0.000489   \n",
       "4607       0.170743      0.002706         0.007680        0.000457   \n",
       "\n",
       "     param_colsample_bylevel param_colsample_bytree param_gamma  \\\n",
       "0                        0.1                    0.4           0   \n",
       "1                        0.1                    0.4           0   \n",
       "2                        0.1                    0.4           0   \n",
       "3                        0.1                    0.4           0   \n",
       "4                        0.1                    0.4           0   \n",
       "...                      ...                    ...         ...   \n",
       "4603                     0.4                    0.9          10   \n",
       "4604                     0.4                    0.9          10   \n",
       "4605                     0.4                    0.9          10   \n",
       "4606                     0.4                    0.9          10   \n",
       "4607                     0.4                    0.9          10   \n",
       "\n",
       "     param_learning_rate param_max_depth param_n_estimators  ...  \\\n",
       "0                    0.1               2                 30  ...   \n",
       "1                    0.1               2                 30  ...   \n",
       "2                    0.1               2                 30  ...   \n",
       "3                    0.1               2                 30  ...   \n",
       "4                    0.1               2                 50  ...   \n",
       "...                  ...             ...                ...  ...   \n",
       "4603                 0.1               5                150  ...   \n",
       "4604                 0.1               5                200  ...   \n",
       "4605                 0.1               5                200  ...   \n",
       "4606                 0.1               5                200  ...   \n",
       "4607                 0.1               5                200  ...   \n",
       "\n",
       "     split3_test_score split4_test_score  split5_test_score  \\\n",
       "0             0.838710          0.790323           0.822581   \n",
       "1             0.838710          0.774194           0.870968   \n",
       "2             0.838710          0.774194           0.870968   \n",
       "3             0.838710          0.790323           0.854839   \n",
       "4             0.870968          0.790323           0.854839   \n",
       "...                ...               ...                ...   \n",
       "4603          0.838710          0.806452           0.919355   \n",
       "4604          0.870968          0.806452           0.903226   \n",
       "4605          0.870968          0.822581           0.887097   \n",
       "4606          0.838710          0.806452           0.903226   \n",
       "4607          0.838710          0.806452           0.919355   \n",
       "\n",
       "      split6_test_score  split7_test_score  split8_test_score  \\\n",
       "0              0.790323           0.709677           0.709677   \n",
       "1              0.806452           0.725806           0.677419   \n",
       "2              0.806452           0.725806           0.693548   \n",
       "3              0.806452           0.725806           0.693548   \n",
       "4              0.806452           0.758065           0.693548   \n",
       "...                 ...                ...                ...   \n",
       "4603           0.822581           0.806452           0.677419   \n",
       "4604           0.822581           0.822581           0.677419   \n",
       "4605           0.822581           0.822581           0.693548   \n",
       "4606           0.822581           0.806452           0.709677   \n",
       "4607           0.822581           0.806452           0.677419   \n",
       "\n",
       "      split9_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0              0.806452         0.791219        0.043138             4572  \n",
       "1              0.806452         0.797619        0.056310             4538  \n",
       "2              0.806452         0.800819        0.053966             4506  \n",
       "3              0.806452         0.799232        0.049960             4523  \n",
       "4              0.790323         0.812007        0.054003             4127  \n",
       "...                 ...              ...             ...              ...  \n",
       "4603           0.838710         0.818587        0.059897             3439  \n",
       "4604           0.822581         0.818612        0.058941             3420  \n",
       "4605           0.822581         0.815463        0.055569             3709  \n",
       "4606           0.822581         0.812238        0.052148             4000  \n",
       "4607           0.838710         0.821761        0.060591             3170  \n",
       "\n",
       "[4608 rows x 25 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score is 0.8506400409626217 with params {'colsample_bylevel': 0.3, 'colsample_bytree': 0.5, 'gamma': 1, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 100, 'subsample': 0.8}\n"
     ]
    }
   ],
   "source": [
    "# Full Tuning - Part 4\n",
    "random.seed(10)\n",
    "\n",
    "xgb = XGBClassifier()\n",
    "\n",
    "xgb_parameters = {'max_depth': [2,3,4,5]\n",
    "                   , 'subsample': [0.6, 0.7, 0.8, 0.9]\n",
    "                   , 'gamma': [0, 1, 10]\n",
    "                   , 'colsample_bytree': [0.4, 0.5, 0.6, 0.9]\n",
    "                   , 'colsample_bylevel': [0.1, 0.2, 0.3, 0.4]\n",
    "                   , 'learning_rate': [0.1]\n",
    "                   , 'n_estimators': [30, 50, 80, 100, 150, 200]}\n",
    "\n",
    "stratified_10_fold_cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "xgb_grid_search = GridSearchCV(xgb, xgb_parameters, scoring='accuracy', cv=stratified_10_fold_cv)\n",
    "\n",
    "xgb_grid_search.fit(X_train, y_train)\n",
    "\n",
    "xgb_grid_search_results_full_4 = pd.DataFrame(xgb_grid_search.cv_results_)\n",
    "display(xgb_grid_search_results_full_4)\n",
    "\n",
    "print(\"best score is {} with params {}\".format(xgb_grid_search.best_score_, xgb_grid_search.best_params_))\n",
    "#best score is 0.8506400409626217 with params\n",
    "#{'colsample_bylevel': 0.3, 'colsample_bytree': 0.5, 'gamma': 1, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 100, 'subsample': 0.8}\n",
    "\n",
    "# save dataframe\n",
    "from datetime import datetime\n",
    "date = str(datetime.now().date()).replace(\"-\", \"\")\n",
    "xgb_grid_search_results_full_4.to_csv(f\"results/xgb_results_full_round3_4_learning=0.1_{date}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "83e43f97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_colsample_bylevel</th>\n",
       "      <th>param_colsample_bytree</th>\n",
       "      <th>param_gamma</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>...</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.028225</td>\n",
       "      <td>0.001002</td>\n",
       "      <td>0.007380</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.15</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.807220</td>\n",
       "      <td>0.059458</td>\n",
       "      <td>4384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.027726</td>\n",
       "      <td>0.000870</td>\n",
       "      <td>0.006783</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.15</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.887097</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.805658</td>\n",
       "      <td>0.060796</td>\n",
       "      <td>4446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.028425</td>\n",
       "      <td>0.001357</td>\n",
       "      <td>0.007184</td>\n",
       "      <td>0.000398</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.15</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.804019</td>\n",
       "      <td>0.053790</td>\n",
       "      <td>4484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.029920</td>\n",
       "      <td>0.001262</td>\n",
       "      <td>0.007680</td>\n",
       "      <td>0.001184</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.15</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.818484</td>\n",
       "      <td>0.052359</td>\n",
       "      <td>3585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.039893</td>\n",
       "      <td>0.001180</td>\n",
       "      <td>0.007580</td>\n",
       "      <td>0.000662</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.15</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.820097</td>\n",
       "      <td>0.044768</td>\n",
       "      <td>3445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4603</th>\n",
       "      <td>0.129254</td>\n",
       "      <td>0.001017</td>\n",
       "      <td>0.007382</td>\n",
       "      <td>0.000488</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.15</td>\n",
       "      <td>5</td>\n",
       "      <td>150</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.903226</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.812212</td>\n",
       "      <td>0.054700</td>\n",
       "      <td>4012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4604</th>\n",
       "      <td>0.171740</td>\n",
       "      <td>0.001657</td>\n",
       "      <td>0.007480</td>\n",
       "      <td>0.000499</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.15</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.813722</td>\n",
       "      <td>0.052700</td>\n",
       "      <td>3948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4605</th>\n",
       "      <td>0.170244</td>\n",
       "      <td>0.001342</td>\n",
       "      <td>0.007780</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.15</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.820123</td>\n",
       "      <td>0.057714</td>\n",
       "      <td>3430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4606</th>\n",
       "      <td>0.170145</td>\n",
       "      <td>0.001795</td>\n",
       "      <td>0.007281</td>\n",
       "      <td>0.000457</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.15</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.903226</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.817025</td>\n",
       "      <td>0.051360</td>\n",
       "      <td>3604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4607</th>\n",
       "      <td>0.170145</td>\n",
       "      <td>0.002410</td>\n",
       "      <td>0.007580</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.15</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.903226</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.812212</td>\n",
       "      <td>0.054700</td>\n",
       "      <td>4012</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4608 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0          0.028225      0.001002         0.007380        0.000489   \n",
       "1          0.027726      0.000870         0.006783        0.000977   \n",
       "2          0.028425      0.001357         0.007184        0.000398   \n",
       "3          0.029920      0.001262         0.007680        0.001184   \n",
       "4          0.039893      0.001180         0.007580        0.000662   \n",
       "...             ...           ...              ...             ...   \n",
       "4603       0.129254      0.001017         0.007382        0.000488   \n",
       "4604       0.171740      0.001657         0.007480        0.000499   \n",
       "4605       0.170244      0.001342         0.007780        0.000399   \n",
       "4606       0.170145      0.001795         0.007281        0.000457   \n",
       "4607       0.170145      0.002410         0.007580        0.000489   \n",
       "\n",
       "      param_colsample_bylevel  param_colsample_bytree  param_gamma  \\\n",
       "0                         0.1                     0.4            0   \n",
       "1                         0.1                     0.4            0   \n",
       "2                         0.1                     0.4            0   \n",
       "3                         0.1                     0.4            0   \n",
       "4                         0.1                     0.4            0   \n",
       "...                       ...                     ...          ...   \n",
       "4603                      0.4                     0.9           10   \n",
       "4604                      0.4                     0.9           10   \n",
       "4605                      0.4                     0.9           10   \n",
       "4606                      0.4                     0.9           10   \n",
       "4607                      0.4                     0.9           10   \n",
       "\n",
       "      param_learning_rate  param_max_depth  param_n_estimators  ...  \\\n",
       "0                    0.15                2                  30  ...   \n",
       "1                    0.15                2                  30  ...   \n",
       "2                    0.15                2                  30  ...   \n",
       "3                    0.15                2                  30  ...   \n",
       "4                    0.15                2                  50  ...   \n",
       "...                   ...              ...                 ...  ...   \n",
       "4603                 0.15                5                 150  ...   \n",
       "4604                 0.15                5                 200  ...   \n",
       "4605                 0.15                5                 200  ...   \n",
       "4606                 0.15                5                 200  ...   \n",
       "4607                 0.15                5                 200  ...   \n",
       "\n",
       "      split3_test_score split4_test_score  split5_test_score  \\\n",
       "0              0.870968          0.790323           0.870968   \n",
       "1              0.854839          0.806452           0.887097   \n",
       "2              0.838710          0.790323           0.854839   \n",
       "3              0.870968          0.806452           0.870968   \n",
       "4              0.870968          0.790323           0.854839   \n",
       "...                 ...               ...                ...   \n",
       "4603           0.838710          0.806452           0.903226   \n",
       "4604           0.838710          0.822581           0.854839   \n",
       "4605           0.870968          0.806452           0.870968   \n",
       "4606           0.838710          0.806452           0.903226   \n",
       "4607           0.838710          0.806452           0.903226   \n",
       "\n",
       "      split6_test_score  split7_test_score  split8_test_score  \\\n",
       "0              0.822581           0.709677           0.693548   \n",
       "1              0.822581           0.725806           0.677419   \n",
       "2              0.838710           0.725806           0.693548   \n",
       "3              0.822581           0.725806           0.725806   \n",
       "4              0.838710           0.758065           0.725806   \n",
       "...                 ...                ...                ...   \n",
       "4603           0.822581           0.806452           0.693548   \n",
       "4604           0.806452           0.806452           0.677419   \n",
       "4605           0.822581           0.806452           0.677419   \n",
       "4606           0.822581           0.806452           0.709677   \n",
       "4607           0.822581           0.806452           0.693548   \n",
       "\n",
       "      split9_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0              0.790323         0.807220        0.059458             4384  \n",
       "1              0.790323         0.805658        0.060796             4446  \n",
       "2              0.790323         0.804019        0.053790             4484  \n",
       "3              0.822581         0.818484        0.052359             3585  \n",
       "4              0.822581         0.820097        0.044768             3445  \n",
       "...                 ...              ...             ...              ...  \n",
       "4603           0.822581         0.812212        0.054700             4012  \n",
       "4604           0.838710         0.813722        0.052700             3948  \n",
       "4605           0.822581         0.820123        0.057714             3430  \n",
       "4606           0.838710         0.817025        0.051360             3604  \n",
       "4607           0.822581         0.812212        0.054700             4012  \n",
       "\n",
       "[4608 rows x 25 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score is 0.856989247311828 with params {'colsample_bylevel': 0.4, 'colsample_bytree': 0.4, 'gamma': 1, 'learning_rate': 0.15, 'max_depth': 4, 'n_estimators': 30, 'subsample': 0.9}\n"
     ]
    }
   ],
   "source": [
    "df5 = pd.read_csv(\"data\\\\xgb_results_full_5_learning=0.15_20221124.csv\")\n",
    "df5.drop(df5.columns[0], axis=1, inplace=True)\n",
    "display(df5)\n",
    "print(\"best score is 0.856989247311828 with params {'colsample_bylevel': 0.4, 'colsample_bytree': 0.4, 'gamma': 1, 'learning_rate': 0.15, 'max_depth': 4, 'n_estimators': 30, 'subsample': 0.9}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8e53020f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_colsample_bylevel</th>\n",
       "      <th>param_colsample_bytree</th>\n",
       "      <th>param_gamma</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>...</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.028225</td>\n",
       "      <td>0.001002</td>\n",
       "      <td>0.007380</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.15</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.807220</td>\n",
       "      <td>0.059458</td>\n",
       "      <td>4384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.027726</td>\n",
       "      <td>0.000870</td>\n",
       "      <td>0.006783</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.15</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.887097</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.805658</td>\n",
       "      <td>0.060796</td>\n",
       "      <td>4446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.028425</td>\n",
       "      <td>0.001357</td>\n",
       "      <td>0.007184</td>\n",
       "      <td>0.000398</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.15</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.804019</td>\n",
       "      <td>0.053790</td>\n",
       "      <td>4484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.029920</td>\n",
       "      <td>0.001262</td>\n",
       "      <td>0.007680</td>\n",
       "      <td>0.001184</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.15</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.818484</td>\n",
       "      <td>0.052359</td>\n",
       "      <td>3585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.039893</td>\n",
       "      <td>0.001180</td>\n",
       "      <td>0.007580</td>\n",
       "      <td>0.000662</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.15</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.820097</td>\n",
       "      <td>0.044768</td>\n",
       "      <td>3445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4603</th>\n",
       "      <td>0.129254</td>\n",
       "      <td>0.001017</td>\n",
       "      <td>0.007382</td>\n",
       "      <td>0.000488</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.15</td>\n",
       "      <td>5</td>\n",
       "      <td>150</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.903226</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.812212</td>\n",
       "      <td>0.054700</td>\n",
       "      <td>4012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4604</th>\n",
       "      <td>0.171740</td>\n",
       "      <td>0.001657</td>\n",
       "      <td>0.007480</td>\n",
       "      <td>0.000499</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.15</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.813722</td>\n",
       "      <td>0.052700</td>\n",
       "      <td>3948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4605</th>\n",
       "      <td>0.170244</td>\n",
       "      <td>0.001342</td>\n",
       "      <td>0.007780</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.15</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.820123</td>\n",
       "      <td>0.057714</td>\n",
       "      <td>3430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4606</th>\n",
       "      <td>0.170145</td>\n",
       "      <td>0.001795</td>\n",
       "      <td>0.007281</td>\n",
       "      <td>0.000457</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.15</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.903226</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.817025</td>\n",
       "      <td>0.051360</td>\n",
       "      <td>3604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4607</th>\n",
       "      <td>0.170145</td>\n",
       "      <td>0.002410</td>\n",
       "      <td>0.007580</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.15</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.903226</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.812212</td>\n",
       "      <td>0.054700</td>\n",
       "      <td>4012</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4608 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0          0.028225      0.001002         0.007380        0.000489   \n",
       "1          0.027726      0.000870         0.006783        0.000977   \n",
       "2          0.028425      0.001357         0.007184        0.000398   \n",
       "3          0.029920      0.001262         0.007680        0.001184   \n",
       "4          0.039893      0.001180         0.007580        0.000662   \n",
       "...             ...           ...              ...             ...   \n",
       "4603       0.129254      0.001017         0.007382        0.000488   \n",
       "4604       0.171740      0.001657         0.007480        0.000499   \n",
       "4605       0.170244      0.001342         0.007780        0.000399   \n",
       "4606       0.170145      0.001795         0.007281        0.000457   \n",
       "4607       0.170145      0.002410         0.007580        0.000489   \n",
       "\n",
       "     param_colsample_bylevel param_colsample_bytree param_gamma  \\\n",
       "0                        0.1                    0.4           0   \n",
       "1                        0.1                    0.4           0   \n",
       "2                        0.1                    0.4           0   \n",
       "3                        0.1                    0.4           0   \n",
       "4                        0.1                    0.4           0   \n",
       "...                      ...                    ...         ...   \n",
       "4603                     0.4                    0.9          10   \n",
       "4604                     0.4                    0.9          10   \n",
       "4605                     0.4                    0.9          10   \n",
       "4606                     0.4                    0.9          10   \n",
       "4607                     0.4                    0.9          10   \n",
       "\n",
       "     param_learning_rate param_max_depth param_n_estimators  ...  \\\n",
       "0                   0.15               2                 30  ...   \n",
       "1                   0.15               2                 30  ...   \n",
       "2                   0.15               2                 30  ...   \n",
       "3                   0.15               2                 30  ...   \n",
       "4                   0.15               2                 50  ...   \n",
       "...                  ...             ...                ...  ...   \n",
       "4603                0.15               5                150  ...   \n",
       "4604                0.15               5                200  ...   \n",
       "4605                0.15               5                200  ...   \n",
       "4606                0.15               5                200  ...   \n",
       "4607                0.15               5                200  ...   \n",
       "\n",
       "     split3_test_score split4_test_score  split5_test_score  \\\n",
       "0             0.870968          0.790323           0.870968   \n",
       "1             0.854839          0.806452           0.887097   \n",
       "2             0.838710          0.790323           0.854839   \n",
       "3             0.870968          0.806452           0.870968   \n",
       "4             0.870968          0.790323           0.854839   \n",
       "...                ...               ...                ...   \n",
       "4603          0.838710          0.806452           0.903226   \n",
       "4604          0.838710          0.822581           0.854839   \n",
       "4605          0.870968          0.806452           0.870968   \n",
       "4606          0.838710          0.806452           0.903226   \n",
       "4607          0.838710          0.806452           0.903226   \n",
       "\n",
       "      split6_test_score  split7_test_score  split8_test_score  \\\n",
       "0              0.822581           0.709677           0.693548   \n",
       "1              0.822581           0.725806           0.677419   \n",
       "2              0.838710           0.725806           0.693548   \n",
       "3              0.822581           0.725806           0.725806   \n",
       "4              0.838710           0.758065           0.725806   \n",
       "...                 ...                ...                ...   \n",
       "4603           0.822581           0.806452           0.693548   \n",
       "4604           0.806452           0.806452           0.677419   \n",
       "4605           0.822581           0.806452           0.677419   \n",
       "4606           0.822581           0.806452           0.709677   \n",
       "4607           0.822581           0.806452           0.693548   \n",
       "\n",
       "      split9_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0              0.790323         0.807220        0.059458             4384  \n",
       "1              0.790323         0.805658        0.060796             4446  \n",
       "2              0.790323         0.804019        0.053790             4484  \n",
       "3              0.822581         0.818484        0.052359             3585  \n",
       "4              0.822581         0.820097        0.044768             3445  \n",
       "...                 ...              ...             ...              ...  \n",
       "4603           0.822581         0.812212        0.054700             4012  \n",
       "4604           0.838710         0.813722        0.052700             3948  \n",
       "4605           0.822581         0.820123        0.057714             3430  \n",
       "4606           0.838710         0.817025        0.051360             3604  \n",
       "4607           0.822581         0.812212        0.054700             4012  \n",
       "\n",
       "[4608 rows x 25 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score is 0.856989247311828 with params {'colsample_bylevel': 0.4, 'colsample_bytree': 0.4, 'gamma': 1, 'learning_rate': 0.15, 'max_depth': 4, 'n_estimators': 30, 'subsample': 0.9}\n"
     ]
    }
   ],
   "source": [
    "# Full Tuning - Part 5\n",
    "random.seed(10)\n",
    "\n",
    "xgb = XGBClassifier()\n",
    "\n",
    "xgb_parameters = {'max_depth': [2,3,4,5]\n",
    "                   , 'subsample': [0.6, 0.7, 0.8, 0.9]\n",
    "                   , 'gamma': [0, 1, 10]\n",
    "                   , 'colsample_bytree': [0.4, 0.5, 0.6, 0.9]\n",
    "                   , 'colsample_bylevel': [0.1, 0.2, 0.3, 0.4]\n",
    "                   , 'learning_rate': [0.15]\n",
    "                   , 'n_estimators': [30, 50, 80, 100, 150, 200]}\n",
    "\n",
    "stratified_10_fold_cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "xgb_grid_search = GridSearchCV(xgb, xgb_parameters, scoring='accuracy', cv=stratified_10_fold_cv)\n",
    "\n",
    "xgb_grid_search.fit(X_train, y_train)\n",
    "\n",
    "xgb_grid_search_results_full_5 = pd.DataFrame(xgb_grid_search.cv_results_)\n",
    "display(xgb_grid_search_results_full_5)\n",
    "\n",
    "print(\"best score is {} with params {}\".format(xgb_grid_search.best_score_, xgb_grid_search.best_params_))\n",
    "#best score is 0.856989247311828 with params\n",
    "#{'colsample_bylevel': 0.4, 'colsample_bytree': 0.4, 'gamma': 1, 'learning_rate': 0.15, 'max_depth': 4, 'n_estimators': 30, 'subsample': 0.9}\n",
    "\n",
    "# save dataframe\n",
    "from datetime import datetime\n",
    "date = str(datetime.now().date()).replace(\"-\", \"\")\n",
    "xgb_grid_search_results_full_5.to_csv(f\"results/xgb_results_full_round3_5_learning=0.15_{date}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "addcfcca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_colsample_bylevel</th>\n",
       "      <th>param_colsample_bytree</th>\n",
       "      <th>param_gamma</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>...</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.028224</td>\n",
       "      <td>0.000897</td>\n",
       "      <td>0.007381</td>\n",
       "      <td>0.000488</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.821582</td>\n",
       "      <td>0.063111</td>\n",
       "      <td>3320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.027226</td>\n",
       "      <td>0.000639</td>\n",
       "      <td>0.006683</td>\n",
       "      <td>0.000897</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>0.887097</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.887097</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.829647</td>\n",
       "      <td>0.062955</td>\n",
       "      <td>2389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.029321</td>\n",
       "      <td>0.001353</td>\n",
       "      <td>0.007580</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.887097</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.816846</td>\n",
       "      <td>0.062937</td>\n",
       "      <td>3729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.028125</td>\n",
       "      <td>0.001657</td>\n",
       "      <td>0.007281</td>\n",
       "      <td>0.000457</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>0.887097</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.829647</td>\n",
       "      <td>0.060854</td>\n",
       "      <td>2389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.039993</td>\n",
       "      <td>0.001133</td>\n",
       "      <td>0.007181</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.887097</td>\n",
       "      <td>0.821710</td>\n",
       "      <td>0.053554</td>\n",
       "      <td>3262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4603</th>\n",
       "      <td>0.129354</td>\n",
       "      <td>0.001184</td>\n",
       "      <td>0.007281</td>\n",
       "      <td>0.000457</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5</td>\n",
       "      <td>150</td>\n",
       "      <td>...</td>\n",
       "      <td>0.887097</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.919355</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.826600</td>\n",
       "      <td>0.059814</td>\n",
       "      <td>2710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4604</th>\n",
       "      <td>0.168948</td>\n",
       "      <td>0.001739</td>\n",
       "      <td>0.007581</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.919355</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.828187</td>\n",
       "      <td>0.060472</td>\n",
       "      <td>2464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4605</th>\n",
       "      <td>0.170344</td>\n",
       "      <td>0.002515</td>\n",
       "      <td>0.007481</td>\n",
       "      <td>0.000498</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.887097</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.824936</td>\n",
       "      <td>0.057195</td>\n",
       "      <td>2943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4606</th>\n",
       "      <td>0.169896</td>\n",
       "      <td>0.002405</td>\n",
       "      <td>0.007281</td>\n",
       "      <td>0.000457</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.824910</td>\n",
       "      <td>0.045101</td>\n",
       "      <td>2951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4607</th>\n",
       "      <td>0.169047</td>\n",
       "      <td>0.001201</td>\n",
       "      <td>0.007281</td>\n",
       "      <td>0.000457</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.887097</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.919355</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.826600</td>\n",
       "      <td>0.059814</td>\n",
       "      <td>2710</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4608 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0          0.028224      0.000897         0.007381        0.000488   \n",
       "1          0.027226      0.000639         0.006683        0.000897   \n",
       "2          0.029321      0.001353         0.007580        0.000489   \n",
       "3          0.028125      0.001657         0.007281        0.000457   \n",
       "4          0.039993      0.001133         0.007181        0.000399   \n",
       "...             ...           ...              ...             ...   \n",
       "4603       0.129354      0.001184         0.007281        0.000457   \n",
       "4604       0.168948      0.001739         0.007581        0.000489   \n",
       "4605       0.170344      0.002515         0.007481        0.000498   \n",
       "4606       0.169896      0.002405         0.007281        0.000457   \n",
       "4607       0.169047      0.001201         0.007281        0.000457   \n",
       "\n",
       "      param_colsample_bylevel  param_colsample_bytree  param_gamma  \\\n",
       "0                         0.1                     0.4            0   \n",
       "1                         0.1                     0.4            0   \n",
       "2                         0.1                     0.4            0   \n",
       "3                         0.1                     0.4            0   \n",
       "4                         0.1                     0.4            0   \n",
       "...                       ...                     ...          ...   \n",
       "4603                      0.4                     0.9           10   \n",
       "4604                      0.4                     0.9           10   \n",
       "4605                      0.4                     0.9           10   \n",
       "4606                      0.4                     0.9           10   \n",
       "4607                      0.4                     0.9           10   \n",
       "\n",
       "      param_learning_rate  param_max_depth  param_n_estimators  ...  \\\n",
       "0                     0.2                2                  30  ...   \n",
       "1                     0.2                2                  30  ...   \n",
       "2                     0.2                2                  30  ...   \n",
       "3                     0.2                2                  30  ...   \n",
       "4                     0.2                2                  50  ...   \n",
       "...                   ...              ...                 ...  ...   \n",
       "4603                  0.2                5                 150  ...   \n",
       "4604                  0.2                5                 200  ...   \n",
       "4605                  0.2                5                 200  ...   \n",
       "4606                  0.2                5                 200  ...   \n",
       "4607                  0.2                5                 200  ...   \n",
       "\n",
       "      split3_test_score split4_test_score  split5_test_score  \\\n",
       "0              0.870968          0.790323           0.854839   \n",
       "1              0.887097          0.806452           0.887097   \n",
       "2              0.870968          0.806452           0.887097   \n",
       "3              0.887097          0.790323           0.870968   \n",
       "4              0.854839          0.790323           0.854839   \n",
       "...                 ...               ...                ...   \n",
       "4603           0.887097          0.806452           0.919355   \n",
       "4604           0.919355          0.838710           0.870968   \n",
       "4605           0.870968          0.806452           0.887097   \n",
       "4606           0.870968          0.806452           0.854839   \n",
       "4607           0.887097          0.806452           0.919355   \n",
       "\n",
       "      split6_test_score  split7_test_score  split8_test_score  \\\n",
       "0              0.838710           0.725806           0.693548   \n",
       "1              0.822581           0.741935           0.693548   \n",
       "2              0.822581           0.725806           0.677419   \n",
       "3              0.822581           0.758065           0.693548   \n",
       "4              0.838710           0.741935           0.709677   \n",
       "...                 ...                ...                ...   \n",
       "4603           0.822581           0.806452           0.693548   \n",
       "4604           0.806452           0.806452           0.677419   \n",
       "4605           0.806452           0.822581           0.677419   \n",
       "4606           0.822581           0.806452           0.709677   \n",
       "4607           0.822581           0.806452           0.693548   \n",
       "\n",
       "      split9_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0              0.822581         0.821582        0.063111             3320  \n",
       "1              0.838710         0.829647        0.062955             2389  \n",
       "2              0.822581         0.816846        0.062937             3729  \n",
       "3              0.854839         0.829647        0.060854             2389  \n",
       "4              0.887097         0.821710        0.053554             3262  \n",
       "...                 ...              ...             ...              ...  \n",
       "4603           0.822581         0.826600        0.059814             2710  \n",
       "4604           0.838710         0.828187        0.060472             2464  \n",
       "4605           0.838710         0.824936        0.057195             2943  \n",
       "4606           0.822581         0.824910        0.045101             2951  \n",
       "4607           0.822581         0.826600        0.059814             2710  \n",
       "\n",
       "[4608 rows x 25 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score is 0.8522017409114184 with params {'colsample_bylevel': 0.2, 'colsample_bytree': 0.9, 'gamma': 1, 'learning_rate': 0.2, 'max_depth': 3, 'n_estimators': 30, 'subsample': 0.6}\n"
     ]
    }
   ],
   "source": [
    "df6 = pd.read_csv(\"data\\\\xgb_results_full_6_learning=0.2_20221124.csv\")\n",
    "df6.drop(df6.columns[0], axis=1, inplace=True)\n",
    "display(df6)\n",
    "print(\"best score is 0.8522017409114184 with params {'colsample_bylevel': 0.2, 'colsample_bytree': 0.9, 'gamma': 1, 'learning_rate': 0.2, 'max_depth': 3, 'n_estimators': 30, 'subsample': 0.6}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "de9ada4d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_colsample_bylevel</th>\n",
       "      <th>param_colsample_bytree</th>\n",
       "      <th>param_gamma</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>...</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.028224</td>\n",
       "      <td>0.000897</td>\n",
       "      <td>0.007381</td>\n",
       "      <td>0.000488</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.821582</td>\n",
       "      <td>0.063111</td>\n",
       "      <td>3320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.027226</td>\n",
       "      <td>0.000639</td>\n",
       "      <td>0.006683</td>\n",
       "      <td>0.000897</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>0.887097</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.887097</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.829647</td>\n",
       "      <td>0.062955</td>\n",
       "      <td>2389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.029321</td>\n",
       "      <td>0.001353</td>\n",
       "      <td>0.007580</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.887097</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.816846</td>\n",
       "      <td>0.062937</td>\n",
       "      <td>3729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.028125</td>\n",
       "      <td>0.001657</td>\n",
       "      <td>0.007281</td>\n",
       "      <td>0.000457</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>0.887097</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.829647</td>\n",
       "      <td>0.060854</td>\n",
       "      <td>2389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.039993</td>\n",
       "      <td>0.001133</td>\n",
       "      <td>0.007181</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.887097</td>\n",
       "      <td>0.821710</td>\n",
       "      <td>0.053554</td>\n",
       "      <td>3262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4603</th>\n",
       "      <td>0.129354</td>\n",
       "      <td>0.001184</td>\n",
       "      <td>0.007281</td>\n",
       "      <td>0.000457</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5</td>\n",
       "      <td>150</td>\n",
       "      <td>...</td>\n",
       "      <td>0.887097</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.919355</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.826600</td>\n",
       "      <td>0.059814</td>\n",
       "      <td>2710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4604</th>\n",
       "      <td>0.168948</td>\n",
       "      <td>0.001739</td>\n",
       "      <td>0.007581</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.919355</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.828187</td>\n",
       "      <td>0.060472</td>\n",
       "      <td>2464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4605</th>\n",
       "      <td>0.170344</td>\n",
       "      <td>0.002515</td>\n",
       "      <td>0.007481</td>\n",
       "      <td>0.000498</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.887097</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.824936</td>\n",
       "      <td>0.057195</td>\n",
       "      <td>2943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4606</th>\n",
       "      <td>0.169896</td>\n",
       "      <td>0.002405</td>\n",
       "      <td>0.007281</td>\n",
       "      <td>0.000457</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.824910</td>\n",
       "      <td>0.045101</td>\n",
       "      <td>2951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4607</th>\n",
       "      <td>0.169047</td>\n",
       "      <td>0.001201</td>\n",
       "      <td>0.007281</td>\n",
       "      <td>0.000457</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.2</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.887097</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.919355</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.826600</td>\n",
       "      <td>0.059814</td>\n",
       "      <td>2710</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4608 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0          0.028224      0.000897         0.007381        0.000488   \n",
       "1          0.027226      0.000639         0.006683        0.000897   \n",
       "2          0.029321      0.001353         0.007580        0.000489   \n",
       "3          0.028125      0.001657         0.007281        0.000457   \n",
       "4          0.039993      0.001133         0.007181        0.000399   \n",
       "...             ...           ...              ...             ...   \n",
       "4603       0.129354      0.001184         0.007281        0.000457   \n",
       "4604       0.168948      0.001739         0.007581        0.000489   \n",
       "4605       0.170344      0.002515         0.007481        0.000498   \n",
       "4606       0.169896      0.002405         0.007281        0.000457   \n",
       "4607       0.169047      0.001201         0.007281        0.000457   \n",
       "\n",
       "     param_colsample_bylevel param_colsample_bytree param_gamma  \\\n",
       "0                        0.1                    0.4           0   \n",
       "1                        0.1                    0.4           0   \n",
       "2                        0.1                    0.4           0   \n",
       "3                        0.1                    0.4           0   \n",
       "4                        0.1                    0.4           0   \n",
       "...                      ...                    ...         ...   \n",
       "4603                     0.4                    0.9          10   \n",
       "4604                     0.4                    0.9          10   \n",
       "4605                     0.4                    0.9          10   \n",
       "4606                     0.4                    0.9          10   \n",
       "4607                     0.4                    0.9          10   \n",
       "\n",
       "     param_learning_rate param_max_depth param_n_estimators  ...  \\\n",
       "0                    0.2               2                 30  ...   \n",
       "1                    0.2               2                 30  ...   \n",
       "2                    0.2               2                 30  ...   \n",
       "3                    0.2               2                 30  ...   \n",
       "4                    0.2               2                 50  ...   \n",
       "...                  ...             ...                ...  ...   \n",
       "4603                 0.2               5                150  ...   \n",
       "4604                 0.2               5                200  ...   \n",
       "4605                 0.2               5                200  ...   \n",
       "4606                 0.2               5                200  ...   \n",
       "4607                 0.2               5                200  ...   \n",
       "\n",
       "     split3_test_score split4_test_score  split5_test_score  \\\n",
       "0             0.870968          0.790323           0.854839   \n",
       "1             0.887097          0.806452           0.887097   \n",
       "2             0.870968          0.806452           0.887097   \n",
       "3             0.887097          0.790323           0.870968   \n",
       "4             0.854839          0.790323           0.854839   \n",
       "...                ...               ...                ...   \n",
       "4603          0.887097          0.806452           0.919355   \n",
       "4604          0.919355          0.838710           0.870968   \n",
       "4605          0.870968          0.806452           0.887097   \n",
       "4606          0.870968          0.806452           0.854839   \n",
       "4607          0.887097          0.806452           0.919355   \n",
       "\n",
       "      split6_test_score  split7_test_score  split8_test_score  \\\n",
       "0              0.838710           0.725806           0.693548   \n",
       "1              0.822581           0.741935           0.693548   \n",
       "2              0.822581           0.725806           0.677419   \n",
       "3              0.822581           0.758065           0.693548   \n",
       "4              0.838710           0.741935           0.709677   \n",
       "...                 ...                ...                ...   \n",
       "4603           0.822581           0.806452           0.693548   \n",
       "4604           0.806452           0.806452           0.677419   \n",
       "4605           0.806452           0.822581           0.677419   \n",
       "4606           0.822581           0.806452           0.709677   \n",
       "4607           0.822581           0.806452           0.693548   \n",
       "\n",
       "      split9_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0              0.822581         0.821582        0.063111             3320  \n",
       "1              0.838710         0.829647        0.062955             2389  \n",
       "2              0.822581         0.816846        0.062937             3729  \n",
       "3              0.854839         0.829647        0.060854             2389  \n",
       "4              0.887097         0.821710        0.053554             3262  \n",
       "...                 ...              ...             ...              ...  \n",
       "4603           0.822581         0.826600        0.059814             2710  \n",
       "4604           0.838710         0.828187        0.060472             2464  \n",
       "4605           0.838710         0.824936        0.057195             2943  \n",
       "4606           0.822581         0.824910        0.045101             2951  \n",
       "4607           0.822581         0.826600        0.059814             2710  \n",
       "\n",
       "[4608 rows x 25 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score is 0.8522017409114184 with params {'colsample_bylevel': 0.2, 'colsample_bytree': 0.9, 'gamma': 1, 'learning_rate': 0.2, 'max_depth': 3, 'n_estimators': 30, 'subsample': 0.6}\n"
     ]
    }
   ],
   "source": [
    "# Full Tuning - Part 6\n",
    "random.seed(10)\n",
    "\n",
    "xgb = XGBClassifier()\n",
    "\n",
    "xgb_parameters = {'max_depth': [2,3,4,5]\n",
    "                   , 'subsample': [0.6, 0.7, 0.8, 0.9]\n",
    "                   , 'gamma': [0, 1, 10]\n",
    "                   , 'colsample_bytree': [0.4, 0.5, 0.6, 0.9]\n",
    "                   , 'colsample_bylevel': [0.1, 0.2, 0.3, 0.4]\n",
    "                   , 'learning_rate': [0.2]\n",
    "                   , 'n_estimators': [30, 50, 80, 100, 150, 200]}\n",
    "\n",
    "stratified_10_fold_cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "xgb_grid_search = GridSearchCV(xgb, xgb_parameters, scoring='accuracy', cv=stratified_10_fold_cv)\n",
    "\n",
    "xgb_grid_search.fit(X_train, y_train)\n",
    "\n",
    "xgb_grid_search_results_full_6 = pd.DataFrame(xgb_grid_search.cv_results_)\n",
    "display(xgb_grid_search_results_full_6)\n",
    "\n",
    "print(\"best score is {} with params {}\".format(xgb_grid_search.best_score_, xgb_grid_search.best_params_))\n",
    "#best score is 0.8522017409114184 with params\n",
    "#{'colsample_bylevel': 0.2, 'colsample_bytree': 0.9, 'gamma': 1, 'learning_rate': 0.2, 'max_depth': 3, 'n_estimators': 30, 'subsample': 0.6}\n",
    "\n",
    "# save dataframe\n",
    "from datetime import datetime\n",
    "date = str(datetime.now().date()).replace(\"-\", \"\")\n",
    "xgb_grid_search_results_full_6.to_csv(f\"results/xgb_results_full_round3_6_learning=0.2_{date}.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b07bc15",
   "metadata": {},
   "source": [
    "Combine single hyper parameter tuning to find best values for hyper parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "aab3352c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_colsample_bylevel</th>\n",
       "      <th>param_colsample_bytree</th>\n",
       "      <th>param_gamma</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>...</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.028623</td>\n",
       "      <td>0.002525</td>\n",
       "      <td>0.007181</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.741295</td>\n",
       "      <td>0.048078</td>\n",
       "      <td>27618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.027127</td>\n",
       "      <td>0.000598</td>\n",
       "      <td>0.007082</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.742908</td>\n",
       "      <td>0.049390</td>\n",
       "      <td>27616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.027028</td>\n",
       "      <td>0.000698</td>\n",
       "      <td>0.007580</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.752586</td>\n",
       "      <td>0.048690</td>\n",
       "      <td>27568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.027427</td>\n",
       "      <td>0.000920</td>\n",
       "      <td>0.007381</td>\n",
       "      <td>0.000662</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.742960</td>\n",
       "      <td>0.043040</td>\n",
       "      <td>27614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.040093</td>\n",
       "      <td>0.001465</td>\n",
       "      <td>0.007082</td>\n",
       "      <td>0.000536</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>...</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.765463</td>\n",
       "      <td>0.037846</td>\n",
       "      <td>27462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27643</th>\n",
       "      <td>0.129354</td>\n",
       "      <td>0.001184</td>\n",
       "      <td>0.007281</td>\n",
       "      <td>0.000457</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.20</td>\n",
       "      <td>5</td>\n",
       "      <td>150</td>\n",
       "      <td>...</td>\n",
       "      <td>0.887097</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.919355</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.826600</td>\n",
       "      <td>0.059814</td>\n",
       "      <td>14497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27644</th>\n",
       "      <td>0.168948</td>\n",
       "      <td>0.001739</td>\n",
       "      <td>0.007581</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.20</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.919355</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.828187</td>\n",
       "      <td>0.060472</td>\n",
       "      <td>13496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27645</th>\n",
       "      <td>0.170344</td>\n",
       "      <td>0.002515</td>\n",
       "      <td>0.007481</td>\n",
       "      <td>0.000498</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.20</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.887097</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.824936</td>\n",
       "      <td>0.057195</td>\n",
       "      <td>15641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27646</th>\n",
       "      <td>0.169896</td>\n",
       "      <td>0.002405</td>\n",
       "      <td>0.007281</td>\n",
       "      <td>0.000457</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.20</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.824910</td>\n",
       "      <td>0.045101</td>\n",
       "      <td>15655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27647</th>\n",
       "      <td>0.169047</td>\n",
       "      <td>0.001201</td>\n",
       "      <td>0.007281</td>\n",
       "      <td>0.000457</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10</td>\n",
       "      <td>0.20</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.887097</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.919355</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.826600</td>\n",
       "      <td>0.059814</td>\n",
       "      <td>14482</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27648 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0           0.028623      0.002525         0.007181        0.000399   \n",
       "1           0.027127      0.000598         0.007082        0.000300   \n",
       "2           0.027028      0.000698         0.007580        0.000489   \n",
       "3           0.027427      0.000920         0.007381        0.000662   \n",
       "4           0.040093      0.001465         0.007082        0.000536   \n",
       "...              ...           ...              ...             ...   \n",
       "27643       0.129354      0.001184         0.007281        0.000457   \n",
       "27644       0.168948      0.001739         0.007581        0.000489   \n",
       "27645       0.170344      0.002515         0.007481        0.000498   \n",
       "27646       0.169896      0.002405         0.007281        0.000457   \n",
       "27647       0.169047      0.001201         0.007281        0.000457   \n",
       "\n",
       "       param_colsample_bylevel  param_colsample_bytree  param_gamma  \\\n",
       "0                          0.1                     0.4            0   \n",
       "1                          0.1                     0.4            0   \n",
       "2                          0.1                     0.4            0   \n",
       "3                          0.1                     0.4            0   \n",
       "4                          0.1                     0.4            0   \n",
       "...                        ...                     ...          ...   \n",
       "27643                      0.4                     0.9           10   \n",
       "27644                      0.4                     0.9           10   \n",
       "27645                      0.4                     0.9           10   \n",
       "27646                      0.4                     0.9           10   \n",
       "27647                      0.4                     0.9           10   \n",
       "\n",
       "       param_learning_rate  param_max_depth  param_n_estimators  ...  \\\n",
       "0                     0.01                2                  30  ...   \n",
       "1                     0.01                2                  30  ...   \n",
       "2                     0.01                2                  30  ...   \n",
       "3                     0.01                2                  30  ...   \n",
       "4                     0.01                2                  50  ...   \n",
       "...                    ...              ...                 ...  ...   \n",
       "27643                 0.20                5                 150  ...   \n",
       "27644                 0.20                5                 200  ...   \n",
       "27645                 0.20                5                 200  ...   \n",
       "27646                 0.20                5                 200  ...   \n",
       "27647                 0.20                5                 200  ...   \n",
       "\n",
       "       split3_test_score split4_test_score  split5_test_score  \\\n",
       "0               0.758065          0.741935           0.741935   \n",
       "1               0.774194          0.741935           0.741935   \n",
       "2               0.774194          0.758065           0.774194   \n",
       "3               0.790323          0.725806           0.709677   \n",
       "4               0.790323          0.774194           0.774194   \n",
       "...                  ...               ...                ...   \n",
       "27643           0.887097          0.806452           0.919355   \n",
       "27644           0.919355          0.838710           0.870968   \n",
       "27645           0.870968          0.806452           0.887097   \n",
       "27646           0.870968          0.806452           0.854839   \n",
       "27647           0.887097          0.806452           0.919355   \n",
       "\n",
       "       split6_test_score  split7_test_score  split8_test_score  \\\n",
       "0               0.725806           0.677419           0.693548   \n",
       "1               0.725806           0.677419           0.677419   \n",
       "2               0.741935           0.693548           0.677419   \n",
       "3               0.741935           0.709677           0.709677   \n",
       "4               0.725806           0.693548           0.725806   \n",
       "...                  ...                ...                ...   \n",
       "27643           0.822581           0.806452           0.693548   \n",
       "27644           0.806452           0.806452           0.677419   \n",
       "27645           0.806452           0.822581           0.677419   \n",
       "27646           0.822581           0.806452           0.709677   \n",
       "27647           0.822581           0.806452           0.693548   \n",
       "\n",
       "       split9_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0               0.677419         0.741295        0.048078            27618  \n",
       "1               0.693548         0.742908        0.049390            27616  \n",
       "2               0.709677         0.752586        0.048690            27568  \n",
       "3               0.677419         0.742960        0.043040            27614  \n",
       "4               0.758065         0.765463        0.037846            27462  \n",
       "...                  ...              ...             ...              ...  \n",
       "27643           0.822581         0.826600        0.059814            14497  \n",
       "27644           0.838710         0.828187        0.060472            13496  \n",
       "27645           0.838710         0.824936        0.057195            15641  \n",
       "27646           0.822581         0.824910        0.045101            15655  \n",
       "27647           0.822581         0.826600        0.059814            14482  \n",
       "\n",
       "[27648 rows x 25 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score is 0.850563 with params {'colsample_bylevel': 0.4, 'colsample_bytree': 0.4, 'gamma': 1, 'learning_rate': 0.15, 'max_depth': 4, 'n_estimators': 30, 'subsample': 0.9}\n"
     ]
    }
   ],
   "source": [
    "# read single parts of round 3, concatenate and update index and rank_test_score\n",
    "\n",
    "df1 = pd.read_csv(\"data\\\\xgb_results_full_1_learning=0.01_20221124.csv\")\n",
    "df1.drop(df1.columns[0], axis=1, inplace=True)\n",
    "\n",
    "df2 = pd.read_csv(\"data\\\\xgb_results_full_2_learning=0.05_20221124.csv\")\n",
    "df2.drop(df2.columns[0], axis=1, inplace=True)\n",
    "\n",
    "df3 = pd.read_csv(\"data\\\\xgb_results_full_3_learning=0.08_20221124.csv\")\n",
    "df3.drop(df3.columns[0], axis=1, inplace=True)\n",
    "\n",
    "df4 = pd.read_csv(\"data\\\\xgb_results_full_4_learning=0.1_20221124.csv\")\n",
    "df4.drop(df4.columns[0], axis=1, inplace=True)\n",
    "\n",
    "df5 = pd.read_csv(\"data\\\\xgb_results_full_5_learning=0.15_20221124.csv\")\n",
    "df5.drop(df5.columns[0], axis=1, inplace=True)\n",
    "\n",
    "df6 = pd.read_csv(\"data\\\\xgb_results_full_6_learning=0.2_20221124.csv\")\n",
    "df6.drop(df6.columns[0], axis=1, inplace=True)\n",
    "\n",
    "df_full = pd.concat([df1,df2,df3,df4,df5,df6])\n",
    "\n",
    "#assign correct rank\n",
    "df_full = df_full.sort_values(by='mean_test_score', ascending=False)\n",
    "df_full['rank_test_score'] = range(1, len(df_full)+1)\n",
    "\n",
    "#get correct order and set new index\n",
    "df_full = df_full.sort_values(by=['param_colsample_bylevel', 'param_colsample_bytree', 'param_gamma', 'param_learning_rate', 'param_max_depth', 'param_n_estimators', 'param_subsample'])\n",
    "xgb_grid_search_results_round3 = df_full.set_index(np.array(range(len(df_full))))\n",
    "display(xgb_grid_search_results_round3)\n",
    "\n",
    "print(\"best score is 0.850563 with params {'colsample_bylevel': 0.4, 'colsample_bytree': 0.4, 'gamma': 1, 'learning_rate': 0.15, 'max_depth': 4, 'n_estimators': 30, 'subsample': 0.9}\")\n",
    "\n",
    "# save dataframe\n",
    "from datetime import datetime\n",
    "date = str(datetime.now().date()).replace(\"-\", \"\")\n",
    "xgb_grid_search_results_round3.to_csv(f\"results/xgb_results_round3_{date}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ffd07def",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_subsample</th>\n",
       "      <th>param_colsample_bylevel</th>\n",
       "      <th>param_colsample_bytree</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_gamma</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21747</th>\n",
       "      <td>4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.15</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>0.856989</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13080</th>\n",
       "      <td>3</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.15</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>0.852227</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13176</th>\n",
       "      <td>3</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.20</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>0.852202</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21720</th>\n",
       "      <td>3</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.15</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>0.852202</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23470</th>\n",
       "      <td>3</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.15</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>0.852151</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6340</th>\n",
       "      <td>2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.01</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>0.718920</td>\n",
       "      <td>27644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6339</th>\n",
       "      <td>2</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.01</td>\n",
       "      <td>30</td>\n",
       "      <td>10</td>\n",
       "      <td>0.709217</td>\n",
       "      <td>27645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6338</th>\n",
       "      <td>2</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.01</td>\n",
       "      <td>30</td>\n",
       "      <td>10</td>\n",
       "      <td>0.705991</td>\n",
       "      <td>27646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6336</th>\n",
       "      <td>2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.01</td>\n",
       "      <td>30</td>\n",
       "      <td>10</td>\n",
       "      <td>0.704403</td>\n",
       "      <td>27647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6337</th>\n",
       "      <td>2</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.01</td>\n",
       "      <td>30</td>\n",
       "      <td>10</td>\n",
       "      <td>0.702765</td>\n",
       "      <td>27648</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27648 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       param_max_depth  param_subsample  param_colsample_bylevel  \\\n",
       "21747                4              0.9                      0.4   \n",
       "13080                3              0.6                      0.2   \n",
       "13176                3              0.6                      0.2   \n",
       "21720                3              0.6                      0.4   \n",
       "23470                3              0.8                      0.4   \n",
       "...                ...              ...                      ...   \n",
       "6340                 2              0.6                      0.1   \n",
       "6339                 2              0.9                      0.1   \n",
       "6338                 2              0.8                      0.1   \n",
       "6336                 2              0.6                      0.1   \n",
       "6337                 2              0.7                      0.1   \n",
       "\n",
       "       param_colsample_bytree  param_learning_rate  param_n_estimators  \\\n",
       "21747                     0.4                 0.15                  30   \n",
       "13080                     0.9                 0.15                  30   \n",
       "13176                     0.9                 0.20                  30   \n",
       "21720                     0.4                 0.15                  30   \n",
       "23470                     0.5                 0.15                 200   \n",
       "...                       ...                  ...                 ...   \n",
       "6340                      0.9                 0.01                  50   \n",
       "6339                      0.9                 0.01                  30   \n",
       "6338                      0.9                 0.01                  30   \n",
       "6336                      0.9                 0.01                  30   \n",
       "6337                      0.9                 0.01                  30   \n",
       "\n",
       "       param_gamma  mean_test_score  rank_test_score  \n",
       "21747            1         0.856989                1  \n",
       "13080            1         0.852227                2  \n",
       "13176            1         0.852202                3  \n",
       "21720            1         0.852202                4  \n",
       "23470            1         0.852151                5  \n",
       "...            ...              ...              ...  \n",
       "6340            10         0.718920            27644  \n",
       "6339            10         0.709217            27645  \n",
       "6338            10         0.705991            27646  \n",
       "6336            10         0.704403            27647  \n",
       "6337            10         0.702765            27648  \n",
       "\n",
       "[27648 rows x 9 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# store relevant columns and sort by rank_test_score\n",
    "cols_round3 = ['param_max_depth', 'param_subsample', 'param_colsample_bylevel', 'param_colsample_bytree', 'param_learning_rate', 'param_n_estimators', 'param_gamma', 'mean_test_score', 'rank_test_score']\n",
    "xgb_results_round3_sorted = xgb_grid_search_results_round3[cols_round3]\n",
    "xgb_results_round3_sorted = xgb_results_round3_sorted.sort_values(by='rank_test_score')\n",
    "display(xgb_results_round3_sorted)\n",
    "\n",
    "# save dataframe\n",
    "from datetime import datetime\n",
    "date = str(datetime.now().date()).replace(\"-\", \"\")\n",
    "xgb_results_round3_sorted.to_csv(f\"results/xgb_results_round3_sorted_{date}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ff9a854a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.8283582089552238\n",
      "F1 Score = 0.7788461538461539\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.90      0.86       157\n",
      "           1       0.84      0.73      0.78       111\n",
      "\n",
      "    accuracy                           0.83       268\n",
      "   macro avg       0.83      0.81      0.82       268\n",
      "weighted avg       0.83      0.83      0.83       268\n",
      "\n",
      "Confusion Matrix:\n",
      "[[141  16]\n",
      " [ 30  81]]\n"
     ]
    }
   ],
   "source": [
    "# Fit and evaluate best model\n",
    "\n",
    "xgb_best = XGBClassifier(max_depth = 4, subsample = 0.9, colsample_bylevel = 0.4, colsample_bytree = 0.4, learning_rate = 0.15, n_estimators = 30, gamma = 1)\n",
    "xgb_best.fit(X_train, y_train)\n",
    "xgb_best_pred = xgb_best.predict(X_test)\n",
    "\n",
    "xgb_best_acc = accuracy_score(y_test, xgb_best_pred)\n",
    "print(\"Accuracy =\", xgb_best_acc) #0.8283582089552238\n",
    "\n",
    "xgb_best_f1 = f1_score(y_test, xgb_best_pred)\n",
    "print(\"F1 Score =\", xgb_best_f1) #0.7788461538461539\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, xgb_best_pred))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, xgb_best_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "077c8219",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.8395522388059702\n",
      "F1 Score = 0.7922705314009663\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.91      0.87       157\n",
      "           1       0.85      0.74      0.79       111\n",
      "\n",
      "    accuracy                           0.84       268\n",
      "   macro avg       0.84      0.82      0.83       268\n",
      "weighted avg       0.84      0.84      0.84       268\n",
      "\n",
      "Confusion Matrix:\n",
      "[[143  14]\n",
      " [ 29  82]]\n"
     ]
    }
   ],
   "source": [
    "# Fit and evaluate second best model with n_estimators=20\n",
    "\n",
    "xgb_best = XGBClassifier(max_depth = 3, subsample = 0.6, colsample_bylevel = 0.2, colsample_bytree = 0.9, learning_rate = 0.15, n_estimators = 20, gamma = 1)\n",
    "xgb_best.fit(X_train, y_train)\n",
    "xgb_best_pred = xgb_best.predict(X_test)\n",
    "\n",
    "xgb_best_acc = accuracy_score(y_test, xgb_best_pred)\n",
    "print(\"Accuracy =\", xgb_best_acc) #0.8395522388059702\n",
    "\n",
    "xgb_best_f1 = f1_score(y_test, xgb_best_pred)\n",
    "print(\"F1 Score =\", xgb_best_f1) #0.7922705314009663\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, xgb_best_pred))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, xgb_best_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4514dfe0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d157f690",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ccfb2ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b4d25208",
   "metadata": {},
   "source": [
    "#### Fourth Attempt\n",
    "We perform a third hyper parameter tuning, adjusting the parameter grid according to the results of round 3. We use the following parameters and values:  \n",
    "\n",
    "{'max_depth': [2,3,4]  \n",
    ", 'subsample': [0.6, 0.8, 0.9]  \n",
    ", 'gamma': [0, 0.5, 1]  \n",
    ", 'colsample_bytree': [0.4, 0.5, 0.9]  \n",
    ", 'colsample_bylevel': [0.2, 0.3, 0.4]  \n",
    ", 'learning_rate': [0.05 0.1, 0.15, 0.2]  \n",
    ", 'n_estimators': [10, 20, 30, 40, 50]}\n",
    "\n",
    "The best hyper parameter setting results to be xxx which leads to an accuracy of xxx% and a f1 score of xxx% on the test data (after training the classifier on the whole train data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "46b05a84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_colsample_bylevel</th>\n",
       "      <th>param_colsample_bytree</th>\n",
       "      <th>param_gamma</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>...</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.021696</td>\n",
       "      <td>0.004852</td>\n",
       "      <td>0.009495</td>\n",
       "      <td>0.002555</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.661290</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.661290</td>\n",
       "      <td>0.661290</td>\n",
       "      <td>0.661290</td>\n",
       "      <td>0.720430</td>\n",
       "      <td>0.052226</td>\n",
       "      <td>4858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.023734</td>\n",
       "      <td>0.003344</td>\n",
       "      <td>0.010269</td>\n",
       "      <td>0.002012</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.661290</td>\n",
       "      <td>0.629032</td>\n",
       "      <td>0.661290</td>\n",
       "      <td>0.720405</td>\n",
       "      <td>0.060569</td>\n",
       "      <td>4860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.021329</td>\n",
       "      <td>0.002649</td>\n",
       "      <td>0.009234</td>\n",
       "      <td>0.001687</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.645161</td>\n",
       "      <td>0.645161</td>\n",
       "      <td>0.661290</td>\n",
       "      <td>0.723630</td>\n",
       "      <td>0.057244</td>\n",
       "      <td>4855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.031445</td>\n",
       "      <td>0.001912</td>\n",
       "      <td>0.009800</td>\n",
       "      <td>0.001109</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>...</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.760599</td>\n",
       "      <td>0.045057</td>\n",
       "      <td>4835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.034447</td>\n",
       "      <td>0.002939</td>\n",
       "      <td>0.010506</td>\n",
       "      <td>0.001006</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>...</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.760625</td>\n",
       "      <td>0.047805</td>\n",
       "      <td>4834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4855</th>\n",
       "      <td>0.039993</td>\n",
       "      <td>0.000829</td>\n",
       "      <td>0.007979</td>\n",
       "      <td>0.000446</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.20</td>\n",
       "      <td>4</td>\n",
       "      <td>40</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.887097</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.850589</td>\n",
       "      <td>0.041824</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4856</th>\n",
       "      <td>0.057798</td>\n",
       "      <td>0.044078</td>\n",
       "      <td>0.008179</td>\n",
       "      <td>0.002352</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.20</td>\n",
       "      <td>4</td>\n",
       "      <td>40</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.823349</td>\n",
       "      <td>0.036404</td>\n",
       "      <td>3249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4857</th>\n",
       "      <td>0.065325</td>\n",
       "      <td>0.017959</td>\n",
       "      <td>0.008279</td>\n",
       "      <td>0.000779</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.20</td>\n",
       "      <td>4</td>\n",
       "      <td>50</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.834434</td>\n",
       "      <td>0.055885</td>\n",
       "      <td>1740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4858</th>\n",
       "      <td>0.067819</td>\n",
       "      <td>0.006180</td>\n",
       "      <td>0.008378</td>\n",
       "      <td>0.001196</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.20</td>\n",
       "      <td>4</td>\n",
       "      <td>50</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.837737</td>\n",
       "      <td>0.042732</td>\n",
       "      <td>1033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4859</th>\n",
       "      <td>0.055651</td>\n",
       "      <td>0.002176</td>\n",
       "      <td>0.007880</td>\n",
       "      <td>0.001042</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.20</td>\n",
       "      <td>4</td>\n",
       "      <td>50</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.828111</td>\n",
       "      <td>0.042532</td>\n",
       "      <td>2692</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4860 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0          0.021696      0.004852         0.009495        0.002555   \n",
       "1          0.023734      0.003344         0.010269        0.002012   \n",
       "2          0.021329      0.002649         0.009234        0.001687   \n",
       "3          0.031445      0.001912         0.009800        0.001109   \n",
       "4          0.034447      0.002939         0.010506        0.001006   \n",
       "...             ...           ...              ...             ...   \n",
       "4855       0.039993      0.000829         0.007979        0.000446   \n",
       "4856       0.057798      0.044078         0.008179        0.002352   \n",
       "4857       0.065325      0.017959         0.008279        0.000779   \n",
       "4858       0.067819      0.006180         0.008378        0.001196   \n",
       "4859       0.055651      0.002176         0.007880        0.001042   \n",
       "\n",
       "      param_colsample_bylevel  param_colsample_bytree  param_gamma  \\\n",
       "0                         0.2                     0.4          0.0   \n",
       "1                         0.2                     0.4          0.0   \n",
       "2                         0.2                     0.4          0.0   \n",
       "3                         0.2                     0.4          0.0   \n",
       "4                         0.2                     0.4          0.0   \n",
       "...                       ...                     ...          ...   \n",
       "4855                      0.4                     0.9          1.0   \n",
       "4856                      0.4                     0.9          1.0   \n",
       "4857                      0.4                     0.9          1.0   \n",
       "4858                      0.4                     0.9          1.0   \n",
       "4859                      0.4                     0.9          1.0   \n",
       "\n",
       "      param_learning_rate  param_max_depth  param_n_estimators  ...  \\\n",
       "0                    0.05                2                  10  ...   \n",
       "1                    0.05                2                  10  ...   \n",
       "2                    0.05                2                  10  ...   \n",
       "3                    0.05                2                  20  ...   \n",
       "4                    0.05                2                  20  ...   \n",
       "...                   ...              ...                 ...  ...   \n",
       "4855                 0.20                4                  40  ...   \n",
       "4856                 0.20                4                  40  ...   \n",
       "4857                 0.20                4                  50  ...   \n",
       "4858                 0.20                4                  50  ...   \n",
       "4859                 0.20                4                  50  ...   \n",
       "\n",
       "      split3_test_score split4_test_score  split5_test_score  \\\n",
       "0              0.741935          0.661290           0.758065   \n",
       "1              0.774194          0.677419           0.758065   \n",
       "2              0.741935          0.709677           0.774194   \n",
       "3              0.774194          0.741935           0.790323   \n",
       "4              0.806452          0.725806           0.790323   \n",
       "...                 ...               ...                ...   \n",
       "4855           0.870968          0.822581           0.854839   \n",
       "4856           0.854839          0.822581           0.806452   \n",
       "4857           0.838710          0.822581           0.790323   \n",
       "4858           0.838710          0.822581           0.822581   \n",
       "4859           0.870968          0.822581           0.790323   \n",
       "\n",
       "      split6_test_score  split7_test_score  split8_test_score  \\\n",
       "0              0.725806           0.661290           0.661290   \n",
       "1              0.693548           0.661290           0.629032   \n",
       "2              0.709677           0.645161           0.645161   \n",
       "3              0.758065           0.693548           0.709677   \n",
       "4              0.774194           0.693548           0.693548   \n",
       "...                 ...                ...                ...   \n",
       "4855           0.887097           0.838710           0.741935   \n",
       "4856           0.854839           0.822581           0.725806   \n",
       "4857           0.854839           0.838710           0.693548   \n",
       "4858           0.870968           0.838710           0.725806   \n",
       "4859           0.854839           0.806452           0.725806   \n",
       "\n",
       "      split9_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0              0.661290         0.720430        0.052226             4858  \n",
       "1              0.661290         0.720405        0.060569             4860  \n",
       "2              0.661290         0.723630        0.057244             4855  \n",
       "3              0.709677         0.760599        0.045057             4835  \n",
       "4              0.709677         0.760625        0.047805             4834  \n",
       "...                 ...              ...             ...              ...  \n",
       "4855           0.854839         0.850589        0.041824               18  \n",
       "4856           0.822581         0.823349        0.036404             3249  \n",
       "4857           0.854839         0.834434        0.055885             1740  \n",
       "4858           0.854839         0.837737        0.042732             1033  \n",
       "4859           0.838710         0.828111        0.042532             2692  \n",
       "\n",
       "[4860 rows x 25 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score is 0.856989 with params {'colsample_bylevel': 0.4, 'colsample_bytree': 0.4, 'gamma': 1, 'learning_rate': 0.15, 'max_depth': 4, 'n_estimators': 30, 'subsample': 0.9}\n"
     ]
    }
   ],
   "source": [
    "# read single parts of round 3, concatenate and update index and rank_test_score\n",
    "\n",
    "df2 = pd.read_csv(\"data\\\\xgb_results_full_2_learning=0.05_r3_20221124.csv\")\n",
    "df2.drop(df2.columns[0], axis=1, inplace=True)\n",
    "\n",
    "df4 = pd.read_csv(\"data\\\\xgb_results_full_4_learning=0.1_r3_20221124.csv\")\n",
    "df4.drop(df4.columns[0], axis=1, inplace=True)\n",
    "\n",
    "df5 = pd.read_csv(\"data\\\\xgb_results_full_5_learning=0.15_r3_20221124.csv\")\n",
    "df5.drop(df5.columns[0], axis=1, inplace=True)\n",
    "\n",
    "df6 = pd.read_csv(\"data\\\\xgb_results_full_6_learning=0.2_r3_20221124.csv\")\n",
    "df6.drop(df6.columns[0], axis=1, inplace=True)\n",
    "\n",
    "df_full = pd.concat([df2,df4,df5,df6])\n",
    "\n",
    "#assign correct rank\n",
    "df_full = df_full.sort_values(by='mean_test_score', ascending=False)\n",
    "df_full['rank_test_score'] = range(1, len(df_full)+1)\n",
    "\n",
    "#get correct order and set new index\n",
    "df_full = df_full.sort_values(by=['param_colsample_bylevel', 'param_colsample_bytree', 'param_gamma', 'param_learning_rate', 'param_max_depth', 'param_n_estimators', 'param_subsample'])\n",
    "xgb_grid_search_results_round4 = df_full.set_index(np.array(range(len(df_full))))\n",
    "display(xgb_grid_search_results_round4)\n",
    "\n",
    "print(\"best score is 0.856989 with params {'colsample_bylevel': 0.4, 'colsample_bytree': 0.4, 'gamma': 1, 'learning_rate': 0.15, 'max_depth': 4, 'n_estimators': 30, 'subsample': 0.9}\")\n",
    "\n",
    "# save dataframe\n",
    "from datetime import datetime\n",
    "date = str(datetime.now().date()).replace(\"-\", \"\")\n",
    "xgb_grid_search_results_round4.to_csv(f\"results/xgb_results_round4_{date}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "db0eebb7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "expression expected after dictionary key and ':' (2098851133.py, line 12)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn [54], line 12\u001b[1;36m\u001b[0m\n\u001b[1;33m    , 'learning_rate': [0.05 0.1, 0.15, 0.2]\u001b[0m\n\u001b[1;37m                     ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m expression expected after dictionary key and ':'\n"
     ]
    }
   ],
   "source": [
    "# Third Attempt\n",
    "\n",
    "random.seed(10)\n",
    "\n",
    "xgb = XGBClassifier()\n",
    "\n",
    "xgb_parameters = {'max_depth': [2,3,4]\n",
    "                   , 'subsample': [0.6, 0.8, 0.9]\n",
    "                   , 'gamma': [0, 0.5, 1]\n",
    "                   , 'colsample_bytree': [0.4, 0.5, 0.9]\n",
    "                   , 'colsample_bylevel': [0.2, 0.3, 0.4]\n",
    "                   , 'learning_rate': [0.05, 0.1, 0.15, 0.2]\n",
    "                   , 'n_estimators': [10, 20, 30, 40, 50]}\n",
    "\n",
    "stratified_10_fold_cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "xgb_grid_search = GridSearchCV(xgb, xgb_parameters, scoring='accuracy', cv=stratified_10_fold_cv)\n",
    "\n",
    "xgb_grid_search.fit(X_train, y_train)\n",
    "\n",
    "xgb_grid_search_results_round4 = pd.DataFrame(xgb_grid_search.cv_results_)\n",
    "display(xgb_grid_search_results_round4)\n",
    "\n",
    "# print the best parameter setting\n",
    "print(\"best score is {} with params {}\".format(xgb_grid_search.best_score_, xgb_grid_search.best_params_))\n",
    "#best score is 0.856989 with params {'colsample_bylevel': 0.4, 'colsample_bytree': 0.4, 'gamma': 1, 'learning_rate': 0.15, 'max_depth': 4, 'n_estimators': 30, 'subsample': 0.9}\n",
    "\n",
    "# save dataframe\n",
    "from datetime import datetime\n",
    "date = str(datetime.now().date()).replace(\"-\", \"\")\n",
    "xgb_grid_search_results_round4.to_csv(f\"results/xgb_results_round4_{date}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ecd39336",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_subsample</th>\n",
       "      <th>param_colsample_bylevel</th>\n",
       "      <th>param_colsample_bytree</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_gamma</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3728</th>\n",
       "      <td>4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.15</td>\n",
       "      <td>30</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.856989</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3714</th>\n",
       "      <td>3</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.15</td>\n",
       "      <td>40</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.853840</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1401</th>\n",
       "      <td>2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.20</td>\n",
       "      <td>30</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.852253</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1551</th>\n",
       "      <td>3</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.15</td>\n",
       "      <td>30</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.852227</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1596</th>\n",
       "      <td>3</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.20</td>\n",
       "      <td>30</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.852202</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.05</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.722043</td>\n",
       "      <td>4856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.05</td>\n",
       "      <td>10</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.720430</td>\n",
       "      <td>4857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.05</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.720430</td>\n",
       "      <td>4858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>2</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.05</td>\n",
       "      <td>10</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.720405</td>\n",
       "      <td>4859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.05</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.720405</td>\n",
       "      <td>4860</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4860 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      param_max_depth  param_subsample  param_colsample_bylevel  \\\n",
       "3728                4              0.9                      0.4   \n",
       "3714                3              0.6                      0.4   \n",
       "1401                2              0.6                      0.2   \n",
       "1551                3              0.6                      0.2   \n",
       "1596                3              0.6                      0.2   \n",
       "...               ...              ...                      ...   \n",
       "360                 2              0.6                      0.2   \n",
       "180                 2              0.6                      0.2   \n",
       "0                   2              0.6                      0.2   \n",
       "181                 2              0.8                      0.2   \n",
       "1                   2              0.8                      0.2   \n",
       "\n",
       "      param_colsample_bytree  param_learning_rate  param_n_estimators  \\\n",
       "3728                     0.4                 0.15                  30   \n",
       "3714                     0.4                 0.15                  40   \n",
       "1401                     0.9                 0.20                  30   \n",
       "1551                     0.9                 0.15                  30   \n",
       "1596                     0.9                 0.20                  30   \n",
       "...                      ...                  ...                 ...   \n",
       "360                      0.4                 0.05                  10   \n",
       "180                      0.4                 0.05                  10   \n",
       "0                        0.4                 0.05                  10   \n",
       "181                      0.4                 0.05                  10   \n",
       "1                        0.4                 0.05                  10   \n",
       "\n",
       "      param_gamma  mean_test_score  rank_test_score  \n",
       "3728          1.0         0.856989                1  \n",
       "3714          1.0         0.853840                2  \n",
       "1401          0.5         0.852253                3  \n",
       "1551          1.0         0.852227                4  \n",
       "1596          1.0         0.852202                5  \n",
       "...           ...              ...              ...  \n",
       "360           1.0         0.722043             4856  \n",
       "180           0.5         0.720430             4857  \n",
       "0             0.0         0.720430             4858  \n",
       "181           0.5         0.720405             4859  \n",
       "1             0.0         0.720405             4860  \n",
       "\n",
       "[4860 rows x 9 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# store relevant columns and sort by rank_test_score\n",
    "cols_round4 = ['param_max_depth', 'param_subsample', 'param_colsample_bylevel', 'param_colsample_bytree', 'param_learning_rate', 'param_n_estimators', 'param_gamma', 'mean_test_score', 'rank_test_score']\n",
    "xgb_results_round4_sorted = xgb_grid_search_results_round4[cols_round4]\n",
    "xgb_results_round4_sorted = xgb_results_round4_sorted.sort_values(by='rank_test_score')\n",
    "display(xgb_results_round4_sorted)\n",
    "\n",
    "# save dataframe\n",
    "from datetime import datetime\n",
    "date = str(datetime.now().date()).replace(\"-\", \"\")\n",
    "xgb_results_round4_sorted.to_csv(f\"results/xgb_results_round4_sorted_{date}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4deb5e3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.8283582089552238\n",
      "F1 Score = 0.7788461538461539\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.90      0.86       157\n",
      "           1       0.84      0.73      0.78       111\n",
      "\n",
      "    accuracy                           0.83       268\n",
      "   macro avg       0.83      0.81      0.82       268\n",
      "weighted avg       0.83      0.83      0.83       268\n",
      "\n",
      "Confusion Matrix:\n",
      "[[141  16]\n",
      " [ 30  81]]\n"
     ]
    }
   ],
   "source": [
    "# Fit and evaluate best model\n",
    "\n",
    "xgb_best = XGBClassifier(max_depth = 4, subsample = 0.9, colsample_bylevel = 0.4, colsample_bytree = 0.4, learning_rate = 0.15, n_estimators = 30, gamma = 1)\n",
    "xgb_best.fit(X_train, y_train)\n",
    "xgb_best_pred = xgb_best.predict(X_test)\n",
    "\n",
    "xgb_best_acc = accuracy_score(y_test, xgb_best_pred)\n",
    "print(\"Accuracy =\", xgb_best_acc) #0.8283582089552238\n",
    "\n",
    "xgb_best_f1 = f1_score(y_test, xgb_best_pred)\n",
    "print(\"F1 Score =\", xgb_best_f1) #0.7788461538461539\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, xgb_best_pred))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, xgb_best_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a1510f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc5a5c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "41362cd1",
   "metadata": {},
   "source": [
    "#### ausführlich"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "74ca2db4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_colsample_bylevel</th>\n",
       "      <th>param_colsample_bytree</th>\n",
       "      <th>param_gamma</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>...</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.021696</td>\n",
       "      <td>0.004852</td>\n",
       "      <td>0.009495</td>\n",
       "      <td>0.002555</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.661290</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.661290</td>\n",
       "      <td>0.661290</td>\n",
       "      <td>0.661290</td>\n",
       "      <td>0.720430</td>\n",
       "      <td>0.052226</td>\n",
       "      <td>1212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.023734</td>\n",
       "      <td>0.003344</td>\n",
       "      <td>0.010269</td>\n",
       "      <td>0.002012</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.661290</td>\n",
       "      <td>0.629032</td>\n",
       "      <td>0.661290</td>\n",
       "      <td>0.720405</td>\n",
       "      <td>0.060569</td>\n",
       "      <td>1214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.021329</td>\n",
       "      <td>0.002649</td>\n",
       "      <td>0.009234</td>\n",
       "      <td>0.001687</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.645161</td>\n",
       "      <td>0.645161</td>\n",
       "      <td>0.661290</td>\n",
       "      <td>0.723630</td>\n",
       "      <td>0.057244</td>\n",
       "      <td>1208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.031445</td>\n",
       "      <td>0.001912</td>\n",
       "      <td>0.009800</td>\n",
       "      <td>0.001109</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>...</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.760599</td>\n",
       "      <td>0.045057</td>\n",
       "      <td>1204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.034447</td>\n",
       "      <td>0.002939</td>\n",
       "      <td>0.010506</td>\n",
       "      <td>0.001006</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>...</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.760625</td>\n",
       "      <td>0.047805</td>\n",
       "      <td>1203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1210</th>\n",
       "      <td>0.064949</td>\n",
       "      <td>0.005643</td>\n",
       "      <td>0.010790</td>\n",
       "      <td>0.002114</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>4</td>\n",
       "      <td>40</td>\n",
       "      <td>...</td>\n",
       "      <td>0.903226</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.829647</td>\n",
       "      <td>0.056432</td>\n",
       "      <td>337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1211</th>\n",
       "      <td>0.059376</td>\n",
       "      <td>0.006451</td>\n",
       "      <td>0.009179</td>\n",
       "      <td>0.002418</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>4</td>\n",
       "      <td>40</td>\n",
       "      <td>...</td>\n",
       "      <td>0.887097</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.824936</td>\n",
       "      <td>0.053006</td>\n",
       "      <td>496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1212</th>\n",
       "      <td>0.072250</td>\n",
       "      <td>0.006942</td>\n",
       "      <td>0.010528</td>\n",
       "      <td>0.001857</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>4</td>\n",
       "      <td>50</td>\n",
       "      <td>...</td>\n",
       "      <td>0.887097</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.834511</td>\n",
       "      <td>0.054857</td>\n",
       "      <td>156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1213</th>\n",
       "      <td>0.075180</td>\n",
       "      <td>0.004525</td>\n",
       "      <td>0.011624</td>\n",
       "      <td>0.001827</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>4</td>\n",
       "      <td>50</td>\n",
       "      <td>...</td>\n",
       "      <td>0.903226</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.837686</td>\n",
       "      <td>0.053661</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1214</th>\n",
       "      <td>0.071844</td>\n",
       "      <td>0.005366</td>\n",
       "      <td>0.010349</td>\n",
       "      <td>0.001572</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>4</td>\n",
       "      <td>50</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.821633</td>\n",
       "      <td>0.045313</td>\n",
       "      <td>643</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1215 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0          0.021696      0.004852         0.009495        0.002555   \n",
       "1          0.023734      0.003344         0.010269        0.002012   \n",
       "2          0.021329      0.002649         0.009234        0.001687   \n",
       "3          0.031445      0.001912         0.009800        0.001109   \n",
       "4          0.034447      0.002939         0.010506        0.001006   \n",
       "...             ...           ...              ...             ...   \n",
       "1210       0.064949      0.005643         0.010790        0.002114   \n",
       "1211       0.059376      0.006451         0.009179        0.002418   \n",
       "1212       0.072250      0.006942         0.010528        0.001857   \n",
       "1213       0.075180      0.004525         0.011624        0.001827   \n",
       "1214       0.071844      0.005366         0.010349        0.001572   \n",
       "\n",
       "      param_colsample_bylevel  param_colsample_bytree  param_gamma  \\\n",
       "0                         0.2                     0.4          0.0   \n",
       "1                         0.2                     0.4          0.0   \n",
       "2                         0.2                     0.4          0.0   \n",
       "3                         0.2                     0.4          0.0   \n",
       "4                         0.2                     0.4          0.0   \n",
       "...                       ...                     ...          ...   \n",
       "1210                      0.4                     0.9          1.0   \n",
       "1211                      0.4                     0.9          1.0   \n",
       "1212                      0.4                     0.9          1.0   \n",
       "1213                      0.4                     0.9          1.0   \n",
       "1214                      0.4                     0.9          1.0   \n",
       "\n",
       "      param_learning_rate  param_max_depth  param_n_estimators  ...  \\\n",
       "0                    0.05                2                  10  ...   \n",
       "1                    0.05                2                  10  ...   \n",
       "2                    0.05                2                  10  ...   \n",
       "3                    0.05                2                  20  ...   \n",
       "4                    0.05                2                  20  ...   \n",
       "...                   ...              ...                 ...  ...   \n",
       "1210                 0.05                4                  40  ...   \n",
       "1211                 0.05                4                  40  ...   \n",
       "1212                 0.05                4                  50  ...   \n",
       "1213                 0.05                4                  50  ...   \n",
       "1214                 0.05                4                  50  ...   \n",
       "\n",
       "      split3_test_score split4_test_score  split5_test_score  \\\n",
       "0              0.741935          0.661290           0.758065   \n",
       "1              0.774194          0.677419           0.758065   \n",
       "2              0.741935          0.709677           0.774194   \n",
       "3              0.774194          0.741935           0.790323   \n",
       "4              0.806452          0.725806           0.790323   \n",
       "...                 ...               ...                ...   \n",
       "1210           0.903226          0.806452           0.822581   \n",
       "1211           0.887097          0.822581           0.870968   \n",
       "1212           0.887097          0.822581           0.870968   \n",
       "1213           0.903226          0.822581           0.838710   \n",
       "1214           0.838710          0.822581           0.822581   \n",
       "\n",
       "      split6_test_score  split7_test_score  split8_test_score  \\\n",
       "0              0.725806           0.661290           0.661290   \n",
       "1              0.693548           0.661290           0.629032   \n",
       "2              0.709677           0.645161           0.645161   \n",
       "3              0.758065           0.693548           0.709677   \n",
       "4              0.774194           0.693548           0.693548   \n",
       "...                 ...                ...                ...   \n",
       "1210           0.822581           0.790323           0.693548   \n",
       "1211           0.822581           0.774194           0.693548   \n",
       "1212           0.822581           0.790323           0.693548   \n",
       "1213           0.822581           0.790323           0.709677   \n",
       "1214           0.822581           0.774194           0.709677   \n",
       "\n",
       "      split9_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0              0.661290         0.720430        0.052226             1212  \n",
       "1              0.661290         0.720405        0.060569             1214  \n",
       "2              0.661290         0.723630        0.057244             1208  \n",
       "3              0.709677         0.760599        0.045057             1204  \n",
       "4              0.709677         0.760625        0.047805             1203  \n",
       "...                 ...              ...             ...              ...  \n",
       "1210           0.838710         0.829647        0.056432              337  \n",
       "1211           0.838710         0.824936        0.053006              496  \n",
       "1212           0.854839         0.834511        0.054857              156  \n",
       "1213           0.854839         0.837686        0.053661               90  \n",
       "1214           0.838710         0.821633        0.045313              643  \n",
       "\n",
       "[1215 rows x 25 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score is 0.8457501280081926 with params {'colsample_bylevel': 0.3, 'colsample_bytree': 0.9, 'gamma': 0.5, 'learning_rate': 0.05, 'max_depth': 4, 'n_estimators': 40, 'subsample': 0.6}\n"
     ]
    }
   ],
   "source": [
    "df2 = pd.read_csv(\"data\\\\xgb_results_full_2_learning=0.05_r3_20221124.csv\")\n",
    "df2.drop(df2.columns[0], axis=1, inplace=True)\n",
    "display(df2)\n",
    "print(\"best score is 0.8457501280081926 with params {'colsample_bylevel': 0.3, 'colsample_bytree': 0.9, 'gamma': 0.5, 'learning_rate': 0.05, 'max_depth': 4, 'n_estimators': 40, 'subsample': 0.6}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "55456590",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_colsample_bylevel</th>\n",
       "      <th>param_colsample_bytree</th>\n",
       "      <th>param_gamma</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>...</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.021696</td>\n",
       "      <td>0.004852</td>\n",
       "      <td>0.009495</td>\n",
       "      <td>0.002555</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.661290</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.661290</td>\n",
       "      <td>0.661290</td>\n",
       "      <td>0.661290</td>\n",
       "      <td>0.720430</td>\n",
       "      <td>0.052226</td>\n",
       "      <td>1212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.023734</td>\n",
       "      <td>0.003344</td>\n",
       "      <td>0.010269</td>\n",
       "      <td>0.002012</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.661290</td>\n",
       "      <td>0.629032</td>\n",
       "      <td>0.661290</td>\n",
       "      <td>0.720405</td>\n",
       "      <td>0.060569</td>\n",
       "      <td>1214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.021329</td>\n",
       "      <td>0.002649</td>\n",
       "      <td>0.009234</td>\n",
       "      <td>0.001687</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.645161</td>\n",
       "      <td>0.645161</td>\n",
       "      <td>0.661290</td>\n",
       "      <td>0.723630</td>\n",
       "      <td>0.057244</td>\n",
       "      <td>1208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.031445</td>\n",
       "      <td>0.001912</td>\n",
       "      <td>0.009800</td>\n",
       "      <td>0.001109</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>...</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.760599</td>\n",
       "      <td>0.045057</td>\n",
       "      <td>1204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.034447</td>\n",
       "      <td>0.002939</td>\n",
       "      <td>0.010506</td>\n",
       "      <td>0.001006</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>...</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.760625</td>\n",
       "      <td>0.047805</td>\n",
       "      <td>1203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1210</th>\n",
       "      <td>0.064949</td>\n",
       "      <td>0.005643</td>\n",
       "      <td>0.010790</td>\n",
       "      <td>0.002114</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.05</td>\n",
       "      <td>4</td>\n",
       "      <td>40</td>\n",
       "      <td>...</td>\n",
       "      <td>0.903226</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.829647</td>\n",
       "      <td>0.056432</td>\n",
       "      <td>337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1211</th>\n",
       "      <td>0.059376</td>\n",
       "      <td>0.006451</td>\n",
       "      <td>0.009179</td>\n",
       "      <td>0.002418</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.05</td>\n",
       "      <td>4</td>\n",
       "      <td>40</td>\n",
       "      <td>...</td>\n",
       "      <td>0.887097</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.824936</td>\n",
       "      <td>0.053006</td>\n",
       "      <td>496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1212</th>\n",
       "      <td>0.072250</td>\n",
       "      <td>0.006942</td>\n",
       "      <td>0.010528</td>\n",
       "      <td>0.001857</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.05</td>\n",
       "      <td>4</td>\n",
       "      <td>50</td>\n",
       "      <td>...</td>\n",
       "      <td>0.887097</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.834511</td>\n",
       "      <td>0.054857</td>\n",
       "      <td>156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1213</th>\n",
       "      <td>0.075180</td>\n",
       "      <td>0.004525</td>\n",
       "      <td>0.011624</td>\n",
       "      <td>0.001827</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.05</td>\n",
       "      <td>4</td>\n",
       "      <td>50</td>\n",
       "      <td>...</td>\n",
       "      <td>0.903226</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.837686</td>\n",
       "      <td>0.053661</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1214</th>\n",
       "      <td>0.071844</td>\n",
       "      <td>0.005366</td>\n",
       "      <td>0.010349</td>\n",
       "      <td>0.001572</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.05</td>\n",
       "      <td>4</td>\n",
       "      <td>50</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.821633</td>\n",
       "      <td>0.045313</td>\n",
       "      <td>643</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1215 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0          0.021696      0.004852         0.009495        0.002555   \n",
       "1          0.023734      0.003344         0.010269        0.002012   \n",
       "2          0.021329      0.002649         0.009234        0.001687   \n",
       "3          0.031445      0.001912         0.009800        0.001109   \n",
       "4          0.034447      0.002939         0.010506        0.001006   \n",
       "...             ...           ...              ...             ...   \n",
       "1210       0.064949      0.005643         0.010790        0.002114   \n",
       "1211       0.059376      0.006451         0.009179        0.002418   \n",
       "1212       0.072250      0.006942         0.010528        0.001857   \n",
       "1213       0.075180      0.004525         0.011624        0.001827   \n",
       "1214       0.071844      0.005366         0.010349        0.001572   \n",
       "\n",
       "     param_colsample_bylevel param_colsample_bytree param_gamma  \\\n",
       "0                        0.2                    0.4           0   \n",
       "1                        0.2                    0.4           0   \n",
       "2                        0.2                    0.4           0   \n",
       "3                        0.2                    0.4           0   \n",
       "4                        0.2                    0.4           0   \n",
       "...                      ...                    ...         ...   \n",
       "1210                     0.4                    0.9           1   \n",
       "1211                     0.4                    0.9           1   \n",
       "1212                     0.4                    0.9           1   \n",
       "1213                     0.4                    0.9           1   \n",
       "1214                     0.4                    0.9           1   \n",
       "\n",
       "     param_learning_rate param_max_depth param_n_estimators  ...  \\\n",
       "0                   0.05               2                 10  ...   \n",
       "1                   0.05               2                 10  ...   \n",
       "2                   0.05               2                 10  ...   \n",
       "3                   0.05               2                 20  ...   \n",
       "4                   0.05               2                 20  ...   \n",
       "...                  ...             ...                ...  ...   \n",
       "1210                0.05               4                 40  ...   \n",
       "1211                0.05               4                 40  ...   \n",
       "1212                0.05               4                 50  ...   \n",
       "1213                0.05               4                 50  ...   \n",
       "1214                0.05               4                 50  ...   \n",
       "\n",
       "     split3_test_score split4_test_score  split5_test_score  \\\n",
       "0             0.741935          0.661290           0.758065   \n",
       "1             0.774194          0.677419           0.758065   \n",
       "2             0.741935          0.709677           0.774194   \n",
       "3             0.774194          0.741935           0.790323   \n",
       "4             0.806452          0.725806           0.790323   \n",
       "...                ...               ...                ...   \n",
       "1210          0.903226          0.806452           0.822581   \n",
       "1211          0.887097          0.822581           0.870968   \n",
       "1212          0.887097          0.822581           0.870968   \n",
       "1213          0.903226          0.822581           0.838710   \n",
       "1214          0.838710          0.822581           0.822581   \n",
       "\n",
       "      split6_test_score  split7_test_score  split8_test_score  \\\n",
       "0              0.725806           0.661290           0.661290   \n",
       "1              0.693548           0.661290           0.629032   \n",
       "2              0.709677           0.645161           0.645161   \n",
       "3              0.758065           0.693548           0.709677   \n",
       "4              0.774194           0.693548           0.693548   \n",
       "...                 ...                ...                ...   \n",
       "1210           0.822581           0.790323           0.693548   \n",
       "1211           0.822581           0.774194           0.693548   \n",
       "1212           0.822581           0.790323           0.693548   \n",
       "1213           0.822581           0.790323           0.709677   \n",
       "1214           0.822581           0.774194           0.709677   \n",
       "\n",
       "      split9_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0              0.661290         0.720430        0.052226             1212  \n",
       "1              0.661290         0.720405        0.060569             1214  \n",
       "2              0.661290         0.723630        0.057244             1208  \n",
       "3              0.709677         0.760599        0.045057             1204  \n",
       "4              0.709677         0.760625        0.047805             1203  \n",
       "...                 ...              ...             ...              ...  \n",
       "1210           0.838710         0.829647        0.056432              337  \n",
       "1211           0.838710         0.824936        0.053006              496  \n",
       "1212           0.854839         0.834511        0.054857              156  \n",
       "1213           0.854839         0.837686        0.053661               90  \n",
       "1214           0.838710         0.821633        0.045313              643  \n",
       "\n",
       "[1215 rows x 25 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score is 0.8457501280081926 with params {'colsample_bylevel': 0.3, 'colsample_bytree': 0.9, 'gamma': 0.5, 'learning_rate': 0.05, 'max_depth': 4, 'n_estimators': 40, 'subsample': 0.6}\n"
     ]
    }
   ],
   "source": [
    "# Full Tuning - Part 2\n",
    "random.seed(10)\n",
    "\n",
    "xgb = XGBClassifier()\n",
    "\n",
    "xgb_parameters = {'max_depth': [2,3,4]\n",
    "                   , 'subsample': [0.6, 0.8, 0.9]\n",
    "                   , 'gamma': [0, 0.5, 1]\n",
    "                   , 'colsample_bytree': [0.4, 0.5, 0.9]\n",
    "                   , 'colsample_bylevel': [0.2, 0.3, 0.4]\n",
    "                   , 'learning_rate': [0.05]\n",
    "                   , 'n_estimators': [10, 20, 30, 40, 50]}\n",
    "\n",
    "stratified_10_fold_cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "xgb_grid_search = GridSearchCV(xgb, xgb_parameters, scoring='accuracy', cv=stratified_10_fold_cv)\n",
    "\n",
    "xgb_grid_search.fit(X_train, y_train)\n",
    "\n",
    "xgb_grid_search_results_full_2 = pd.DataFrame(xgb_grid_search.cv_results_)\n",
    "display(xgb_grid_search_results_full_2)\n",
    "\n",
    "print(\"best score is {} with params {}\".format(xgb_grid_search.best_score_, xgb_grid_search.best_params_))\n",
    "#best score is 0.8457501280081926 with params\n",
    "#{'colsample_bylevel': 0.3, 'colsample_bytree': 0.9, 'gamma': 0.5, 'learning_rate': 0.05, 'max_depth': 4, 'n_estimators': 40, 'subsample': 0.6}\n",
    "\n",
    "# save dataframe\n",
    "from datetime import datetime\n",
    "date = str(datetime.now().date()).replace(\"-\", \"\")\n",
    "xgb_grid_search_results_full_2.to_csv(f\"results/xgb_results_full_round4_2_learning=0.05_r3_{date}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "56f26de1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_colsample_bylevel</th>\n",
       "      <th>param_colsample_bytree</th>\n",
       "      <th>param_gamma</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>...</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.023281</td>\n",
       "      <td>0.003346</td>\n",
       "      <td>0.010147</td>\n",
       "      <td>0.001151</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.645161</td>\n",
       "      <td>0.661290</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.738095</td>\n",
       "      <td>0.056816</td>\n",
       "      <td>1210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.021142</td>\n",
       "      <td>0.004710</td>\n",
       "      <td>0.008830</td>\n",
       "      <td>0.001959</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.629032</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.741321</td>\n",
       "      <td>0.059607</td>\n",
       "      <td>1207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.017339</td>\n",
       "      <td>0.001338</td>\n",
       "      <td>0.007330</td>\n",
       "      <td>0.000460</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.661290</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.734869</td>\n",
       "      <td>0.053170</td>\n",
       "      <td>1215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.029686</td>\n",
       "      <td>0.004877</td>\n",
       "      <td>0.010679</td>\n",
       "      <td>0.006277</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>...</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.776728</td>\n",
       "      <td>0.041775</td>\n",
       "      <td>1197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.028296</td>\n",
       "      <td>0.005223</td>\n",
       "      <td>0.008654</td>\n",
       "      <td>0.001540</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>...</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.778341</td>\n",
       "      <td>0.046040</td>\n",
       "      <td>1192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1210</th>\n",
       "      <td>0.046617</td>\n",
       "      <td>0.003638</td>\n",
       "      <td>0.006846</td>\n",
       "      <td>0.000652</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4</td>\n",
       "      <td>40</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.831285</td>\n",
       "      <td>0.053063</td>\n",
       "      <td>569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1211</th>\n",
       "      <td>0.046081</td>\n",
       "      <td>0.002453</td>\n",
       "      <td>0.007303</td>\n",
       "      <td>0.000902</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4</td>\n",
       "      <td>40</td>\n",
       "      <td>...</td>\n",
       "      <td>0.903226</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.834511</td>\n",
       "      <td>0.055329</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1212</th>\n",
       "      <td>0.054877</td>\n",
       "      <td>0.003162</td>\n",
       "      <td>0.007232</td>\n",
       "      <td>0.000972</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4</td>\n",
       "      <td>50</td>\n",
       "      <td>...</td>\n",
       "      <td>0.903226</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.836098</td>\n",
       "      <td>0.055697</td>\n",
       "      <td>330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1213</th>\n",
       "      <td>0.048312</td>\n",
       "      <td>0.001028</td>\n",
       "      <td>0.005916</td>\n",
       "      <td>0.000878</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4</td>\n",
       "      <td>50</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.832898</td>\n",
       "      <td>0.049449</td>\n",
       "      <td>480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1214</th>\n",
       "      <td>0.051567</td>\n",
       "      <td>0.004369</td>\n",
       "      <td>0.006275</td>\n",
       "      <td>0.001148</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4</td>\n",
       "      <td>50</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.831336</td>\n",
       "      <td>0.046681</td>\n",
       "      <td>524</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1215 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0          0.023281      0.003346         0.010147        0.001151   \n",
       "1          0.021142      0.004710         0.008830        0.001959   \n",
       "2          0.017339      0.001338         0.007330        0.000460   \n",
       "3          0.029686      0.004877         0.010679        0.006277   \n",
       "4          0.028296      0.005223         0.008654        0.001540   \n",
       "...             ...           ...              ...             ...   \n",
       "1210       0.046617      0.003638         0.006846        0.000652   \n",
       "1211       0.046081      0.002453         0.007303        0.000902   \n",
       "1212       0.054877      0.003162         0.007232        0.000972   \n",
       "1213       0.048312      0.001028         0.005916        0.000878   \n",
       "1214       0.051567      0.004369         0.006275        0.001148   \n",
       "\n",
       "      param_colsample_bylevel  param_colsample_bytree  param_gamma  \\\n",
       "0                         0.2                     0.4          0.0   \n",
       "1                         0.2                     0.4          0.0   \n",
       "2                         0.2                     0.4          0.0   \n",
       "3                         0.2                     0.4          0.0   \n",
       "4                         0.2                     0.4          0.0   \n",
       "...                       ...                     ...          ...   \n",
       "1210                      0.4                     0.9          1.0   \n",
       "1211                      0.4                     0.9          1.0   \n",
       "1212                      0.4                     0.9          1.0   \n",
       "1213                      0.4                     0.9          1.0   \n",
       "1214                      0.4                     0.9          1.0   \n",
       "\n",
       "      param_learning_rate  param_max_depth  param_n_estimators  ...  \\\n",
       "0                     0.1                2                  10  ...   \n",
       "1                     0.1                2                  10  ...   \n",
       "2                     0.1                2                  10  ...   \n",
       "3                     0.1                2                  20  ...   \n",
       "4                     0.1                2                  20  ...   \n",
       "...                   ...              ...                 ...  ...   \n",
       "1210                  0.1                4                  40  ...   \n",
       "1211                  0.1                4                  40  ...   \n",
       "1212                  0.1                4                  50  ...   \n",
       "1213                  0.1                4                  50  ...   \n",
       "1214                  0.1                4                  50  ...   \n",
       "\n",
       "      split3_test_score split4_test_score  split5_test_score  \\\n",
       "0              0.790323          0.693548           0.774194   \n",
       "1              0.806452          0.693548           0.774194   \n",
       "2              0.758065          0.693548           0.774194   \n",
       "3              0.806452          0.758065           0.806452   \n",
       "4              0.790323          0.758065           0.838710   \n",
       "...                 ...               ...                ...   \n",
       "1210           0.870968          0.822581           0.790323   \n",
       "1211           0.903226          0.822581           0.806452   \n",
       "1212           0.903226          0.806452           0.822581   \n",
       "1213           0.870968          0.838710           0.790323   \n",
       "1214           0.870968          0.838710           0.806452   \n",
       "\n",
       "      split6_test_score  split7_test_score  split8_test_score  \\\n",
       "0              0.725806           0.645161           0.661290   \n",
       "1              0.741935           0.677419           0.629032   \n",
       "2              0.725806           0.677419           0.661290   \n",
       "3              0.790323           0.693548           0.709677   \n",
       "4              0.790323           0.693548           0.709677   \n",
       "...                 ...                ...                ...   \n",
       "1210           0.838710           0.822581           0.693548   \n",
       "1211           0.854839           0.806452           0.693548   \n",
       "1212           0.838710           0.822581           0.693548   \n",
       "1213           0.822581           0.822581           0.709677   \n",
       "1214           0.870968           0.806452           0.709677   \n",
       "\n",
       "      split9_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0              0.709677         0.738095        0.056816             1210  \n",
       "1              0.709677         0.741321        0.059607             1207  \n",
       "2              0.677419         0.734869        0.053170             1215  \n",
       "3              0.774194         0.776728        0.041775             1197  \n",
       "4              0.774194         0.778341        0.046040             1192  \n",
       "...                 ...              ...             ...              ...  \n",
       "1210           0.870968         0.831285        0.053063              569  \n",
       "1211           0.854839         0.834511        0.055329              400  \n",
       "1212           0.854839         0.836098        0.055697              330  \n",
       "1213           0.870968         0.832898        0.049449              480  \n",
       "1214           0.838710         0.831336        0.046681              524  \n",
       "\n",
       "[1215 rows x 25 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score is 0.8489759344598055 with params {'colsample_bylevel': 0.2, 'colsample_bytree': 0.9, 'gamma': 1, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 40, 'subsample': 0.6}\n"
     ]
    }
   ],
   "source": [
    "df4 = pd.read_csv(\"data\\\\xgb_results_full_4_learning=0.1_r3_20221124.csv\")\n",
    "df4.drop(df4.columns[0], axis=1, inplace=True)\n",
    "display(df4)\n",
    "print(\"best score is 0.8489759344598055 with params {'colsample_bylevel': 0.2, 'colsample_bytree': 0.9, 'gamma': 1, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 40, 'subsample': 0.6}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "38267cf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_colsample_bylevel</th>\n",
       "      <th>param_colsample_bytree</th>\n",
       "      <th>param_gamma</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>...</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.023281</td>\n",
       "      <td>0.003346</td>\n",
       "      <td>0.010147</td>\n",
       "      <td>0.001151</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.645161</td>\n",
       "      <td>0.661290</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.738095</td>\n",
       "      <td>0.056816</td>\n",
       "      <td>1210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.021142</td>\n",
       "      <td>0.004710</td>\n",
       "      <td>0.008830</td>\n",
       "      <td>0.001959</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.629032</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.741321</td>\n",
       "      <td>0.059607</td>\n",
       "      <td>1207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.017339</td>\n",
       "      <td>0.001338</td>\n",
       "      <td>0.007330</td>\n",
       "      <td>0.000460</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.661290</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.734869</td>\n",
       "      <td>0.053170</td>\n",
       "      <td>1215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.029686</td>\n",
       "      <td>0.004877</td>\n",
       "      <td>0.010679</td>\n",
       "      <td>0.006277</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>...</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.776728</td>\n",
       "      <td>0.041775</td>\n",
       "      <td>1197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.028296</td>\n",
       "      <td>0.005223</td>\n",
       "      <td>0.008654</td>\n",
       "      <td>0.001540</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>...</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.778341</td>\n",
       "      <td>0.046040</td>\n",
       "      <td>1192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1210</th>\n",
       "      <td>0.046617</td>\n",
       "      <td>0.003638</td>\n",
       "      <td>0.006846</td>\n",
       "      <td>0.000652</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4</td>\n",
       "      <td>40</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.831285</td>\n",
       "      <td>0.053063</td>\n",
       "      <td>569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1211</th>\n",
       "      <td>0.046081</td>\n",
       "      <td>0.002453</td>\n",
       "      <td>0.007303</td>\n",
       "      <td>0.000902</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4</td>\n",
       "      <td>40</td>\n",
       "      <td>...</td>\n",
       "      <td>0.903226</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.834511</td>\n",
       "      <td>0.055329</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1212</th>\n",
       "      <td>0.054877</td>\n",
       "      <td>0.003162</td>\n",
       "      <td>0.007232</td>\n",
       "      <td>0.000972</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4</td>\n",
       "      <td>50</td>\n",
       "      <td>...</td>\n",
       "      <td>0.903226</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.836098</td>\n",
       "      <td>0.055697</td>\n",
       "      <td>330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1213</th>\n",
       "      <td>0.048312</td>\n",
       "      <td>0.001028</td>\n",
       "      <td>0.005916</td>\n",
       "      <td>0.000878</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4</td>\n",
       "      <td>50</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.832898</td>\n",
       "      <td>0.049449</td>\n",
       "      <td>480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1214</th>\n",
       "      <td>0.051567</td>\n",
       "      <td>0.004369</td>\n",
       "      <td>0.006275</td>\n",
       "      <td>0.001148</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4</td>\n",
       "      <td>50</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.831336</td>\n",
       "      <td>0.046681</td>\n",
       "      <td>524</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1215 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0          0.023281      0.003346         0.010147        0.001151   \n",
       "1          0.021142      0.004710         0.008830        0.001959   \n",
       "2          0.017339      0.001338         0.007330        0.000460   \n",
       "3          0.029686      0.004877         0.010679        0.006277   \n",
       "4          0.028296      0.005223         0.008654        0.001540   \n",
       "...             ...           ...              ...             ...   \n",
       "1210       0.046617      0.003638         0.006846        0.000652   \n",
       "1211       0.046081      0.002453         0.007303        0.000902   \n",
       "1212       0.054877      0.003162         0.007232        0.000972   \n",
       "1213       0.048312      0.001028         0.005916        0.000878   \n",
       "1214       0.051567      0.004369         0.006275        0.001148   \n",
       "\n",
       "     param_colsample_bylevel param_colsample_bytree param_gamma  \\\n",
       "0                        0.2                    0.4           0   \n",
       "1                        0.2                    0.4           0   \n",
       "2                        0.2                    0.4           0   \n",
       "3                        0.2                    0.4           0   \n",
       "4                        0.2                    0.4           0   \n",
       "...                      ...                    ...         ...   \n",
       "1210                     0.4                    0.9           1   \n",
       "1211                     0.4                    0.9           1   \n",
       "1212                     0.4                    0.9           1   \n",
       "1213                     0.4                    0.9           1   \n",
       "1214                     0.4                    0.9           1   \n",
       "\n",
       "     param_learning_rate param_max_depth param_n_estimators  ...  \\\n",
       "0                    0.1               2                 10  ...   \n",
       "1                    0.1               2                 10  ...   \n",
       "2                    0.1               2                 10  ...   \n",
       "3                    0.1               2                 20  ...   \n",
       "4                    0.1               2                 20  ...   \n",
       "...                  ...             ...                ...  ...   \n",
       "1210                 0.1               4                 40  ...   \n",
       "1211                 0.1               4                 40  ...   \n",
       "1212                 0.1               4                 50  ...   \n",
       "1213                 0.1               4                 50  ...   \n",
       "1214                 0.1               4                 50  ...   \n",
       "\n",
       "     split3_test_score split4_test_score  split5_test_score  \\\n",
       "0             0.790323          0.693548           0.774194   \n",
       "1             0.806452          0.693548           0.774194   \n",
       "2             0.758065          0.693548           0.774194   \n",
       "3             0.806452          0.758065           0.806452   \n",
       "4             0.790323          0.758065           0.838710   \n",
       "...                ...               ...                ...   \n",
       "1210          0.870968          0.822581           0.790323   \n",
       "1211          0.903226          0.822581           0.806452   \n",
       "1212          0.903226          0.806452           0.822581   \n",
       "1213          0.870968          0.838710           0.790323   \n",
       "1214          0.870968          0.838710           0.806452   \n",
       "\n",
       "      split6_test_score  split7_test_score  split8_test_score  \\\n",
       "0              0.725806           0.645161           0.661290   \n",
       "1              0.741935           0.677419           0.629032   \n",
       "2              0.725806           0.677419           0.661290   \n",
       "3              0.790323           0.693548           0.709677   \n",
       "4              0.790323           0.693548           0.709677   \n",
       "...                 ...                ...                ...   \n",
       "1210           0.838710           0.822581           0.693548   \n",
       "1211           0.854839           0.806452           0.693548   \n",
       "1212           0.838710           0.822581           0.693548   \n",
       "1213           0.822581           0.822581           0.709677   \n",
       "1214           0.870968           0.806452           0.709677   \n",
       "\n",
       "      split9_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0              0.709677         0.738095        0.056816             1210  \n",
       "1              0.709677         0.741321        0.059607             1207  \n",
       "2              0.677419         0.734869        0.053170             1215  \n",
       "3              0.774194         0.776728        0.041775             1197  \n",
       "4              0.774194         0.778341        0.046040             1192  \n",
       "...                 ...              ...             ...              ...  \n",
       "1210           0.870968         0.831285        0.053063              569  \n",
       "1211           0.854839         0.834511        0.055329              400  \n",
       "1212           0.854839         0.836098        0.055697              330  \n",
       "1213           0.870968         0.832898        0.049449              480  \n",
       "1214           0.838710         0.831336        0.046681              524  \n",
       "\n",
       "[1215 rows x 25 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score is 0.8489759344598055 with params {'colsample_bylevel': 0.2, 'colsample_bytree': 0.9, 'gamma': 1, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 40, 'subsample': 0.6}\n"
     ]
    }
   ],
   "source": [
    "# Full Tuning - Part 4\n",
    "random.seed(10)\n",
    "\n",
    "xgb = XGBClassifier()\n",
    "\n",
    "xgb_parameters = {'max_depth': [2,3,4]\n",
    "                   , 'subsample': [0.6, 0.8, 0.9]\n",
    "                   , 'gamma': [0, 0.5, 1]\n",
    "                   , 'colsample_bytree': [0.4, 0.5, 0.9]\n",
    "                   , 'colsample_bylevel': [0.2, 0.3, 0.4]\n",
    "                   , 'learning_rate': [0.1]\n",
    "                   , 'n_estimators': [10, 20, 30, 40, 50]}\n",
    "\n",
    "stratified_10_fold_cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "xgb_grid_search = GridSearchCV(xgb, xgb_parameters, scoring='accuracy', cv=stratified_10_fold_cv)\n",
    "\n",
    "xgb_grid_search.fit(X_train, y_train)\n",
    "\n",
    "xgb_grid_search_results_full_4 = pd.DataFrame(xgb_grid_search.cv_results_)\n",
    "display(xgb_grid_search_results_full_4)\n",
    "\n",
    "print(\"best score is {} with params {}\".format(xgb_grid_search.best_score_, xgb_grid_search.best_params_))\n",
    "#best score is 0.8489759344598055 with params\n",
    "#{'colsample_bylevel': 0.2, 'colsample_bytree': 0.9, 'gamma': 1, 'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 40, 'subsample': 0.6}\n",
    "\n",
    "# save dataframe\n",
    "from datetime import datetime\n",
    "date = str(datetime.now().date()).replace(\"-\", \"\")\n",
    "xgb_grid_search_results_full_4.to_csv(f\"results/xgb_results_full_round4_4_learning=0.1_r3_{date}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4039a71d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_colsample_bylevel</th>\n",
       "      <th>param_colsample_bytree</th>\n",
       "      <th>param_gamma</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>...</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.016554</td>\n",
       "      <td>0.002537</td>\n",
       "      <td>0.007182</td>\n",
       "      <td>0.000959</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.15</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.757424</td>\n",
       "      <td>0.050947</td>\n",
       "      <td>1215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.016427</td>\n",
       "      <td>0.001717</td>\n",
       "      <td>0.007107</td>\n",
       "      <td>0.001197</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.15</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.757450</td>\n",
       "      <td>0.053333</td>\n",
       "      <td>1214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.016237</td>\n",
       "      <td>0.001671</td>\n",
       "      <td>0.006752</td>\n",
       "      <td>0.001091</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.15</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.760676</td>\n",
       "      <td>0.044198</td>\n",
       "      <td>1209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.021693</td>\n",
       "      <td>0.001708</td>\n",
       "      <td>0.006730</td>\n",
       "      <td>0.000781</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.15</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>...</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.786380</td>\n",
       "      <td>0.041426</td>\n",
       "      <td>1198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.022707</td>\n",
       "      <td>0.001195</td>\n",
       "      <td>0.006760</td>\n",
       "      <td>0.001250</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.15</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.887097</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.788070</td>\n",
       "      <td>0.060361</td>\n",
       "      <td>1193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1210</th>\n",
       "      <td>0.042887</td>\n",
       "      <td>0.006616</td>\n",
       "      <td>0.007578</td>\n",
       "      <td>0.000661</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.15</td>\n",
       "      <td>4</td>\n",
       "      <td>40</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.840937</td>\n",
       "      <td>0.052094</td>\n",
       "      <td>216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1211</th>\n",
       "      <td>0.040591</td>\n",
       "      <td>0.002564</td>\n",
       "      <td>0.007381</td>\n",
       "      <td>0.000488</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.15</td>\n",
       "      <td>4</td>\n",
       "      <td>40</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.826498</td>\n",
       "      <td>0.044226</td>\n",
       "      <td>844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1212</th>\n",
       "      <td>0.047273</td>\n",
       "      <td>0.000661</td>\n",
       "      <td>0.007281</td>\n",
       "      <td>0.000457</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.15</td>\n",
       "      <td>4</td>\n",
       "      <td>50</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.836047</td>\n",
       "      <td>0.049856</td>\n",
       "      <td>522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1213</th>\n",
       "      <td>0.046974</td>\n",
       "      <td>0.001218</td>\n",
       "      <td>0.007380</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.15</td>\n",
       "      <td>4</td>\n",
       "      <td>50</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.837711</td>\n",
       "      <td>0.051631</td>\n",
       "      <td>393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1214</th>\n",
       "      <td>0.046675</td>\n",
       "      <td>0.001163</td>\n",
       "      <td>0.007381</td>\n",
       "      <td>0.000488</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.15</td>\n",
       "      <td>4</td>\n",
       "      <td>50</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.826523</td>\n",
       "      <td>0.043519</td>\n",
       "      <td>838</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1215 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0          0.016554      0.002537         0.007182        0.000959   \n",
       "1          0.016427      0.001717         0.007107        0.001197   \n",
       "2          0.016237      0.001671         0.006752        0.001091   \n",
       "3          0.021693      0.001708         0.006730        0.000781   \n",
       "4          0.022707      0.001195         0.006760        0.001250   \n",
       "...             ...           ...              ...             ...   \n",
       "1210       0.042887      0.006616         0.007578        0.000661   \n",
       "1211       0.040591      0.002564         0.007381        0.000488   \n",
       "1212       0.047273      0.000661         0.007281        0.000457   \n",
       "1213       0.046974      0.001218         0.007380        0.000489   \n",
       "1214       0.046675      0.001163         0.007381        0.000488   \n",
       "\n",
       "      param_colsample_bylevel  param_colsample_bytree  param_gamma  \\\n",
       "0                         0.2                     0.4          0.0   \n",
       "1                         0.2                     0.4          0.0   \n",
       "2                         0.2                     0.4          0.0   \n",
       "3                         0.2                     0.4          0.0   \n",
       "4                         0.2                     0.4          0.0   \n",
       "...                       ...                     ...          ...   \n",
       "1210                      0.4                     0.9          1.0   \n",
       "1211                      0.4                     0.9          1.0   \n",
       "1212                      0.4                     0.9          1.0   \n",
       "1213                      0.4                     0.9          1.0   \n",
       "1214                      0.4                     0.9          1.0   \n",
       "\n",
       "      param_learning_rate  param_max_depth  param_n_estimators  ...  \\\n",
       "0                    0.15                2                  10  ...   \n",
       "1                    0.15                2                  10  ...   \n",
       "2                    0.15                2                  10  ...   \n",
       "3                    0.15                2                  20  ...   \n",
       "4                    0.15                2                  20  ...   \n",
       "...                   ...              ...                 ...  ...   \n",
       "1210                 0.15                4                  40  ...   \n",
       "1211                 0.15                4                  40  ...   \n",
       "1212                 0.15                4                  50  ...   \n",
       "1213                 0.15                4                  50  ...   \n",
       "1214                 0.15                4                  50  ...   \n",
       "\n",
       "      split3_test_score split4_test_score  split5_test_score  \\\n",
       "0              0.822581          0.677419           0.774194   \n",
       "1              0.822581          0.693548           0.774194   \n",
       "2              0.806452          0.693548           0.774194   \n",
       "3              0.806452          0.790323           0.822581   \n",
       "4              0.854839          0.790323           0.887097   \n",
       "...                 ...               ...                ...   \n",
       "1210           0.854839          0.822581           0.854839   \n",
       "1211           0.854839          0.822581           0.790323   \n",
       "1212           0.838710          0.822581           0.806452   \n",
       "1213           0.854839          0.838710           0.838710   \n",
       "1214           0.854839          0.822581           0.806452   \n",
       "\n",
       "      split6_test_score  split7_test_score  split8_test_score  \\\n",
       "0              0.758065           0.677419           0.709677   \n",
       "1              0.790323           0.677419           0.677419   \n",
       "2              0.774194           0.693548           0.709677   \n",
       "3              0.806452           0.693548           0.725806   \n",
       "4              0.806452           0.709677           0.677419   \n",
       "...                 ...                ...                ...   \n",
       "1210           0.854839           0.838710           0.693548   \n",
       "1211           0.854839           0.822581           0.709677   \n",
       "1212           0.838710           0.838710           0.709677   \n",
       "1213           0.870968           0.822581           0.693548   \n",
       "1214           0.838710           0.822581           0.709677   \n",
       "\n",
       "      split9_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0              0.758065         0.757424        0.050947             1215  \n",
       "1              0.758065         0.757450        0.053333             1214  \n",
       "2              0.774194         0.760676        0.044198             1209  \n",
       "3              0.774194         0.786380        0.041426             1198  \n",
       "4              0.758065         0.788070        0.060361             1193  \n",
       "...                 ...              ...             ...              ...  \n",
       "1210           0.870968         0.840937        0.052094              216  \n",
       "1211           0.838710         0.826498        0.044226              844  \n",
       "1212           0.854839         0.836047        0.049856              522  \n",
       "1213           0.838710         0.837711        0.051631              393  \n",
       "1214           0.854839         0.826523        0.043519              838  \n",
       "\n",
       "[1215 rows x 25 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score is 0.856989247311828 with params {'colsample_bylevel': 0.4, 'colsample_bytree': 0.4, 'gamma': 1, 'learning_rate': 0.15, 'max_depth': 4, 'n_estimators': 30, 'subsample': 0.9}\n"
     ]
    }
   ],
   "source": [
    "df5 = pd.read_csv(\"data\\\\xgb_results_full_5_learning=0.15_r3_20221124.csv\")\n",
    "df5.drop(df5.columns[0], axis=1, inplace=True)\n",
    "display(df5)\n",
    "print(\"best score is 0.856989247311828 with params {'colsample_bylevel': 0.4, 'colsample_bytree': 0.4, 'gamma': 1, 'learning_rate': 0.15, 'max_depth': 4, 'n_estimators': 30, 'subsample': 0.9}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "47aa628f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_colsample_bylevel</th>\n",
       "      <th>param_colsample_bytree</th>\n",
       "      <th>param_gamma</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>...</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.016554</td>\n",
       "      <td>0.002537</td>\n",
       "      <td>0.007182</td>\n",
       "      <td>0.000959</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.15</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.757424</td>\n",
       "      <td>0.050947</td>\n",
       "      <td>1215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.016427</td>\n",
       "      <td>0.001717</td>\n",
       "      <td>0.007107</td>\n",
       "      <td>0.001197</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.15</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.757450</td>\n",
       "      <td>0.053333</td>\n",
       "      <td>1214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.016237</td>\n",
       "      <td>0.001671</td>\n",
       "      <td>0.006752</td>\n",
       "      <td>0.001091</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.15</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.760676</td>\n",
       "      <td>0.044198</td>\n",
       "      <td>1209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.021693</td>\n",
       "      <td>0.001708</td>\n",
       "      <td>0.006730</td>\n",
       "      <td>0.000781</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.15</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>...</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.786380</td>\n",
       "      <td>0.041426</td>\n",
       "      <td>1198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.022707</td>\n",
       "      <td>0.001195</td>\n",
       "      <td>0.006760</td>\n",
       "      <td>0.001250</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.15</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.887097</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.788070</td>\n",
       "      <td>0.060361</td>\n",
       "      <td>1193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1210</th>\n",
       "      <td>0.042887</td>\n",
       "      <td>0.006616</td>\n",
       "      <td>0.007578</td>\n",
       "      <td>0.000661</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.15</td>\n",
       "      <td>4</td>\n",
       "      <td>40</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.840937</td>\n",
       "      <td>0.052094</td>\n",
       "      <td>216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1211</th>\n",
       "      <td>0.040591</td>\n",
       "      <td>0.002564</td>\n",
       "      <td>0.007381</td>\n",
       "      <td>0.000488</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.15</td>\n",
       "      <td>4</td>\n",
       "      <td>40</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.826498</td>\n",
       "      <td>0.044226</td>\n",
       "      <td>844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1212</th>\n",
       "      <td>0.047273</td>\n",
       "      <td>0.000661</td>\n",
       "      <td>0.007281</td>\n",
       "      <td>0.000457</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.15</td>\n",
       "      <td>4</td>\n",
       "      <td>50</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.836047</td>\n",
       "      <td>0.049856</td>\n",
       "      <td>522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1213</th>\n",
       "      <td>0.046974</td>\n",
       "      <td>0.001218</td>\n",
       "      <td>0.007380</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.15</td>\n",
       "      <td>4</td>\n",
       "      <td>50</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.837711</td>\n",
       "      <td>0.051631</td>\n",
       "      <td>393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1214</th>\n",
       "      <td>0.046675</td>\n",
       "      <td>0.001163</td>\n",
       "      <td>0.007381</td>\n",
       "      <td>0.000488</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.15</td>\n",
       "      <td>4</td>\n",
       "      <td>50</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.826523</td>\n",
       "      <td>0.043519</td>\n",
       "      <td>838</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1215 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0          0.016554      0.002537         0.007182        0.000959   \n",
       "1          0.016427      0.001717         0.007107        0.001197   \n",
       "2          0.016237      0.001671         0.006752        0.001091   \n",
       "3          0.021693      0.001708         0.006730        0.000781   \n",
       "4          0.022707      0.001195         0.006760        0.001250   \n",
       "...             ...           ...              ...             ...   \n",
       "1210       0.042887      0.006616         0.007578        0.000661   \n",
       "1211       0.040591      0.002564         0.007381        0.000488   \n",
       "1212       0.047273      0.000661         0.007281        0.000457   \n",
       "1213       0.046974      0.001218         0.007380        0.000489   \n",
       "1214       0.046675      0.001163         0.007381        0.000488   \n",
       "\n",
       "     param_colsample_bylevel param_colsample_bytree param_gamma  \\\n",
       "0                        0.2                    0.4           0   \n",
       "1                        0.2                    0.4           0   \n",
       "2                        0.2                    0.4           0   \n",
       "3                        0.2                    0.4           0   \n",
       "4                        0.2                    0.4           0   \n",
       "...                      ...                    ...         ...   \n",
       "1210                     0.4                    0.9           1   \n",
       "1211                     0.4                    0.9           1   \n",
       "1212                     0.4                    0.9           1   \n",
       "1213                     0.4                    0.9           1   \n",
       "1214                     0.4                    0.9           1   \n",
       "\n",
       "     param_learning_rate param_max_depth param_n_estimators  ...  \\\n",
       "0                   0.15               2                 10  ...   \n",
       "1                   0.15               2                 10  ...   \n",
       "2                   0.15               2                 10  ...   \n",
       "3                   0.15               2                 20  ...   \n",
       "4                   0.15               2                 20  ...   \n",
       "...                  ...             ...                ...  ...   \n",
       "1210                0.15               4                 40  ...   \n",
       "1211                0.15               4                 40  ...   \n",
       "1212                0.15               4                 50  ...   \n",
       "1213                0.15               4                 50  ...   \n",
       "1214                0.15               4                 50  ...   \n",
       "\n",
       "     split3_test_score split4_test_score  split5_test_score  \\\n",
       "0             0.822581          0.677419           0.774194   \n",
       "1             0.822581          0.693548           0.774194   \n",
       "2             0.806452          0.693548           0.774194   \n",
       "3             0.806452          0.790323           0.822581   \n",
       "4             0.854839          0.790323           0.887097   \n",
       "...                ...               ...                ...   \n",
       "1210          0.854839          0.822581           0.854839   \n",
       "1211          0.854839          0.822581           0.790323   \n",
       "1212          0.838710          0.822581           0.806452   \n",
       "1213          0.854839          0.838710           0.838710   \n",
       "1214          0.854839          0.822581           0.806452   \n",
       "\n",
       "      split6_test_score  split7_test_score  split8_test_score  \\\n",
       "0              0.758065           0.677419           0.709677   \n",
       "1              0.790323           0.677419           0.677419   \n",
       "2              0.774194           0.693548           0.709677   \n",
       "3              0.806452           0.693548           0.725806   \n",
       "4              0.806452           0.709677           0.677419   \n",
       "...                 ...                ...                ...   \n",
       "1210           0.854839           0.838710           0.693548   \n",
       "1211           0.854839           0.822581           0.709677   \n",
       "1212           0.838710           0.838710           0.709677   \n",
       "1213           0.870968           0.822581           0.693548   \n",
       "1214           0.838710           0.822581           0.709677   \n",
       "\n",
       "      split9_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0              0.758065         0.757424        0.050947             1215  \n",
       "1              0.758065         0.757450        0.053333             1214  \n",
       "2              0.774194         0.760676        0.044198             1209  \n",
       "3              0.774194         0.786380        0.041426             1198  \n",
       "4              0.758065         0.788070        0.060361             1193  \n",
       "...                 ...              ...             ...              ...  \n",
       "1210           0.870968         0.840937        0.052094              216  \n",
       "1211           0.838710         0.826498        0.044226              844  \n",
       "1212           0.854839         0.836047        0.049856              522  \n",
       "1213           0.838710         0.837711        0.051631              393  \n",
       "1214           0.854839         0.826523        0.043519              838  \n",
       "\n",
       "[1215 rows x 25 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score is 0.856989247311828 with params {'colsample_bylevel': 0.4, 'colsample_bytree': 0.4, 'gamma': 1, 'learning_rate': 0.15, 'max_depth': 4, 'n_estimators': 30, 'subsample': 0.9}\n"
     ]
    }
   ],
   "source": [
    "# Full Tuning - Part 5\n",
    "random.seed(10)\n",
    "\n",
    "xgb = XGBClassifier()\n",
    "\n",
    "xgb_parameters = {'max_depth': [2,3,4]\n",
    "                   , 'subsample': [0.6, 0.8, 0.9]\n",
    "                   , 'gamma': [0, 0.5, 1]\n",
    "                   , 'colsample_bytree': [0.4, 0.5, 0.9]\n",
    "                   , 'colsample_bylevel': [0.2, 0.3, 0.4]\n",
    "                   , 'learning_rate': [0.15]\n",
    "                   , 'n_estimators': [10, 20, 30, 40, 50]}\n",
    "\n",
    "stratified_10_fold_cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "xgb_grid_search = GridSearchCV(xgb, xgb_parameters, scoring='accuracy', cv=stratified_10_fold_cv)\n",
    "\n",
    "xgb_grid_search.fit(X_train, y_train)\n",
    "\n",
    "xgb_grid_search_results_full_5 = pd.DataFrame(xgb_grid_search.cv_results_)\n",
    "display(xgb_grid_search_results_full_5)\n",
    "\n",
    "print(\"best score is {} with params {}\".format(xgb_grid_search.best_score_, xgb_grid_search.best_params_))\n",
    "#best score is 0.856989247311828 with params\n",
    "#{'colsample_bylevel': 0.4, 'colsample_bytree': 0.4, 'gamma': 1, 'learning_rate': 0.15, 'max_depth': 4, 'n_estimators': 30, 'subsample': 0.9}\n",
    "\n",
    "# save dataframe\n",
    "from datetime import datetime\n",
    "date = str(datetime.now().date()).replace(\"-\", \"\")\n",
    "xgb_grid_search_results_full_5.to_csv(f\"results/xgb_results_full_round4_5_learning=0.15_r3_{date}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6660d344",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_colsample_bylevel</th>\n",
       "      <th>param_colsample_bytree</th>\n",
       "      <th>param_gamma</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>...</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.017553</td>\n",
       "      <td>0.003160</td>\n",
       "      <td>0.006982</td>\n",
       "      <td>0.000446</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.661290</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.661290</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.763850</td>\n",
       "      <td>0.060953</td>\n",
       "      <td>1214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.014960</td>\n",
       "      <td>0.000446</td>\n",
       "      <td>0.007181</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.768689</td>\n",
       "      <td>0.054639</td>\n",
       "      <td>1210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.014760</td>\n",
       "      <td>0.001323</td>\n",
       "      <td>0.006583</td>\n",
       "      <td>0.000798</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.765515</td>\n",
       "      <td>0.050031</td>\n",
       "      <td>1211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.020445</td>\n",
       "      <td>0.002610</td>\n",
       "      <td>0.005785</td>\n",
       "      <td>0.000870</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.800768</td>\n",
       "      <td>0.050666</td>\n",
       "      <td>1196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.022241</td>\n",
       "      <td>0.002404</td>\n",
       "      <td>0.006483</td>\n",
       "      <td>0.000499</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.903226</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.805658</td>\n",
       "      <td>0.055483</td>\n",
       "      <td>1176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1210</th>\n",
       "      <td>0.039993</td>\n",
       "      <td>0.000829</td>\n",
       "      <td>0.007979</td>\n",
       "      <td>0.000446</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>4</td>\n",
       "      <td>40</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.887097</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.850589</td>\n",
       "      <td>0.041824</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1211</th>\n",
       "      <td>0.057798</td>\n",
       "      <td>0.044078</td>\n",
       "      <td>0.008179</td>\n",
       "      <td>0.002352</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>4</td>\n",
       "      <td>40</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.823349</td>\n",
       "      <td>0.036404</td>\n",
       "      <td>966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1212</th>\n",
       "      <td>0.065325</td>\n",
       "      <td>0.017959</td>\n",
       "      <td>0.008279</td>\n",
       "      <td>0.000779</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>4</td>\n",
       "      <td>50</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.834434</td>\n",
       "      <td>0.055885</td>\n",
       "      <td>546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1213</th>\n",
       "      <td>0.067819</td>\n",
       "      <td>0.006180</td>\n",
       "      <td>0.008378</td>\n",
       "      <td>0.001196</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>4</td>\n",
       "      <td>50</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.837737</td>\n",
       "      <td>0.042732</td>\n",
       "      <td>317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1214</th>\n",
       "      <td>0.055651</td>\n",
       "      <td>0.002176</td>\n",
       "      <td>0.007880</td>\n",
       "      <td>0.001042</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>4</td>\n",
       "      <td>50</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.828111</td>\n",
       "      <td>0.042532</td>\n",
       "      <td>829</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1215 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0          0.017553      0.003160         0.006982        0.000446   \n",
       "1          0.014960      0.000446         0.007181        0.000399   \n",
       "2          0.014760      0.001323         0.006583        0.000798   \n",
       "3          0.020445      0.002610         0.005785        0.000870   \n",
       "4          0.022241      0.002404         0.006483        0.000499   \n",
       "...             ...           ...              ...             ...   \n",
       "1210       0.039993      0.000829         0.007979        0.000446   \n",
       "1211       0.057798      0.044078         0.008179        0.002352   \n",
       "1212       0.065325      0.017959         0.008279        0.000779   \n",
       "1213       0.067819      0.006180         0.008378        0.001196   \n",
       "1214       0.055651      0.002176         0.007880        0.001042   \n",
       "\n",
       "      param_colsample_bylevel  param_colsample_bytree  param_gamma  \\\n",
       "0                         0.2                     0.4          0.0   \n",
       "1                         0.2                     0.4          0.0   \n",
       "2                         0.2                     0.4          0.0   \n",
       "3                         0.2                     0.4          0.0   \n",
       "4                         0.2                     0.4          0.0   \n",
       "...                       ...                     ...          ...   \n",
       "1210                      0.4                     0.9          1.0   \n",
       "1211                      0.4                     0.9          1.0   \n",
       "1212                      0.4                     0.9          1.0   \n",
       "1213                      0.4                     0.9          1.0   \n",
       "1214                      0.4                     0.9          1.0   \n",
       "\n",
       "      param_learning_rate  param_max_depth  param_n_estimators  ...  \\\n",
       "0                     0.2                2                  10  ...   \n",
       "1                     0.2                2                  10  ...   \n",
       "2                     0.2                2                  10  ...   \n",
       "3                     0.2                2                  20  ...   \n",
       "4                     0.2                2                  20  ...   \n",
       "...                   ...              ...                 ...  ...   \n",
       "1210                  0.2                4                  40  ...   \n",
       "1211                  0.2                4                  40  ...   \n",
       "1212                  0.2                4                  50  ...   \n",
       "1213                  0.2                4                  50  ...   \n",
       "1214                  0.2                4                  50  ...   \n",
       "\n",
       "      split3_test_score split4_test_score  split5_test_score  \\\n",
       "0              0.838710          0.661290           0.790323   \n",
       "1              0.854839          0.693548           0.790323   \n",
       "2              0.838710          0.725806           0.790323   \n",
       "3              0.838710          0.774194           0.838710   \n",
       "4              0.838710          0.774194           0.903226   \n",
       "...                 ...               ...                ...   \n",
       "1210           0.870968          0.822581           0.854839   \n",
       "1211           0.854839          0.822581           0.806452   \n",
       "1212           0.838710          0.822581           0.790323   \n",
       "1213           0.838710          0.822581           0.822581   \n",
       "1214           0.870968          0.822581           0.790323   \n",
       "\n",
       "      split6_test_score  split7_test_score  split8_test_score  \\\n",
       "0              0.774194           0.661290           0.709677   \n",
       "1              0.774194           0.693548           0.693548   \n",
       "2              0.774194           0.677419           0.693548   \n",
       "3              0.806452           0.709677           0.709677   \n",
       "4              0.806452           0.741935           0.693548   \n",
       "...                 ...                ...                ...   \n",
       "1210           0.887097           0.838710           0.741935   \n",
       "1211           0.854839           0.822581           0.725806   \n",
       "1212           0.854839           0.838710           0.693548   \n",
       "1213           0.870968           0.838710           0.725806   \n",
       "1214           0.854839           0.806452           0.725806   \n",
       "\n",
       "      split9_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0              0.790323         0.763850        0.060953             1214  \n",
       "1              0.774194         0.768689        0.054639             1210  \n",
       "2              0.774194         0.765515        0.050031             1211  \n",
       "3              0.806452         0.800768        0.050666             1196  \n",
       "4              0.806452         0.805658        0.055483             1176  \n",
       "...                 ...              ...             ...              ...  \n",
       "1210           0.854839         0.850589        0.041824                6  \n",
       "1211           0.822581         0.823349        0.036404              966  \n",
       "1212           0.854839         0.834434        0.055885              546  \n",
       "1213           0.854839         0.837737        0.042732              317  \n",
       "1214           0.838710         0.828111        0.042532              829  \n",
       "\n",
       "[1215 rows x 25 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score is 0.8522529441884281 with params {'colsample_bylevel': 0.2, 'colsample_bytree': 0.9, 'gamma': 0.5, 'learning_rate': 0.2, 'max_depth': 2, 'n_estimators': 30, 'subsample': 0.6}\n"
     ]
    }
   ],
   "source": [
    "df6 = pd.read_csv(\"data\\\\xgb_results_full_6_learning=0.2_r3_20221124.csv\")\n",
    "df6.drop(df6.columns[0], axis=1, inplace=True)\n",
    "display(df6)\n",
    "print(\"best score is 0.8522529441884281 with params {'colsample_bylevel': 0.2, 'colsample_bytree': 0.9, 'gamma': 0.5, 'learning_rate': 0.2, 'max_depth': 2, 'n_estimators': 30, 'subsample': 0.6}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "10ee410e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_colsample_bylevel</th>\n",
       "      <th>param_colsample_bytree</th>\n",
       "      <th>param_gamma</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>...</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.017553</td>\n",
       "      <td>0.003160</td>\n",
       "      <td>0.006982</td>\n",
       "      <td>0.000446</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.661290</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.661290</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.763850</td>\n",
       "      <td>0.060953</td>\n",
       "      <td>1214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.014960</td>\n",
       "      <td>0.000446</td>\n",
       "      <td>0.007181</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.768689</td>\n",
       "      <td>0.054639</td>\n",
       "      <td>1210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.014760</td>\n",
       "      <td>0.001323</td>\n",
       "      <td>0.006583</td>\n",
       "      <td>0.000798</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.765515</td>\n",
       "      <td>0.050031</td>\n",
       "      <td>1211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.020445</td>\n",
       "      <td>0.002610</td>\n",
       "      <td>0.005785</td>\n",
       "      <td>0.000870</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.800768</td>\n",
       "      <td>0.050666</td>\n",
       "      <td>1196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.022241</td>\n",
       "      <td>0.002404</td>\n",
       "      <td>0.006483</td>\n",
       "      <td>0.000499</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.903226</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.805658</td>\n",
       "      <td>0.055483</td>\n",
       "      <td>1176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1210</th>\n",
       "      <td>0.039993</td>\n",
       "      <td>0.000829</td>\n",
       "      <td>0.007979</td>\n",
       "      <td>0.000446</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>4</td>\n",
       "      <td>40</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.887097</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.850589</td>\n",
       "      <td>0.041824</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1211</th>\n",
       "      <td>0.057798</td>\n",
       "      <td>0.044078</td>\n",
       "      <td>0.008179</td>\n",
       "      <td>0.002352</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>4</td>\n",
       "      <td>40</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.823349</td>\n",
       "      <td>0.036404</td>\n",
       "      <td>966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1212</th>\n",
       "      <td>0.065325</td>\n",
       "      <td>0.017959</td>\n",
       "      <td>0.008279</td>\n",
       "      <td>0.000779</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>4</td>\n",
       "      <td>50</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.834434</td>\n",
       "      <td>0.055885</td>\n",
       "      <td>546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1213</th>\n",
       "      <td>0.067819</td>\n",
       "      <td>0.006180</td>\n",
       "      <td>0.008378</td>\n",
       "      <td>0.001196</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>4</td>\n",
       "      <td>50</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.837737</td>\n",
       "      <td>0.042732</td>\n",
       "      <td>317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1214</th>\n",
       "      <td>0.055651</td>\n",
       "      <td>0.002176</td>\n",
       "      <td>0.007880</td>\n",
       "      <td>0.001042</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>4</td>\n",
       "      <td>50</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.828111</td>\n",
       "      <td>0.042532</td>\n",
       "      <td>829</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1215 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0          0.017553      0.003160         0.006982        0.000446   \n",
       "1          0.014960      0.000446         0.007181        0.000399   \n",
       "2          0.014760      0.001323         0.006583        0.000798   \n",
       "3          0.020445      0.002610         0.005785        0.000870   \n",
       "4          0.022241      0.002404         0.006483        0.000499   \n",
       "...             ...           ...              ...             ...   \n",
       "1210       0.039993      0.000829         0.007979        0.000446   \n",
       "1211       0.057798      0.044078         0.008179        0.002352   \n",
       "1212       0.065325      0.017959         0.008279        0.000779   \n",
       "1213       0.067819      0.006180         0.008378        0.001196   \n",
       "1214       0.055651      0.002176         0.007880        0.001042   \n",
       "\n",
       "     param_colsample_bylevel param_colsample_bytree param_gamma  \\\n",
       "0                        0.2                    0.4           0   \n",
       "1                        0.2                    0.4           0   \n",
       "2                        0.2                    0.4           0   \n",
       "3                        0.2                    0.4           0   \n",
       "4                        0.2                    0.4           0   \n",
       "...                      ...                    ...         ...   \n",
       "1210                     0.4                    0.9           1   \n",
       "1211                     0.4                    0.9           1   \n",
       "1212                     0.4                    0.9           1   \n",
       "1213                     0.4                    0.9           1   \n",
       "1214                     0.4                    0.9           1   \n",
       "\n",
       "     param_learning_rate param_max_depth param_n_estimators  ...  \\\n",
       "0                    0.2               2                 10  ...   \n",
       "1                    0.2               2                 10  ...   \n",
       "2                    0.2               2                 10  ...   \n",
       "3                    0.2               2                 20  ...   \n",
       "4                    0.2               2                 20  ...   \n",
       "...                  ...             ...                ...  ...   \n",
       "1210                 0.2               4                 40  ...   \n",
       "1211                 0.2               4                 40  ...   \n",
       "1212                 0.2               4                 50  ...   \n",
       "1213                 0.2               4                 50  ...   \n",
       "1214                 0.2               4                 50  ...   \n",
       "\n",
       "     split3_test_score split4_test_score  split5_test_score  \\\n",
       "0             0.838710          0.661290           0.790323   \n",
       "1             0.854839          0.693548           0.790323   \n",
       "2             0.838710          0.725806           0.790323   \n",
       "3             0.838710          0.774194           0.838710   \n",
       "4             0.838710          0.774194           0.903226   \n",
       "...                ...               ...                ...   \n",
       "1210          0.870968          0.822581           0.854839   \n",
       "1211          0.854839          0.822581           0.806452   \n",
       "1212          0.838710          0.822581           0.790323   \n",
       "1213          0.838710          0.822581           0.822581   \n",
       "1214          0.870968          0.822581           0.790323   \n",
       "\n",
       "      split6_test_score  split7_test_score  split8_test_score  \\\n",
       "0              0.774194           0.661290           0.709677   \n",
       "1              0.774194           0.693548           0.693548   \n",
       "2              0.774194           0.677419           0.693548   \n",
       "3              0.806452           0.709677           0.709677   \n",
       "4              0.806452           0.741935           0.693548   \n",
       "...                 ...                ...                ...   \n",
       "1210           0.887097           0.838710           0.741935   \n",
       "1211           0.854839           0.822581           0.725806   \n",
       "1212           0.854839           0.838710           0.693548   \n",
       "1213           0.870968           0.838710           0.725806   \n",
       "1214           0.854839           0.806452           0.725806   \n",
       "\n",
       "      split9_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0              0.790323         0.763850        0.060953             1214  \n",
       "1              0.774194         0.768689        0.054639             1210  \n",
       "2              0.774194         0.765515        0.050031             1211  \n",
       "3              0.806452         0.800768        0.050666             1196  \n",
       "4              0.806452         0.805658        0.055483             1176  \n",
       "...                 ...              ...             ...              ...  \n",
       "1210           0.854839         0.850589        0.041824                6  \n",
       "1211           0.822581         0.823349        0.036404              966  \n",
       "1212           0.854839         0.834434        0.055885              546  \n",
       "1213           0.854839         0.837737        0.042732              317  \n",
       "1214           0.838710         0.828111        0.042532              829  \n",
       "\n",
       "[1215 rows x 25 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score is 0.8522529441884281 with params {'colsample_bylevel': 0.2, 'colsample_bytree': 0.9, 'gamma': 0.5, 'learning_rate': 0.2, 'max_depth': 2, 'n_estimators': 30, 'subsample': 0.6}\n"
     ]
    }
   ],
   "source": [
    "# Full Tuning - Part 6\n",
    "random.seed(10)\n",
    "\n",
    "xgb = XGBClassifier()\n",
    "\n",
    "xgb_parameters = {'max_depth': [2,3,4]\n",
    "                   , 'subsample': [0.6, 0.8, 0.9]\n",
    "                   , 'gamma': [0, 0.5, 1]\n",
    "                   , 'colsample_bytree': [0.4, 0.5, 0.9]\n",
    "                   , 'colsample_bylevel': [0.2, 0.3, 0.4]\n",
    "                   , 'learning_rate': [0.2]\n",
    "                   , 'n_estimators': [10, 20, 30, 40, 50]}\n",
    "\n",
    "stratified_10_fold_cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "xgb_grid_search = GridSearchCV(xgb, xgb_parameters, scoring='accuracy', cv=stratified_10_fold_cv)\n",
    "\n",
    "xgb_grid_search.fit(X_train, y_train)\n",
    "\n",
    "xgb_grid_search_results_full_6 = pd.DataFrame(xgb_grid_search.cv_results_)\n",
    "display(xgb_grid_search_results_full_6)\n",
    "\n",
    "print(\"best score is {} with params {}\".format(xgb_grid_search.best_score_, xgb_grid_search.best_params_))\n",
    "#best score is 0.8522529441884281 with params\n",
    "#{'colsample_bylevel': 0.2, 'colsample_bytree': 0.9, 'gamma': 0.5, 'learning_rate': 0.2, 'max_depth': 2, 'n_estimators': 30, 'subsample': 0.6}\n",
    "\n",
    "# save dataframe\n",
    "from datetime import datetime\n",
    "date = str(datetime.now().date()).replace(\"-\", \"\")\n",
    "xgb_grid_search_results_full_6.to_csv(f\"results/xgb_results_full_round4_6_learning=0.2_r3_{date}.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57b04632",
   "metadata": {},
   "source": [
    "Combine single hyper parameter tuning to find best values for hyper parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9a382288",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_colsample_bylevel</th>\n",
       "      <th>param_colsample_bytree</th>\n",
       "      <th>param_gamma</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>...</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.021696</td>\n",
       "      <td>0.004852</td>\n",
       "      <td>0.009495</td>\n",
       "      <td>0.002555</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.661290</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.661290</td>\n",
       "      <td>0.661290</td>\n",
       "      <td>0.661290</td>\n",
       "      <td>0.720430</td>\n",
       "      <td>0.052226</td>\n",
       "      <td>4858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.023734</td>\n",
       "      <td>0.003344</td>\n",
       "      <td>0.010269</td>\n",
       "      <td>0.002012</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.661290</td>\n",
       "      <td>0.629032</td>\n",
       "      <td>0.661290</td>\n",
       "      <td>0.720405</td>\n",
       "      <td>0.060569</td>\n",
       "      <td>4860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.021329</td>\n",
       "      <td>0.002649</td>\n",
       "      <td>0.009234</td>\n",
       "      <td>0.001687</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.645161</td>\n",
       "      <td>0.645161</td>\n",
       "      <td>0.661290</td>\n",
       "      <td>0.723630</td>\n",
       "      <td>0.057244</td>\n",
       "      <td>4855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.031445</td>\n",
       "      <td>0.001912</td>\n",
       "      <td>0.009800</td>\n",
       "      <td>0.001109</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>...</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.760599</td>\n",
       "      <td>0.045057</td>\n",
       "      <td>4835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.034447</td>\n",
       "      <td>0.002939</td>\n",
       "      <td>0.010506</td>\n",
       "      <td>0.001006</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>...</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.760625</td>\n",
       "      <td>0.047805</td>\n",
       "      <td>4834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4855</th>\n",
       "      <td>0.039993</td>\n",
       "      <td>0.000829</td>\n",
       "      <td>0.007979</td>\n",
       "      <td>0.000446</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.20</td>\n",
       "      <td>4</td>\n",
       "      <td>40</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.887097</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.850589</td>\n",
       "      <td>0.041824</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4856</th>\n",
       "      <td>0.057798</td>\n",
       "      <td>0.044078</td>\n",
       "      <td>0.008179</td>\n",
       "      <td>0.002352</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.20</td>\n",
       "      <td>4</td>\n",
       "      <td>40</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.823349</td>\n",
       "      <td>0.036404</td>\n",
       "      <td>3249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4857</th>\n",
       "      <td>0.065325</td>\n",
       "      <td>0.017959</td>\n",
       "      <td>0.008279</td>\n",
       "      <td>0.000779</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.20</td>\n",
       "      <td>4</td>\n",
       "      <td>50</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.834434</td>\n",
       "      <td>0.055885</td>\n",
       "      <td>1740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4858</th>\n",
       "      <td>0.067819</td>\n",
       "      <td>0.006180</td>\n",
       "      <td>0.008378</td>\n",
       "      <td>0.001196</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.20</td>\n",
       "      <td>4</td>\n",
       "      <td>50</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.837737</td>\n",
       "      <td>0.042732</td>\n",
       "      <td>1033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4859</th>\n",
       "      <td>0.055651</td>\n",
       "      <td>0.002176</td>\n",
       "      <td>0.007880</td>\n",
       "      <td>0.001042</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.20</td>\n",
       "      <td>4</td>\n",
       "      <td>50</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.828111</td>\n",
       "      <td>0.042532</td>\n",
       "      <td>2692</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4860 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0          0.021696      0.004852         0.009495        0.002555   \n",
       "1          0.023734      0.003344         0.010269        0.002012   \n",
       "2          0.021329      0.002649         0.009234        0.001687   \n",
       "3          0.031445      0.001912         0.009800        0.001109   \n",
       "4          0.034447      0.002939         0.010506        0.001006   \n",
       "...             ...           ...              ...             ...   \n",
       "4855       0.039993      0.000829         0.007979        0.000446   \n",
       "4856       0.057798      0.044078         0.008179        0.002352   \n",
       "4857       0.065325      0.017959         0.008279        0.000779   \n",
       "4858       0.067819      0.006180         0.008378        0.001196   \n",
       "4859       0.055651      0.002176         0.007880        0.001042   \n",
       "\n",
       "      param_colsample_bylevel  param_colsample_bytree  param_gamma  \\\n",
       "0                         0.2                     0.4          0.0   \n",
       "1                         0.2                     0.4          0.0   \n",
       "2                         0.2                     0.4          0.0   \n",
       "3                         0.2                     0.4          0.0   \n",
       "4                         0.2                     0.4          0.0   \n",
       "...                       ...                     ...          ...   \n",
       "4855                      0.4                     0.9          1.0   \n",
       "4856                      0.4                     0.9          1.0   \n",
       "4857                      0.4                     0.9          1.0   \n",
       "4858                      0.4                     0.9          1.0   \n",
       "4859                      0.4                     0.9          1.0   \n",
       "\n",
       "      param_learning_rate  param_max_depth  param_n_estimators  ...  \\\n",
       "0                    0.05                2                  10  ...   \n",
       "1                    0.05                2                  10  ...   \n",
       "2                    0.05                2                  10  ...   \n",
       "3                    0.05                2                  20  ...   \n",
       "4                    0.05                2                  20  ...   \n",
       "...                   ...              ...                 ...  ...   \n",
       "4855                 0.20                4                  40  ...   \n",
       "4856                 0.20                4                  40  ...   \n",
       "4857                 0.20                4                  50  ...   \n",
       "4858                 0.20                4                  50  ...   \n",
       "4859                 0.20                4                  50  ...   \n",
       "\n",
       "      split3_test_score split4_test_score  split5_test_score  \\\n",
       "0              0.741935          0.661290           0.758065   \n",
       "1              0.774194          0.677419           0.758065   \n",
       "2              0.741935          0.709677           0.774194   \n",
       "3              0.774194          0.741935           0.790323   \n",
       "4              0.806452          0.725806           0.790323   \n",
       "...                 ...               ...                ...   \n",
       "4855           0.870968          0.822581           0.854839   \n",
       "4856           0.854839          0.822581           0.806452   \n",
       "4857           0.838710          0.822581           0.790323   \n",
       "4858           0.838710          0.822581           0.822581   \n",
       "4859           0.870968          0.822581           0.790323   \n",
       "\n",
       "      split6_test_score  split7_test_score  split8_test_score  \\\n",
       "0              0.725806           0.661290           0.661290   \n",
       "1              0.693548           0.661290           0.629032   \n",
       "2              0.709677           0.645161           0.645161   \n",
       "3              0.758065           0.693548           0.709677   \n",
       "4              0.774194           0.693548           0.693548   \n",
       "...                 ...                ...                ...   \n",
       "4855           0.887097           0.838710           0.741935   \n",
       "4856           0.854839           0.822581           0.725806   \n",
       "4857           0.854839           0.838710           0.693548   \n",
       "4858           0.870968           0.838710           0.725806   \n",
       "4859           0.854839           0.806452           0.725806   \n",
       "\n",
       "      split9_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0              0.661290         0.720430        0.052226             4858  \n",
       "1              0.661290         0.720405        0.060569             4860  \n",
       "2              0.661290         0.723630        0.057244             4855  \n",
       "3              0.709677         0.760599        0.045057             4835  \n",
       "4              0.709677         0.760625        0.047805             4834  \n",
       "...                 ...              ...             ...              ...  \n",
       "4855           0.854839         0.850589        0.041824               18  \n",
       "4856           0.822581         0.823349        0.036404             3249  \n",
       "4857           0.854839         0.834434        0.055885             1740  \n",
       "4858           0.854839         0.837737        0.042732             1033  \n",
       "4859           0.838710         0.828111        0.042532             2692  \n",
       "\n",
       "[4860 rows x 25 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score is 0.856989 with params {'colsample_bylevel': 0.4, 'colsample_bytree': 0.4, 'gamma': 1, 'learning_rate': 0.15, 'max_depth': 4, 'n_estimators': 30, 'subsample': 0.9}\n"
     ]
    }
   ],
   "source": [
    "# read single parts of round 3, concatenate and update index and rank_test_score\n",
    "\n",
    "df2 = pd.read_csv(\"data\\\\xgb_results_full_2_learning=0.05_r3_20221124.csv\")\n",
    "df2.drop(df2.columns[0], axis=1, inplace=True)\n",
    "\n",
    "df4 = pd.read_csv(\"data\\\\xgb_results_full_4_learning=0.1_r3_20221124.csv\")\n",
    "df4.drop(df4.columns[0], axis=1, inplace=True)\n",
    "\n",
    "df5 = pd.read_csv(\"data\\\\xgb_results_full_5_learning=0.15_r3_20221124.csv\")\n",
    "df5.drop(df5.columns[0], axis=1, inplace=True)\n",
    "\n",
    "df6 = pd.read_csv(\"data\\\\xgb_results_full_6_learning=0.2_r3_20221124.csv\")\n",
    "df6.drop(df6.columns[0], axis=1, inplace=True)\n",
    "\n",
    "df_full = pd.concat([df2,df4,df5,df6])\n",
    "\n",
    "#assign correct rank\n",
    "df_full = df_full.sort_values(by='mean_test_score', ascending=False)\n",
    "df_full['rank_test_score'] = range(1, len(df_full)+1)\n",
    "\n",
    "#get correct order and set new index\n",
    "df_full = df_full.sort_values(by=['param_colsample_bylevel', 'param_colsample_bytree', 'param_gamma', 'param_learning_rate', 'param_max_depth', 'param_n_estimators', 'param_subsample'])\n",
    "xgb_grid_search_results_round4 = df_full.set_index(np.array(range(len(df_full))))\n",
    "display(xgb_grid_search_results_round4)\n",
    "\n",
    "print(\"best score is 0.856989 with params {'colsample_bylevel': 0.4, 'colsample_bytree': 0.4, 'gamma': 1, 'learning_rate': 0.15, 'max_depth': 4, 'n_estimators': 30, 'subsample': 0.9}\")\n",
    "\n",
    "# save dataframe\n",
    "from datetime import datetime\n",
    "date = str(datetime.now().date()).replace(\"-\", \"\")\n",
    "xgb_grid_search_results_round4.to_csv(f\"results/xgb_results_round4_{date}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "137cdd22",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_subsample</th>\n",
       "      <th>param_colsample_bylevel</th>\n",
       "      <th>param_colsample_bytree</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_gamma</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3728</th>\n",
       "      <td>4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.15</td>\n",
       "      <td>30</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.856989</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3714</th>\n",
       "      <td>3</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.15</td>\n",
       "      <td>40</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.853840</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1401</th>\n",
       "      <td>2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.20</td>\n",
       "      <td>30</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.852253</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1551</th>\n",
       "      <td>3</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.15</td>\n",
       "      <td>30</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.852227</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1596</th>\n",
       "      <td>3</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.20</td>\n",
       "      <td>30</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.852202</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.05</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.722043</td>\n",
       "      <td>4856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.05</td>\n",
       "      <td>10</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.720430</td>\n",
       "      <td>4857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.05</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.720430</td>\n",
       "      <td>4858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>2</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.05</td>\n",
       "      <td>10</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.720405</td>\n",
       "      <td>4859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.05</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.720405</td>\n",
       "      <td>4860</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4860 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      param_max_depth  param_subsample  param_colsample_bylevel  \\\n",
       "3728                4              0.9                      0.4   \n",
       "3714                3              0.6                      0.4   \n",
       "1401                2              0.6                      0.2   \n",
       "1551                3              0.6                      0.2   \n",
       "1596                3              0.6                      0.2   \n",
       "...               ...              ...                      ...   \n",
       "360                 2              0.6                      0.2   \n",
       "180                 2              0.6                      0.2   \n",
       "0                   2              0.6                      0.2   \n",
       "181                 2              0.8                      0.2   \n",
       "1                   2              0.8                      0.2   \n",
       "\n",
       "      param_colsample_bytree  param_learning_rate  param_n_estimators  \\\n",
       "3728                     0.4                 0.15                  30   \n",
       "3714                     0.4                 0.15                  40   \n",
       "1401                     0.9                 0.20                  30   \n",
       "1551                     0.9                 0.15                  30   \n",
       "1596                     0.9                 0.20                  30   \n",
       "...                      ...                  ...                 ...   \n",
       "360                      0.4                 0.05                  10   \n",
       "180                      0.4                 0.05                  10   \n",
       "0                        0.4                 0.05                  10   \n",
       "181                      0.4                 0.05                  10   \n",
       "1                        0.4                 0.05                  10   \n",
       "\n",
       "      param_gamma  mean_test_score  rank_test_score  \n",
       "3728          1.0         0.856989                1  \n",
       "3714          1.0         0.853840                2  \n",
       "1401          0.5         0.852253                3  \n",
       "1551          1.0         0.852227                4  \n",
       "1596          1.0         0.852202                5  \n",
       "...           ...              ...              ...  \n",
       "360           1.0         0.722043             4856  \n",
       "180           0.5         0.720430             4857  \n",
       "0             0.0         0.720430             4858  \n",
       "181           0.5         0.720405             4859  \n",
       "1             0.0         0.720405             4860  \n",
       "\n",
       "[4860 rows x 9 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# store relevant columns and sort by rank_test_score\n",
    "cols_round4 = ['param_max_depth', 'param_subsample', 'param_colsample_bylevel', 'param_colsample_bytree', 'param_learning_rate', 'param_n_estimators', 'param_gamma', 'mean_test_score', 'rank_test_score']\n",
    "xgb_results_round4_sorted = xgb_grid_search_results_round4[cols_round4]\n",
    "xgb_results_round4_sorted = xgb_results_round4_sorted.sort_values(by='rank_test_score')\n",
    "display(xgb_results_round4_sorted)\n",
    "\n",
    "# save dataframe\n",
    "from datetime import datetime\n",
    "date = str(datetime.now().date()).replace(\"-\", \"\")\n",
    "xgb_results_round4_sorted.to_csv(f\"results/xgb_results_round4_sorted_{date}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f31aba85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.8171641791044776\n",
      "F1 Score = 0.7655502392344496\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.89      0.85       157\n",
      "           1       0.82      0.72      0.77       111\n",
      "\n",
      "    accuracy                           0.82       268\n",
      "   macro avg       0.82      0.80      0.81       268\n",
      "weighted avg       0.82      0.82      0.82       268\n",
      "\n",
      "Confusion Matrix:\n",
      "[[139  18]\n",
      " [ 31  80]]\n"
     ]
    }
   ],
   "source": [
    "# Fit and evaluate best model\n",
    "\n",
    "xgb_best = XGBClassifier(max_depth = 4, subsample = 0.9, colsample_bylevel = 0.4, colsample_bytree = 0.4, learning_rate = 0.15, n_estimators = 30, gamma = 1)\n",
    "xgb_best.fit(X_train, y_train)\n",
    "xgb_best_pred = xgb_best.predict(X_test)\n",
    "\n",
    "xgb_best_acc = accuracy_score(y_test, xgb_best_pred)\n",
    "print(\"Accuracy =\", xgb_best_acc) #0.8283582089552238\n",
    "\n",
    "xgb_best_f1 = f1_score(y_test, xgb_best_pred)\n",
    "print(\"F1 Score =\", xgb_best_f1) #0.7788461538461539\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, xgb_best_pred))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, xgb_best_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10317046",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba1a3507",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9882d10e",
   "metadata": {},
   "source": [
    "## Best Model by trying out some combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9a358d23",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.8470149253731343\n",
      "F1 Score = 0.8093023255813953\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.89      0.87       157\n",
      "           1       0.84      0.78      0.81       111\n",
      "\n",
      "    accuracy                           0.85       268\n",
      "   macro avg       0.85      0.84      0.84       268\n",
      "weighted avg       0.85      0.85      0.85       268\n",
      "\n",
      "Confusion Matrix:\n",
      "[[140  17]\n",
      " [ 24  87]]\n"
     ]
    }
   ],
   "source": [
    "# Fit and evaluate best model\n",
    "\n",
    "xgb_best = XGBClassifier(max_depth = 2, subsample = 0.7, colsample_bylevel = 0.4, colsample_bytree = 0.9, learning_rate = 0.7, n_estimators = 30, gamma = 1)\n",
    "xgb_best.fit(X_train, y_train)\n",
    "xgb_best_pred = xgb_best.predict(X_test)\n",
    "\n",
    "xgb_best_acc = accuracy_score(y_test, xgb_best_pred)\n",
    "print(\"Accuracy =\", xgb_best_acc) #0.8470149253731343\n",
    "\n",
    "xgb_best_f1 = f1_score(y_test, xgb_best_pred)\n",
    "print(\"F1 Score =\", xgb_best_f1) #0.8093023255813953\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, xgb_best_pred))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, xgb_best_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c9dbc2fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance2 = xgb_best.feature_importances_\n",
    "feature_names2 = list(X_train.columns)\n",
    "\n",
    "feature_importance = []\n",
    "feature_names = []\n",
    "feature_importance2 = list(feature_importance2)\n",
    "for i in range(len(feature_importance2)):\n",
    "    m = min(feature_importance2)\n",
    "    idx = feature_importance2.index(m)\n",
    "    feature_importance.append(m)\n",
    "    feature_names.append(feature_names2[idx])\n",
    "    feature_importance2.pop(idx)\n",
    "    feature_names2.pop(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "318e6206",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "#plt.margins(0,0)\n",
    "plt.rc('font', size=13)\n",
    "plt.tight_layout()\n",
    "plt.barh(feature_names, feature_importance)\n",
    "plt.savefig(\"figures\\\\feature_importance_xgb.jpg\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e922a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "991bf8fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "c8101d7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.746268656716418 with params max_depth = 2 subsample = 0.7 colsample_bylevel = 0.2 colsample_bytree = 0.5 learning_rate = 0.1 n_estimators = 30 gamma = 0\n",
      "0.7611940298507462 with params max_depth = 2 subsample = 0.7 colsample_bylevel = 0.2 colsample_bytree = 0.5 learning_rate = 0.15 n_estimators = 30 gamma = 0\n",
      "0.8208955223880597 with params max_depth = 2 subsample = 0.7 colsample_bylevel = 0.2 colsample_bytree = 0.5 learning_rate = 0.7 n_estimators = 30 gamma = 0\n",
      "0.832089552238806 with params max_depth = 2 subsample = 0.7 colsample_bylevel = 0.3 colsample_bytree = 0.6 learning_rate = 0.1 n_estimators = 30 gamma = 0\n",
      "0.835820895522388 with params max_depth = 2 subsample = 0.7 colsample_bylevel = 0.4 colsample_bytree = 0.9 learning_rate = 0.15 n_estimators = 30 gamma = 0\n",
      "0.8470149253731343 with params max_depth = 2 subsample = 0.7 colsample_bylevel = 0.4 colsample_bytree = 0.9 learning_rate = 0.7 n_estimators = 30 gamma = 1\n"
     ]
    }
   ],
   "source": [
    "# n = 90\n",
    "max_acc = 0\n",
    "for m in [2,3,4]:\n",
    "    for s in [0.7, 0.8, 0.9]:\n",
    "        for g in [0,1]:\n",
    "            for t in [0.5, 0.6, 0.9]:\n",
    "                for l in [0.2, 0.3, 0.4]:\n",
    "                    for r in [0.1, 0.15, 0.7]:\n",
    "                        xgb = XGBClassifier(max_depth = m, subsample = s, colsample_bylevel = l, colsample_bytree = t, learning_rate = r, n_estimators = 30, gamma = g)\n",
    "                        xgb.fit(X_train, y_train)\n",
    "                        pred = xgb.predict(X_test)\n",
    "                        acc = accuracy_score(y_test, pred)\n",
    "                        if acc > max_acc:\n",
    "                            max_acc = acc\n",
    "                            print(acc, \"with params max_depth =\", m, \"subsample =\", s, \"colsample_bylevel =\", l, \"colsample_bytree =\", t, \"learning_rate =\", r, \"n_estimators =\", 30, \"gamma =\", g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86652b50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ab4d20",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
