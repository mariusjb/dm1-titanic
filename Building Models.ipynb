{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7104d2ce",
   "metadata": {},
   "source": [
    "# Building Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "202391f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load required packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ce61838",
   "metadata": {},
   "source": [
    "## Train and Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "de0a10cb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Age_true</th>\n",
       "      <th>AgeGroup</th>\n",
       "      <th>FareGroup</th>\n",
       "      <th>CabinLvl</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "      <th>Title_Master</th>\n",
       "      <th>Title_Mr</th>\n",
       "      <th>Title_Mrs</th>\n",
       "      <th>Title_Ms</th>\n",
       "      <th>Title_Noble</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pclass  SibSp  Parch  Age_true  AgeGroup  FareGroup  CabinLvl  Embarked_C  \\\n",
       "0       1      0      2         1         0          4         7           0   \n",
       "1       3      0      0         0         3          1         0           0   \n",
       "2       3      1      1         1         0          2         0           0   \n",
       "3       2      1      2         1         4          3         0           0   \n",
       "4       2      1      1         1         4          3         0           0   \n",
       "\n",
       "   Embarked_Q  Embarked_S  Title_Master  Title_Mr  Title_Mrs  Title_Ms  \\\n",
       "0           0           1             1         0          0         0   \n",
       "1           0           1             0         1          0         0   \n",
       "2           0           1             0         0          0         1   \n",
       "3           0           1             0         1          0         0   \n",
       "4           0           1             0         1          0         0   \n",
       "\n",
       "   Title_Noble  Survived  \n",
       "0            0         1  \n",
       "1            0         0  \n",
       "2            0         1  \n",
       "3            0         0  \n",
       "4            0         0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Age_true</th>\n",
       "      <th>AgeGroup</th>\n",
       "      <th>FareGroup</th>\n",
       "      <th>CabinLvl</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "      <th>Title_Master</th>\n",
       "      <th>Title_Mr</th>\n",
       "      <th>Title_Mrs</th>\n",
       "      <th>Title_Ms</th>\n",
       "      <th>Title_Noble</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pclass  SibSp  Parch  Age_true  AgeGroup  FareGroup  CabinLvl  Embarked_C  \\\n",
       "0       3      1      1         0         0          2         0           1   \n",
       "1       2      0      0         1         3          1         0           0   \n",
       "2       3      0      0         1         2          1         0           0   \n",
       "3       2      0      1         1         0          3         0           0   \n",
       "4       3      1      0         1         1          2         0           1   \n",
       "\n",
       "   Embarked_Q  Embarked_S  Title_Master  Title_Mr  Title_Mrs  Title_Ms  \\\n",
       "0           0           0             1         0          0         0   \n",
       "1           0           1             0         1          0         0   \n",
       "2           0           1             0         1          0         0   \n",
       "3           0           1             0         0          0         1   \n",
       "4           0           0             0         0          0         1   \n",
       "\n",
       "   Title_Noble  Survived  \n",
       "0            0         1  \n",
       "1            0         0  \n",
       "2            0         0  \n",
       "3            0         1  \n",
       "4            0         1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# read train and test data\n",
    "\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "# train_data\n",
    "train_data_files = sorted([f for f in os.listdir(\"data\") if (f.endswith(\".csv\") and (f.startswith(\"train_data_\")))], reverse=True)\n",
    "latest_train_data = train_data_files[0]\n",
    "train_data = pd.read_csv(f\"data/{latest_train_data}\")\n",
    "\n",
    "# drop new generated index column\n",
    "train_data.drop(train_data.columns[0], axis=1, inplace=True)\n",
    "display(train_data.head())\n",
    "\n",
    "# split train_data for models\n",
    "y_train = train_data['Survived']\n",
    "X_train = train_data.drop('Survived', axis=1)\n",
    "\n",
    "\n",
    "# test_data\n",
    "test_data_files = sorted([f for f in os.listdir(\"data\") if (f.endswith(\".csv\") and (f.startswith(\"test_data_\")))], reverse=True)\n",
    "latest_test_data = test_data_files[0]\n",
    "test_data = pd.read_csv(f\"data/{latest_test_data}\")\n",
    "\n",
    "#drop new generated index column\n",
    "test_data.drop(test_data.columns[0], axis=1, inplace=True)\n",
    "display(test_data.head())\n",
    "\n",
    "# split test_data for models\n",
    "y_test = test_data['Survived']\n",
    "X_test = test_data.drop('Survived', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa37aba1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "675b47e0",
   "metadata": {},
   "source": [
    "## Baseline Model\n",
    "\n",
    "We build a model which predicts \"Survival\" (Class 1) for first-class passengers and \"No Survival\" (Class 0) if a passenger has ticket class 2 or 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "149eba15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.585820895522388\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      1.00      0.74       157\n",
      "           1       0.00      0.00      0.00       111\n",
      "\n",
      "    accuracy                           0.59       268\n",
      "   macro avg       0.29      0.50      0.37       268\n",
      "weighted avg       0.34      0.59      0.43       268\n",
      "\n",
      "Confusion Matrix:\n",
      "[[157   0]\n",
      " [111   0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kikip\\anaconda3\\envs\\dm1_hws22\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\kikip\\anaconda3\\envs\\dm1_hws22\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\kikip\\anaconda3\\envs\\dm1_hws22\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Option A - predict \"No Survival\" for all passengers\n",
    "train_data.groupby('Survived').size()\n",
    "\n",
    "baseline_pred_A = pd.Series(np.zeros(len(y_test)))\n",
    "\n",
    "baseline_acc_A = accuracy_score(y_test, baseline_pred_A)\n",
    "print(baseline_acc_A)\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, baseline_pred_A))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, baseline_pred_A))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "62b13d8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pclass  Survived\n",
      "1       0            56\n",
      "        1            83\n",
      "2       0            69\n",
      "        1            63\n",
      "3       0           267\n",
      "        1            85\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Option B - predict \"Survival\" or \"No Survival\" based on 'Pclass'\n",
    "\n",
    "# for each 'PClass' find number of passengers that survived and did not survive\n",
    "print(train_data.groupby(['Pclass', 'Survived']).size())\n",
    "# if 'Pclass'==1, we predict 'Survived'=1, else we predict 'Survived'=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3a04d4b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6940298507462687\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.85      0.76       157\n",
      "           1       0.69      0.48      0.56       111\n",
      "\n",
      "    accuracy                           0.69       268\n",
      "   macro avg       0.69      0.66      0.66       268\n",
      "weighted avg       0.69      0.69      0.68       268\n",
      "\n",
      "Confusion Matrix:\n",
      "[[133  24]\n",
      " [ 58  53]]\n"
     ]
    }
   ],
   "source": [
    "# make prediction\n",
    "X_test['baseline_pred_B'] = 0\n",
    "X_test.loc[X_test['Pclass'] == 1, 'baseline_pred_B'] = 1\n",
    "baseline_pred_B = X_test.baseline_pred_B\n",
    "X_test.drop('baseline_pred_B', axis=1, inplace=True)\n",
    "\n",
    "# print performance measures\n",
    "baseline_acc_B = accuracy_score(y_test, baseline_pred_B)\n",
    "print(baseline_acc_B)\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, baseline_pred_B))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, baseline_pred_B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b87fee6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "41d03a15",
   "metadata": {},
   "source": [
    "## XGBoost\n",
    "\n",
    "https://www.datacamp.com/tutorial/xgboost-in-python  \n",
    "https://thinkingneuron.com/how-to-create-a-classification-model-using-xgboost-in-python/  \n",
    "https://towardsdatascience.com/a-guide-to-xgboost-hyperparameters-87980c7f44a9 (Hyperparameter Cheatsheet)  \n",
    "https://towardsdatascience.com/beyond-grid-search-hypercharge-hyperparameter-tuning-for-xgboost-7c78f7a2929d (Step by Step Tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "556c7c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a74371cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "949742ca",
   "metadata": {},
   "source": [
    "### Simple XGB-Classifier with default parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0a53a8be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8097014925373134\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.89      0.84       157\n",
      "           1       0.81      0.70      0.75       111\n",
      "\n",
      "    accuracy                           0.81       268\n",
      "   macro avg       0.81      0.79      0.80       268\n",
      "weighted avg       0.81      0.81      0.81       268\n",
      "\n",
      "Confusion Matrix:\n",
      "[[139  18]\n",
      " [ 33  78]]\n"
     ]
    }
   ],
   "source": [
    "# simple XGB-Classifier with default parameters\n",
    "\n",
    "random.seed(10)\n",
    "\n",
    "xgb_simple = XGBClassifier()\n",
    "xgb_simple.fit(X_train, y_train)\n",
    "xgb_simple_pred = xgb_simple.predict(X_test)\n",
    "xgb_simple_acc = accuracy_score(y_test, xgb_simple_pred)\n",
    "print(xgb_simple_acc)\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, xgb_simple_pred))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, xgb_simple_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fb5892c",
   "metadata": {},
   "source": [
    "### Hyperparameter-Tuning for best parameter setting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "624c745e",
   "metadata": {},
   "source": [
    "#### First Attempt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ab20af8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_colsample_bylevel</th>\n",
       "      <th>param_colsample_bytree</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_subsample</th>\n",
       "      <th>...</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.037898</td>\n",
       "      <td>0.004635</td>\n",
       "      <td>0.005885</td>\n",
       "      <td>0.000537</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>3</td>\n",
       "      <td>50</td>\n",
       "      <td>0.3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.818433</td>\n",
       "      <td>0.049987</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.035405</td>\n",
       "      <td>0.000804</td>\n",
       "      <td>0.005785</td>\n",
       "      <td>0.001163</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>3</td>\n",
       "      <td>50</td>\n",
       "      <td>0.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.824885</td>\n",
       "      <td>0.055524</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.063929</td>\n",
       "      <td>0.001916</td>\n",
       "      <td>0.005785</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>0.3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.834485</td>\n",
       "      <td>0.040747</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.064627</td>\n",
       "      <td>0.001163</td>\n",
       "      <td>0.005486</td>\n",
       "      <td>0.000499</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>0.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.887097</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.836073</td>\n",
       "      <td>0.052347</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.036103</td>\n",
       "      <td>0.000746</td>\n",
       "      <td>0.005785</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "      <td>0.3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.818433</td>\n",
       "      <td>0.052027</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>0.099732</td>\n",
       "      <td>0.017440</td>\n",
       "      <td>0.006386</td>\n",
       "      <td>0.001114</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.7</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>0.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.823067</td>\n",
       "      <td>0.065056</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>0.058144</td>\n",
       "      <td>0.008638</td>\n",
       "      <td>0.006184</td>\n",
       "      <td>0.000598</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.7</td>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "      <td>0.3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.794470</td>\n",
       "      <td>0.050498</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>0.064428</td>\n",
       "      <td>0.012028</td>\n",
       "      <td>0.006785</td>\n",
       "      <td>0.000981</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.7</td>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "      <td>0.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.816846</td>\n",
       "      <td>0.053297</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>0.126063</td>\n",
       "      <td>0.022533</td>\n",
       "      <td>0.007381</td>\n",
       "      <td>0.001017</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.7</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>0.3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.803917</td>\n",
       "      <td>0.053965</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>0.107910</td>\n",
       "      <td>0.005584</td>\n",
       "      <td>0.006283</td>\n",
       "      <td>0.000457</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.7</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>0.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.812033</td>\n",
       "      <td>0.046151</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>64 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0        0.037898      0.004635         0.005885        0.000537   \n",
       "1        0.035405      0.000804         0.005785        0.001163   \n",
       "2        0.063929      0.001916         0.005785        0.000399   \n",
       "3        0.064627      0.001163         0.005486        0.000499   \n",
       "4        0.036103      0.000746         0.005785        0.000399   \n",
       "..            ...           ...              ...             ...   \n",
       "59       0.099732      0.017440         0.006386        0.001114   \n",
       "60       0.058144      0.008638         0.006184        0.000598   \n",
       "61       0.064428      0.012028         0.006785        0.000981   \n",
       "62       0.126063      0.022533         0.007381        0.001017   \n",
       "63       0.107910      0.005584         0.006283        0.000457   \n",
       "\n",
       "   param_colsample_bylevel param_colsample_bytree param_learning_rate  \\\n",
       "0                      0.3                    0.3                 0.3   \n",
       "1                      0.3                    0.3                 0.3   \n",
       "2                      0.3                    0.3                 0.3   \n",
       "3                      0.3                    0.3                 0.3   \n",
       "4                      0.3                    0.3                 0.3   \n",
       "..                     ...                    ...                 ...   \n",
       "59                     0.8                    0.8                 0.7   \n",
       "60                     0.8                    0.8                 0.7   \n",
       "61                     0.8                    0.8                 0.7   \n",
       "62                     0.8                    0.8                 0.7   \n",
       "63                     0.8                    0.8                 0.7   \n",
       "\n",
       "   param_max_depth param_n_estimators param_subsample  ... split3_test_score  \\\n",
       "0                3                 50             0.3  ...          0.854839   \n",
       "1                3                 50             0.8  ...          0.854839   \n",
       "2                3                100             0.3  ...          0.854839   \n",
       "3                3                100             0.8  ...          0.838710   \n",
       "4                5                 50             0.3  ...          0.854839   \n",
       "..             ...                ...             ...  ...               ...   \n",
       "59               3                100             0.8  ...          0.854839   \n",
       "60               5                 50             0.3  ...          0.838710   \n",
       "61               5                 50             0.8  ...          0.854839   \n",
       "62               5                100             0.3  ...          0.806452   \n",
       "63               5                100             0.8  ...          0.854839   \n",
       "\n",
       "    split4_test_score  split5_test_score  split6_test_score  \\\n",
       "0            0.790323           0.806452           0.790323   \n",
       "1            0.806452           0.870968           0.790323   \n",
       "2            0.822581           0.854839           0.790323   \n",
       "3            0.806452           0.887097           0.806452   \n",
       "4            0.774194           0.806452           0.806452   \n",
       "..                ...                ...                ...   \n",
       "59           0.790323           0.806452           0.822581   \n",
       "60           0.741935           0.741935           0.790323   \n",
       "61           0.790323           0.774194           0.822581   \n",
       "62           0.741935           0.741935           0.838710   \n",
       "63           0.790323           0.790323           0.854839   \n",
       "\n",
       "    split7_test_score  split8_test_score  split9_test_score  mean_test_score  \\\n",
       "0            0.822581           0.693548           0.854839         0.818433   \n",
       "1            0.822581           0.677419           0.854839         0.824885   \n",
       "2            0.822581           0.741935           0.838710         0.834485   \n",
       "3            0.822581           0.709677           0.854839         0.836073   \n",
       "4            0.806452           0.693548           0.870968         0.818433   \n",
       "..                ...                ...                ...              ...   \n",
       "59           0.758065           0.693548           0.806452         0.823067   \n",
       "60           0.838710           0.709677           0.854839         0.794470   \n",
       "61           0.822581           0.709677           0.838710         0.816846   \n",
       "62           0.774194           0.725806           0.838710         0.803917   \n",
       "63           0.774194           0.709677           0.806452         0.812033   \n",
       "\n",
       "    std_test_score  rank_test_score  \n",
       "0         0.049987               41  \n",
       "1         0.055524               23  \n",
       "2         0.040747                3  \n",
       "3         0.052347                2  \n",
       "4         0.052027               41  \n",
       "..             ...              ...  \n",
       "59        0.065056               33  \n",
       "60        0.050498               63  \n",
       "61        0.053297               50  \n",
       "62        0.053965               59  \n",
       "63        0.046151               53  \n",
       "\n",
       "[64 rows x 24 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score is 0.8360983102918587 with params {'colsample_bylevel': 0.3, 'colsample_bytree': 0.3, 'learning_rate': 0.7, 'max_depth': 3, 'n_estimators': 50, 'subsample': 0.8}\n"
     ]
    }
   ],
   "source": [
    "# Grid Search\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "random.seed(10)\n",
    "\n",
    "# create an estimator\n",
    "xgb = XGBClassifier()\n",
    "\n",
    "# specify the parameter grid\n",
    "xgb_parameters = {\n",
    "    'max_depth': [3, 5]\n",
    "    , 'subsample': [0.3, 0.8]\n",
    "    , 'colsample_bytree': [0.3, 0.8]\n",
    "    , 'colsample_bylevel': [0.3, 0.8]\n",
    "    , 'learning_rate': [0.3, 0.7]\n",
    "    , 'n_estimators': [50, 100]\n",
    "    #, 'gamma': [0.5, 1, 3]\n",
    "}\n",
    "\n",
    "# specify the cross validation\n",
    "stratified_10_fold_cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "# create grid search instance\n",
    "xgb_grid_search = GridSearchCV(xgb, xgb_parameters, scoring='accuracy', cv=stratified_10_fold_cv)\n",
    "#cv=stratified_10_fold_cv OR cv=10\n",
    "\n",
    "# run the grid search\n",
    "xgb_grid_search.fit(X_train, y_train)\n",
    "\n",
    "# print the results of all hyper-parameter combinations\n",
    "xgb_grid_search_results = pd.DataFrame(xgb_grid_search.cv_results_)\n",
    "display(xgb_grid_search_results)\n",
    "\n",
    "# print the best parameter setting\n",
    "print(\"best score is {} with params {}\".format(xgb_grid_search.best_score_, xgb_grid_search.best_params_))\n",
    "# cv=10: best score is 0.8410906298003071 with params {'colsample_bytree': 0.8, 'learning_rate': 0.3, 'max_depth': 5, 'n_estimators': 50}\n",
    "# stratcv: best score is 0.8344854070660522 with params {'colsample_bytree': 0.8, 'learning_rate': 0.3, 'max_depth': 3, 'n_estimators': 50}\n",
    "\n",
    "# stratcv: best score is 0.8360983102918587 with params {'colsample_bylevel': 0.3, 'colsample_bytree': 0.3, 'learning_rate': 0.7, 'max_depth': 3, 'n_estimators': 50, 'subsample': 0.8}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d6d4c5cd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8208955223880597\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.89      0.85       157\n",
      "           1       0.82      0.72      0.77       111\n",
      "\n",
      "    accuracy                           0.82       268\n",
      "   macro avg       0.82      0.81      0.81       268\n",
      "weighted avg       0.82      0.82      0.82       268\n",
      "\n",
      "Confusion Matrix:\n",
      "[[140  17]\n",
      " [ 31  80]]\n"
     ]
    }
   ],
   "source": [
    "# Fit and evaluate best model\n",
    "\n",
    "xgb_best = XGBClassifier(colsample_bylevel = 0.3, colsample_bytree = 0.3, learning_rate = 0.7, max_depth = 3, n_estimators = 50, subsample = 0.8)\n",
    "#0.8208955223880597\n",
    "xgb_best.fit(X_train, y_train)\n",
    "xgb_best_pred = xgb_best.predict(X_test)\n",
    "xgb_best_acc = accuracy_score(y_test, xgb_best_pred)\n",
    "print(xgb_best_acc)\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, xgb_best_pred))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, xgb_best_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7384224d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2d753d5d",
   "metadata": {},
   "source": [
    "#### Second Attempt: Step by Step Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9d7c2be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7a900b24",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.087154</td>\n",
       "      <td>0.004174</td>\n",
       "      <td>0.010836</td>\n",
       "      <td>0.001057</td>\n",
       "      <td>1</td>\n",
       "      <td>{'max_depth': 1}</td>\n",
       "      <td>0.841270</td>\n",
       "      <td>0.873016</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.887097</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.645161</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.828059</td>\n",
       "      <td>0.067254</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.094481</td>\n",
       "      <td>0.002924</td>\n",
       "      <td>0.010386</td>\n",
       "      <td>0.000974</td>\n",
       "      <td>2</td>\n",
       "      <td>{'max_depth': 2}</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.873016</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.831234</td>\n",
       "      <td>0.042811</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.110572</td>\n",
       "      <td>0.006613</td>\n",
       "      <td>0.011512</td>\n",
       "      <td>0.001681</td>\n",
       "      <td>3</td>\n",
       "      <td>{'max_depth': 3}</td>\n",
       "      <td>0.873016</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.839247</td>\n",
       "      <td>0.052996</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.126249</td>\n",
       "      <td>0.005697</td>\n",
       "      <td>0.011529</td>\n",
       "      <td>0.000684</td>\n",
       "      <td>4</td>\n",
       "      <td>{'max_depth': 4}</td>\n",
       "      <td>0.873016</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.840911</td>\n",
       "      <td>0.042800</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.124245</td>\n",
       "      <td>0.005004</td>\n",
       "      <td>0.010724</td>\n",
       "      <td>0.001062</td>\n",
       "      <td>5</td>\n",
       "      <td>{'max_depth': 5}</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.825397</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.829647</td>\n",
       "      <td>0.053972</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.135976</td>\n",
       "      <td>0.006056</td>\n",
       "      <td>0.010989</td>\n",
       "      <td>0.001387</td>\n",
       "      <td>6</td>\n",
       "      <td>{'max_depth': 6}</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.841270</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.826421</td>\n",
       "      <td>0.050897</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.153583</td>\n",
       "      <td>0.004269</td>\n",
       "      <td>0.011954</td>\n",
       "      <td>0.001374</td>\n",
       "      <td>7</td>\n",
       "      <td>{'max_depth': 7}</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.825397</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.826421</td>\n",
       "      <td>0.048206</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.164184</td>\n",
       "      <td>0.004594</td>\n",
       "      <td>0.011235</td>\n",
       "      <td>0.001078</td>\n",
       "      <td>8</td>\n",
       "      <td>{'max_depth': 8}</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.825397</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.821608</td>\n",
       "      <td>0.049133</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.175875</td>\n",
       "      <td>0.004721</td>\n",
       "      <td>0.011879</td>\n",
       "      <td>0.001131</td>\n",
       "      <td>9</td>\n",
       "      <td>{'max_depth': 9}</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.841270</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.821557</td>\n",
       "      <td>0.057062</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.184306</td>\n",
       "      <td>0.006106</td>\n",
       "      <td>0.010497</td>\n",
       "      <td>0.001322</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_depth': 10}</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.841270</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.823195</td>\n",
       "      <td>0.052047</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.189104</td>\n",
       "      <td>0.003913</td>\n",
       "      <td>0.011821</td>\n",
       "      <td>0.000954</td>\n",
       "      <td>11</td>\n",
       "      <td>{'max_depth': 11}</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.841270</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.824782</td>\n",
       "      <td>0.049718</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.195445</td>\n",
       "      <td>0.006807</td>\n",
       "      <td>0.011502</td>\n",
       "      <td>0.001110</td>\n",
       "      <td>12</td>\n",
       "      <td>{'max_depth': 12}</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.841270</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.823195</td>\n",
       "      <td>0.051545</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.197330</td>\n",
       "      <td>0.006292</td>\n",
       "      <td>0.012240</td>\n",
       "      <td>0.001282</td>\n",
       "      <td>13</td>\n",
       "      <td>{'max_depth': 13}</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.841270</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.819969</td>\n",
       "      <td>0.051482</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.198870</td>\n",
       "      <td>0.004559</td>\n",
       "      <td>0.011641</td>\n",
       "      <td>0.001339</td>\n",
       "      <td>14</td>\n",
       "      <td>{'max_depth': 14}</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.841270</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.819944</td>\n",
       "      <td>0.053963</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.220262</td>\n",
       "      <td>0.020288</td>\n",
       "      <td>0.011362</td>\n",
       "      <td>0.001438</td>\n",
       "      <td>15</td>\n",
       "      <td>{'max_depth': 15}</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.841270</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.826421</td>\n",
       "      <td>0.045499</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0        0.087154      0.004174         0.010836        0.001057   \n",
       "1        0.094481      0.002924         0.010386        0.000974   \n",
       "2        0.110572      0.006613         0.011512        0.001681   \n",
       "3        0.126249      0.005697         0.011529        0.000684   \n",
       "4        0.124245      0.005004         0.010724        0.001062   \n",
       "5        0.135976      0.006056         0.010989        0.001387   \n",
       "6        0.153583      0.004269         0.011954        0.001374   \n",
       "7        0.164184      0.004594         0.011235        0.001078   \n",
       "8        0.175875      0.004721         0.011879        0.001131   \n",
       "9        0.184306      0.006106         0.010497        0.001322   \n",
       "10       0.189104      0.003913         0.011821        0.000954   \n",
       "11       0.195445      0.006807         0.011502        0.001110   \n",
       "12       0.197330      0.006292         0.012240        0.001282   \n",
       "13       0.198870      0.004559         0.011641        0.001339   \n",
       "14       0.220262      0.020288         0.011362        0.001438   \n",
       "\n",
       "   param_max_depth             params  split0_test_score  split1_test_score  \\\n",
       "0                1   {'max_depth': 1}           0.841270           0.873016   \n",
       "1                2   {'max_depth': 2}           0.904762           0.857143   \n",
       "2                3   {'max_depth': 3}           0.873016           0.904762   \n",
       "3                4   {'max_depth': 4}           0.873016           0.904762   \n",
       "4                5   {'max_depth': 5}           0.888889           0.904762   \n",
       "5                6   {'max_depth': 6}           0.888889           0.888889   \n",
       "6                7   {'max_depth': 7}           0.904762           0.888889   \n",
       "7                8   {'max_depth': 8}           0.888889           0.888889   \n",
       "8                9   {'max_depth': 9}           0.904762           0.888889   \n",
       "9               10  {'max_depth': 10}           0.888889           0.888889   \n",
       "10              11  {'max_depth': 11}           0.904762           0.888889   \n",
       "11              12  {'max_depth': 12}           0.888889           0.888889   \n",
       "12              13  {'max_depth': 13}           0.888889           0.888889   \n",
       "13              14  {'max_depth': 14}           0.904762           0.888889   \n",
       "14              15  {'max_depth': 15}           0.888889           0.888889   \n",
       "\n",
       "    split2_test_score  split3_test_score  split4_test_score  \\\n",
       "0            0.888889           0.887097           0.838710   \n",
       "1            0.873016           0.870968           0.790323   \n",
       "2            0.888889           0.870968           0.806452   \n",
       "3            0.857143           0.870968           0.822581   \n",
       "4            0.825397           0.838710           0.822581   \n",
       "5            0.841270           0.854839           0.806452   \n",
       "6            0.825397           0.838710           0.790323   \n",
       "7            0.825397           0.838710           0.790323   \n",
       "8            0.841270           0.838710           0.790323   \n",
       "9            0.841270           0.838710           0.790323   \n",
       "10           0.841270           0.838710           0.790323   \n",
       "11           0.841270           0.838710           0.790323   \n",
       "12           0.841270           0.822581           0.790323   \n",
       "13           0.841270           0.838710           0.790323   \n",
       "14           0.841270           0.838710           0.790323   \n",
       "\n",
       "    split5_test_score  split6_test_score  split7_test_score  \\\n",
       "0            0.854839           0.822581           0.790323   \n",
       "1            0.790323           0.822581           0.822581   \n",
       "2            0.774194           0.838710           0.838710   \n",
       "3            0.774194           0.854839           0.838710   \n",
       "4            0.741935           0.854839           0.838710   \n",
       "5            0.774194           0.838710           0.822581   \n",
       "6            0.790323           0.838710           0.822581   \n",
       "7            0.758065           0.838710           0.822581   \n",
       "8            0.741935           0.838710           0.822581   \n",
       "9            0.774194           0.838710           0.806452   \n",
       "10           0.774194           0.822581           0.822581   \n",
       "11           0.774194           0.822581           0.822581   \n",
       "12           0.774194           0.822581           0.806452   \n",
       "13           0.741935           0.838710           0.806452   \n",
       "14           0.774194           0.838710           0.806452   \n",
       "\n",
       "    split8_test_score  split9_test_score  mean_test_score  std_test_score  \\\n",
       "0            0.645161           0.838710         0.828059        0.067254   \n",
       "1            0.758065           0.822581         0.831234        0.042811   \n",
       "2            0.725806           0.870968         0.839247        0.052996   \n",
       "3            0.758065           0.854839         0.840911        0.042800   \n",
       "4            0.725806           0.854839         0.829647        0.053972   \n",
       "5            0.709677           0.838710         0.826421        0.050897   \n",
       "6            0.725806           0.838710         0.826421        0.048206   \n",
       "7            0.725806           0.838710         0.821608        0.049133   \n",
       "8            0.709677           0.838710         0.821557        0.057062   \n",
       "9            0.709677           0.854839         0.823195        0.052047   \n",
       "10           0.725806           0.838710         0.824782        0.049718   \n",
       "11           0.709677           0.854839         0.823195        0.051545   \n",
       "12           0.709677           0.854839         0.819969        0.051482   \n",
       "13           0.725806           0.822581         0.819944        0.053963   \n",
       "14           0.741935           0.854839         0.826421        0.045499   \n",
       "\n",
       "    rank_test_score  \n",
       "0                 5  \n",
       "1                 3  \n",
       "2                 2  \n",
       "3                 1  \n",
       "4                 4  \n",
       "5                 6  \n",
       "6                 8  \n",
       "7                12  \n",
       "8                13  \n",
       "9                10  \n",
       "10                9  \n",
       "11               10  \n",
       "12               14  \n",
       "13               15  \n",
       "14                6  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score is 0.8409114183307731 with params {'max_depth': 4}\n"
     ]
    }
   ],
   "source": [
    "# Step 1: max_depth\n",
    "random.seed(10)\n",
    "\n",
    "xgb = XGBClassifier()\n",
    "\n",
    "xgb_parameters_1 = {'max_depth': [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15]}\n",
    "\n",
    "stratified_10_fold_cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "xgb_grid_search = GridSearchCV(xgb, xgb_parameters_1, scoring='accuracy', cv=stratified_10_fold_cv)\n",
    "\n",
    "xgb_grid_search.fit(X_train, y_train)\n",
    "\n",
    "xgb_grid_search_results = pd.DataFrame(xgb_grid_search.cv_results_)\n",
    "display(xgb_grid_search_results)\n",
    "\n",
    "print(\"best score is {} with params {}\".format(xgb_grid_search.best_score_, xgb_grid_search.best_params_))\n",
    "\n",
    "# best values for max_depth = [2,3,4,5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "de590b3b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_colsample_bylevel</th>\n",
       "      <th>param_colsample_bytree</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_subsample</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.094148</td>\n",
       "      <td>0.005155</td>\n",
       "      <td>0.009989</td>\n",
       "      <td>0.001835</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'colsample_bylevel': 0.1, 'colsample_bytree':...</td>\n",
       "      <td>0.809524</td>\n",
       "      <td>...</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.795981</td>\n",
       "      <td>0.051484</td>\n",
       "      <td>847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.094689</td>\n",
       "      <td>0.005821</td>\n",
       "      <td>0.010009</td>\n",
       "      <td>0.001320</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>{'colsample_bylevel': 0.1, 'colsample_bytree':...</td>\n",
       "      <td>0.841270</td>\n",
       "      <td>...</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.661290</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.813569</td>\n",
       "      <td>0.060517</td>\n",
       "      <td>717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.103950</td>\n",
       "      <td>0.004508</td>\n",
       "      <td>0.010321</td>\n",
       "      <td>0.000866</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'colsample_bylevel': 0.1, 'colsample_bytree':...</td>\n",
       "      <td>0.841270</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.645161</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.821633</td>\n",
       "      <td>0.061811</td>\n",
       "      <td>555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.101710</td>\n",
       "      <td>0.010839</td>\n",
       "      <td>0.010511</td>\n",
       "      <td>0.001010</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.7</td>\n",
       "      <td>{'colsample_bylevel': 0.1, 'colsample_bytree':...</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>...</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.661290</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.819995</td>\n",
       "      <td>0.059893</td>\n",
       "      <td>612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.124227</td>\n",
       "      <td>0.060625</td>\n",
       "      <td>0.009744</td>\n",
       "      <td>0.001571</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.9</td>\n",
       "      <td>{'colsample_bylevel': 0.1, 'colsample_bytree':...</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>...</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.828085</td>\n",
       "      <td>0.051964</td>\n",
       "      <td>303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>859</th>\n",
       "      <td>0.144559</td>\n",
       "      <td>0.005306</td>\n",
       "      <td>0.011619</td>\n",
       "      <td>0.001396</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>{'colsample_bylevel': 1, 'colsample_bytree': 1...</td>\n",
       "      <td>0.825397</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.821710</td>\n",
       "      <td>0.040200</td>\n",
       "      <td>543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>0.150761</td>\n",
       "      <td>0.004301</td>\n",
       "      <td>0.011664</td>\n",
       "      <td>0.000834</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'colsample_bylevel': 1, 'colsample_bytree': 1...</td>\n",
       "      <td>0.873016</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.828059</td>\n",
       "      <td>0.043837</td>\n",
       "      <td>317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>861</th>\n",
       "      <td>0.154240</td>\n",
       "      <td>0.007147</td>\n",
       "      <td>0.012484</td>\n",
       "      <td>0.000650</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.7</td>\n",
       "      <td>{'colsample_bylevel': 1, 'colsample_bytree': 1...</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.824834</td>\n",
       "      <td>0.054132</td>\n",
       "      <td>483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>862</th>\n",
       "      <td>0.151982</td>\n",
       "      <td>0.003265</td>\n",
       "      <td>0.011645</td>\n",
       "      <td>0.000631</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.9</td>\n",
       "      <td>{'colsample_bylevel': 1, 'colsample_bytree': 1...</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.824808</td>\n",
       "      <td>0.057412</td>\n",
       "      <td>491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>863</th>\n",
       "      <td>0.137040</td>\n",
       "      <td>0.004987</td>\n",
       "      <td>0.011659</td>\n",
       "      <td>0.000649</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>{'colsample_bylevel': 1, 'colsample_bytree': 1...</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.829647</td>\n",
       "      <td>0.053972</td>\n",
       "      <td>253</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>864 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0         0.094148      0.005155         0.009989        0.001835   \n",
       "1         0.094689      0.005821         0.010009        0.001320   \n",
       "2         0.103950      0.004508         0.010321        0.000866   \n",
       "3         0.101710      0.010839         0.010511        0.001010   \n",
       "4         0.124227      0.060625         0.009744        0.001571   \n",
       "..             ...           ...              ...             ...   \n",
       "859       0.144559      0.005306         0.011619        0.001396   \n",
       "860       0.150761      0.004301         0.011664        0.000834   \n",
       "861       0.154240      0.007147         0.012484        0.000650   \n",
       "862       0.151982      0.003265         0.011645        0.000631   \n",
       "863       0.137040      0.004987         0.011659        0.000649   \n",
       "\n",
       "    param_colsample_bylevel param_colsample_bytree param_max_depth  \\\n",
       "0                       0.1                    0.1               2   \n",
       "1                       0.1                    0.1               2   \n",
       "2                       0.1                    0.1               2   \n",
       "3                       0.1                    0.1               2   \n",
       "4                       0.1                    0.1               2   \n",
       "..                      ...                    ...             ...   \n",
       "859                       1                      1               5   \n",
       "860                       1                      1               5   \n",
       "861                       1                      1               5   \n",
       "862                       1                      1               5   \n",
       "863                       1                      1               5   \n",
       "\n",
       "    param_subsample                                             params  \\\n",
       "0               0.1  {'colsample_bylevel': 0.1, 'colsample_bytree':...   \n",
       "1               0.3  {'colsample_bylevel': 0.1, 'colsample_bytree':...   \n",
       "2               0.5  {'colsample_bylevel': 0.1, 'colsample_bytree':...   \n",
       "3               0.7  {'colsample_bylevel': 0.1, 'colsample_bytree':...   \n",
       "4               0.9  {'colsample_bylevel': 0.1, 'colsample_bytree':...   \n",
       "..              ...                                                ...   \n",
       "859             0.3  {'colsample_bylevel': 1, 'colsample_bytree': 1...   \n",
       "860             0.5  {'colsample_bylevel': 1, 'colsample_bytree': 1...   \n",
       "861             0.7  {'colsample_bylevel': 1, 'colsample_bytree': 1...   \n",
       "862             0.9  {'colsample_bylevel': 1, 'colsample_bytree': 1...   \n",
       "863               1  {'colsample_bylevel': 1, 'colsample_bytree': 1...   \n",
       "\n",
       "     split0_test_score  ...  split3_test_score  split4_test_score  \\\n",
       "0             0.809524  ...           0.806452           0.838710   \n",
       "1             0.841270  ...           0.790323           0.822581   \n",
       "2             0.841270  ...           0.838710           0.822581   \n",
       "3             0.857143  ...           0.790323           0.822581   \n",
       "4             0.857143  ...           0.822581           0.822581   \n",
       "..                 ...  ...                ...                ...   \n",
       "859           0.825397  ...           0.854839           0.774194   \n",
       "860           0.873016  ...           0.854839           0.790323   \n",
       "861           0.888889  ...           0.870968           0.806452   \n",
       "862           0.904762  ...           0.854839           0.806452   \n",
       "863           0.888889  ...           0.838710           0.822581   \n",
       "\n",
       "     split5_test_score  split6_test_score  split7_test_score  \\\n",
       "0             0.774194           0.774194           0.758065   \n",
       "1             0.758065           0.838710           0.838710   \n",
       "2             0.822581           0.822581           0.822581   \n",
       "3             0.822581           0.822581           0.806452   \n",
       "4             0.870968           0.822581           0.790323   \n",
       "..                 ...                ...                ...   \n",
       "859           0.822581           0.822581           0.838710   \n",
       "860           0.790323           0.806452           0.822581   \n",
       "861           0.758065           0.822581           0.822581   \n",
       "862           0.774194           0.806452           0.838710   \n",
       "863           0.741935           0.854839           0.838710   \n",
       "\n",
       "     split8_test_score  split9_test_score  mean_test_score  std_test_score  \\\n",
       "0             0.677419           0.838710         0.795981        0.051484   \n",
       "1             0.661290           0.838710         0.813569        0.060517   \n",
       "2             0.645161           0.854839         0.821633        0.061811   \n",
       "3             0.661290           0.870968         0.819995        0.059893   \n",
       "4             0.693548           0.870968         0.828085        0.051964   \n",
       "..                 ...                ...              ...             ...   \n",
       "859           0.725806           0.838710         0.821710        0.040200   \n",
       "860           0.741935           0.870968         0.828059        0.043837   \n",
       "861           0.709677           0.854839         0.824834        0.054132   \n",
       "862           0.693548           0.854839         0.824808        0.057412   \n",
       "863           0.725806           0.854839         0.829647        0.053972   \n",
       "\n",
       "     rank_test_score  \n",
       "0                847  \n",
       "1                717  \n",
       "2                555  \n",
       "3                612  \n",
       "4                303  \n",
       "..               ...  \n",
       "859              543  \n",
       "860              317  \n",
       "861              483  \n",
       "862              491  \n",
       "863              253  \n",
       "\n",
       "[864 rows x 22 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score is 0.8441372247823861 with params {'colsample_bylevel': 0.1, 'colsample_bytree': 0.9, 'max_depth': 2, 'subsample': 0.7}\n"
     ]
    }
   ],
   "source": [
    "# Step 2: subsample, colsample_bytree, colsample_bylevel\n",
    "random.seed(10)\n",
    "\n",
    "xgb = XGBClassifier()\n",
    "\n",
    "xgb_parameters_2 = {'max_depth': [2,3,4,5]\n",
    "                   , 'subsample': [0.1, 0.3, 0.5, 0.7, 0.9, 1]\n",
    "                   , 'colsample_bytree': [0.1, 0.3, 0.5, 0.7, 0.9, 1]\n",
    "                   , 'colsample_bylevel': [0.1, 0.3, 0.5, 0.7, 0.9, 1]}\n",
    "\n",
    "stratified_10_fold_cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "xgb_grid_search = GridSearchCV(xgb, xgb_parameters_2, scoring='accuracy', cv=stratified_10_fold_cv)\n",
    "\n",
    "xgb_grid_search.fit(X_train, y_train)\n",
    "\n",
    "xgb_grid_search_results_2 = pd.DataFrame(xgb_grid_search.cv_results_)\n",
    "display(xgb_grid_search_results_2)\n",
    "\n",
    "print(\"best score is {} with params {}\".format(xgb_grid_search.best_score_, xgb_grid_search.best_params_))\n",
    "\n",
    "# best values for\n",
    "# max_depth = [2,4]\n",
    "# subsample = [0.5, 0.7, 0.9]\n",
    "# colsample_bytree = [0.3, 0.5, 0.9]\n",
    "# colsample_bylevel = [0.1, 0.3, 0.7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "137ec7d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save dataframe\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "# save data with date to track changes \n",
    "date = str(datetime.now().date()).replace(\"-\", \"\")\n",
    "\n",
    "xgb_grid_search_results_2.to_csv(f\"data/xgb_results_step2_{date}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5d8a0a77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_colsample_bylevel</th>\n",
       "      <th>param_colsample_bytree</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_subsample</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>2</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.844137</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>483</th>\n",
       "      <td>0.7</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.844060</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.842576</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.842576</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.7</td>\n",
       "      <td>2</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.842550</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.842499</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.7</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.840963</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.840937</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459</th>\n",
       "      <td>0.7</td>\n",
       "      <td>0.3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.840937</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>857</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.840911</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    param_colsample_bylevel param_colsample_bytree param_max_depth  \\\n",
       "99                      0.1                    0.9               2   \n",
       "483                     0.7                    0.5               2   \n",
       "170                     0.3                    0.3               2   \n",
       "26                      0.1                    0.3               2   \n",
       "76                      0.1                    0.7               2   \n",
       "98                      0.1                    0.9               2   \n",
       "77                      0.1                    0.7               2   \n",
       "315                     0.5                    0.3               2   \n",
       "459                     0.7                    0.3               2   \n",
       "857                       1                      1               4   \n",
       "\n",
       "    param_subsample  mean_test_score  rank_test_score  \n",
       "99              0.7         0.844137                1  \n",
       "483             0.7         0.844060                2  \n",
       "170             0.5         0.842576                3  \n",
       "26              0.5         0.842576                3  \n",
       "76              0.9         0.842550                5  \n",
       "98              0.5         0.842499                6  \n",
       "77                1         0.840963                7  \n",
       "315             0.7         0.840937                8  \n",
       "459             0.7         0.840937                8  \n",
       "857               1         0.840911               10  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols_2 = ['param_max_depth', 'param_subsample', 'param_colsample_bytree', 'param_colsample_bylevel', 'mean_test_score', 'rank_test_score']\n",
    "df_2 = xgb_grid_search_results_2[cols_2]\n",
    "df_2_sorted = df_2.sort_values(by='rank_test_score')\n",
    "df_2_sorted.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0cb9e376",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_colsample_bylevel</th>\n",
       "      <th>param_colsample_bytree</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_subsample</th>\n",
       "      <th>...</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.063518</td>\n",
       "      <td>0.004715</td>\n",
       "      <td>0.009346</td>\n",
       "      <td>0.001981</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.821608</td>\n",
       "      <td>0.050230</td>\n",
       "      <td>936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.058864</td>\n",
       "      <td>0.003199</td>\n",
       "      <td>0.009017</td>\n",
       "      <td>0.001919</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>0.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.818484</td>\n",
       "      <td>0.050169</td>\n",
       "      <td>1104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.060230</td>\n",
       "      <td>0.003488</td>\n",
       "      <td>0.010143</td>\n",
       "      <td>0.001395</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>0.9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.818433</td>\n",
       "      <td>0.048299</td>\n",
       "      <td>1115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.106949</td>\n",
       "      <td>0.010550</td>\n",
       "      <td>0.009827</td>\n",
       "      <td>0.001825</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.820020</td>\n",
       "      <td>0.048275</td>\n",
       "      <td>1033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.110194</td>\n",
       "      <td>0.008693</td>\n",
       "      <td>0.010148</td>\n",
       "      <td>0.002095</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.824782</td>\n",
       "      <td>0.057512</td>\n",
       "      <td>764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1615</th>\n",
       "      <td>0.181315</td>\n",
       "      <td>0.001596</td>\n",
       "      <td>0.007281</td>\n",
       "      <td>0.000457</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.9</td>\n",
       "      <td>4</td>\n",
       "      <td>250</td>\n",
       "      <td>0.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.803943</td>\n",
       "      <td>0.050455</td>\n",
       "      <td>1557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1616</th>\n",
       "      <td>0.178622</td>\n",
       "      <td>0.002114</td>\n",
       "      <td>0.007081</td>\n",
       "      <td>0.000299</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.9</td>\n",
       "      <td>4</td>\n",
       "      <td>250</td>\n",
       "      <td>0.9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.811956</td>\n",
       "      <td>0.057165</td>\n",
       "      <td>1429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1617</th>\n",
       "      <td>0.214528</td>\n",
       "      <td>0.002377</td>\n",
       "      <td>0.007680</td>\n",
       "      <td>0.000457</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.9</td>\n",
       "      <td>4</td>\n",
       "      <td>300</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.781490</td>\n",
       "      <td>0.053158</td>\n",
       "      <td>1618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1618</th>\n",
       "      <td>0.215025</td>\n",
       "      <td>0.002491</td>\n",
       "      <td>0.007381</td>\n",
       "      <td>0.000488</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.9</td>\n",
       "      <td>4</td>\n",
       "      <td>300</td>\n",
       "      <td>0.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.799104</td>\n",
       "      <td>0.060610</td>\n",
       "      <td>1591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1619</th>\n",
       "      <td>0.211135</td>\n",
       "      <td>0.002047</td>\n",
       "      <td>0.007181</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.9</td>\n",
       "      <td>4</td>\n",
       "      <td>300</td>\n",
       "      <td>0.9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.811956</td>\n",
       "      <td>0.057533</td>\n",
       "      <td>1425</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1620 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0          0.063518      0.004715         0.009346        0.001981   \n",
       "1          0.058864      0.003199         0.009017        0.001919   \n",
       "2          0.060230      0.003488         0.010143        0.001395   \n",
       "3          0.106949      0.010550         0.009827        0.001825   \n",
       "4          0.110194      0.008693         0.010148        0.002095   \n",
       "...             ...           ...              ...             ...   \n",
       "1615       0.181315      0.001596         0.007281        0.000457   \n",
       "1616       0.178622      0.002114         0.007081        0.000299   \n",
       "1617       0.214528      0.002377         0.007680        0.000457   \n",
       "1618       0.215025      0.002491         0.007381        0.000488   \n",
       "1619       0.211135      0.002047         0.007181        0.000399   \n",
       "\n",
       "     param_colsample_bylevel param_colsample_bytree param_learning_rate  \\\n",
       "0                        0.1                    0.3                 0.1   \n",
       "1                        0.1                    0.3                 0.1   \n",
       "2                        0.1                    0.3                 0.1   \n",
       "3                        0.1                    0.3                 0.1   \n",
       "4                        0.1                    0.3                 0.1   \n",
       "...                      ...                    ...                 ...   \n",
       "1615                     0.7                    0.9                 0.9   \n",
       "1616                     0.7                    0.9                 0.9   \n",
       "1617                     0.7                    0.9                 0.9   \n",
       "1618                     0.7                    0.9                 0.9   \n",
       "1619                     0.7                    0.9                 0.9   \n",
       "\n",
       "     param_max_depth param_n_estimators param_subsample  ...  \\\n",
       "0                  2                 50             0.5  ...   \n",
       "1                  2                 50             0.7  ...   \n",
       "2                  2                 50             0.9  ...   \n",
       "3                  2                100             0.5  ...   \n",
       "4                  2                100             0.7  ...   \n",
       "...              ...                ...             ...  ...   \n",
       "1615               4                250             0.7  ...   \n",
       "1616               4                250             0.9  ...   \n",
       "1617               4                300             0.5  ...   \n",
       "1618               4                300             0.7  ...   \n",
       "1619               4                300             0.9  ...   \n",
       "\n",
       "     split3_test_score  split4_test_score  split5_test_score  \\\n",
       "0             0.838710           0.854839           0.806452   \n",
       "1             0.854839           0.838710           0.790323   \n",
       "2             0.854839           0.838710           0.790323   \n",
       "3             0.822581           0.822581           0.806452   \n",
       "4             0.838710           0.806452           0.806452   \n",
       "...                ...                ...                ...   \n",
       "1615          0.838710           0.741935           0.741935   \n",
       "1616          0.806452           0.790323           0.774194   \n",
       "1617          0.822581           0.709677           0.774194   \n",
       "1618          0.838710           0.758065           0.725806   \n",
       "1619          0.822581           0.758065           0.758065   \n",
       "\n",
       "      split6_test_score  split7_test_score  split8_test_score  \\\n",
       "0              0.838710           0.790323           0.709677   \n",
       "1              0.838710           0.790323           0.709677   \n",
       "2              0.822581           0.790323           0.709677   \n",
       "3              0.822581           0.806452           0.693548   \n",
       "4              0.838710           0.806452           0.677419   \n",
       "...                 ...                ...                ...   \n",
       "1615           0.822581           0.822581           0.725806   \n",
       "1616           0.822581           0.806452           0.693548   \n",
       "1617           0.790323           0.790323           0.677419   \n",
       "1618           0.774194           0.806452           0.677419   \n",
       "1619           0.838710           0.806452           0.725806   \n",
       "\n",
       "      split9_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0              0.774194         0.821608        0.050230              936  \n",
       "1              0.822581         0.818484        0.050169             1104  \n",
       "2              0.806452         0.818433        0.048299             1115  \n",
       "3              0.838710         0.820020        0.048275             1033  \n",
       "4              0.838710         0.824782        0.057512              764  \n",
       "...                 ...              ...             ...              ...  \n",
       "1615           0.790323         0.803943        0.050455             1557  \n",
       "1616           0.838710         0.811956        0.057165             1429  \n",
       "1617           0.774194         0.781490        0.053158             1618  \n",
       "1618           0.854839         0.799104        0.060610             1591  \n",
       "1619           0.822581         0.811956        0.057533             1425  \n",
       "\n",
       "[1620 rows x 24 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score is 0.847363031233999 with params {'colsample_bylevel': 0.7, 'colsample_bytree': 0.5, 'learning_rate': 0.3, 'max_depth': 2, 'n_estimators': 50, 'subsample': 0.7}\n"
     ]
    }
   ],
   "source": [
    "# Step 3: learning_rate\n",
    "random.seed(10)\n",
    "\n",
    "xgb = XGBClassifier()\n",
    "\n",
    "xgb_parameters_3 = {'max_depth': [2,4]\n",
    "                   , 'subsample': [0.5, 0.7, 0.9]\n",
    "                   , 'colsample_bytree': [0.3, 0.5, 0.9]\n",
    "                   , 'colsample_bylevel': [0.1, 0.3, 0.7]\n",
    "                   , 'learning_rate': [0.1, 0.3, 0.5, 0.7, 0.9]\n",
    "                   , 'n_estimators': [50, 100, 150, 200, 250, 300]}\n",
    "\n",
    "stratified_10_fold_cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "xgb_grid_search = GridSearchCV(xgb, xgb_parameters_3, scoring='accuracy', cv=stratified_10_fold_cv)\n",
    "\n",
    "xgb_grid_search.fit(X_train, y_train)\n",
    "\n",
    "xgb_grid_search_results_3 = pd.DataFrame(xgb_grid_search.cv_results_)\n",
    "display(xgb_grid_search_results_3)\n",
    "\n",
    "print(\"best score is {} with params {}\".format(xgb_grid_search.best_score_, xgb_grid_search.best_params_))\n",
    "\n",
    "# best values for\n",
    "# max_depth = [2,4]\n",
    "# subsample = [0.5, 0.7, 0.9]\n",
    "# colsample_bytree = [0.3, 0.5, 0.9]\n",
    "# colsample_bylevel = [0.1, 0.3, 0.7]\n",
    "# learning_rate = []\n",
    "# n_estimators = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ead32303",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save dataframe\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "# save data with date to track changes \n",
    "date = str(datetime.now().date()).replace(\"-\", \"\")\n",
    "\n",
    "xgb_grid_search_results_3.to_csv(f\"data/xgb_results_step3_{date}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8d0a38e8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'xgb_grid_search_results_3' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [15], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m cols_3 \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparam_max_depth\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparam_subsample\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparam_colsample_bytree\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparam_colsample_bylevel\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparam_learning_rate\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparam_n_estimators\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean_test_score\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrank_test_score\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m----> 2\u001b[0m df_3 \u001b[38;5;241m=\u001b[39m \u001b[43mxgb_grid_search_results_3\u001b[49m[cols_3]\n\u001b[0;32m      3\u001b[0m df_3_sorted \u001b[38;5;241m=\u001b[39m df_3\u001b[38;5;241m.\u001b[39msort_values(by\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrank_test_score\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      4\u001b[0m df_3_sorted\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m10\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'xgb_grid_search_results_3' is not defined"
     ]
    }
   ],
   "source": [
    "cols_3 = ['param_max_depth', 'param_subsample', 'param_colsample_bytree', 'param_colsample_bylevel', 'param_learning_rate', 'param_n_estimators', 'mean_test_score', 'rank_test_score']\n",
    "df_3 = xgb_grid_search_results_3[cols_3]\n",
    "df_3_sorted = df_3.sort_values(by='rank_test_score')\n",
    "df_3_sorted.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c51c3ca9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c44bb7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "549997dc",
   "metadata": {},
   "source": [
    "#### Third Attempt: Full Tuning in Parts - Round 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ffbd470",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0c55dbe6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_colsample_bylevel</th>\n",
       "      <th>param_colsample_bytree</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_subsample</th>\n",
       "      <th>...</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.064527</td>\n",
       "      <td>0.004136</td>\n",
       "      <td>0.005885</td>\n",
       "      <td>5.376236e-04</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.820020</td>\n",
       "      <td>0.048275</td>\n",
       "      <td>2651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.064327</td>\n",
       "      <td>0.002493</td>\n",
       "      <td>0.005885</td>\n",
       "      <td>5.374151e-04</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.661290</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.823221</td>\n",
       "      <td>0.059057</td>\n",
       "      <td>2358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.063231</td>\n",
       "      <td>0.001954</td>\n",
       "      <td>0.005785</td>\n",
       "      <td>3.990535e-04</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.824782</td>\n",
       "      <td>0.057512</td>\n",
       "      <td>2252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.062235</td>\n",
       "      <td>0.001017</td>\n",
       "      <td>0.006082</td>\n",
       "      <td>3.001655e-04</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.661290</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.824834</td>\n",
       "      <td>0.059251</td>\n",
       "      <td>2175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.062333</td>\n",
       "      <td>0.002285</td>\n",
       "      <td>0.005784</td>\n",
       "      <td>3.991850e-04</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.828059</td>\n",
       "      <td>0.053977</td>\n",
       "      <td>1747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2995</th>\n",
       "      <td>0.180018</td>\n",
       "      <td>0.001496</td>\n",
       "      <td>0.007081</td>\n",
       "      <td>2.993507e-04</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.887097</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.828085</td>\n",
       "      <td>0.048801</td>\n",
       "      <td>1701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2996</th>\n",
       "      <td>0.182212</td>\n",
       "      <td>0.003339</td>\n",
       "      <td>0.006982</td>\n",
       "      <td>4.460618e-04</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.826421</td>\n",
       "      <td>0.052840</td>\n",
       "      <td>1992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2997</th>\n",
       "      <td>0.181813</td>\n",
       "      <td>0.001548</td>\n",
       "      <td>0.007082</td>\n",
       "      <td>2.990570e-04</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.824808</td>\n",
       "      <td>0.053239</td>\n",
       "      <td>2204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998</th>\n",
       "      <td>0.181666</td>\n",
       "      <td>0.001723</td>\n",
       "      <td>0.006982</td>\n",
       "      <td>4.529953e-07</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.823272</td>\n",
       "      <td>0.043729</td>\n",
       "      <td>2305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999</th>\n",
       "      <td>0.182113</td>\n",
       "      <td>0.002005</td>\n",
       "      <td>0.007081</td>\n",
       "      <td>2.993824e-04</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.823169</td>\n",
       "      <td>0.050024</td>\n",
       "      <td>2460</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0          0.064527      0.004136         0.005885    5.376236e-04   \n",
       "1          0.064327      0.002493         0.005885    5.374151e-04   \n",
       "2          0.063231      0.001954         0.005785    3.990535e-04   \n",
       "3          0.062235      0.001017         0.006082    3.001655e-04   \n",
       "4          0.062333      0.002285         0.005784    3.991850e-04   \n",
       "...             ...           ...              ...             ...   \n",
       "2995       0.180018      0.001496         0.007081    2.993507e-04   \n",
       "2996       0.182212      0.003339         0.006982    4.460618e-04   \n",
       "2997       0.181813      0.001548         0.007082    2.990570e-04   \n",
       "2998       0.181666      0.001723         0.006982    4.529953e-07   \n",
       "2999       0.182113      0.002005         0.007081    2.993824e-04   \n",
       "\n",
       "     param_colsample_bylevel param_colsample_bytree param_learning_rate  \\\n",
       "0                        0.1                    0.3                 0.1   \n",
       "1                        0.1                    0.3                 0.1   \n",
       "2                        0.1                    0.3                 0.1   \n",
       "3                        0.1                    0.3                 0.1   \n",
       "4                        0.1                    0.3                 0.1   \n",
       "...                      ...                    ...                 ...   \n",
       "2995                     0.1                    0.9                 0.4   \n",
       "2996                     0.1                    0.9                 0.4   \n",
       "2997                     0.1                    0.9                 0.4   \n",
       "2998                     0.1                    0.9                 0.4   \n",
       "2999                     0.1                    0.9                 0.4   \n",
       "\n",
       "     param_max_depth param_n_estimators param_subsample  ...  \\\n",
       "0                  2                100             0.5  ...   \n",
       "1                  2                100             0.6  ...   \n",
       "2                  2                100             0.7  ...   \n",
       "3                  2                100             0.8  ...   \n",
       "4                  2                100             0.9  ...   \n",
       "...              ...                ...             ...  ...   \n",
       "2995               5                300             0.5  ...   \n",
       "2996               5                300             0.6  ...   \n",
       "2997               5                300             0.7  ...   \n",
       "2998               5                300             0.8  ...   \n",
       "2999               5                300             0.9  ...   \n",
       "\n",
       "     split3_test_score  split4_test_score  split5_test_score  \\\n",
       "0             0.822581           0.822581           0.806452   \n",
       "1             0.838710           0.822581           0.806452   \n",
       "2             0.838710           0.806452           0.806452   \n",
       "3             0.854839           0.822581           0.806452   \n",
       "4             0.854839           0.822581           0.838710   \n",
       "...                ...                ...                ...   \n",
       "2995          0.887097           0.806452           0.774194   \n",
       "2996          0.870968           0.774194           0.758065   \n",
       "2997          0.870968           0.790323           0.790323   \n",
       "2998          0.870968           0.790323           0.774194   \n",
       "2999          0.854839           0.806452           0.774194   \n",
       "\n",
       "      split6_test_score  split7_test_score  split8_test_score  \\\n",
       "0              0.822581           0.806452           0.693548   \n",
       "1              0.838710           0.806452           0.661290   \n",
       "2              0.838710           0.806452           0.677419   \n",
       "3              0.854839           0.806452           0.661290   \n",
       "4              0.838710           0.806452           0.677419   \n",
       "...                 ...                ...                ...   \n",
       "2995           0.822581           0.822581           0.725806   \n",
       "2996           0.806452           0.838710           0.741935   \n",
       "2997           0.790323           0.854839           0.709677   \n",
       "2998           0.806452           0.854839           0.741935   \n",
       "2999           0.806452           0.822581           0.725806   \n",
       "\n",
       "      split9_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0              0.838710         0.820020        0.048275             2651  \n",
       "1              0.854839         0.823221        0.059057             2358  \n",
       "2              0.838710         0.824782        0.057512             2252  \n",
       "3              0.838710         0.824834        0.059251             2175  \n",
       "4              0.838710         0.828059        0.053977             1747  \n",
       "...                 ...              ...             ...              ...  \n",
       "2995           0.854839         0.828085        0.048801             1701  \n",
       "2996           0.854839         0.826421        0.052840             1992  \n",
       "2997           0.822581         0.824808        0.053239             2204  \n",
       "2998           0.822581         0.823272        0.043729             2305  \n",
       "2999           0.806452         0.823169        0.050024             2460  \n",
       "\n",
       "[3000 rows x 24 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score is 0.8505376344086022 with params {'colsample_bylevel': 0.1, 'colsample_bytree': 0.6, 'learning_rate': 0.15, 'max_depth': 5, 'n_estimators': 100, 'subsample': 0.6}\n"
     ]
    }
   ],
   "source": [
    "# Full Tuning - Part 1\n",
    "random.seed(10)\n",
    "\n",
    "xgb = XGBClassifier()\n",
    "\n",
    "xgb_parameters = {'max_depth': [2,3,4,5]\n",
    "                   , 'subsample': [0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "                   , 'colsample_bytree': [0.3, 0.4, 0.5, 0.6, 0.9]\n",
    "                   , 'colsample_bylevel': [0.1]\n",
    "                   , 'learning_rate': [0.1, 0.15, 0.2, 0.25, 0.3, 0.4]\n",
    "                   , 'n_estimators': [100, 150, 200, 250, 300]}\n",
    "\n",
    "stratified_10_fold_cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "xgb_grid_search = GridSearchCV(xgb, xgb_parameters, scoring='accuracy', cv=stratified_10_fold_cv)\n",
    "\n",
    "xgb_grid_search.fit(X_train, y_train)\n",
    "\n",
    "xgb_grid_search_results_full_1 = pd.DataFrame(xgb_grid_search.cv_results_)\n",
    "display(xgb_grid_search_results_full_1)\n",
    "\n",
    "print(\"best score is {} with params {}\".format(xgb_grid_search.best_score_, xgb_grid_search.best_params_))\n",
    "\n",
    "# best values for\n",
    "\n",
    "# save dataframe\n",
    "from datetime import datetime\n",
    "date = str(datetime.now().date()).replace(\"-\", \"\")\n",
    "xgb_grid_search_results_full_1.to_csv(f\"data/xgb_results_full_1_bylevel=0.1_{date}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "613e4353",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_colsample_bylevel</th>\n",
       "      <th>param_colsample_bytree</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_subsample</th>\n",
       "      <th>...</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.062133</td>\n",
       "      <td>0.002485</td>\n",
       "      <td>0.006284</td>\n",
       "      <td>0.000639</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.820020</td>\n",
       "      <td>0.048275</td>\n",
       "      <td>2663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.063131</td>\n",
       "      <td>0.003027</td>\n",
       "      <td>0.006683</td>\n",
       "      <td>0.000457</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.661290</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.823221</td>\n",
       "      <td>0.059057</td>\n",
       "      <td>2338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.060438</td>\n",
       "      <td>0.000798</td>\n",
       "      <td>0.006782</td>\n",
       "      <td>0.000398</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.824782</td>\n",
       "      <td>0.057512</td>\n",
       "      <td>2222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.059541</td>\n",
       "      <td>0.000779</td>\n",
       "      <td>0.006682</td>\n",
       "      <td>0.000457</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.661290</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.824834</td>\n",
       "      <td>0.059251</td>\n",
       "      <td>2132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.059840</td>\n",
       "      <td>0.001092</td>\n",
       "      <td>0.006782</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.828059</td>\n",
       "      <td>0.053977</td>\n",
       "      <td>1661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2995</th>\n",
       "      <td>0.195577</td>\n",
       "      <td>0.001636</td>\n",
       "      <td>0.017653</td>\n",
       "      <td>0.031683</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.819918</td>\n",
       "      <td>0.052433</td>\n",
       "      <td>2744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2996</th>\n",
       "      <td>0.221308</td>\n",
       "      <td>0.011234</td>\n",
       "      <td>0.006782</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.819995</td>\n",
       "      <td>0.058351</td>\n",
       "      <td>2693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2997</th>\n",
       "      <td>0.226194</td>\n",
       "      <td>0.002309</td>\n",
       "      <td>0.007082</td>\n",
       "      <td>0.000299</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.821582</td>\n",
       "      <td>0.054587</td>\n",
       "      <td>2581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998</th>\n",
       "      <td>0.199167</td>\n",
       "      <td>0.006213</td>\n",
       "      <td>0.007381</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.823195</td>\n",
       "      <td>0.052389</td>\n",
       "      <td>2389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999</th>\n",
       "      <td>0.196574</td>\n",
       "      <td>0.001133</td>\n",
       "      <td>0.007480</td>\n",
       "      <td>0.000499</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.826395</td>\n",
       "      <td>0.049816</td>\n",
       "      <td>2002</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0          0.062133      0.002485         0.006284        0.000639   \n",
       "1          0.063131      0.003027         0.006683        0.000457   \n",
       "2          0.060438      0.000798         0.006782        0.000398   \n",
       "3          0.059541      0.000779         0.006682        0.000457   \n",
       "4          0.059840      0.001092         0.006782        0.000399   \n",
       "...             ...           ...              ...             ...   \n",
       "2995       0.195577      0.001636         0.017653        0.031683   \n",
       "2996       0.221308      0.011234         0.006782        0.000399   \n",
       "2997       0.226194      0.002309         0.007082        0.000299   \n",
       "2998       0.199167      0.006213         0.007381        0.000489   \n",
       "2999       0.196574      0.001133         0.007480        0.000499   \n",
       "\n",
       "     param_colsample_bylevel param_colsample_bytree param_learning_rate  \\\n",
       "0                        0.2                    0.3                 0.1   \n",
       "1                        0.2                    0.3                 0.1   \n",
       "2                        0.2                    0.3                 0.1   \n",
       "3                        0.2                    0.3                 0.1   \n",
       "4                        0.2                    0.3                 0.1   \n",
       "...                      ...                    ...                 ...   \n",
       "2995                     0.2                    0.9                 0.4   \n",
       "2996                     0.2                    0.9                 0.4   \n",
       "2997                     0.2                    0.9                 0.4   \n",
       "2998                     0.2                    0.9                 0.4   \n",
       "2999                     0.2                    0.9                 0.4   \n",
       "\n",
       "     param_max_depth param_n_estimators param_subsample  ...  \\\n",
       "0                  2                100             0.5  ...   \n",
       "1                  2                100             0.6  ...   \n",
       "2                  2                100             0.7  ...   \n",
       "3                  2                100             0.8  ...   \n",
       "4                  2                100             0.9  ...   \n",
       "...              ...                ...             ...  ...   \n",
       "2995               5                300             0.5  ...   \n",
       "2996               5                300             0.6  ...   \n",
       "2997               5                300             0.7  ...   \n",
       "2998               5                300             0.8  ...   \n",
       "2999               5                300             0.9  ...   \n",
       "\n",
       "     split3_test_score  split4_test_score  split5_test_score  \\\n",
       "0             0.822581           0.822581           0.806452   \n",
       "1             0.838710           0.822581           0.806452   \n",
       "2             0.838710           0.806452           0.806452   \n",
       "3             0.854839           0.822581           0.806452   \n",
       "4             0.854839           0.822581           0.838710   \n",
       "...                ...                ...                ...   \n",
       "2995          0.822581           0.806452           0.774194   \n",
       "2996          0.838710           0.806452           0.774194   \n",
       "2997          0.838710           0.790323           0.758065   \n",
       "2998          0.838710           0.822581           0.774194   \n",
       "2999          0.838710           0.806452           0.790323   \n",
       "\n",
       "      split6_test_score  split7_test_score  split8_test_score  \\\n",
       "0              0.822581           0.806452           0.693548   \n",
       "1              0.838710           0.806452           0.661290   \n",
       "2              0.838710           0.806452           0.677419   \n",
       "3              0.854839           0.806452           0.661290   \n",
       "4              0.838710           0.806452           0.677419   \n",
       "...                 ...                ...                ...   \n",
       "2995           0.790323           0.790323           0.741935   \n",
       "2996           0.822581           0.838710           0.693548   \n",
       "2997           0.806452           0.854839           0.725806   \n",
       "2998           0.838710           0.822581           0.725806   \n",
       "2999           0.838710           0.822581           0.725806   \n",
       "\n",
       "      split9_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0              0.838710         0.820020        0.048275             2663  \n",
       "1              0.854839         0.823221        0.059057             2338  \n",
       "2              0.838710         0.824782        0.057512             2222  \n",
       "3              0.838710         0.824834        0.059251             2132  \n",
       "4              0.838710         0.828059        0.053977             1661  \n",
       "...                 ...              ...             ...              ...  \n",
       "2995           0.822581         0.819918        0.052433             2744  \n",
       "2996           0.822581         0.819995        0.058351             2693  \n",
       "2997           0.822581         0.821582        0.054587             2581  \n",
       "2998           0.790323         0.823195        0.052389             2389  \n",
       "2999           0.806452         0.826395        0.049816             2002  \n",
       "\n",
       "[3000 rows x 24 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score is 0.8505376344086022 with params {'colsample_bylevel': 0.2, 'colsample_bytree': 0.6, 'learning_rate': 0.15, 'max_depth': 5, 'n_estimators': 100, 'subsample': 0.6}\n"
     ]
    }
   ],
   "source": [
    "# Full Tuning - Part 2\n",
    "random.seed(10)\n",
    "\n",
    "xgb = XGBClassifier()\n",
    "\n",
    "xgb_parameters = {'max_depth': [2,3,4,5]\n",
    "                   , 'subsample': [0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "                   , 'colsample_bytree': [0.3, 0.4, 0.5, 0.6, 0.9]\n",
    "                   , 'colsample_bylevel': [0.2]\n",
    "                   , 'learning_rate': [0.1, 0.15, 0.2, 0.25, 0.3, 0.4]\n",
    "                   , 'n_estimators': [100, 150, 200, 250, 300]}\n",
    "\n",
    "stratified_10_fold_cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "xgb_grid_search = GridSearchCV(xgb, xgb_parameters, scoring='accuracy', cv=stratified_10_fold_cv)\n",
    "\n",
    "xgb_grid_search.fit(X_train, y_train)\n",
    "\n",
    "xgb_grid_search_results_full_2 = pd.DataFrame(xgb_grid_search.cv_results_)\n",
    "display(xgb_grid_search_results_full_2)\n",
    "\n",
    "print(\"best score is {} with params {}\".format(xgb_grid_search.best_score_, xgb_grid_search.best_params_))\n",
    "\n",
    "# best values for\n",
    "\n",
    "# save dataframe\n",
    "from datetime import datetime\n",
    "date = str(datetime.now().date()).replace(\"-\", \"\")\n",
    "xgb_grid_search_results_full_2.to_csv(f\"data/xgb_results_full_2_bylevel=0.2_{date}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8f09d50d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_colsample_bylevel</th>\n",
       "      <th>param_colsample_bytree</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_subsample</th>\n",
       "      <th>...</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.062034</td>\n",
       "      <td>0.001596</td>\n",
       "      <td>0.006882</td>\n",
       "      <td>0.000537</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.820020</td>\n",
       "      <td>0.048275</td>\n",
       "      <td>2509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.068327</td>\n",
       "      <td>0.005910</td>\n",
       "      <td>0.006573</td>\n",
       "      <td>0.000502</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.661290</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.823221</td>\n",
       "      <td>0.059057</td>\n",
       "      <td>2140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.065225</td>\n",
       "      <td>0.003191</td>\n",
       "      <td>0.006683</td>\n",
       "      <td>0.000457</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.824782</td>\n",
       "      <td>0.057512</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.063630</td>\n",
       "      <td>0.001596</td>\n",
       "      <td>0.006483</td>\n",
       "      <td>0.000499</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.661290</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.824834</td>\n",
       "      <td>0.059251</td>\n",
       "      <td>1898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.061435</td>\n",
       "      <td>0.001493</td>\n",
       "      <td>0.006483</td>\n",
       "      <td>0.000498</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.828059</td>\n",
       "      <td>0.053977</td>\n",
       "      <td>1394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2995</th>\n",
       "      <td>0.206226</td>\n",
       "      <td>0.002782</td>\n",
       "      <td>0.007182</td>\n",
       "      <td>0.000598</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.813646</td>\n",
       "      <td>0.044452</td>\n",
       "      <td>2900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2996</th>\n",
       "      <td>0.207998</td>\n",
       "      <td>0.002457</td>\n",
       "      <td>0.007280</td>\n",
       "      <td>0.000457</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.818459</td>\n",
       "      <td>0.053856</td>\n",
       "      <td>2648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2997</th>\n",
       "      <td>0.207744</td>\n",
       "      <td>0.000898</td>\n",
       "      <td>0.007480</td>\n",
       "      <td>0.000499</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.813594</td>\n",
       "      <td>0.056215</td>\n",
       "      <td>2908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998</th>\n",
       "      <td>0.208343</td>\n",
       "      <td>0.001863</td>\n",
       "      <td>0.007280</td>\n",
       "      <td>0.000457</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.815207</td>\n",
       "      <td>0.053961</td>\n",
       "      <td>2850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999</th>\n",
       "      <td>0.207644</td>\n",
       "      <td>0.001882</td>\n",
       "      <td>0.007381</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.820020</td>\n",
       "      <td>0.055129</td>\n",
       "      <td>2509</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0          0.062034      0.001596         0.006882        0.000537   \n",
       "1          0.068327      0.005910         0.006573        0.000502   \n",
       "2          0.065225      0.003191         0.006683        0.000457   \n",
       "3          0.063630      0.001596         0.006483        0.000499   \n",
       "4          0.061435      0.001493         0.006483        0.000498   \n",
       "...             ...           ...              ...             ...   \n",
       "2995       0.206226      0.002782         0.007182        0.000598   \n",
       "2996       0.207998      0.002457         0.007280        0.000457   \n",
       "2997       0.207744      0.000898         0.007480        0.000499   \n",
       "2998       0.208343      0.001863         0.007280        0.000457   \n",
       "2999       0.207644      0.001882         0.007381        0.000489   \n",
       "\n",
       "     param_colsample_bylevel param_colsample_bytree param_learning_rate  \\\n",
       "0                        0.3                    0.3                 0.1   \n",
       "1                        0.3                    0.3                 0.1   \n",
       "2                        0.3                    0.3                 0.1   \n",
       "3                        0.3                    0.3                 0.1   \n",
       "4                        0.3                    0.3                 0.1   \n",
       "...                      ...                    ...                 ...   \n",
       "2995                     0.3                    0.9                 0.4   \n",
       "2996                     0.3                    0.9                 0.4   \n",
       "2997                     0.3                    0.9                 0.4   \n",
       "2998                     0.3                    0.9                 0.4   \n",
       "2999                     0.3                    0.9                 0.4   \n",
       "\n",
       "     param_max_depth param_n_estimators param_subsample  ...  \\\n",
       "0                  2                100             0.5  ...   \n",
       "1                  2                100             0.6  ...   \n",
       "2                  2                100             0.7  ...   \n",
       "3                  2                100             0.8  ...   \n",
       "4                  2                100             0.9  ...   \n",
       "...              ...                ...             ...  ...   \n",
       "2995               5                300             0.5  ...   \n",
       "2996               5                300             0.6  ...   \n",
       "2997               5                300             0.7  ...   \n",
       "2998               5                300             0.8  ...   \n",
       "2999               5                300             0.9  ...   \n",
       "\n",
       "     split3_test_score  split4_test_score  split5_test_score  \\\n",
       "0             0.822581           0.822581           0.806452   \n",
       "1             0.838710           0.822581           0.806452   \n",
       "2             0.838710           0.806452           0.806452   \n",
       "3             0.854839           0.822581           0.806452   \n",
       "4             0.854839           0.822581           0.838710   \n",
       "...                ...                ...                ...   \n",
       "2995          0.838710           0.790323           0.774194   \n",
       "2996          0.854839           0.774194           0.790323   \n",
       "2997          0.854839           0.790323           0.758065   \n",
       "2998          0.854839           0.790323           0.790323   \n",
       "2999          0.822581           0.790323           0.774194   \n",
       "\n",
       "      split6_test_score  split7_test_score  split8_test_score  \\\n",
       "0              0.822581           0.806452           0.693548   \n",
       "1              0.838710           0.806452           0.661290   \n",
       "2              0.838710           0.806452           0.677419   \n",
       "3              0.854839           0.806452           0.661290   \n",
       "4              0.838710           0.806452           0.677419   \n",
       "...                 ...                ...                ...   \n",
       "2995           0.838710           0.822581           0.709677   \n",
       "2996           0.854839           0.806452           0.693548   \n",
       "2997           0.822581           0.806452           0.709677   \n",
       "2998           0.822581           0.806452           0.693548   \n",
       "2999           0.854839           0.806452           0.709677   \n",
       "\n",
       "      split9_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0              0.838710         0.820020        0.048275             2509  \n",
       "1              0.854839         0.823221        0.059057             2140  \n",
       "2              0.838710         0.824782        0.057512             2021  \n",
       "3              0.838710         0.824834        0.059251             1898  \n",
       "4              0.838710         0.828059        0.053977             1394  \n",
       "...                 ...              ...             ...              ...  \n",
       "2995           0.822581         0.813646        0.044452             2900  \n",
       "2996           0.854839         0.818459        0.053856             2648  \n",
       "2997           0.822581         0.813594        0.056215             2908  \n",
       "2998           0.822581         0.815207        0.053961             2850  \n",
       "2999           0.854839         0.820020        0.055129             2509  \n",
       "\n",
       "[3000 rows x 24 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score is 0.850563236047107 with params {'colsample_bylevel': 0.3, 'colsample_bytree': 0.5, 'learning_rate': 0.15, 'max_depth': 2, 'n_estimators': 100, 'subsample': 0.7}\n"
     ]
    }
   ],
   "source": [
    "# Full Tuning - Part 3\n",
    "random.seed(10)\n",
    "\n",
    "xgb = XGBClassifier()\n",
    "\n",
    "xgb_parameters = {'max_depth': [2,3,4,5]\n",
    "                   , 'subsample': [0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "                   , 'colsample_bytree': [0.3, 0.4, 0.5, 0.6, 0.9]\n",
    "                   , 'colsample_bylevel': [0.3]\n",
    "                   , 'learning_rate': [0.1, 0.15, 0.2, 0.25, 0.3, 0.4]\n",
    "                   , 'n_estimators': [100, 150, 200, 250, 300]}\n",
    "\n",
    "stratified_10_fold_cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "xgb_grid_search = GridSearchCV(xgb, xgb_parameters, scoring='accuracy', cv=stratified_10_fold_cv)\n",
    "\n",
    "xgb_grid_search.fit(X_train, y_train)\n",
    "\n",
    "xgb_grid_search_results_full_3 = pd.DataFrame(xgb_grid_search.cv_results_)\n",
    "display(xgb_grid_search_results_full_3)\n",
    "\n",
    "print(\"best score is {} with params {}\".format(xgb_grid_search.best_score_, xgb_grid_search.best_params_))\n",
    "\n",
    "# best values for\n",
    "\n",
    "# save dataframe\n",
    "from datetime import datetime\n",
    "date = str(datetime.now().date()).replace(\"-\", \"\")\n",
    "xgb_grid_search_results_full_3.to_csv(f\"data/xgb_results_full_3_bylevel=0.3_{date}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "08bbc473",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_colsample_bylevel</th>\n",
       "      <th>param_colsample_bytree</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_subsample</th>\n",
       "      <th>...</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.061735</td>\n",
       "      <td>0.001296</td>\n",
       "      <td>0.006482</td>\n",
       "      <td>0.000669</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.820020</td>\n",
       "      <td>0.048275</td>\n",
       "      <td>2502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.063031</td>\n",
       "      <td>0.002778</td>\n",
       "      <td>0.006483</td>\n",
       "      <td>0.000669</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.661290</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.823221</td>\n",
       "      <td>0.059057</td>\n",
       "      <td>2077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.060638</td>\n",
       "      <td>0.000746</td>\n",
       "      <td>0.006782</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.824782</td>\n",
       "      <td>0.057512</td>\n",
       "      <td>1941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.060339</td>\n",
       "      <td>0.000919</td>\n",
       "      <td>0.006483</td>\n",
       "      <td>0.000499</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.661290</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.824834</td>\n",
       "      <td>0.059251</td>\n",
       "      <td>1818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.059840</td>\n",
       "      <td>0.001180</td>\n",
       "      <td>0.006682</td>\n",
       "      <td>0.000457</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.828059</td>\n",
       "      <td>0.053977</td>\n",
       "      <td>1289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2995</th>\n",
       "      <td>0.218216</td>\n",
       "      <td>0.004179</td>\n",
       "      <td>0.007181</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.808807</td>\n",
       "      <td>0.046180</td>\n",
       "      <td>2975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2996</th>\n",
       "      <td>0.221009</td>\n",
       "      <td>0.003402</td>\n",
       "      <td>0.007480</td>\n",
       "      <td>0.000499</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.812007</td>\n",
       "      <td>0.049754</td>\n",
       "      <td>2922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2997</th>\n",
       "      <td>0.221308</td>\n",
       "      <td>0.004515</td>\n",
       "      <td>0.007380</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.816795</td>\n",
       "      <td>0.050406</td>\n",
       "      <td>2770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998</th>\n",
       "      <td>0.219213</td>\n",
       "      <td>0.003908</td>\n",
       "      <td>0.007194</td>\n",
       "      <td>0.000425</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.816820</td>\n",
       "      <td>0.047212</td>\n",
       "      <td>2763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999</th>\n",
       "      <td>0.216122</td>\n",
       "      <td>0.003092</td>\n",
       "      <td>0.007381</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.818382</td>\n",
       "      <td>0.050014</td>\n",
       "      <td>2693</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0          0.061735      0.001296         0.006482        0.000669   \n",
       "1          0.063031      0.002778         0.006483        0.000669   \n",
       "2          0.060638      0.000746         0.006782        0.000399   \n",
       "3          0.060339      0.000919         0.006483        0.000499   \n",
       "4          0.059840      0.001180         0.006682        0.000457   \n",
       "...             ...           ...              ...             ...   \n",
       "2995       0.218216      0.004179         0.007181        0.000399   \n",
       "2996       0.221009      0.003402         0.007480        0.000499   \n",
       "2997       0.221308      0.004515         0.007380        0.000489   \n",
       "2998       0.219213      0.003908         0.007194        0.000425   \n",
       "2999       0.216122      0.003092         0.007381        0.000489   \n",
       "\n",
       "     param_colsample_bylevel param_colsample_bytree param_learning_rate  \\\n",
       "0                        0.4                    0.3                 0.1   \n",
       "1                        0.4                    0.3                 0.1   \n",
       "2                        0.4                    0.3                 0.1   \n",
       "3                        0.4                    0.3                 0.1   \n",
       "4                        0.4                    0.3                 0.1   \n",
       "...                      ...                    ...                 ...   \n",
       "2995                     0.4                    0.9                 0.4   \n",
       "2996                     0.4                    0.9                 0.4   \n",
       "2997                     0.4                    0.9                 0.4   \n",
       "2998                     0.4                    0.9                 0.4   \n",
       "2999                     0.4                    0.9                 0.4   \n",
       "\n",
       "     param_max_depth param_n_estimators param_subsample  ...  \\\n",
       "0                  2                100             0.5  ...   \n",
       "1                  2                100             0.6  ...   \n",
       "2                  2                100             0.7  ...   \n",
       "3                  2                100             0.8  ...   \n",
       "4                  2                100             0.9  ...   \n",
       "...              ...                ...             ...  ...   \n",
       "2995               5                300             0.5  ...   \n",
       "2996               5                300             0.6  ...   \n",
       "2997               5                300             0.7  ...   \n",
       "2998               5                300             0.8  ...   \n",
       "2999               5                300             0.9  ...   \n",
       "\n",
       "     split3_test_score  split4_test_score  split5_test_score  \\\n",
       "0             0.822581           0.822581           0.806452   \n",
       "1             0.838710           0.822581           0.806452   \n",
       "2             0.838710           0.806452           0.806452   \n",
       "3             0.854839           0.822581           0.806452   \n",
       "4             0.854839           0.822581           0.838710   \n",
       "...                ...                ...                ...   \n",
       "2995          0.838710           0.758065           0.790323   \n",
       "2996          0.838710           0.790323           0.806452   \n",
       "2997          0.838710           0.790323           0.790323   \n",
       "2998          0.838710           0.790323           0.806452   \n",
       "2999          0.822581           0.774194           0.774194   \n",
       "\n",
       "      split6_test_score  split7_test_score  split8_test_score  \\\n",
       "0              0.822581           0.806452           0.693548   \n",
       "1              0.838710           0.806452           0.661290   \n",
       "2              0.838710           0.806452           0.677419   \n",
       "3              0.854839           0.806452           0.661290   \n",
       "4              0.838710           0.806452           0.677419   \n",
       "...                 ...                ...                ...   \n",
       "2995           0.806452           0.790323           0.741935   \n",
       "2996           0.838710           0.774194           0.725806   \n",
       "2997           0.790323           0.822581           0.725806   \n",
       "2998           0.838710           0.790323           0.725806   \n",
       "2999           0.854839           0.790323           0.725806   \n",
       "\n",
       "      split9_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0              0.838710         0.820020        0.048275             2502  \n",
       "1              0.854839         0.823221        0.059057             2077  \n",
       "2              0.838710         0.824782        0.057512             1941  \n",
       "3              0.838710         0.824834        0.059251             1818  \n",
       "4              0.838710         0.828059        0.053977             1289  \n",
       "...                 ...              ...             ...              ...  \n",
       "2995           0.822581         0.808807        0.046180             2975  \n",
       "2996           0.790323         0.812007        0.049754             2922  \n",
       "2997           0.822581         0.816795        0.050406             2770  \n",
       "2998           0.806452         0.816820        0.047212             2763  \n",
       "2999           0.838710         0.818382        0.050014             2693  \n",
       "\n",
       "[3000 rows x 24 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score is 0.850563236047107 with params {'colsample_bylevel': 0.4, 'colsample_bytree': 0.5, 'learning_rate': 0.15, 'max_depth': 2, 'n_estimators': 100, 'subsample': 0.7}\n"
     ]
    }
   ],
   "source": [
    "# Full Tuning - Part 4\n",
    "random.seed(10)\n",
    "\n",
    "xgb = XGBClassifier()\n",
    "\n",
    "xgb_parameters = {'max_depth': [2,3,4,5]\n",
    "                   , 'subsample': [0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "                   , 'colsample_bytree': [0.3, 0.4, 0.5, 0.6, 0.9]\n",
    "                   , 'colsample_bylevel': [0.4]\n",
    "                   , 'learning_rate': [0.1, 0.15, 0.2, 0.25, 0.3, 0.4]\n",
    "                   , 'n_estimators': [100, 150, 200, 250, 300]}\n",
    "\n",
    "stratified_10_fold_cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "xgb_grid_search = GridSearchCV(xgb, xgb_parameters, scoring='accuracy', cv=stratified_10_fold_cv)\n",
    "\n",
    "xgb_grid_search.fit(X_train, y_train)\n",
    "\n",
    "xgb_grid_search_results_full_4 = pd.DataFrame(xgb_grid_search.cv_results_)\n",
    "display(xgb_grid_search_results_full_4)\n",
    "\n",
    "print(\"best score is {} with params {}\".format(xgb_grid_search.best_score_, xgb_grid_search.best_params_))\n",
    "\n",
    "# best values for\n",
    "\n",
    "# save dataframe\n",
    "from datetime import datetime\n",
    "date = str(datetime.now().date()).replace(\"-\", \"\")\n",
    "xgb_grid_search_results_full_4.to_csv(f\"data/xgb_results_full_4_bylevel=0.4_{date}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f0c2ba0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_colsample_bylevel</th>\n",
       "      <th>param_colsample_bytree</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_subsample</th>\n",
       "      <th>...</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.063530</td>\n",
       "      <td>0.002446</td>\n",
       "      <td>0.006383</td>\n",
       "      <td>0.000662</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.834537</td>\n",
       "      <td>0.044892</td>\n",
       "      <td>215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.065725</td>\n",
       "      <td>0.003351</td>\n",
       "      <td>0.006882</td>\n",
       "      <td>0.000299</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.832949</td>\n",
       "      <td>0.048291</td>\n",
       "      <td>320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.062236</td>\n",
       "      <td>0.001196</td>\n",
       "      <td>0.006780</td>\n",
       "      <td>0.000398</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.887097</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.842601</td>\n",
       "      <td>0.046342</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.061335</td>\n",
       "      <td>0.001798</td>\n",
       "      <td>0.006583</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.834562</td>\n",
       "      <td>0.050284</td>\n",
       "      <td>208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.060937</td>\n",
       "      <td>0.000698</td>\n",
       "      <td>0.006483</td>\n",
       "      <td>0.000669</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.887097</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.832924</td>\n",
       "      <td>0.057218</td>\n",
       "      <td>327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2995</th>\n",
       "      <td>0.219613</td>\n",
       "      <td>0.001532</td>\n",
       "      <td>0.007380</td>\n",
       "      <td>0.000488</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.805504</td>\n",
       "      <td>0.051226</td>\n",
       "      <td>2997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2996</th>\n",
       "      <td>0.222105</td>\n",
       "      <td>0.001787</td>\n",
       "      <td>0.006882</td>\n",
       "      <td>0.000698</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.810317</td>\n",
       "      <td>0.059764</td>\n",
       "      <td>2968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2997</th>\n",
       "      <td>0.221906</td>\n",
       "      <td>0.002534</td>\n",
       "      <td>0.007281</td>\n",
       "      <td>0.000457</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.818331</td>\n",
       "      <td>0.051641</td>\n",
       "      <td>2706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998</th>\n",
       "      <td>0.224599</td>\n",
       "      <td>0.011023</td>\n",
       "      <td>0.007380</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.816718</td>\n",
       "      <td>0.054669</td>\n",
       "      <td>2825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999</th>\n",
       "      <td>0.219812</td>\n",
       "      <td>0.002609</td>\n",
       "      <td>0.007381</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.807220</td>\n",
       "      <td>0.045482</td>\n",
       "      <td>2983</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0          0.063530      0.002446         0.006383        0.000662   \n",
       "1          0.065725      0.003351         0.006882        0.000299   \n",
       "2          0.062236      0.001196         0.006780        0.000398   \n",
       "3          0.061335      0.001798         0.006583        0.000489   \n",
       "4          0.060937      0.000698         0.006483        0.000669   \n",
       "...             ...           ...              ...             ...   \n",
       "2995       0.219613      0.001532         0.007380        0.000488   \n",
       "2996       0.222105      0.001787         0.006882        0.000698   \n",
       "2997       0.221906      0.002534         0.007281        0.000457   \n",
       "2998       0.224599      0.011023         0.007380        0.000489   \n",
       "2999       0.219812      0.002609         0.007381        0.000489   \n",
       "\n",
       "     param_colsample_bylevel param_colsample_bytree param_learning_rate  \\\n",
       "0                        0.6                    0.3                 0.1   \n",
       "1                        0.6                    0.3                 0.1   \n",
       "2                        0.6                    0.3                 0.1   \n",
       "3                        0.6                    0.3                 0.1   \n",
       "4                        0.6                    0.3                 0.1   \n",
       "...                      ...                    ...                 ...   \n",
       "2995                     0.6                    0.9                 0.4   \n",
       "2996                     0.6                    0.9                 0.4   \n",
       "2997                     0.6                    0.9                 0.4   \n",
       "2998                     0.6                    0.9                 0.4   \n",
       "2999                     0.6                    0.9                 0.4   \n",
       "\n",
       "     param_max_depth param_n_estimators param_subsample  ...  \\\n",
       "0                  2                100             0.5  ...   \n",
       "1                  2                100             0.6  ...   \n",
       "2                  2                100             0.7  ...   \n",
       "3                  2                100             0.8  ...   \n",
       "4                  2                100             0.9  ...   \n",
       "...              ...                ...             ...  ...   \n",
       "2995               5                300             0.5  ...   \n",
       "2996               5                300             0.6  ...   \n",
       "2997               5                300             0.7  ...   \n",
       "2998               5                300             0.8  ...   \n",
       "2999               5                300             0.9  ...   \n",
       "\n",
       "     split3_test_score  split4_test_score  split5_test_score  \\\n",
       "0             0.870968           0.822581           0.838710   \n",
       "1             0.854839           0.822581           0.854839   \n",
       "2             0.887097           0.838710           0.854839   \n",
       "3             0.870968           0.822581           0.870968   \n",
       "4             0.870968           0.822581           0.887097   \n",
       "...                ...                ...                ...   \n",
       "2995          0.806452           0.741935           0.774194   \n",
       "2996          0.854839           0.790323           0.758065   \n",
       "2997          0.838710           0.774194           0.790323   \n",
       "2998          0.838710           0.790323           0.758065   \n",
       "2999          0.822581           0.790323           0.758065   \n",
       "\n",
       "      split6_test_score  split7_test_score  split8_test_score  \\\n",
       "0              0.854839           0.822581           0.709677   \n",
       "1              0.854839           0.822581           0.693548   \n",
       "2              0.854839           0.838710           0.709677   \n",
       "3              0.838710           0.822581           0.693548   \n",
       "4              0.822581           0.806452           0.677419   \n",
       "...                 ...                ...                ...   \n",
       "2995           0.806452           0.790323           0.741935   \n",
       "2996           0.822581           0.741935           0.725806   \n",
       "2997           0.822581           0.774194           0.725806   \n",
       "2998           0.822581           0.806452           0.709677   \n",
       "2999           0.838710           0.806452           0.709677   \n",
       "\n",
       "      split9_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0              0.838710         0.834537        0.044892              215  \n",
       "1              0.854839         0.832949        0.048291              320  \n",
       "2              0.854839         0.842601        0.046342               17  \n",
       "3              0.854839         0.834562        0.050284              208  \n",
       "4              0.854839         0.832924        0.057218              327  \n",
       "...                 ...              ...             ...              ...  \n",
       "2995           0.806452         0.805504        0.051226             2997  \n",
       "2996           0.806452         0.810317        0.059764             2968  \n",
       "2997           0.822581         0.818331        0.051641             2706  \n",
       "2998           0.806452         0.816718        0.054669             2825  \n",
       "2999           0.822581         0.807220        0.045482             2983  \n",
       "\n",
       "[3000 rows x 24 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score is 0.8458269329237071 with params {'colsample_bylevel': 0.6, 'colsample_bytree': 0.4, 'learning_rate': 0.1, 'max_depth': 2, 'n_estimators': 100, 'subsample': 0.8}\n"
     ]
    }
   ],
   "source": [
    "# Full Tuning - Part 5\n",
    "random.seed(10)\n",
    "\n",
    "xgb = XGBClassifier()\n",
    "\n",
    "xgb_parameters = {'max_depth': [2,3,4,5]\n",
    "                   , 'subsample': [0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "                   , 'colsample_bytree': [0.3, 0.4, 0.5, 0.6, 0.9]\n",
    "                   , 'colsample_bylevel': [0.6]\n",
    "                   , 'learning_rate': [0.1, 0.15, 0.2, 0.25, 0.3, 0.4]\n",
    "                   , 'n_estimators': [100, 150, 200, 250, 300]}\n",
    "\n",
    "stratified_10_fold_cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "xgb_grid_search = GridSearchCV(xgb, xgb_parameters, scoring='accuracy', cv=stratified_10_fold_cv)\n",
    "\n",
    "xgb_grid_search.fit(X_train, y_train)\n",
    "\n",
    "xgb_grid_search_results_full_5 = pd.DataFrame(xgb_grid_search.cv_results_)\n",
    "display(xgb_grid_search_results_full_5)\n",
    "\n",
    "print(\"best score is {} with params {}\".format(xgb_grid_search.best_score_, xgb_grid_search.best_params_))\n",
    "\n",
    "# best values for\n",
    "\n",
    "# save dataframe\n",
    "from datetime import datetime\n",
    "date = str(datetime.now().date()).replace(\"-\", \"\")\n",
    "xgb_grid_search_results_full_5.to_csv(f\"data/xgb_results_full_5_bylevel=0.6_{date}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2295a913",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_colsample_bylevel</th>\n",
       "      <th>param_colsample_bytree</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_subsample</th>\n",
       "      <th>...</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.063128</td>\n",
       "      <td>0.002527</td>\n",
       "      <td>0.006483</td>\n",
       "      <td>0.000669</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.834537</td>\n",
       "      <td>0.044892</td>\n",
       "      <td>218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.065325</td>\n",
       "      <td>0.003097</td>\n",
       "      <td>0.006882</td>\n",
       "      <td>0.000537</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.832949</td>\n",
       "      <td>0.048291</td>\n",
       "      <td>327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.061886</td>\n",
       "      <td>0.000566</td>\n",
       "      <td>0.006583</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.887097</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.842601</td>\n",
       "      <td>0.046342</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.061137</td>\n",
       "      <td>0.000638</td>\n",
       "      <td>0.006882</td>\n",
       "      <td>0.000299</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.834562</td>\n",
       "      <td>0.050284</td>\n",
       "      <td>210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.060537</td>\n",
       "      <td>0.000638</td>\n",
       "      <td>0.006682</td>\n",
       "      <td>0.000457</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.887097</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.832924</td>\n",
       "      <td>0.057218</td>\n",
       "      <td>333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2995</th>\n",
       "      <td>0.228489</td>\n",
       "      <td>0.002462</td>\n",
       "      <td>0.007480</td>\n",
       "      <td>0.000499</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.802355</td>\n",
       "      <td>0.049888</td>\n",
       "      <td>2998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2996</th>\n",
       "      <td>0.228688</td>\n",
       "      <td>0.002142</td>\n",
       "      <td>0.007281</td>\n",
       "      <td>0.000457</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.800768</td>\n",
       "      <td>0.052893</td>\n",
       "      <td>2999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2997</th>\n",
       "      <td>0.228987</td>\n",
       "      <td>0.001197</td>\n",
       "      <td>0.007580</td>\n",
       "      <td>0.000488</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.810317</td>\n",
       "      <td>0.057193</td>\n",
       "      <td>2964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998</th>\n",
       "      <td>0.228788</td>\n",
       "      <td>0.001620</td>\n",
       "      <td>0.007181</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.816692</td>\n",
       "      <td>0.055624</td>\n",
       "      <td>2812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999</th>\n",
       "      <td>0.226893</td>\n",
       "      <td>0.002150</td>\n",
       "      <td>0.007381</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.818382</td>\n",
       "      <td>0.053516</td>\n",
       "      <td>2629</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0          0.063128      0.002527         0.006483        0.000669   \n",
       "1          0.065325      0.003097         0.006882        0.000537   \n",
       "2          0.061886      0.000566         0.006583        0.000489   \n",
       "3          0.061137      0.000638         0.006882        0.000299   \n",
       "4          0.060537      0.000638         0.006682        0.000457   \n",
       "...             ...           ...              ...             ...   \n",
       "2995       0.228489      0.002462         0.007480        0.000499   \n",
       "2996       0.228688      0.002142         0.007281        0.000457   \n",
       "2997       0.228987      0.001197         0.007580        0.000488   \n",
       "2998       0.228788      0.001620         0.007181        0.000399   \n",
       "2999       0.226893      0.002150         0.007381        0.000489   \n",
       "\n",
       "     param_colsample_bylevel param_colsample_bytree param_learning_rate  \\\n",
       "0                        0.7                    0.3                 0.1   \n",
       "1                        0.7                    0.3                 0.1   \n",
       "2                        0.7                    0.3                 0.1   \n",
       "3                        0.7                    0.3                 0.1   \n",
       "4                        0.7                    0.3                 0.1   \n",
       "...                      ...                    ...                 ...   \n",
       "2995                     0.7                    0.9                 0.4   \n",
       "2996                     0.7                    0.9                 0.4   \n",
       "2997                     0.7                    0.9                 0.4   \n",
       "2998                     0.7                    0.9                 0.4   \n",
       "2999                     0.7                    0.9                 0.4   \n",
       "\n",
       "     param_max_depth param_n_estimators param_subsample  ...  \\\n",
       "0                  2                100             0.5  ...   \n",
       "1                  2                100             0.6  ...   \n",
       "2                  2                100             0.7  ...   \n",
       "3                  2                100             0.8  ...   \n",
       "4                  2                100             0.9  ...   \n",
       "...              ...                ...             ...  ...   \n",
       "2995               5                300             0.5  ...   \n",
       "2996               5                300             0.6  ...   \n",
       "2997               5                300             0.7  ...   \n",
       "2998               5                300             0.8  ...   \n",
       "2999               5                300             0.9  ...   \n",
       "\n",
       "     split3_test_score  split4_test_score  split5_test_score  \\\n",
       "0             0.870968           0.822581           0.838710   \n",
       "1             0.854839           0.822581           0.854839   \n",
       "2             0.887097           0.838710           0.854839   \n",
       "3             0.870968           0.822581           0.870968   \n",
       "4             0.870968           0.822581           0.887097   \n",
       "...                ...                ...                ...   \n",
       "2995          0.822581           0.774194           0.806452   \n",
       "2996          0.822581           0.774194           0.790323   \n",
       "2997          0.870968           0.774194           0.774194   \n",
       "2998          0.822581           0.790323           0.774194   \n",
       "2999          0.806452           0.790323           0.774194   \n",
       "\n",
       "      split6_test_score  split7_test_score  split8_test_score  \\\n",
       "0              0.854839           0.822581           0.709677   \n",
       "1              0.854839           0.822581           0.693548   \n",
       "2              0.854839           0.838710           0.709677   \n",
       "3              0.838710           0.822581           0.693548   \n",
       "4              0.822581           0.806452           0.677419   \n",
       "...                 ...                ...                ...   \n",
       "2995           0.822581           0.774194           0.709677   \n",
       "2996           0.822581           0.790323           0.693548   \n",
       "2997           0.790323           0.790323           0.709677   \n",
       "2998           0.822581           0.790323           0.709677   \n",
       "2999           0.854839           0.790323           0.709677   \n",
       "\n",
       "      split9_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0              0.838710         0.834537        0.044892              218  \n",
       "1              0.854839         0.832949        0.048291              327  \n",
       "2              0.854839         0.842601        0.046342               16  \n",
       "3              0.854839         0.834562        0.050284              210  \n",
       "4              0.854839         0.832924        0.057218              333  \n",
       "...                 ...              ...             ...              ...  \n",
       "2995           0.774194         0.802355        0.049888             2998  \n",
       "2996           0.790323         0.800768        0.052893             2999  \n",
       "2997           0.790323         0.810317        0.057193             2964  \n",
       "2998           0.806452         0.816692        0.055624             2812  \n",
       "2999           0.854839         0.818382        0.053516             2629  \n",
       "\n",
       "[3000 rows x 24 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score is 0.8490015360983103 with params {'colsample_bylevel': 0.7, 'colsample_bytree': 0.4, 'learning_rate': 0.1, 'max_depth': 2, 'n_estimators': 150, 'subsample': 0.9}\n"
     ]
    }
   ],
   "source": [
    "# Full Tuning - Part 6\n",
    "random.seed(10)\n",
    "\n",
    "xgb = XGBClassifier()\n",
    "\n",
    "xgb_parameters = {'max_depth': [2,3,4,5]\n",
    "                   , 'subsample': [0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "                   , 'colsample_bytree': [0.3, 0.4, 0.5, 0.6, 0.9]\n",
    "                   , 'colsample_bylevel': [0.7]\n",
    "                   , 'learning_rate': [0.1, 0.15, 0.2, 0.25, 0.3, 0.4]\n",
    "                   , 'n_estimators': [100, 150, 200, 250, 300]}\n",
    "\n",
    "stratified_10_fold_cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "xgb_grid_search = GridSearchCV(xgb, xgb_parameters, scoring='accuracy', cv=stratified_10_fold_cv)\n",
    "\n",
    "xgb_grid_search.fit(X_train, y_train)\n",
    "\n",
    "xgb_grid_search_results_full_6 = pd.DataFrame(xgb_grid_search.cv_results_)\n",
    "display(xgb_grid_search_results_full_6)\n",
    "\n",
    "print(\"best score is {} with params {}\".format(xgb_grid_search.best_score_, xgb_grid_search.best_params_))\n",
    "\n",
    "# best values for\n",
    "\n",
    "# save dataframe\n",
    "from datetime import datetime\n",
    "date = str(datetime.now().date()).replace(\"-\", \"\")\n",
    "xgb_grid_search_results_full_6.to_csv(f\"data/xgb_results_full_6_bylevel=0.7_{date}.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6f32066",
   "metadata": {},
   "source": [
    "Combine single hyperparameter tuning to find best values for hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "f96d3ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(\"data\\\\xgb_results_full_1_bylevel=0.1_20221123.csv\")\n",
    "df1.drop(df1.columns[0], axis=1, inplace=True)\n",
    "\n",
    "df2 = pd.read_csv(\"data\\\\xgb_results_full_2_bylevel=0.2_20221123.csv\")\n",
    "df2.drop(df2.columns[0], axis=1, inplace=True)\n",
    "\n",
    "df3 = pd.read_csv(\"data\\\\xgb_results_full_3_bylevel=0.3_20221123.csv\")\n",
    "df3.drop(df3.columns[0], axis=1, inplace=True)\n",
    "\n",
    "df4 = pd.read_csv(\"data\\\\xgb_results_full_4_bylevel=0.4_20221123.csv\")\n",
    "df4.drop(df4.columns[0], axis=1, inplace=True)\n",
    "\n",
    "df5 = pd.read_csv(\"data\\\\xgb_results_full_5_bylevel=0.6_20221123.csv\")\n",
    "df5.drop(df5.columns[0], axis=1, inplace=True)\n",
    "\n",
    "df6 = pd.read_csv(\"data\\\\xgb_results_full_6_bylevel=0.7_20221123.csv\")\n",
    "df6.drop(df6.columns[0], axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3ff16d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_grid_search_results_full = pd.concat([df1,df2,df3,df4,df5,df6])\n",
    "from datetime import datetime\n",
    "date = str(datetime.now().date()).replace(\"-\", \"\")\n",
    "xgb_grid_search_results_full.to_csv(f\"data/xgb_results_full_combined_2_{date}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0ffb993b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_subsample</th>\n",
       "      <th>param_colsample_bytree</th>\n",
       "      <th>param_colsample_bylevel</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1302</th>\n",
       "      <td>2</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.15</td>\n",
       "      <td>100</td>\n",
       "      <td>0.850563</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1302</th>\n",
       "      <td>2</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.15</td>\n",
       "      <td>100</td>\n",
       "      <td>0.850563</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1976</th>\n",
       "      <td>5</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.15</td>\n",
       "      <td>100</td>\n",
       "      <td>0.850538</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1976</th>\n",
       "      <td>5</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.15</td>\n",
       "      <td>100</td>\n",
       "      <td>0.850538</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2419</th>\n",
       "      <td>2</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>250</td>\n",
       "      <td>0.849002</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>609</th>\n",
       "      <td>2</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.1</td>\n",
       "      <td>150</td>\n",
       "      <td>0.849002</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2603</th>\n",
       "      <td>2</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.848950</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2456</th>\n",
       "      <td>4</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>150</td>\n",
       "      <td>0.848925</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1329</th>\n",
       "      <td>3</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.15</td>\n",
       "      <td>100</td>\n",
       "      <td>0.847312</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1329</th>\n",
       "      <td>3</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.15</td>\n",
       "      <td>100</td>\n",
       "      <td>0.847312</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1853</th>\n",
       "      <td>4</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>100</td>\n",
       "      <td>0.847312</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1853</th>\n",
       "      <td>4</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>100</td>\n",
       "      <td>0.847312</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>603</th>\n",
       "      <td>2</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.1</td>\n",
       "      <td>100</td>\n",
       "      <td>0.845827</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.1</td>\n",
       "      <td>150</td>\n",
       "      <td>0.845801</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.1</td>\n",
       "      <td>150</td>\n",
       "      <td>0.845801</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.1</td>\n",
       "      <td>250</td>\n",
       "      <td>0.845801</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.1</td>\n",
       "      <td>250</td>\n",
       "      <td>0.845801</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1951</th>\n",
       "      <td>4</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.15</td>\n",
       "      <td>100</td>\n",
       "      <td>0.845776</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1951</th>\n",
       "      <td>4</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.15</td>\n",
       "      <td>100</td>\n",
       "      <td>0.845776</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1850</th>\n",
       "      <td>4</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>100</td>\n",
       "      <td>0.845776</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1801</th>\n",
       "      <td>2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>100</td>\n",
       "      <td>0.845776</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1328</th>\n",
       "      <td>3</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.15</td>\n",
       "      <td>100</td>\n",
       "      <td>0.845776</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1850</th>\n",
       "      <td>4</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>100</td>\n",
       "      <td>0.845776</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2475</th>\n",
       "      <td>5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>100</td>\n",
       "      <td>0.845776</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1300</th>\n",
       "      <td>2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.15</td>\n",
       "      <td>100</td>\n",
       "      <td>0.845776</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1328</th>\n",
       "      <td>3</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.15</td>\n",
       "      <td>100</td>\n",
       "      <td>0.845776</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1801</th>\n",
       "      <td>2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>100</td>\n",
       "      <td>0.845776</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1300</th>\n",
       "      <td>2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.15</td>\n",
       "      <td>100</td>\n",
       "      <td>0.845776</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2508</th>\n",
       "      <td>2</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.15</td>\n",
       "      <td>150</td>\n",
       "      <td>0.845776</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1802</th>\n",
       "      <td>2</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>100</td>\n",
       "      <td>0.845776</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     param_max_depth param_subsample param_colsample_bytree  \\\n",
       "1302               2             0.7                    0.5   \n",
       "1302               2             0.7                    0.5   \n",
       "1976               5             0.6                    0.6   \n",
       "1976               5             0.6                    0.6   \n",
       "2419               2             0.9                    0.9   \n",
       "609                2             0.9                    0.4   \n",
       "2603               2             0.8                    0.9   \n",
       "2456               4             0.6                    0.9   \n",
       "1329               3             0.9                    0.5   \n",
       "1329               3             0.9                    0.5   \n",
       "1853               4             0.8                    0.6   \n",
       "1853               4             0.8                    0.6   \n",
       "603                2             0.8                    0.4   \n",
       "8                  2             0.8                    0.3   \n",
       "8                  2             0.8                    0.3   \n",
       "15                 2             0.5                    0.3   \n",
       "15                 2             0.5                    0.3   \n",
       "1951               4             0.6                    0.6   \n",
       "1951               4             0.6                    0.6   \n",
       "1850               4             0.5                    0.6   \n",
       "1801               2             0.6                    0.6   \n",
       "1328               3             0.8                    0.5   \n",
       "1850               4             0.5                    0.6   \n",
       "2475               5             0.5                    0.9   \n",
       "1300               2             0.5                    0.5   \n",
       "1328               3             0.8                    0.5   \n",
       "1801               2             0.6                    0.6   \n",
       "1300               2             0.5                    0.5   \n",
       "2508               2             0.8                    0.9   \n",
       "1802               2             0.7                    0.6   \n",
       "\n",
       "     param_colsample_bylevel param_learning_rate param_n_estimators  \\\n",
       "1302                     0.4                0.15                100   \n",
       "1302                     0.3                0.15                100   \n",
       "1976                     0.2                0.15                100   \n",
       "1976                     0.1                0.15                100   \n",
       "2419                     0.2                 0.1                250   \n",
       "609                      0.7                 0.1                150   \n",
       "2603                     0.2                 0.2                100   \n",
       "2456                     0.1                 0.1                150   \n",
       "1329                     0.4                0.15                100   \n",
       "1329                     0.3                0.15                100   \n",
       "1853                     0.2                 0.1                100   \n",
       "1853                     0.1                 0.1                100   \n",
       "603                      0.6                 0.1                100   \n",
       "8                        0.7                 0.1                150   \n",
       "8                        0.6                 0.1                150   \n",
       "15                       0.6                 0.1                250   \n",
       "15                       0.7                 0.1                250   \n",
       "1951                     0.1                0.15                100   \n",
       "1951                     0.2                0.15                100   \n",
       "1850                     0.2                 0.1                100   \n",
       "1801                     0.2                 0.1                100   \n",
       "1328                     0.1                0.15                100   \n",
       "1850                     0.1                 0.1                100   \n",
       "2475                     0.1                 0.1                100   \n",
       "1300                     0.4                0.15                100   \n",
       "1328                     0.2                0.15                100   \n",
       "1801                     0.1                 0.1                100   \n",
       "1300                     0.3                0.15                100   \n",
       "2508                     0.1                0.15                150   \n",
       "1802                     0.2                 0.1                100   \n",
       "\n",
       "      mean_test_score  rank_test_score  \n",
       "1302         0.850563                1  \n",
       "1302         0.850563                2  \n",
       "1976         0.850538                3  \n",
       "1976         0.850538                4  \n",
       "2419         0.849002                5  \n",
       "609          0.849002                6  \n",
       "2603         0.848950                7  \n",
       "2456         0.848925                8  \n",
       "1329         0.847312                9  \n",
       "1329         0.847312               10  \n",
       "1853         0.847312               11  \n",
       "1853         0.847312               12  \n",
       "603          0.845827               13  \n",
       "8            0.845801               14  \n",
       "8            0.845801               15  \n",
       "15           0.845801               16  \n",
       "15           0.845801               17  \n",
       "1951         0.845776               18  \n",
       "1951         0.845776               19  \n",
       "1850         0.845776               20  \n",
       "1801         0.845776               21  \n",
       "1328         0.845776               22  \n",
       "1850         0.845776               23  \n",
       "2475         0.845776               24  \n",
       "1300         0.845776               25  \n",
       "1328         0.845776               26  \n",
       "1801         0.845776               27  \n",
       "1300         0.845776               28  \n",
       "2508         0.845776               29  \n",
       "1802         0.845776               30  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols_full = ['param_max_depth', 'param_subsample', 'param_colsample_bytree', 'param_colsample_bylevel', 'param_learning_rate', 'param_n_estimators', 'mean_test_score']\n",
    "df_full = xgb_grid_search_results_full[cols_full]\n",
    "df_full_sorted = df_full.sort_values(by='mean_test_score', ascending=False)\n",
    "df_full_sorted['rank_test_score'] = range(1, len(df_full_sorted)+1)\n",
    "df_full_sorted.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "cc14b600",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "date = str(datetime.now().date()).replace(\"-\", \"\")\n",
    "df_full_sorted.to_csv(f\"data/xgb_results_full_sorted_{date}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "93b2c3b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8246268656716418\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.89      0.86       157\n",
      "           1       0.83      0.73      0.78       111\n",
      "\n",
      "    accuracy                           0.82       268\n",
      "   macro avg       0.83      0.81      0.82       268\n",
      "weighted avg       0.82      0.82      0.82       268\n",
      "\n",
      "Confusion Matrix:\n",
      "[[140  17]\n",
      " [ 30  81]]\n"
     ]
    }
   ],
   "source": [
    "# Fit and evaluate best model - 1\n",
    "\n",
    "#colsample_bylevel = 0.3 liefert gleiche Ergebnisse\n",
    "xgb_best = XGBClassifier(max_depth = 2, subsample = 0.7, colsample_bytree = 0.5, colsample_bylevel = 0.4, learning_rate = 0.15, n_estimators = 100)\n",
    "#0.8246268656716418\n",
    "xgb_best.fit(X_train, y_train)\n",
    "xgb_best_pred = xgb_best.predict(X_test)\n",
    "xgb_best_acc = accuracy_score(y_test, xgb_best_pred)\n",
    "print(xgb_best_acc)\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, xgb_best_pred))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, xgb_best_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "9624c86e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8283582089552238\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.89      0.86       157\n",
      "           1       0.82      0.75      0.78       111\n",
      "\n",
      "    accuracy                           0.83       268\n",
      "   macro avg       0.83      0.82      0.82       268\n",
      "weighted avg       0.83      0.83      0.83       268\n",
      "\n",
      "Confusion Matrix:\n",
      "[[139  18]\n",
      " [ 28  83]]\n"
     ]
    }
   ],
   "source": [
    "# Fit and evaluate best model - 2\n",
    "\n",
    "#colsample_bylevel = 0.2 liefert gleiche Ergebnisse\n",
    "#ebenso wie Kombi: max_depth = 2, subsample = 0.9, colsample_bytree = 0.9, colsample_bylevel = 0.2, learning_rate = 0.1, n_estimators = 250\n",
    "xgb_best = XGBClassifier(max_depth = 5, subsample = 0.6, colsample_bytree = 0.6, colsample_bylevel = 0.2, learning_rate = 0.15, n_estimators = 100)\n",
    "#0.8283582089552238\n",
    "xgb_best.fit(X_train, y_train)\n",
    "xgb_best_pred = xgb_best.predict(X_test)\n",
    "xgb_best_acc = accuracy_score(y_test, xgb_best_pred)\n",
    "print(xgb_best_acc)\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, xgb_best_pred))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, xgb_best_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b5ca8bf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 1\n",
      "250 5\n",
      "150 6\n",
      "200 35\n",
      "300 58\n"
     ]
    }
   ],
   "source": [
    "for v in df_full_sorted['param_n_estimators'].unique():\n",
    "    h = df_full_sorted.rank_test_score[df_full_sorted['param_n_estimators'] == v]\n",
    "    print(v, min(h))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e36c2e8c",
   "metadata": {},
   "source": [
    "beim nÃ¤chsten Tuning:  \n",
    "- param_subsample ungleich 0.5\n",
    "- param_colsample_bytree ungleich 0.3\n",
    "- param_colsample_bylevel ungleich 0.6\n",
    "- param_learning_rate kleiner gleich 0.2\n",
    "- param_n_estimators ungleich 200 und ungleich 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8945364",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "871fce0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "486b0ff9",
   "metadata": {},
   "source": [
    "## Full Tuning in Parts - Round 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a8b1f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "042c4de6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_colsample_bylevel</th>\n",
       "      <th>param_colsample_bytree</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_subsample</th>\n",
       "      <th>...</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.064527</td>\n",
       "      <td>0.004136</td>\n",
       "      <td>0.005885</td>\n",
       "      <td>5.376236e-04</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.820020</td>\n",
       "      <td>0.048275</td>\n",
       "      <td>2651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.064327</td>\n",
       "      <td>0.002493</td>\n",
       "      <td>0.005885</td>\n",
       "      <td>5.374151e-04</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.661290</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.823221</td>\n",
       "      <td>0.059057</td>\n",
       "      <td>2358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.063231</td>\n",
       "      <td>0.001954</td>\n",
       "      <td>0.005785</td>\n",
       "      <td>3.990535e-04</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.824782</td>\n",
       "      <td>0.057512</td>\n",
       "      <td>2252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.062235</td>\n",
       "      <td>0.001017</td>\n",
       "      <td>0.006082</td>\n",
       "      <td>3.001655e-04</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.661290</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.824834</td>\n",
       "      <td>0.059251</td>\n",
       "      <td>2175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.062333</td>\n",
       "      <td>0.002285</td>\n",
       "      <td>0.005784</td>\n",
       "      <td>3.991850e-04</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.828059</td>\n",
       "      <td>0.053977</td>\n",
       "      <td>1747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2995</th>\n",
       "      <td>0.180018</td>\n",
       "      <td>0.001496</td>\n",
       "      <td>0.007081</td>\n",
       "      <td>2.993507e-04</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.887097</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.828085</td>\n",
       "      <td>0.048801</td>\n",
       "      <td>1701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2996</th>\n",
       "      <td>0.182212</td>\n",
       "      <td>0.003339</td>\n",
       "      <td>0.006982</td>\n",
       "      <td>4.460618e-04</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.826421</td>\n",
       "      <td>0.052840</td>\n",
       "      <td>1992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2997</th>\n",
       "      <td>0.181813</td>\n",
       "      <td>0.001548</td>\n",
       "      <td>0.007082</td>\n",
       "      <td>2.990570e-04</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.824808</td>\n",
       "      <td>0.053239</td>\n",
       "      <td>2204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998</th>\n",
       "      <td>0.181666</td>\n",
       "      <td>0.001723</td>\n",
       "      <td>0.006982</td>\n",
       "      <td>4.529953e-07</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.823272</td>\n",
       "      <td>0.043729</td>\n",
       "      <td>2305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999</th>\n",
       "      <td>0.182113</td>\n",
       "      <td>0.002005</td>\n",
       "      <td>0.007081</td>\n",
       "      <td>2.993824e-04</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.823169</td>\n",
       "      <td>0.050024</td>\n",
       "      <td>2460</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0          0.064527      0.004136         0.005885    5.376236e-04   \n",
       "1          0.064327      0.002493         0.005885    5.374151e-04   \n",
       "2          0.063231      0.001954         0.005785    3.990535e-04   \n",
       "3          0.062235      0.001017         0.006082    3.001655e-04   \n",
       "4          0.062333      0.002285         0.005784    3.991850e-04   \n",
       "...             ...           ...              ...             ...   \n",
       "2995       0.180018      0.001496         0.007081    2.993507e-04   \n",
       "2996       0.182212      0.003339         0.006982    4.460618e-04   \n",
       "2997       0.181813      0.001548         0.007082    2.990570e-04   \n",
       "2998       0.181666      0.001723         0.006982    4.529953e-07   \n",
       "2999       0.182113      0.002005         0.007081    2.993824e-04   \n",
       "\n",
       "     param_colsample_bylevel param_colsample_bytree param_learning_rate  \\\n",
       "0                        0.1                    0.3                 0.1   \n",
       "1                        0.1                    0.3                 0.1   \n",
       "2                        0.1                    0.3                 0.1   \n",
       "3                        0.1                    0.3                 0.1   \n",
       "4                        0.1                    0.3                 0.1   \n",
       "...                      ...                    ...                 ...   \n",
       "2995                     0.1                    0.9                 0.4   \n",
       "2996                     0.1                    0.9                 0.4   \n",
       "2997                     0.1                    0.9                 0.4   \n",
       "2998                     0.1                    0.9                 0.4   \n",
       "2999                     0.1                    0.9                 0.4   \n",
       "\n",
       "     param_max_depth param_n_estimators param_subsample  ...  \\\n",
       "0                  2                100             0.5  ...   \n",
       "1                  2                100             0.6  ...   \n",
       "2                  2                100             0.7  ...   \n",
       "3                  2                100             0.8  ...   \n",
       "4                  2                100             0.9  ...   \n",
       "...              ...                ...             ...  ...   \n",
       "2995               5                300             0.5  ...   \n",
       "2996               5                300             0.6  ...   \n",
       "2997               5                300             0.7  ...   \n",
       "2998               5                300             0.8  ...   \n",
       "2999               5                300             0.9  ...   \n",
       "\n",
       "     split3_test_score  split4_test_score  split5_test_score  \\\n",
       "0             0.822581           0.822581           0.806452   \n",
       "1             0.838710           0.822581           0.806452   \n",
       "2             0.838710           0.806452           0.806452   \n",
       "3             0.854839           0.822581           0.806452   \n",
       "4             0.854839           0.822581           0.838710   \n",
       "...                ...                ...                ...   \n",
       "2995          0.887097           0.806452           0.774194   \n",
       "2996          0.870968           0.774194           0.758065   \n",
       "2997          0.870968           0.790323           0.790323   \n",
       "2998          0.870968           0.790323           0.774194   \n",
       "2999          0.854839           0.806452           0.774194   \n",
       "\n",
       "      split6_test_score  split7_test_score  split8_test_score  \\\n",
       "0              0.822581           0.806452           0.693548   \n",
       "1              0.838710           0.806452           0.661290   \n",
       "2              0.838710           0.806452           0.677419   \n",
       "3              0.854839           0.806452           0.661290   \n",
       "4              0.838710           0.806452           0.677419   \n",
       "...                 ...                ...                ...   \n",
       "2995           0.822581           0.822581           0.725806   \n",
       "2996           0.806452           0.838710           0.741935   \n",
       "2997           0.790323           0.854839           0.709677   \n",
       "2998           0.806452           0.854839           0.741935   \n",
       "2999           0.806452           0.822581           0.725806   \n",
       "\n",
       "      split9_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0              0.838710         0.820020        0.048275             2651  \n",
       "1              0.854839         0.823221        0.059057             2358  \n",
       "2              0.838710         0.824782        0.057512             2252  \n",
       "3              0.838710         0.824834        0.059251             2175  \n",
       "4              0.838710         0.828059        0.053977             1747  \n",
       "...                 ...              ...             ...              ...  \n",
       "2995           0.854839         0.828085        0.048801             1701  \n",
       "2996           0.854839         0.826421        0.052840             1992  \n",
       "2997           0.822581         0.824808        0.053239             2204  \n",
       "2998           0.822581         0.823272        0.043729             2305  \n",
       "2999           0.806452         0.823169        0.050024             2460  \n",
       "\n",
       "[3000 rows x 24 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score is 0.8505376344086022 with params {'colsample_bylevel': 0.1, 'colsample_bytree': 0.6, 'learning_rate': 0.15, 'max_depth': 5, 'n_estimators': 100, 'subsample': 0.6}\n"
     ]
    }
   ],
   "source": [
    "# Full Tuning - Part 1\n",
    "random.seed(10)\n",
    "\n",
    "xgb = XGBClassifier()\n",
    "\n",
    "xgb_parameters = {'max_depth': [2,3,4,5]\n",
    "                   , 'subsample': [0.6, 0.7, 0.8, 0.9]\n",
    "                   , 'gamma': [0, 1, 10]\n",
    "                   , 'colsample_bytree': [0.4, 0.5, 0.6, 0.9]\n",
    "                   , 'colsample_bylevel': [0.1, 0.2, 0.3, 0.4]\n",
    "                   , 'learning_rate': [0.01]\n",
    "                   , 'n_estimators': [30, 50, 80, 100, 150, 200]}\n",
    "\n",
    "stratified_10_fold_cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "xgb_grid_search = GridSearchCV(xgb, xgb_parameters, scoring='accuracy', cv=stratified_10_fold_cv)\n",
    "\n",
    "xgb_grid_search.fit(X_train, y_train)\n",
    "\n",
    "xgb_grid_search_results_full_1 = pd.DataFrame(xgb_grid_search.cv_results_)\n",
    "display(xgb_grid_search_results_full_1)\n",
    "\n",
    "print(\"best score is {} with params {}\".format(xgb_grid_search.best_score_, xgb_grid_search.best_params_))\n",
    "\n",
    "# best values for\n",
    "\n",
    "# save dataframe\n",
    "from datetime import datetime\n",
    "date = str(datetime.now().date()).replace(\"-\", \"\")\n",
    "xgb_grid_search_results_full_1.to_csv(f\"data/xgb_results_full_1_learning=0.01_{date}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d50dac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cecd42a5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_colsample_bylevel</th>\n",
       "      <th>param_colsample_bytree</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_subsample</th>\n",
       "      <th>...</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.062133</td>\n",
       "      <td>0.002485</td>\n",
       "      <td>0.006284</td>\n",
       "      <td>0.000639</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.820020</td>\n",
       "      <td>0.048275</td>\n",
       "      <td>2663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.063131</td>\n",
       "      <td>0.003027</td>\n",
       "      <td>0.006683</td>\n",
       "      <td>0.000457</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.661290</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.823221</td>\n",
       "      <td>0.059057</td>\n",
       "      <td>2338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.060438</td>\n",
       "      <td>0.000798</td>\n",
       "      <td>0.006782</td>\n",
       "      <td>0.000398</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.824782</td>\n",
       "      <td>0.057512</td>\n",
       "      <td>2222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.059541</td>\n",
       "      <td>0.000779</td>\n",
       "      <td>0.006682</td>\n",
       "      <td>0.000457</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.661290</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.824834</td>\n",
       "      <td>0.059251</td>\n",
       "      <td>2132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.059840</td>\n",
       "      <td>0.001092</td>\n",
       "      <td>0.006782</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.828059</td>\n",
       "      <td>0.053977</td>\n",
       "      <td>1661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2995</th>\n",
       "      <td>0.195577</td>\n",
       "      <td>0.001636</td>\n",
       "      <td>0.017653</td>\n",
       "      <td>0.031683</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.819918</td>\n",
       "      <td>0.052433</td>\n",
       "      <td>2744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2996</th>\n",
       "      <td>0.221308</td>\n",
       "      <td>0.011234</td>\n",
       "      <td>0.006782</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.819995</td>\n",
       "      <td>0.058351</td>\n",
       "      <td>2693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2997</th>\n",
       "      <td>0.226194</td>\n",
       "      <td>0.002309</td>\n",
       "      <td>0.007082</td>\n",
       "      <td>0.000299</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.821582</td>\n",
       "      <td>0.054587</td>\n",
       "      <td>2581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998</th>\n",
       "      <td>0.199167</td>\n",
       "      <td>0.006213</td>\n",
       "      <td>0.007381</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.823195</td>\n",
       "      <td>0.052389</td>\n",
       "      <td>2389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999</th>\n",
       "      <td>0.196574</td>\n",
       "      <td>0.001133</td>\n",
       "      <td>0.007480</td>\n",
       "      <td>0.000499</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.826395</td>\n",
       "      <td>0.049816</td>\n",
       "      <td>2002</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0          0.062133      0.002485         0.006284        0.000639   \n",
       "1          0.063131      0.003027         0.006683        0.000457   \n",
       "2          0.060438      0.000798         0.006782        0.000398   \n",
       "3          0.059541      0.000779         0.006682        0.000457   \n",
       "4          0.059840      0.001092         0.006782        0.000399   \n",
       "...             ...           ...              ...             ...   \n",
       "2995       0.195577      0.001636         0.017653        0.031683   \n",
       "2996       0.221308      0.011234         0.006782        0.000399   \n",
       "2997       0.226194      0.002309         0.007082        0.000299   \n",
       "2998       0.199167      0.006213         0.007381        0.000489   \n",
       "2999       0.196574      0.001133         0.007480        0.000499   \n",
       "\n",
       "     param_colsample_bylevel param_colsample_bytree param_learning_rate  \\\n",
       "0                        0.2                    0.3                 0.1   \n",
       "1                        0.2                    0.3                 0.1   \n",
       "2                        0.2                    0.3                 0.1   \n",
       "3                        0.2                    0.3                 0.1   \n",
       "4                        0.2                    0.3                 0.1   \n",
       "...                      ...                    ...                 ...   \n",
       "2995                     0.2                    0.9                 0.4   \n",
       "2996                     0.2                    0.9                 0.4   \n",
       "2997                     0.2                    0.9                 0.4   \n",
       "2998                     0.2                    0.9                 0.4   \n",
       "2999                     0.2                    0.9                 0.4   \n",
       "\n",
       "     param_max_depth param_n_estimators param_subsample  ...  \\\n",
       "0                  2                100             0.5  ...   \n",
       "1                  2                100             0.6  ...   \n",
       "2                  2                100             0.7  ...   \n",
       "3                  2                100             0.8  ...   \n",
       "4                  2                100             0.9  ...   \n",
       "...              ...                ...             ...  ...   \n",
       "2995               5                300             0.5  ...   \n",
       "2996               5                300             0.6  ...   \n",
       "2997               5                300             0.7  ...   \n",
       "2998               5                300             0.8  ...   \n",
       "2999               5                300             0.9  ...   \n",
       "\n",
       "     split3_test_score  split4_test_score  split5_test_score  \\\n",
       "0             0.822581           0.822581           0.806452   \n",
       "1             0.838710           0.822581           0.806452   \n",
       "2             0.838710           0.806452           0.806452   \n",
       "3             0.854839           0.822581           0.806452   \n",
       "4             0.854839           0.822581           0.838710   \n",
       "...                ...                ...                ...   \n",
       "2995          0.822581           0.806452           0.774194   \n",
       "2996          0.838710           0.806452           0.774194   \n",
       "2997          0.838710           0.790323           0.758065   \n",
       "2998          0.838710           0.822581           0.774194   \n",
       "2999          0.838710           0.806452           0.790323   \n",
       "\n",
       "      split6_test_score  split7_test_score  split8_test_score  \\\n",
       "0              0.822581           0.806452           0.693548   \n",
       "1              0.838710           0.806452           0.661290   \n",
       "2              0.838710           0.806452           0.677419   \n",
       "3              0.854839           0.806452           0.661290   \n",
       "4              0.838710           0.806452           0.677419   \n",
       "...                 ...                ...                ...   \n",
       "2995           0.790323           0.790323           0.741935   \n",
       "2996           0.822581           0.838710           0.693548   \n",
       "2997           0.806452           0.854839           0.725806   \n",
       "2998           0.838710           0.822581           0.725806   \n",
       "2999           0.838710           0.822581           0.725806   \n",
       "\n",
       "      split9_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0              0.838710         0.820020        0.048275             2663  \n",
       "1              0.854839         0.823221        0.059057             2338  \n",
       "2              0.838710         0.824782        0.057512             2222  \n",
       "3              0.838710         0.824834        0.059251             2132  \n",
       "4              0.838710         0.828059        0.053977             1661  \n",
       "...                 ...              ...             ...              ...  \n",
       "2995           0.822581         0.819918        0.052433             2744  \n",
       "2996           0.822581         0.819995        0.058351             2693  \n",
       "2997           0.822581         0.821582        0.054587             2581  \n",
       "2998           0.790323         0.823195        0.052389             2389  \n",
       "2999           0.806452         0.826395        0.049816             2002  \n",
       "\n",
       "[3000 rows x 24 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score is 0.8505376344086022 with params {'colsample_bylevel': 0.2, 'colsample_bytree': 0.6, 'learning_rate': 0.15, 'max_depth': 5, 'n_estimators': 100, 'subsample': 0.6}\n"
     ]
    }
   ],
   "source": [
    "# Full Tuning - Part 2\n",
    "random.seed(10)\n",
    "\n",
    "xgb = XGBClassifier()\n",
    "\n",
    "xgb_parameters = {'max_depth': [2,3,4,5]\n",
    "                   , 'subsample': [0.6, 0.7, 0.8, 0.9]\n",
    "                   , 'gamma': [0, 1, 10]\n",
    "                   , 'colsample_bytree': [0.4, 0.5, 0.6, 0.9]\n",
    "                   , 'colsample_bylevel': [0.1, 0.2, 0.3, 0.4]\n",
    "                   , 'learning_rate': [0.05]\n",
    "                   , 'n_estimators': [30, 50, 80, 100, 150, 200]}\n",
    "\n",
    "stratified_10_fold_cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "xgb_grid_search = GridSearchCV(xgb, xgb_parameters, scoring='accuracy', cv=stratified_10_fold_cv)\n",
    "\n",
    "xgb_grid_search.fit(X_train, y_train)\n",
    "\n",
    "xgb_grid_search_results_full_2 = pd.DataFrame(xgb_grid_search.cv_results_)\n",
    "display(xgb_grid_search_results_full_2)\n",
    "\n",
    "print(\"best score is {} with params {}\".format(xgb_grid_search.best_score_, xgb_grid_search.best_params_))\n",
    "\n",
    "# best values for\n",
    "\n",
    "# save dataframe\n",
    "from datetime import datetime\n",
    "date = str(datetime.now().date()).replace(\"-\", \"\")\n",
    "xgb_grid_search_results_full_2.to_csv(f\"data/xgb_results_full_2_learning=0.05_{date}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de35f20c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3ae2939c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_colsample_bylevel</th>\n",
       "      <th>param_colsample_bytree</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_subsample</th>\n",
       "      <th>...</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.062034</td>\n",
       "      <td>0.001596</td>\n",
       "      <td>0.006882</td>\n",
       "      <td>0.000537</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.820020</td>\n",
       "      <td>0.048275</td>\n",
       "      <td>2509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.068327</td>\n",
       "      <td>0.005910</td>\n",
       "      <td>0.006573</td>\n",
       "      <td>0.000502</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.661290</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.823221</td>\n",
       "      <td>0.059057</td>\n",
       "      <td>2140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.065225</td>\n",
       "      <td>0.003191</td>\n",
       "      <td>0.006683</td>\n",
       "      <td>0.000457</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.824782</td>\n",
       "      <td>0.057512</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.063630</td>\n",
       "      <td>0.001596</td>\n",
       "      <td>0.006483</td>\n",
       "      <td>0.000499</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.661290</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.824834</td>\n",
       "      <td>0.059251</td>\n",
       "      <td>1898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.061435</td>\n",
       "      <td>0.001493</td>\n",
       "      <td>0.006483</td>\n",
       "      <td>0.000498</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.828059</td>\n",
       "      <td>0.053977</td>\n",
       "      <td>1394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2995</th>\n",
       "      <td>0.206226</td>\n",
       "      <td>0.002782</td>\n",
       "      <td>0.007182</td>\n",
       "      <td>0.000598</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.813646</td>\n",
       "      <td>0.044452</td>\n",
       "      <td>2900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2996</th>\n",
       "      <td>0.207998</td>\n",
       "      <td>0.002457</td>\n",
       "      <td>0.007280</td>\n",
       "      <td>0.000457</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.818459</td>\n",
       "      <td>0.053856</td>\n",
       "      <td>2648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2997</th>\n",
       "      <td>0.207744</td>\n",
       "      <td>0.000898</td>\n",
       "      <td>0.007480</td>\n",
       "      <td>0.000499</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.813594</td>\n",
       "      <td>0.056215</td>\n",
       "      <td>2908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998</th>\n",
       "      <td>0.208343</td>\n",
       "      <td>0.001863</td>\n",
       "      <td>0.007280</td>\n",
       "      <td>0.000457</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.815207</td>\n",
       "      <td>0.053961</td>\n",
       "      <td>2850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999</th>\n",
       "      <td>0.207644</td>\n",
       "      <td>0.001882</td>\n",
       "      <td>0.007381</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.820020</td>\n",
       "      <td>0.055129</td>\n",
       "      <td>2509</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0          0.062034      0.001596         0.006882        0.000537   \n",
       "1          0.068327      0.005910         0.006573        0.000502   \n",
       "2          0.065225      0.003191         0.006683        0.000457   \n",
       "3          0.063630      0.001596         0.006483        0.000499   \n",
       "4          0.061435      0.001493         0.006483        0.000498   \n",
       "...             ...           ...              ...             ...   \n",
       "2995       0.206226      0.002782         0.007182        0.000598   \n",
       "2996       0.207998      0.002457         0.007280        0.000457   \n",
       "2997       0.207744      0.000898         0.007480        0.000499   \n",
       "2998       0.208343      0.001863         0.007280        0.000457   \n",
       "2999       0.207644      0.001882         0.007381        0.000489   \n",
       "\n",
       "     param_colsample_bylevel param_colsample_bytree param_learning_rate  \\\n",
       "0                        0.3                    0.3                 0.1   \n",
       "1                        0.3                    0.3                 0.1   \n",
       "2                        0.3                    0.3                 0.1   \n",
       "3                        0.3                    0.3                 0.1   \n",
       "4                        0.3                    0.3                 0.1   \n",
       "...                      ...                    ...                 ...   \n",
       "2995                     0.3                    0.9                 0.4   \n",
       "2996                     0.3                    0.9                 0.4   \n",
       "2997                     0.3                    0.9                 0.4   \n",
       "2998                     0.3                    0.9                 0.4   \n",
       "2999                     0.3                    0.9                 0.4   \n",
       "\n",
       "     param_max_depth param_n_estimators param_subsample  ...  \\\n",
       "0                  2                100             0.5  ...   \n",
       "1                  2                100             0.6  ...   \n",
       "2                  2                100             0.7  ...   \n",
       "3                  2                100             0.8  ...   \n",
       "4                  2                100             0.9  ...   \n",
       "...              ...                ...             ...  ...   \n",
       "2995               5                300             0.5  ...   \n",
       "2996               5                300             0.6  ...   \n",
       "2997               5                300             0.7  ...   \n",
       "2998               5                300             0.8  ...   \n",
       "2999               5                300             0.9  ...   \n",
       "\n",
       "     split3_test_score  split4_test_score  split5_test_score  \\\n",
       "0             0.822581           0.822581           0.806452   \n",
       "1             0.838710           0.822581           0.806452   \n",
       "2             0.838710           0.806452           0.806452   \n",
       "3             0.854839           0.822581           0.806452   \n",
       "4             0.854839           0.822581           0.838710   \n",
       "...                ...                ...                ...   \n",
       "2995          0.838710           0.790323           0.774194   \n",
       "2996          0.854839           0.774194           0.790323   \n",
       "2997          0.854839           0.790323           0.758065   \n",
       "2998          0.854839           0.790323           0.790323   \n",
       "2999          0.822581           0.790323           0.774194   \n",
       "\n",
       "      split6_test_score  split7_test_score  split8_test_score  \\\n",
       "0              0.822581           0.806452           0.693548   \n",
       "1              0.838710           0.806452           0.661290   \n",
       "2              0.838710           0.806452           0.677419   \n",
       "3              0.854839           0.806452           0.661290   \n",
       "4              0.838710           0.806452           0.677419   \n",
       "...                 ...                ...                ...   \n",
       "2995           0.838710           0.822581           0.709677   \n",
       "2996           0.854839           0.806452           0.693548   \n",
       "2997           0.822581           0.806452           0.709677   \n",
       "2998           0.822581           0.806452           0.693548   \n",
       "2999           0.854839           0.806452           0.709677   \n",
       "\n",
       "      split9_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0              0.838710         0.820020        0.048275             2509  \n",
       "1              0.854839         0.823221        0.059057             2140  \n",
       "2              0.838710         0.824782        0.057512             2021  \n",
       "3              0.838710         0.824834        0.059251             1898  \n",
       "4              0.838710         0.828059        0.053977             1394  \n",
       "...                 ...              ...             ...              ...  \n",
       "2995           0.822581         0.813646        0.044452             2900  \n",
       "2996           0.854839         0.818459        0.053856             2648  \n",
       "2997           0.822581         0.813594        0.056215             2908  \n",
       "2998           0.822581         0.815207        0.053961             2850  \n",
       "2999           0.854839         0.820020        0.055129             2509  \n",
       "\n",
       "[3000 rows x 24 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score is 0.850563236047107 with params {'colsample_bylevel': 0.3, 'colsample_bytree': 0.5, 'learning_rate': 0.15, 'max_depth': 2, 'n_estimators': 100, 'subsample': 0.7}\n"
     ]
    }
   ],
   "source": [
    "# Full Tuning - Part 3\n",
    "random.seed(10)\n",
    "\n",
    "xgb = XGBClassifier()\n",
    "\n",
    "xgb_parameters = {'max_depth': [2,3,4,5]\n",
    "                   , 'subsample': [0.6, 0.7, 0.8, 0.9]\n",
    "                   , 'gamma': [0, 1, 10]\n",
    "                   , 'colsample_bytree': [0.4, 0.5, 0.6, 0.9]\n",
    "                   , 'colsample_bylevel': [0.1, 0.2, 0.3, 0.4]\n",
    "                   , 'learning_rate': [0.08]\n",
    "                   , 'n_estimators': [30, 50, 80, 100, 150, 200]}\n",
    "\n",
    "stratified_10_fold_cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "xgb_grid_search = GridSearchCV(xgb, xgb_parameters, scoring='accuracy', cv=stratified_10_fold_cv)\n",
    "\n",
    "xgb_grid_search.fit(X_train, y_train)\n",
    "\n",
    "xgb_grid_search_results_full_3 = pd.DataFrame(xgb_grid_search.cv_results_)\n",
    "display(xgb_grid_search_results_full_3)\n",
    "\n",
    "print(\"best score is {} with params {}\".format(xgb_grid_search.best_score_, xgb_grid_search.best_params_))\n",
    "\n",
    "# best values for\n",
    "\n",
    "# save dataframe\n",
    "from datetime import datetime\n",
    "date = str(datetime.now().date()).replace(\"-\", \"\")\n",
    "xgb_grid_search_results_full_3.to_csv(f\"data/xgb_results_full_3_learning=0.08_{date}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eef9359",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "81c3993c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_colsample_bylevel</th>\n",
       "      <th>param_colsample_bytree</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_subsample</th>\n",
       "      <th>...</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.061735</td>\n",
       "      <td>0.001296</td>\n",
       "      <td>0.006482</td>\n",
       "      <td>0.000669</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.820020</td>\n",
       "      <td>0.048275</td>\n",
       "      <td>2502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.063031</td>\n",
       "      <td>0.002778</td>\n",
       "      <td>0.006483</td>\n",
       "      <td>0.000669</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.661290</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.823221</td>\n",
       "      <td>0.059057</td>\n",
       "      <td>2077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.060638</td>\n",
       "      <td>0.000746</td>\n",
       "      <td>0.006782</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.824782</td>\n",
       "      <td>0.057512</td>\n",
       "      <td>1941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.060339</td>\n",
       "      <td>0.000919</td>\n",
       "      <td>0.006483</td>\n",
       "      <td>0.000499</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.661290</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.824834</td>\n",
       "      <td>0.059251</td>\n",
       "      <td>1818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.059840</td>\n",
       "      <td>0.001180</td>\n",
       "      <td>0.006682</td>\n",
       "      <td>0.000457</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.828059</td>\n",
       "      <td>0.053977</td>\n",
       "      <td>1289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2995</th>\n",
       "      <td>0.218216</td>\n",
       "      <td>0.004179</td>\n",
       "      <td>0.007181</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.808807</td>\n",
       "      <td>0.046180</td>\n",
       "      <td>2975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2996</th>\n",
       "      <td>0.221009</td>\n",
       "      <td>0.003402</td>\n",
       "      <td>0.007480</td>\n",
       "      <td>0.000499</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.812007</td>\n",
       "      <td>0.049754</td>\n",
       "      <td>2922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2997</th>\n",
       "      <td>0.221308</td>\n",
       "      <td>0.004515</td>\n",
       "      <td>0.007380</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.816795</td>\n",
       "      <td>0.050406</td>\n",
       "      <td>2770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998</th>\n",
       "      <td>0.219213</td>\n",
       "      <td>0.003908</td>\n",
       "      <td>0.007194</td>\n",
       "      <td>0.000425</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.816820</td>\n",
       "      <td>0.047212</td>\n",
       "      <td>2763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999</th>\n",
       "      <td>0.216122</td>\n",
       "      <td>0.003092</td>\n",
       "      <td>0.007381</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.818382</td>\n",
       "      <td>0.050014</td>\n",
       "      <td>2693</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0          0.061735      0.001296         0.006482        0.000669   \n",
       "1          0.063031      0.002778         0.006483        0.000669   \n",
       "2          0.060638      0.000746         0.006782        0.000399   \n",
       "3          0.060339      0.000919         0.006483        0.000499   \n",
       "4          0.059840      0.001180         0.006682        0.000457   \n",
       "...             ...           ...              ...             ...   \n",
       "2995       0.218216      0.004179         0.007181        0.000399   \n",
       "2996       0.221009      0.003402         0.007480        0.000499   \n",
       "2997       0.221308      0.004515         0.007380        0.000489   \n",
       "2998       0.219213      0.003908         0.007194        0.000425   \n",
       "2999       0.216122      0.003092         0.007381        0.000489   \n",
       "\n",
       "     param_colsample_bylevel param_colsample_bytree param_learning_rate  \\\n",
       "0                        0.4                    0.3                 0.1   \n",
       "1                        0.4                    0.3                 0.1   \n",
       "2                        0.4                    0.3                 0.1   \n",
       "3                        0.4                    0.3                 0.1   \n",
       "4                        0.4                    0.3                 0.1   \n",
       "...                      ...                    ...                 ...   \n",
       "2995                     0.4                    0.9                 0.4   \n",
       "2996                     0.4                    0.9                 0.4   \n",
       "2997                     0.4                    0.9                 0.4   \n",
       "2998                     0.4                    0.9                 0.4   \n",
       "2999                     0.4                    0.9                 0.4   \n",
       "\n",
       "     param_max_depth param_n_estimators param_subsample  ...  \\\n",
       "0                  2                100             0.5  ...   \n",
       "1                  2                100             0.6  ...   \n",
       "2                  2                100             0.7  ...   \n",
       "3                  2                100             0.8  ...   \n",
       "4                  2                100             0.9  ...   \n",
       "...              ...                ...             ...  ...   \n",
       "2995               5                300             0.5  ...   \n",
       "2996               5                300             0.6  ...   \n",
       "2997               5                300             0.7  ...   \n",
       "2998               5                300             0.8  ...   \n",
       "2999               5                300             0.9  ...   \n",
       "\n",
       "     split3_test_score  split4_test_score  split5_test_score  \\\n",
       "0             0.822581           0.822581           0.806452   \n",
       "1             0.838710           0.822581           0.806452   \n",
       "2             0.838710           0.806452           0.806452   \n",
       "3             0.854839           0.822581           0.806452   \n",
       "4             0.854839           0.822581           0.838710   \n",
       "...                ...                ...                ...   \n",
       "2995          0.838710           0.758065           0.790323   \n",
       "2996          0.838710           0.790323           0.806452   \n",
       "2997          0.838710           0.790323           0.790323   \n",
       "2998          0.838710           0.790323           0.806452   \n",
       "2999          0.822581           0.774194           0.774194   \n",
       "\n",
       "      split6_test_score  split7_test_score  split8_test_score  \\\n",
       "0              0.822581           0.806452           0.693548   \n",
       "1              0.838710           0.806452           0.661290   \n",
       "2              0.838710           0.806452           0.677419   \n",
       "3              0.854839           0.806452           0.661290   \n",
       "4              0.838710           0.806452           0.677419   \n",
       "...                 ...                ...                ...   \n",
       "2995           0.806452           0.790323           0.741935   \n",
       "2996           0.838710           0.774194           0.725806   \n",
       "2997           0.790323           0.822581           0.725806   \n",
       "2998           0.838710           0.790323           0.725806   \n",
       "2999           0.854839           0.790323           0.725806   \n",
       "\n",
       "      split9_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0              0.838710         0.820020        0.048275             2502  \n",
       "1              0.854839         0.823221        0.059057             2077  \n",
       "2              0.838710         0.824782        0.057512             1941  \n",
       "3              0.838710         0.824834        0.059251             1818  \n",
       "4              0.838710         0.828059        0.053977             1289  \n",
       "...                 ...              ...             ...              ...  \n",
       "2995           0.822581         0.808807        0.046180             2975  \n",
       "2996           0.790323         0.812007        0.049754             2922  \n",
       "2997           0.822581         0.816795        0.050406             2770  \n",
       "2998           0.806452         0.816820        0.047212             2763  \n",
       "2999           0.838710         0.818382        0.050014             2693  \n",
       "\n",
       "[3000 rows x 24 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score is 0.850563236047107 with params {'colsample_bylevel': 0.4, 'colsample_bytree': 0.5, 'learning_rate': 0.15, 'max_depth': 2, 'n_estimators': 100, 'subsample': 0.7}\n"
     ]
    }
   ],
   "source": [
    "# Full Tuning - Part 4\n",
    "random.seed(10)\n",
    "\n",
    "xgb = XGBClassifier()\n",
    "\n",
    "xgb_parameters = {'max_depth': [2,3,4,5]\n",
    "                   , 'subsample': [0.6, 0.7, 0.8, 0.9]\n",
    "                   , 'gamma': [0, 1, 10]\n",
    "                   , 'colsample_bytree': [0.4, 0.5, 0.6, 0.9]\n",
    "                   , 'colsample_bylevel': [0.1, 0.2, 0.3, 0.4]\n",
    "                   , 'learning_rate': [0.1]\n",
    "                   , 'n_estimators': [30, 50, 80, 100, 150, 200]}\n",
    "\n",
    "stratified_10_fold_cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "xgb_grid_search = GridSearchCV(xgb, xgb_parameters, scoring='accuracy', cv=stratified_10_fold_cv)\n",
    "\n",
    "xgb_grid_search.fit(X_train, y_train)\n",
    "\n",
    "xgb_grid_search_results_full_4 = pd.DataFrame(xgb_grid_search.cv_results_)\n",
    "display(xgb_grid_search_results_full_4)\n",
    "\n",
    "print(\"best score is {} with params {}\".format(xgb_grid_search.best_score_, xgb_grid_search.best_params_))\n",
    "\n",
    "# best values for\n",
    "\n",
    "# save dataframe\n",
    "from datetime import datetime\n",
    "date = str(datetime.now().date()).replace(\"-\", \"\")\n",
    "xgb_grid_search_results_full_4.to_csv(f\"data/xgb_results_full_4_learning=0.1_{date}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e43f97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8e53020f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_colsample_bylevel</th>\n",
       "      <th>param_colsample_bytree</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_subsample</th>\n",
       "      <th>...</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.063530</td>\n",
       "      <td>0.002446</td>\n",
       "      <td>0.006383</td>\n",
       "      <td>0.000662</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.834537</td>\n",
       "      <td>0.044892</td>\n",
       "      <td>215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.065725</td>\n",
       "      <td>0.003351</td>\n",
       "      <td>0.006882</td>\n",
       "      <td>0.000299</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.832949</td>\n",
       "      <td>0.048291</td>\n",
       "      <td>320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.062236</td>\n",
       "      <td>0.001196</td>\n",
       "      <td>0.006780</td>\n",
       "      <td>0.000398</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.887097</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.842601</td>\n",
       "      <td>0.046342</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.061335</td>\n",
       "      <td>0.001798</td>\n",
       "      <td>0.006583</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.834562</td>\n",
       "      <td>0.050284</td>\n",
       "      <td>208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.060937</td>\n",
       "      <td>0.000698</td>\n",
       "      <td>0.006483</td>\n",
       "      <td>0.000669</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.887097</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.832924</td>\n",
       "      <td>0.057218</td>\n",
       "      <td>327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2995</th>\n",
       "      <td>0.219613</td>\n",
       "      <td>0.001532</td>\n",
       "      <td>0.007380</td>\n",
       "      <td>0.000488</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.805504</td>\n",
       "      <td>0.051226</td>\n",
       "      <td>2997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2996</th>\n",
       "      <td>0.222105</td>\n",
       "      <td>0.001787</td>\n",
       "      <td>0.006882</td>\n",
       "      <td>0.000698</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.810317</td>\n",
       "      <td>0.059764</td>\n",
       "      <td>2968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2997</th>\n",
       "      <td>0.221906</td>\n",
       "      <td>0.002534</td>\n",
       "      <td>0.007281</td>\n",
       "      <td>0.000457</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.818331</td>\n",
       "      <td>0.051641</td>\n",
       "      <td>2706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998</th>\n",
       "      <td>0.224599</td>\n",
       "      <td>0.011023</td>\n",
       "      <td>0.007380</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.816718</td>\n",
       "      <td>0.054669</td>\n",
       "      <td>2825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999</th>\n",
       "      <td>0.219812</td>\n",
       "      <td>0.002609</td>\n",
       "      <td>0.007381</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.807220</td>\n",
       "      <td>0.045482</td>\n",
       "      <td>2983</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0          0.063530      0.002446         0.006383        0.000662   \n",
       "1          0.065725      0.003351         0.006882        0.000299   \n",
       "2          0.062236      0.001196         0.006780        0.000398   \n",
       "3          0.061335      0.001798         0.006583        0.000489   \n",
       "4          0.060937      0.000698         0.006483        0.000669   \n",
       "...             ...           ...              ...             ...   \n",
       "2995       0.219613      0.001532         0.007380        0.000488   \n",
       "2996       0.222105      0.001787         0.006882        0.000698   \n",
       "2997       0.221906      0.002534         0.007281        0.000457   \n",
       "2998       0.224599      0.011023         0.007380        0.000489   \n",
       "2999       0.219812      0.002609         0.007381        0.000489   \n",
       "\n",
       "     param_colsample_bylevel param_colsample_bytree param_learning_rate  \\\n",
       "0                        0.6                    0.3                 0.1   \n",
       "1                        0.6                    0.3                 0.1   \n",
       "2                        0.6                    0.3                 0.1   \n",
       "3                        0.6                    0.3                 0.1   \n",
       "4                        0.6                    0.3                 0.1   \n",
       "...                      ...                    ...                 ...   \n",
       "2995                     0.6                    0.9                 0.4   \n",
       "2996                     0.6                    0.9                 0.4   \n",
       "2997                     0.6                    0.9                 0.4   \n",
       "2998                     0.6                    0.9                 0.4   \n",
       "2999                     0.6                    0.9                 0.4   \n",
       "\n",
       "     param_max_depth param_n_estimators param_subsample  ...  \\\n",
       "0                  2                100             0.5  ...   \n",
       "1                  2                100             0.6  ...   \n",
       "2                  2                100             0.7  ...   \n",
       "3                  2                100             0.8  ...   \n",
       "4                  2                100             0.9  ...   \n",
       "...              ...                ...             ...  ...   \n",
       "2995               5                300             0.5  ...   \n",
       "2996               5                300             0.6  ...   \n",
       "2997               5                300             0.7  ...   \n",
       "2998               5                300             0.8  ...   \n",
       "2999               5                300             0.9  ...   \n",
       "\n",
       "     split3_test_score  split4_test_score  split5_test_score  \\\n",
       "0             0.870968           0.822581           0.838710   \n",
       "1             0.854839           0.822581           0.854839   \n",
       "2             0.887097           0.838710           0.854839   \n",
       "3             0.870968           0.822581           0.870968   \n",
       "4             0.870968           0.822581           0.887097   \n",
       "...                ...                ...                ...   \n",
       "2995          0.806452           0.741935           0.774194   \n",
       "2996          0.854839           0.790323           0.758065   \n",
       "2997          0.838710           0.774194           0.790323   \n",
       "2998          0.838710           0.790323           0.758065   \n",
       "2999          0.822581           0.790323           0.758065   \n",
       "\n",
       "      split6_test_score  split7_test_score  split8_test_score  \\\n",
       "0              0.854839           0.822581           0.709677   \n",
       "1              0.854839           0.822581           0.693548   \n",
       "2              0.854839           0.838710           0.709677   \n",
       "3              0.838710           0.822581           0.693548   \n",
       "4              0.822581           0.806452           0.677419   \n",
       "...                 ...                ...                ...   \n",
       "2995           0.806452           0.790323           0.741935   \n",
       "2996           0.822581           0.741935           0.725806   \n",
       "2997           0.822581           0.774194           0.725806   \n",
       "2998           0.822581           0.806452           0.709677   \n",
       "2999           0.838710           0.806452           0.709677   \n",
       "\n",
       "      split9_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0              0.838710         0.834537        0.044892              215  \n",
       "1              0.854839         0.832949        0.048291              320  \n",
       "2              0.854839         0.842601        0.046342               17  \n",
       "3              0.854839         0.834562        0.050284              208  \n",
       "4              0.854839         0.832924        0.057218              327  \n",
       "...                 ...              ...             ...              ...  \n",
       "2995           0.806452         0.805504        0.051226             2997  \n",
       "2996           0.806452         0.810317        0.059764             2968  \n",
       "2997           0.822581         0.818331        0.051641             2706  \n",
       "2998           0.806452         0.816718        0.054669             2825  \n",
       "2999           0.822581         0.807220        0.045482             2983  \n",
       "\n",
       "[3000 rows x 24 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score is 0.8458269329237071 with params {'colsample_bylevel': 0.6, 'colsample_bytree': 0.4, 'learning_rate': 0.1, 'max_depth': 2, 'n_estimators': 100, 'subsample': 0.8}\n"
     ]
    }
   ],
   "source": [
    "# Full Tuning - Part 5\n",
    "random.seed(10)\n",
    "\n",
    "xgb = XGBClassifier()\n",
    "\n",
    "xgb_parameters = {'max_depth': [2,3,4,5]\n",
    "                   , 'subsample': [0.6, 0.7, 0.8, 0.9]\n",
    "                   , 'gamma': [0, 1, 10]\n",
    "                   , 'colsample_bytree': [0.4, 0.5, 0.6, 0.9]\n",
    "                   , 'colsample_bylevel': [0.1, 0.2, 0.3, 0.4]\n",
    "                   , 'learning_rate': [0.15]\n",
    "                   , 'n_estimators': [30, 50, 80, 100, 150, 200]}\n",
    "\n",
    "stratified_10_fold_cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "xgb_grid_search = GridSearchCV(xgb, xgb_parameters, scoring='accuracy', cv=stratified_10_fold_cv)\n",
    "\n",
    "xgb_grid_search.fit(X_train, y_train)\n",
    "\n",
    "xgb_grid_search_results_full_5 = pd.DataFrame(xgb_grid_search.cv_results_)\n",
    "display(xgb_grid_search_results_full_5)\n",
    "\n",
    "print(\"best score is {} with params {}\".format(xgb_grid_search.best_score_, xgb_grid_search.best_params_))\n",
    "\n",
    "# best values for\n",
    "\n",
    "# save dataframe\n",
    "from datetime import datetime\n",
    "date = str(datetime.now().date()).replace(\"-\", \"\")\n",
    "xgb_grid_search_results_full_5.to_csv(f\"data/xgb_results_full_5_learning=0.15_{date}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "addcfcca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "de9ada4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_colsample_bylevel</th>\n",
       "      <th>param_colsample_bytree</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_subsample</th>\n",
       "      <th>...</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.063128</td>\n",
       "      <td>0.002527</td>\n",
       "      <td>0.006483</td>\n",
       "      <td>0.000669</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.834537</td>\n",
       "      <td>0.044892</td>\n",
       "      <td>218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.065325</td>\n",
       "      <td>0.003097</td>\n",
       "      <td>0.006882</td>\n",
       "      <td>0.000537</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.832949</td>\n",
       "      <td>0.048291</td>\n",
       "      <td>327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.061886</td>\n",
       "      <td>0.000566</td>\n",
       "      <td>0.006583</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.887097</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.842601</td>\n",
       "      <td>0.046342</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.061137</td>\n",
       "      <td>0.000638</td>\n",
       "      <td>0.006882</td>\n",
       "      <td>0.000299</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.834562</td>\n",
       "      <td>0.050284</td>\n",
       "      <td>210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.060537</td>\n",
       "      <td>0.000638</td>\n",
       "      <td>0.006682</td>\n",
       "      <td>0.000457</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>0.9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.887097</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.832924</td>\n",
       "      <td>0.057218</td>\n",
       "      <td>333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2995</th>\n",
       "      <td>0.228489</td>\n",
       "      <td>0.002462</td>\n",
       "      <td>0.007480</td>\n",
       "      <td>0.000499</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.802355</td>\n",
       "      <td>0.049888</td>\n",
       "      <td>2998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2996</th>\n",
       "      <td>0.228688</td>\n",
       "      <td>0.002142</td>\n",
       "      <td>0.007281</td>\n",
       "      <td>0.000457</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.693548</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.800768</td>\n",
       "      <td>0.052893</td>\n",
       "      <td>2999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2997</th>\n",
       "      <td>0.228987</td>\n",
       "      <td>0.001197</td>\n",
       "      <td>0.007580</td>\n",
       "      <td>0.000488</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.810317</td>\n",
       "      <td>0.057193</td>\n",
       "      <td>2964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998</th>\n",
       "      <td>0.228788</td>\n",
       "      <td>0.001620</td>\n",
       "      <td>0.007181</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.816692</td>\n",
       "      <td>0.055624</td>\n",
       "      <td>2812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999</th>\n",
       "      <td>0.226893</td>\n",
       "      <td>0.002150</td>\n",
       "      <td>0.007381</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>0.9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.818382</td>\n",
       "      <td>0.053516</td>\n",
       "      <td>2629</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0          0.063128      0.002527         0.006483        0.000669   \n",
       "1          0.065325      0.003097         0.006882        0.000537   \n",
       "2          0.061886      0.000566         0.006583        0.000489   \n",
       "3          0.061137      0.000638         0.006882        0.000299   \n",
       "4          0.060537      0.000638         0.006682        0.000457   \n",
       "...             ...           ...              ...             ...   \n",
       "2995       0.228489      0.002462         0.007480        0.000499   \n",
       "2996       0.228688      0.002142         0.007281        0.000457   \n",
       "2997       0.228987      0.001197         0.007580        0.000488   \n",
       "2998       0.228788      0.001620         0.007181        0.000399   \n",
       "2999       0.226893      0.002150         0.007381        0.000489   \n",
       "\n",
       "     param_colsample_bylevel param_colsample_bytree param_learning_rate  \\\n",
       "0                        0.7                    0.3                 0.1   \n",
       "1                        0.7                    0.3                 0.1   \n",
       "2                        0.7                    0.3                 0.1   \n",
       "3                        0.7                    0.3                 0.1   \n",
       "4                        0.7                    0.3                 0.1   \n",
       "...                      ...                    ...                 ...   \n",
       "2995                     0.7                    0.9                 0.4   \n",
       "2996                     0.7                    0.9                 0.4   \n",
       "2997                     0.7                    0.9                 0.4   \n",
       "2998                     0.7                    0.9                 0.4   \n",
       "2999                     0.7                    0.9                 0.4   \n",
       "\n",
       "     param_max_depth param_n_estimators param_subsample  ...  \\\n",
       "0                  2                100             0.5  ...   \n",
       "1                  2                100             0.6  ...   \n",
       "2                  2                100             0.7  ...   \n",
       "3                  2                100             0.8  ...   \n",
       "4                  2                100             0.9  ...   \n",
       "...              ...                ...             ...  ...   \n",
       "2995               5                300             0.5  ...   \n",
       "2996               5                300             0.6  ...   \n",
       "2997               5                300             0.7  ...   \n",
       "2998               5                300             0.8  ...   \n",
       "2999               5                300             0.9  ...   \n",
       "\n",
       "     split3_test_score  split4_test_score  split5_test_score  \\\n",
       "0             0.870968           0.822581           0.838710   \n",
       "1             0.854839           0.822581           0.854839   \n",
       "2             0.887097           0.838710           0.854839   \n",
       "3             0.870968           0.822581           0.870968   \n",
       "4             0.870968           0.822581           0.887097   \n",
       "...                ...                ...                ...   \n",
       "2995          0.822581           0.774194           0.806452   \n",
       "2996          0.822581           0.774194           0.790323   \n",
       "2997          0.870968           0.774194           0.774194   \n",
       "2998          0.822581           0.790323           0.774194   \n",
       "2999          0.806452           0.790323           0.774194   \n",
       "\n",
       "      split6_test_score  split7_test_score  split8_test_score  \\\n",
       "0              0.854839           0.822581           0.709677   \n",
       "1              0.854839           0.822581           0.693548   \n",
       "2              0.854839           0.838710           0.709677   \n",
       "3              0.838710           0.822581           0.693548   \n",
       "4              0.822581           0.806452           0.677419   \n",
       "...                 ...                ...                ...   \n",
       "2995           0.822581           0.774194           0.709677   \n",
       "2996           0.822581           0.790323           0.693548   \n",
       "2997           0.790323           0.790323           0.709677   \n",
       "2998           0.822581           0.790323           0.709677   \n",
       "2999           0.854839           0.790323           0.709677   \n",
       "\n",
       "      split9_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0              0.838710         0.834537        0.044892              218  \n",
       "1              0.854839         0.832949        0.048291              327  \n",
       "2              0.854839         0.842601        0.046342               16  \n",
       "3              0.854839         0.834562        0.050284              210  \n",
       "4              0.854839         0.832924        0.057218              333  \n",
       "...                 ...              ...             ...              ...  \n",
       "2995           0.774194         0.802355        0.049888             2998  \n",
       "2996           0.790323         0.800768        0.052893             2999  \n",
       "2997           0.790323         0.810317        0.057193             2964  \n",
       "2998           0.806452         0.816692        0.055624             2812  \n",
       "2999           0.854839         0.818382        0.053516             2629  \n",
       "\n",
       "[3000 rows x 24 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score is 0.8490015360983103 with params {'colsample_bylevel': 0.7, 'colsample_bytree': 0.4, 'learning_rate': 0.1, 'max_depth': 2, 'n_estimators': 150, 'subsample': 0.9}\n"
     ]
    }
   ],
   "source": [
    "# Full Tuning - Part 6\n",
    "random.seed(10)\n",
    "\n",
    "xgb = XGBClassifier()\n",
    "\n",
    "xgb_parameters = {'max_depth': [2,3,4,5]\n",
    "                   , 'subsample': [0.6, 0.7, 0.8, 0.9]\n",
    "                   , 'gamma': [0, 1, 10]\n",
    "                   , 'colsample_bytree': [0.4, 0.5, 0.6, 0.9]\n",
    "                   , 'colsample_bylevel': [0.1, 0.2, 0.3, 0.4]\n",
    "                   , 'learning_rate': [0.2]\n",
    "                   , 'n_estimators': [30, 50, 80, 100, 150, 200]}\n",
    "\n",
    "stratified_10_fold_cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "xgb_grid_search = GridSearchCV(xgb, xgb_parameters, scoring='accuracy', cv=stratified_10_fold_cv)\n",
    "\n",
    "xgb_grid_search.fit(X_train, y_train)\n",
    "\n",
    "xgb_grid_search_results_full_6 = pd.DataFrame(xgb_grid_search.cv_results_)\n",
    "display(xgb_grid_search_results_full_6)\n",
    "\n",
    "print(\"best score is {} with params {}\".format(xgb_grid_search.best_score_, xgb_grid_search.best_params_))\n",
    "\n",
    "# best values for\n",
    "\n",
    "# save dataframe\n",
    "from datetime import datetime\n",
    "date = str(datetime.now().date()).replace(\"-\", \"\")\n",
    "xgb_grid_search_results_full_6.to_csv(f\"data/xgb_results_full_6_learning=0.2_{date}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c0742cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "378b32c7",
   "metadata": {},
   "source": [
    "### cross_val_score and cross_val_predict\n",
    "Das sagt uns nur fÃ¼r welchen Fold der Estimator am besten ist, aber gibt kein Modell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b452c2a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0: Accuracy = 84.12698412698413%\n",
      "Fold 1: Accuracy = 80.95238095238095%\n",
      "Fold 2: Accuracy = 87.3015873015873%\n",
      "Fold 3: Accuracy = 87.09677419354838%\n",
      "Fold 4: Accuracy = 82.25806451612904%\n",
      "Fold 5: Accuracy = 72.58064516129032%\n",
      "Fold 6: Accuracy = 82.25806451612904%\n",
      "Fold 7: Accuracy = 83.87096774193549%\n",
      "Fold 8: Accuracy = 82.25806451612904%\n",
      "Fold 9: Accuracy = 90.32258064516128%\n",
      "Average Accuracy = 83.3026113671275%\n"
     ]
    }
   ],
   "source": [
    "# cross_val_score\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "xgb_cv = XGBClassifier()\n",
    "xgb_cv_score = cross_val_score(xgb_cv, X_train, y_train, cv=10, scoring = 'accuracy') #scoring='f1_macro', 'f1_micro'\n",
    "\n",
    "for i, acc in enumerate(xgb_cv_score):\n",
    "    print(\"Fold {}: Accuracy = {}%\".format(i, acc*100.0))\n",
    "print (\"Average Accuracy = {}%\".format(xgb_cv_score.mean()*100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c49703df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8330658105939005"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cross_val_predict\n",
    "\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "xgb_cv_pred = cross_val_predict(xgb_cv, X_train, y_train, cv=10)\n",
    "xgb_cv_acc = accuracy_score(y_train, xgb_cv_pred)\n",
    "xgb_cv_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "55b7f06f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8235096774193549"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_colsample_bytree</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.092668</td>\n",
       "      <td>0.068974</td>\n",
       "      <td>0.010241</td>\n",
       "      <td>0.004584</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>3</td>\n",
       "      <td>50</td>\n",
       "      <td>{'colsample_bytree': 0.3, 'learning_rate': 0.3...</td>\n",
       "      <td>0.800</td>\n",
       "      <td>0.856</td>\n",
       "      <td>0.800</td>\n",
       "      <td>0.798387</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.821845</td>\n",
       "      <td>0.027422</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.288282</td>\n",
       "      <td>0.145202</td>\n",
       "      <td>0.013407</td>\n",
       "      <td>0.008197</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>{'colsample_bytree': 0.3, 'learning_rate': 0.3...</td>\n",
       "      <td>0.792</td>\n",
       "      <td>0.888</td>\n",
       "      <td>0.792</td>\n",
       "      <td>0.814516</td>\n",
       "      <td>0.862903</td>\n",
       "      <td>0.829884</td>\n",
       "      <td>0.038921</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.120098</td>\n",
       "      <td>0.070939</td>\n",
       "      <td>0.015562</td>\n",
       "      <td>0.011004</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "      <td>{'colsample_bytree': 0.3, 'learning_rate': 0.3...</td>\n",
       "      <td>0.800</td>\n",
       "      <td>0.864</td>\n",
       "      <td>0.784</td>\n",
       "      <td>0.814516</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.823471</td>\n",
       "      <td>0.031034</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.114842</td>\n",
       "      <td>0.010915</td>\n",
       "      <td>0.009151</td>\n",
       "      <td>0.001635</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>{'colsample_bytree': 0.3, 'learning_rate': 0.3...</td>\n",
       "      <td>0.784</td>\n",
       "      <td>0.848</td>\n",
       "      <td>0.808</td>\n",
       "      <td>0.814516</td>\n",
       "      <td>0.862903</td>\n",
       "      <td>0.823484</td>\n",
       "      <td>0.028404</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.052624</td>\n",
       "      <td>0.002154</td>\n",
       "      <td>0.007510</td>\n",
       "      <td>0.000662</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.7</td>\n",
       "      <td>3</td>\n",
       "      <td>50</td>\n",
       "      <td>{'colsample_bytree': 0.3, 'learning_rate': 0.7...</td>\n",
       "      <td>0.792</td>\n",
       "      <td>0.848</td>\n",
       "      <td>0.792</td>\n",
       "      <td>0.814516</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.823497</td>\n",
       "      <td>0.031364</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.090101</td>\n",
       "      <td>0.019783</td>\n",
       "      <td>0.008794</td>\n",
       "      <td>0.001738</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.7</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>{'colsample_bytree': 0.3, 'learning_rate': 0.7...</td>\n",
       "      <td>0.768</td>\n",
       "      <td>0.848</td>\n",
       "      <td>0.784</td>\n",
       "      <td>0.846774</td>\n",
       "      <td>0.879032</td>\n",
       "      <td>0.825161</td>\n",
       "      <td>0.042077</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.059273</td>\n",
       "      <td>0.005971</td>\n",
       "      <td>0.007694</td>\n",
       "      <td>0.001034</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.7</td>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "      <td>{'colsample_bytree': 0.3, 'learning_rate': 0.7...</td>\n",
       "      <td>0.792</td>\n",
       "      <td>0.848</td>\n",
       "      <td>0.784</td>\n",
       "      <td>0.830645</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.821897</td>\n",
       "      <td>0.028890</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.082045</td>\n",
       "      <td>0.010339</td>\n",
       "      <td>0.007185</td>\n",
       "      <td>0.000484</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.7</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>{'colsample_bytree': 0.3, 'learning_rate': 0.7...</td>\n",
       "      <td>0.800</td>\n",
       "      <td>0.832</td>\n",
       "      <td>0.776</td>\n",
       "      <td>0.846774</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.821923</td>\n",
       "      <td>0.029638</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.040890</td>\n",
       "      <td>0.003696</td>\n",
       "      <td>0.007092</td>\n",
       "      <td>0.000434</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.3</td>\n",
       "      <td>3</td>\n",
       "      <td>50</td>\n",
       "      <td>{'colsample_bytree': 0.8, 'learning_rate': 0.3...</td>\n",
       "      <td>0.808</td>\n",
       "      <td>0.888</td>\n",
       "      <td>0.776</td>\n",
       "      <td>0.814516</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.828271</td>\n",
       "      <td>0.039002</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.085391</td>\n",
       "      <td>0.002370</td>\n",
       "      <td>0.008212</td>\n",
       "      <td>0.000730</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.3</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>{'colsample_bytree': 0.8, 'learning_rate': 0.3...</td>\n",
       "      <td>0.808</td>\n",
       "      <td>0.872</td>\n",
       "      <td>0.784</td>\n",
       "      <td>0.814516</td>\n",
       "      <td>0.862903</td>\n",
       "      <td>0.828284</td>\n",
       "      <td>0.033680</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.047418</td>\n",
       "      <td>0.005844</td>\n",
       "      <td>0.007159</td>\n",
       "      <td>0.000354</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.3</td>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "      <td>{'colsample_bytree': 0.8, 'learning_rate': 0.3...</td>\n",
       "      <td>0.808</td>\n",
       "      <td>0.856</td>\n",
       "      <td>0.776</td>\n",
       "      <td>0.814516</td>\n",
       "      <td>0.879032</td>\n",
       "      <td>0.826710</td>\n",
       "      <td>0.036512</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.080390</td>\n",
       "      <td>0.004495</td>\n",
       "      <td>0.006812</td>\n",
       "      <td>0.000526</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.3</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>{'colsample_bytree': 0.8, 'learning_rate': 0.3...</td>\n",
       "      <td>0.800</td>\n",
       "      <td>0.816</td>\n",
       "      <td>0.752</td>\n",
       "      <td>0.814516</td>\n",
       "      <td>0.846774</td>\n",
       "      <td>0.805858</td>\n",
       "      <td>0.030942</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.042130</td>\n",
       "      <td>0.003501</td>\n",
       "      <td>0.007502</td>\n",
       "      <td>0.000692</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.7</td>\n",
       "      <td>3</td>\n",
       "      <td>50</td>\n",
       "      <td>{'colsample_bytree': 0.8, 'learning_rate': 0.7...</td>\n",
       "      <td>0.792</td>\n",
       "      <td>0.864</td>\n",
       "      <td>0.768</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.862903</td>\n",
       "      <td>0.818671</td>\n",
       "      <td>0.038573</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.070223</td>\n",
       "      <td>0.006916</td>\n",
       "      <td>0.007454</td>\n",
       "      <td>0.000528</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.7</td>\n",
       "      <td>3</td>\n",
       "      <td>100</td>\n",
       "      <td>{'colsample_bytree': 0.8, 'learning_rate': 0.7...</td>\n",
       "      <td>0.792</td>\n",
       "      <td>0.840</td>\n",
       "      <td>0.760</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.807432</td>\n",
       "      <td>0.030093</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.048666</td>\n",
       "      <td>0.005174</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.000394</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.7</td>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "      <td>{'colsample_bytree': 0.8, 'learning_rate': 0.7...</td>\n",
       "      <td>0.816</td>\n",
       "      <td>0.808</td>\n",
       "      <td>0.784</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.810632</td>\n",
       "      <td>0.014357</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.083833</td>\n",
       "      <td>0.007350</td>\n",
       "      <td>0.007236</td>\n",
       "      <td>0.000380</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.7</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>{'colsample_bytree': 0.8, 'learning_rate': 0.7...</td>\n",
       "      <td>0.792</td>\n",
       "      <td>0.800</td>\n",
       "      <td>0.768</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.830645</td>\n",
       "      <td>0.805871</td>\n",
       "      <td>0.025897</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0        0.092668      0.068974         0.010241        0.004584   \n",
       "1        0.288282      0.145202         0.013407        0.008197   \n",
       "2        0.120098      0.070939         0.015562        0.011004   \n",
       "3        0.114842      0.010915         0.009151        0.001635   \n",
       "4        0.052624      0.002154         0.007510        0.000662   \n",
       "5        0.090101      0.019783         0.008794        0.001738   \n",
       "6        0.059273      0.005971         0.007694        0.001034   \n",
       "7        0.082045      0.010339         0.007185        0.000484   \n",
       "8        0.040890      0.003696         0.007092        0.000434   \n",
       "9        0.085391      0.002370         0.008212        0.000730   \n",
       "10       0.047418      0.005844         0.007159        0.000354   \n",
       "11       0.080390      0.004495         0.006812        0.000526   \n",
       "12       0.042130      0.003501         0.007502        0.000692   \n",
       "13       0.070223      0.006916         0.007454        0.000528   \n",
       "14       0.048666      0.005174         0.007778        0.000394   \n",
       "15       0.083833      0.007350         0.007236        0.000380   \n",
       "\n",
       "   param_colsample_bytree param_learning_rate param_max_depth  \\\n",
       "0                     0.3                 0.3               3   \n",
       "1                     0.3                 0.3               3   \n",
       "2                     0.3                 0.3               5   \n",
       "3                     0.3                 0.3               5   \n",
       "4                     0.3                 0.7               3   \n",
       "5                     0.3                 0.7               3   \n",
       "6                     0.3                 0.7               5   \n",
       "7                     0.3                 0.7               5   \n",
       "8                     0.8                 0.3               3   \n",
       "9                     0.8                 0.3               3   \n",
       "10                    0.8                 0.3               5   \n",
       "11                    0.8                 0.3               5   \n",
       "12                    0.8                 0.7               3   \n",
       "13                    0.8                 0.7               3   \n",
       "14                    0.8                 0.7               5   \n",
       "15                    0.8                 0.7               5   \n",
       "\n",
       "   param_n_estimators                                             params  \\\n",
       "0                  50  {'colsample_bytree': 0.3, 'learning_rate': 0.3...   \n",
       "1                 100  {'colsample_bytree': 0.3, 'learning_rate': 0.3...   \n",
       "2                  50  {'colsample_bytree': 0.3, 'learning_rate': 0.3...   \n",
       "3                 100  {'colsample_bytree': 0.3, 'learning_rate': 0.3...   \n",
       "4                  50  {'colsample_bytree': 0.3, 'learning_rate': 0.7...   \n",
       "5                 100  {'colsample_bytree': 0.3, 'learning_rate': 0.7...   \n",
       "6                  50  {'colsample_bytree': 0.3, 'learning_rate': 0.7...   \n",
       "7                 100  {'colsample_bytree': 0.3, 'learning_rate': 0.7...   \n",
       "8                  50  {'colsample_bytree': 0.8, 'learning_rate': 0.3...   \n",
       "9                 100  {'colsample_bytree': 0.8, 'learning_rate': 0.3...   \n",
       "10                 50  {'colsample_bytree': 0.8, 'learning_rate': 0.3...   \n",
       "11                100  {'colsample_bytree': 0.8, 'learning_rate': 0.3...   \n",
       "12                 50  {'colsample_bytree': 0.8, 'learning_rate': 0.7...   \n",
       "13                100  {'colsample_bytree': 0.8, 'learning_rate': 0.7...   \n",
       "14                 50  {'colsample_bytree': 0.8, 'learning_rate': 0.7...   \n",
       "15                100  {'colsample_bytree': 0.8, 'learning_rate': 0.7...   \n",
       "\n",
       "    split0_test_score  split1_test_score  split2_test_score  \\\n",
       "0               0.800              0.856              0.800   \n",
       "1               0.792              0.888              0.792   \n",
       "2               0.800              0.864              0.784   \n",
       "3               0.784              0.848              0.808   \n",
       "4               0.792              0.848              0.792   \n",
       "5               0.768              0.848              0.784   \n",
       "6               0.792              0.848              0.784   \n",
       "7               0.800              0.832              0.776   \n",
       "8               0.808              0.888              0.776   \n",
       "9               0.808              0.872              0.784   \n",
       "10              0.808              0.856              0.776   \n",
       "11              0.800              0.816              0.752   \n",
       "12              0.792              0.864              0.768   \n",
       "13              0.792              0.840              0.760   \n",
       "14              0.816              0.808              0.784   \n",
       "15              0.792              0.800              0.768   \n",
       "\n",
       "    split3_test_score  split4_test_score  mean_test_score  std_test_score  \\\n",
       "0            0.798387           0.854839         0.821845        0.027422   \n",
       "1            0.814516           0.862903         0.829884        0.038921   \n",
       "2            0.814516           0.854839         0.823471        0.031034   \n",
       "3            0.814516           0.862903         0.823484        0.028404   \n",
       "4            0.814516           0.870968         0.823497        0.031364   \n",
       "5            0.846774           0.879032         0.825161        0.042077   \n",
       "6            0.830645           0.854839         0.821897        0.028890   \n",
       "7            0.846774           0.854839         0.821923        0.029638   \n",
       "8            0.814516           0.854839         0.828271        0.039002   \n",
       "9            0.814516           0.862903         0.828284        0.033680   \n",
       "10           0.814516           0.879032         0.826710        0.036512   \n",
       "11           0.814516           0.846774         0.805858        0.030942   \n",
       "12           0.806452           0.862903         0.818671        0.038573   \n",
       "13           0.806452           0.838710         0.807432        0.030093   \n",
       "14           0.822581           0.822581         0.810632        0.014357   \n",
       "15           0.838710           0.830645         0.805871        0.025897   \n",
       "\n",
       "    rank_test_score  \n",
       "0                11  \n",
       "1                 1  \n",
       "2                 8  \n",
       "3                 7  \n",
       "4                 6  \n",
       "5                 5  \n",
       "6                10  \n",
       "7                 9  \n",
       "8                 3  \n",
       "9                 2  \n",
       "10                4  \n",
       "11               16  \n",
       "12               12  \n",
       "13               14  \n",
       "14               13  \n",
       "15               15  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score is 0.8298838709677421 with params {'colsample_bytree': 0.3, 'learning_rate': 0.3, 'max_depth': 3, 'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "# Nested CV\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# create an estimator\n",
    "xgb_nested = XGBClassifier()\n",
    "\n",
    "# specify the parameter grid\n",
    "parameters = {\n",
    "    'learning_rate': [0.3, 0.7]\n",
    "    , 'max_depth': [3, 5]\n",
    "    , 'colsample_bytree': [0.3, 0.8]\n",
    "    , 'n_estimators': [50, 100]\n",
    "    #, 'gamma': [0.5, 1, 3]\n",
    "}\n",
    "\n",
    "# specify the cross validation\n",
    "#stratified_10_fold_cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "# create grid search instance\n",
    "xgb_nested_grid_search = GridSearchCV(xgb_nested, parameters, scoring='accuracy', cv=5)\n",
    "#cv=stratified_10_fold_cv\n",
    "\n",
    "xgb_nested_cv_score = cross_val_score(xgb_nested_grid_search, X_train, y_train, cv=5, scoring = 'accuracy') # kein Modell\n",
    "display(xgb_nested_cv_score.mean())\n",
    "\n",
    "# run the grid search\n",
    "xgb_nested_grid_search.fit(X_train, y_train)\n",
    "\n",
    "# print the results of all hyper-parameter combinations\n",
    "xgb_nested_grid_search_results = pd.DataFrame(xgb_nested_grid_search.cv_results_)\n",
    "display(xgb_nested_grid_search_results)\n",
    "\n",
    "# print the best parameter setting\n",
    "print(\"best score is {} with params {}\".format(xgb_nested_grid_search.best_score_, xgb_nested_grid_search.best_params_))\n",
    "#best score is 0.8298838709677421 with params {'colsample_bytree': 0.3, 'learning_rate': 0.3, 'max_depth': 3, 'n_estimators': 100}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cebef47d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
