{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mariusj/Documents/Edu/UMA/lectures/Data Mining/Project/dm1-titanic/.venv/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:455: UserWarning: Warm-start fitting without increasing n_estimators does not fit new trees.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------+---------------------------------------------------------------------------------+--------+----------+\n",
      "|          Name         |                                    Estimator                                    |   F1   | Accuracy |\n",
      "+-----------------------+---------------------------------------------------------------------------------+--------+----------+\n",
      "|   gradient_boosting   | GradientBoostingClassifier(learning_rate=0.3, max_depth=8, max_features='log2', | 0.7407 |  0.791   |\n",
      "|                       |                                     n_estimators=25, random_state=500)          |        |          |\n",
      "|   knearest_neighbor   | KNeighborsClassifier(algorithm='ball_tree', n_neighbors=10, weights='distance') | 0.7465 |  0.7948  |\n",
      "|      naive_bayes      |                                   GaussianNB()                                  | 0.7692 |  0.7985  |\n",
      "|     random_forest     |  RandomForestClassifier(bootstrap=False, max_features=None, min_samples_leaf=3, | 0.756  |  0.8097  |\n",
      "|                       |                           n_estimators=10, random_state=500, warm_start=True)   |        |          |\n",
      "| multilayer_perceptron |        MLPClassifier(hidden_layer_sizes=[11], learning_rate='invscaling',       | 0.7656 |  0.8172  |\n",
      "|                       |                                max_iter=1500, random_state=500)                 |        |          |\n",
      "|     support_vector    |           SVC(class_weight='balanced', gamma='auto', random_state=500)          | 0.7932 |  0.8172  |\n",
      "|        xgboost        |         XGBClassifier(base_score=0.5, booster='gbtree', callbacks=None,         | 0.7678 |  0.8172  |\n",
      "|                       |                 colsample_bylevel=1, colsample_bynode=1, colsample_bytree=0.6,  |        |          |\n",
      "|                       |                     early_stopping_rounds=None, enable_categorical=False,       |        |          |\n",
      "|                       |                  eval_metric=None, feature_types=None, gamma=0.5, gpu_id=-1,    |        |          |\n",
      "|                       |                         grow_policy='depthwise', importance_type=None,          |        |          |\n",
      "|                       |                  interaction_constraints='', learning_rate=0.01, max_bin=256,   |        |          |\n",
      "|                       |                  max_cat_threshold=64, max_cat_to_onehot=4, max_delta_step=0,   |        |          |\n",
      "|                       |                  max_depth=8, max_leaves=0, min_child_weight=1, missing=nan,    |        |          |\n",
      "|                       |                     monotone_constraints='()', n_estimators=25, n_jobs=0,       |        |          |\n",
      "|                       |                 num_parallel_tree=1, predictor='auto', random_state=500, ...)   |        |          |\n",
      "|  logistic_regression  |                       LogisticRegression(random_state=500)                      | 0.7818 |  0.8209  |\n",
      "|     decision_tree     |          DecisionTreeClassifier(criterion='log_loss', max_features=10,          | 0.7788 |  0.8284  |\n",
      "|                       |                             min_impurity_decrease=0.01, min_samples_leaf=9,     |        |          |\n",
      "|                       |                                 min_samples_split=15, random_state=500)         |        |          |\n",
      "+-----------------------+---------------------------------------------------------------------------------+--------+----------+\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import logging\n",
    "from gscv_configs import gscv_cfg_dt, gscv_cfg_gb, gscv_cfg_knn, gscv_cfg_mlp, gscv_cfg_rf, gscv_cfg_sv, gscv_cfg_xgb, gscv_cfg_nb, gscv_cfg_lr\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from utils import retrieve_latest_train_test\n",
    "from prettytable import PrettyTable\n",
    "import random\n",
    "import pandas as pd\n",
    "\n",
    "cfgs = [gscv_cfg_dt, gscv_cfg_gb, gscv_cfg_knn, gscv_cfg_mlp, gscv_cfg_rf, gscv_cfg_xgb, gscv_cfg_nb, gscv_cfg_lr, gscv_cfg_sv]\n",
    "\n",
    "train, test = retrieve_latest_train_test()#drop_col=[\"Age_true\", \"AgeGroup\", \"Embarked_S\", \"Title_Noble\"])\n",
    "\n",
    "# TRAIN\n",
    "X_train = train.drop([\"Survived\"], axis=1)\n",
    "y_train=train[\"Survived\"]\n",
    "\n",
    "# TEST\n",
    "X_test=test.drop([\"Survived\"], axis=1)\n",
    "y_test=test[\"Survived\"]\n",
    "\n",
    "output = PrettyTable()\n",
    "output.field_names = [\"Name\", \"Estimator\", \"F1\", \"Accuracy\"]\n",
    "for cfg in cfgs:\n",
    "    dir = f\"../gscv/{cfg.name}\"\n",
    "    files = sorted([f for f in os.listdir(dir) if (f.endswith(\".json\"))], reverse=True)\n",
    "    try:\n",
    "        file = files[0]\n",
    "        with open(f\"{dir}/{file}\") as f:\n",
    "            gscv = json.load(f)\n",
    "\n",
    "        random.seed(10)\n",
    "\n",
    "        estimator = cfg.estimator\n",
    "        param_grid = gscv['best_params_']\n",
    "\n",
    "        estimator.set_params(**param_grid)\n",
    "        estimator.random_state = 500\n",
    "        estimator.fit(X_train, y_train)\n",
    "\n",
    "        yhat = estimator.predict(X_test)\n",
    "\n",
    "        output.add_row([cfg.name, estimator, round(f1_score(yhat, y_test), 4), round(accuracy_score(yhat, y_test), 4)])\n",
    "\n",
    "        KAGGLE_TRAIN = pd.read_csv(f\"../data/preprocessed_20221117.csv\", index_col=0)\n",
    "        # KAGGLE_TRAIN = KAGGLE_TRAIN.drop([\"Age_true\", \"AgeGroup\", \"Embarked_S\", \"Title_Noble\"], axis=1)\n",
    "        KAGGLE_TEST_X = pd.read_csv(f\"../data/test_preprocessed_20221125.csv\", index_col=0)\n",
    "        # KAGGLE_TEST_X = KAGGLE_TEST_X.drop([\"Age_true\", \"AgeGroup\", \"Embarked_S\", \"Title_Noble\"], axis=1)\n",
    "        KAGLLE_TEST_INDEX = pd.read_csv(f\"../data/test.csv\", index_col=0).index\n",
    "\n",
    "        estimator.set_params(**param_grid)\n",
    "        estimator.fit(KAGGLE_TRAIN.drop([\"Survived\"], axis=1), KAGGLE_TRAIN[\"Survived\"])\n",
    "\n",
    "        yhat = estimator.predict(KAGGLE_TEST_X)\n",
    "\n",
    "        subm = pd.DataFrame(yhat, columns=[\"Survived\"], index=KAGLLE_TEST_INDEX)\n",
    "        subm.index.name=\"PassengerId\"\n",
    "\n",
    "        subm.to_csv(f\"../submission/{cfg.name}_submission.csv\")\n",
    "\n",
    "    except IndexError:\n",
    "        logging.warning(f\"There are no results for {cfg.name}\")\n",
    "\n",
    "output.sortby = 'Accuracy'\n",
    "print(output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.10 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1710d972e5371705a792993fb31d06207a980ac4b5639e60f5dec81b00e20006"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
